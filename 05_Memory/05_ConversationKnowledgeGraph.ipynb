{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8af94d6a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc91be71",
   "metadata": {},
   "source": [
    "* 출처: LangChain 공식 문서 또는 해당 교재명\n",
    "* 원본 URL: https://smith.langchain.com/hub/teddynote/summary-stuff-documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e325a8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60044868",
   "metadata": {},
   "source": [
    "## **`ConversationKGMemory`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2fc3081",
   "metadata": {},
   "source": [
    "* 대화 내용을 **`지식 그래프(ConversationKnowledgeGraphMemory)`** 라는 `복잡한 네트워크 형태`로 정리하여 저장하는 메모리\n",
    "\n",
    "<br>\n",
    "\n",
    "* **역할**: \n",
    "    * `대화 속 여러 정보들의 관계를 파악`하고 연결하여, `더 깊이 있는 대화를 가능`하게 함\n",
    "\n",
    "    * **`모델이 서로 다른 개체 간 관계를 이해하는 데 도움을 줌`**\n",
    "\n",
    "    * **`≒ 복잡한 인물 관계도를 그려놓은 메모`**\n",
    "\n",
    "<br>\n",
    "\n",
    "* **`LLM` 사용 → `엔티티에 대한 정보 추출` → 시간이 지남에 따라 `해당 엔티티에 대한 지식 축적`**\n",
    "\n",
    "    * **`복잡한 연결망과 역사적 맥락을 기반으로 대응하는 능력을 향상시킴`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81ca8725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 환경변수 처리 및 클라이언트 생성\n",
    "from langsmith import Client\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "# 클라이언트 생성 \n",
    "api_key = os.getenv(\"LANGSMITH_API_KEY\")\n",
    "client = Client(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5087a040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangSmith 추적 설정하기 (https:smith.langchin.com)\n",
    "# LangSmith 추적을 위한 라이브러리 임포트\n",
    "from langsmith import traceable                                                             # @traceable 데코레이터 사용 시\n",
    "\n",
    "# LangSmith 환경 변수 확인\n",
    "\n",
    "print(\"\\n--- LangSmith 환경 변수 확인 ---\")\n",
    "langchain_tracing_v2 = os.getenv('LANGCHAIN_TRACING_V2')\n",
    "langchain_project = os.getenv('LANGCHAIN_PROJECT')\n",
    "langchain_api_key_status = \"설정됨\" if os.getenv('LANGCHAIN_API_KEY') else \"설정되지 않음\"      # API 키 값은 직접 출력하지 않음\n",
    "org = \"설정됨\" if os.getenv('LANGCHAIN_ORGANIZATION') else \"설정되지 않음\"                      # 직접 출력하지 않음\n",
    "\n",
    "if langchain_tracing_v2 == \"true\" and os.getenv('LANGCHAIN_API_KEY') and langchain_project:\n",
    "    print(f\"✅ LangSmith 추적 활성화됨 (LANGCHAIN_TRACING_V2='{langchain_tracing_v2}')\")\n",
    "    print(f\"✅ LangSmith 프로젝트: '{langchain_project}'\")\n",
    "    print(f\"✅ LangSmith API Key: {langchain_api_key_status}\")\n",
    "    print(\"  -> 이제 LangSmith 대시보드에서 이 프로젝트를 확인해 보세요.\")\n",
    "else:\n",
    "    print(\"❌ LangSmith 추적이 완전히 활성화되지 않았습니다. 다음을 확인하세요:\")\n",
    "    if langchain_tracing_v2 != \"true\":\n",
    "        print(f\"  - LANGCHAIN_TRACING_V2가 'true'로 설정되어 있지 않습니다 (현재: '{langchain_tracing_v2}').\")\n",
    "    if not os.getenv('LANGCHAIN_API_KEY'):\n",
    "        print(\"  - LANGCHAIN_API_KEY가 설정되어 있지 않습니다.\")\n",
    "    if not langchain_project:\n",
    "        print(\"  - LANGCHAIN_PROJECT가 설정되어 있지 않습니다.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a80de88",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 셀 출력\n",
    "\n",
    "    ```markdown\n",
    "    --- LangSmith 환경 변수 확인 ---\n",
    "    ✅ LangSmith 추적 활성화됨 (LANGCHAIN_TRACING_V2='true')\n",
    "    ✅ LangSmith 프로젝트: 'LangChain-prantice'\n",
    "    ✅ LangSmith API Key: 설정됨\n",
    "    -> 이제 LangSmith 대시보드에서 이 프로젝트를 확인해 보세요.\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58747f06",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd58150",
   "metadata": {},
   "source": [
    "* 대화 지식그래프 메모리 모듈 추출을 위한 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1eb9c382",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationKGMemory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1788b1",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1623846",
   "metadata": {},
   "source": [
    "* **`LLM` 생성하기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3aa3ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "\n",
    "# .env 파일에서 환경변수 불러오기\n",
    "load_dotenv()\n",
    "\n",
    "# 환경변수에서 API 키 가져오기\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# OpenAI API 키 설정\n",
    "openai.api_key = api_key\n",
    "\n",
    "# OpenAI를 불러오기\n",
    "# ✅ 디버깅 함수: API 키가 잘 불러와졌는지 확인\n",
    "def debug_api_key():\n",
    "    if api_key is None:\n",
    "        print(\"❌ API 키를 불러오지 못했습니다. .env 파일과 변수명을 확인하세요.\")\n",
    "    elif api_key.startswith(\"sk-\") and len(api_key) > 20:\n",
    "        print(\"✅ API 키를 성공적으로 불러왔습니다.\")\n",
    "    else:\n",
    "        print(\"⚠️ API 키 형식이 올바르지 않은 것 같습니다. 값을 확인하세요.\")\n",
    "\n",
    "# 디버깅 함수 실행\n",
    "debug_api_key()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1dcd2e",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 셀 출력\n",
    "\n",
    "    ```markdown\n",
    "    ✅ API 키를 성공적으로 불러왔습니다.\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634a2043",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f64241",
   "metadata": {},
   "source": [
    "### **`Chain`에 메모리 활용하기**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26032c01",
   "metadata": {},
   "source": [
    "* **`ConversationChain`에 `ConversationKGMemory`를 메모리로 지정하여 대화를 나눈 후 `memory` 확인해보기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32663aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain.chains import ConversationChain\n",
    "\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "\n",
    "template = \"\"\"The following is a friendly conversation between a human and an AI. \n",
    "The AI is talkative and provides lots of specific details from its context. \n",
    "If the AI does not know the answer to a question, it truthfully says it does not know. \n",
    "The AI ONLY uses information contained in the \"Relevant Information\" section and does not hallucinate.\n",
    "\n",
    "Relevant Information:\n",
    "\n",
    "{history}\n",
    "\n",
    "Conversation:\n",
    "Human: {input}\n",
    "AI:\"\"\"\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"history\", \"input\"], template=template)\n",
    "\n",
    "conversation_with_kg = ConversationChain(\n",
    "    llm=llm, prompt=prompt, memory=ConversationKGMemory(llm=llm)\n",
    ")\n",
    "\n",
    "conversation_with_kg.predict(\n",
    "    input=\"My name is Teddy. Shirley is a coworker of mine, and she's a new designer at our company.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948498cd",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 셀 출력\n",
    "\n",
    "    ```markdown\n",
    "    /var/folders/h3/l7wnkv352kqftv0t8ctl2ld40000gn/T/ipykernel_39258/3115637315.py:28: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use :class:`~langchain_core.runnables.history.RunnableWithMessageHistory` instead.\n",
    "    conversation_with_kg = ConversationChain(\n",
    "    ```\n",
    "\n",
    "<br>\n",
    "\n",
    "* 셀 출력 내용\n",
    "\n",
    "  * **`ConversationChain` 클래스** **= `LangChain 0.2.7` 버전** 에서 **`deprecated(사용되지 않음)`** 경고가 나오는 클래스\n",
    "\n",
    "  * 이후 **`1.0`에서 제거될 예정 → 대신 `RunnableWithMessageHistory`를 사용하는 방식으로 업데이트 필요**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28d5ee8",
   "metadata": {},
   "source": [
    "### **`업데이트된 방식`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026bd3f3",
   "metadata": {},
   "source": [
    "#### **1) `ConversationKGMemory`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b558444d",
   "metadata": {},
   "source": [
    "* 지식 추출: 대화에서 엔티티와 관계를 자동 추출\n",
    "* 구조화: 지식을 그래프 형태로 저장\n",
    "* 질의: 특정 엔티티에 대한 정보를 빠르게 검색 가능\n",
    "* 한계: 단순한 체인 구조, 복잡한 워크플로우 처리 어려움"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffeb18bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 수동으로 메모리 관리하기\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from langchain.memory import ConversationKGMemory\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# LLM과 메모리 초기화\n",
    "# .env에서 API 키 로드\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# LLM 생성하기\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0,\n",
    "    openai_api_key=api_key,\n",
    "    model=\"gpt-4o-mini\",    \n",
    "    )\n",
    "\n",
    "memory = ConversationKGMemory(llm=llm)\n",
    "\n",
    "# 첫 번째 대화 저장\n",
    "memory.save_context(\n",
    "    {\"input\": \"My name is Teddy. Shirley is a coworker of mine, and she's a new designer at our company.\"},\n",
    "    {\"output\": \"Nice to meet you, Teddy! It's great to hear that Shirley is joining as a new designer. How are you finding working with her so far?\"}\n",
    ")\n",
    "\n",
    "# 메모리 내용 확인\n",
    "history = memory.load_memory_variables({\"input\": \"Who is Shirley?\"})\n",
    "print(history)\n",
    "\n",
    "# 지식 트리플 확인\n",
    "triplets = memory.get_knowledge_triplets(\"Shirley is a designer\")\n",
    "print(triplets)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0658b6cb",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 셀 출력 (4.2s)\n",
    "\n",
    "    ```python\n",
    "    {'history': 'On Shirley: Shirley is a coworker. Shirley is a new designer. Shirley works at the company.'}\n",
    "    [KnowledgeTriple(subject='Shirley', predicate='is a', object_='designer')]\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beeea37f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89fdeb33",
   "metadata": {},
   "source": [
    "#### **2) `LangGraph`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797c8f16",
   "metadata": {},
   "source": [
    "* 상태 관리: 대화 전체를 상태로 관리하여 더 유연\n",
    "* 워크플로우: 복잡한 대화 흐름 제어 가능\n",
    "* 확장성: 여러 노드와 조건부 분기 지원\n",
    "* 현대적: LangChain의 **`최신 아키텍처`** 반영"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5210775c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최신 LangGraph 방식\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import uuid\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import START, MessagesState, StateGraph\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# LLM과 메모리 초기화\n",
    "# .env에서 API 키 로드\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# LangGraph를 사용한 현대적 접근\n",
    "def create_conversation_graph():\n",
    "    # LLM 생성하기\n",
    "    llm = ChatOpenAI(\n",
    "        temperature=0,\n",
    "        openai_api_key=api_key,\n",
    "        model=\"gpt-4o-mini\",    \n",
    "        )\n",
    "\n",
    "    \n",
    "    def call_model(state: MessagesState):\n",
    "        response = llm.invoke(state[\"messages\"])\n",
    "        return {\"messages\": response}\n",
    "    \n",
    "    # 그래프 생성\n",
    "    workflow = StateGraph(state_schema=MessagesState)\n",
    "    workflow.add_edge(START, \"model\")\n",
    "    workflow.add_node(\"model\", call_model)\n",
    "    \n",
    "    # 메모리 설정\n",
    "    memory = MemorySaver()\n",
    "    app = workflow.compile(checkpointer=memory)\n",
    "    \n",
    "    return app\n",
    "\n",
    "# 사용 예시\n",
    "app = create_conversation_graph()\n",
    "thread_id = str(uuid.uuid4())\n",
    "config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "\n",
    "# 대화 실행\n",
    "input_message = HumanMessage(\n",
    "    content=\"My name is Teddy. Shirley is a coworker of mine, and she's a new designer at our company.\"\n",
    ")\n",
    "\n",
    "for event in app.stream({\"messages\": [input_message]}, config, stream_mode=\"values\"):\n",
    "    event[\"messages\"][-1].pretty_print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26ac6d4",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 셀 출력 (1.5s)\n",
    "\n",
    "    ```markdown\n",
    "    ================================ **Human Message** =================================\n",
    "\n",
    "    My name is Teddy. Shirley is a coworker of mine, and she's a new designer at our company.\n",
    "    ================================== **Ai Message** ==================================\n",
    "\n",
    "    Hi Teddy! It's great to hear about your coworker Shirley joining the team as a new designer. How's she settling in? Have you had a chance to collaborate with her on any projects yet?\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232f3e9a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9276f33b",
   "metadata": {},
   "source": [
    "* *next: 대화 요약 메모리(ConversationSummaryMemory)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84e973c",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lc_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
