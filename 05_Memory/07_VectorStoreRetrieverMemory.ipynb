{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8af94d6a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc91be71",
   "metadata": {},
   "source": [
    "* ì¶œì²˜: LangChain ê³µì‹ ë¬¸ì„œ ë˜ëŠ” í•´ë‹¹ êµì¬ëª…\n",
    "* ì›ë³¸ URL: https://smith.langchain.com/hub/teddynote/summary-stuff-documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e325a8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60044868",
   "metadata": {},
   "source": [
    "## **`VectorStoreRetrieverMemory`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2fc3081",
   "metadata": {},
   "source": [
    "* ëŒ€í™” ë‚´ìš©ì„ `ë²¡í„°(ìˆ«ì ë°°ì—´)ë¡œ ë³€í™˜`í•˜ì—¬ ì €ì¥í•˜ê³ , **í•„ìš”í•  ë•Œ `ê²€ìƒ‰`í•´ì„œ ë¶ˆëŸ¬ì˜¤ëŠ” ë©”ëª¨ë¦¬**\n",
    "  \n",
    "* ì¦‰, `ë²¡í„° ìŠ¤í† ì–´`ì— ë©”ëª¨ë¦¬ ì €ì¥ â†’ í˜¸ì¶œë  ë•Œë§ˆë‹¤ ê°€ì¥ **`ëˆˆì— ë„ëŠ” ìƒìœ„ Kê°œì˜ ë¬¸ì„œ`ë¥¼ ì¿¼ë¦¬** \n",
    "\n",
    "<br>\n",
    "\n",
    "* **ë‹¤ë¥¸ ë©”ëª¨ë¦¬ í´ë˜ìŠ¤ì™€ì˜ `ì°¨ì´ì `**: ëŒ€í™” ë‚´ìš©ì˜ **`ìˆœì„œë¥¼ ëª…ì‹œì ìœ¼ë¡œ ì¶”ì í•˜ì§€ ì•ŠëŠ”ë‹¤ëŠ” ì `** \n",
    "\n",
    "<br>\n",
    "\n",
    "* **ì—­í• **: \n",
    "\n",
    "    * `ë§¤ìš° ë°©ëŒ€í•œ ì–‘ì˜ ì •ë³´ë¥¼ ì €ì¥`í•˜ê³ , ì‚¬ìš©ìê°€ ì§ˆë¬¸í•˜ëŠ” ë‚´ìš©ê³¼ **`ê°€ì¥ ìœ ì‚¬í•œ ì •ë³´ë¥¼ ì°¾ì•„ëƒ„`**\n",
    "\n",
    "    * **`â‰’ ì›í•˜ëŠ” ì •ë³´ë¥¼ ê²€ìƒ‰ì°½ì— ì…ë ¥í•˜ë©´ ìˆ˜ë§ì€ ìë£Œ ì¤‘ì—ì„œ ì°¾ì•„ì£¼ëŠ” ë„ì„œê´€ ê²€ìƒ‰ ì‹œìŠ¤í…œ`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81ca8725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í™˜ê²½ë³€ìˆ˜ ì²˜ë¦¬ ë° í´ë¼ì´ì–¸íŠ¸ ìƒì„±\n",
    "from langsmith import Client\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "# í´ë¼ì´ì–¸íŠ¸ ìƒì„± \n",
    "api_key = os.getenv(\"LANGSMITH_API_KEY\")\n",
    "client = Client(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5087a040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangSmith ì¶”ì  ì„¤ì •í•˜ê¸° (https:smith.langchin.com)\n",
    "# LangSmith ì¶”ì ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
    "from langsmith import traceable                                                             # @traceable ë°ì½”ë ˆì´í„° ì‚¬ìš© ì‹œ\n",
    "\n",
    "# LangSmith í™˜ê²½ ë³€ìˆ˜ í™•ì¸\n",
    "\n",
    "print(\"\\n--- LangSmith í™˜ê²½ ë³€ìˆ˜ í™•ì¸ ---\")\n",
    "langchain_tracing_v2 = os.getenv('LANGCHAIN_TRACING_V2')\n",
    "langchain_project = os.getenv('LANGCHAIN_PROJECT')\n",
    "langchain_api_key_status = \"ì„¤ì •ë¨\" if os.getenv('LANGCHAIN_API_KEY') else \"ì„¤ì •ë˜ì§€ ì•ŠìŒ\"      # API í‚¤ ê°’ì€ ì§ì ‘ ì¶œë ¥í•˜ì§€ ì•ŠìŒ\n",
    "org = \"ì„¤ì •ë¨\" if os.getenv('LANGCHAIN_ORGANIZATION') else \"ì„¤ì •ë˜ì§€ ì•ŠìŒ\"                      # ì§ì ‘ ì¶œë ¥í•˜ì§€ ì•ŠìŒ\n",
    "\n",
    "if langchain_tracing_v2 == \"true\" and os.getenv('LANGCHAIN_API_KEY') and langchain_project:\n",
    "    print(f\"âœ… LangSmith ì¶”ì  í™œì„±í™”ë¨ (LANGCHAIN_TRACING_V2='{langchain_tracing_v2}')\")\n",
    "    print(f\"âœ… LangSmith í”„ë¡œì íŠ¸: '{langchain_project}'\")\n",
    "    print(f\"âœ… LangSmith API Key: {langchain_api_key_status}\")\n",
    "    print(\"  -> ì´ì œ LangSmith ëŒ€ì‹œë³´ë“œì—ì„œ ì´ í”„ë¡œì íŠ¸ë¥¼ í™•ì¸í•´ ë³´ì„¸ìš”.\")\n",
    "else:\n",
    "    print(\"âŒ LangSmith ì¶”ì ì´ ì™„ì „íˆ í™œì„±í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë‹¤ìŒì„ í™•ì¸í•˜ì„¸ìš”:\")\n",
    "    if langchain_tracing_v2 != \"true\":\n",
    "        print(f\"  - LANGCHAIN_TRACING_V2ê°€ 'true'ë¡œ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤ (í˜„ì¬: '{langchain_tracing_v2}').\")\n",
    "    if not os.getenv('LANGCHAIN_API_KEY'):\n",
    "        print(\"  - LANGCHAIN_API_KEYê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.\")\n",
    "    if not langchain_project:\n",
    "        print(\"  - LANGCHAIN_PROJECTê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a80de88",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* ì…€ ì¶œë ¥\n",
    "\n",
    "    ```markdown\n",
    "    --- LangSmith í™˜ê²½ ë³€ìˆ˜ í™•ì¸ ---\n",
    "    âœ… LangSmith ì¶”ì  í™œì„±í™”ë¨ (LANGCHAIN_TRACING_V2='true')\n",
    "    âœ… LangSmith í”„ë¡œì íŠ¸: 'LangChain-prantice'\n",
    "    âœ… LangSmith API Key: ì„¤ì •ë¨\n",
    "    -> ì´ì œ LangSmith ëŒ€ì‹œë³´ë“œì—ì„œ ì´ í”„ë¡œì íŠ¸ë¥¼ í™•ì¸í•´ ë³´ì„¸ìš”.\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b7596d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "\n",
    "# .env íŒŒì¼ì—ì„œ í™˜ê²½ë³€ìˆ˜ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "load_dotenv()\n",
    "\n",
    "# í™˜ê²½ë³€ìˆ˜ì—ì„œ API í‚¤ ê°€ì ¸ì˜¤ê¸°\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# OpenAI API í‚¤ ì„¤ì •\n",
    "openai.api_key = api_key\n",
    "\n",
    "# OpenAIë¥¼ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "# âœ… ë””ë²„ê¹… í•¨ìˆ˜: API í‚¤ê°€ ì˜ ë¶ˆëŸ¬ì™€ì¡ŒëŠ”ì§€ í™•ì¸\n",
    "def debug_api_key():\n",
    "    if api_key is None:\n",
    "        print(\"âŒ API í‚¤ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. .env íŒŒì¼ê³¼ ë³€ìˆ˜ëª…ì„ í™•ì¸í•˜ì„¸ìš”.\")\n",
    "    elif api_key.startswith(\"sk-\") and len(api_key) > 20:\n",
    "        print(\"âœ… API í‚¤ë¥¼ ì„±ê³µì ìœ¼ë¡œ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.\")\n",
    "    else:\n",
    "        print(\"âš ï¸ API í‚¤ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•Šì€ ê²ƒ ê°™ìŠµë‹ˆë‹¤. ê°’ì„ í™•ì¸í•˜ì„¸ìš”.\")\n",
    "\n",
    "# ë””ë²„ê¹… í•¨ìˆ˜ ì‹¤í–‰\n",
    "debug_api_key()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129b5eb3",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* ì…€ ì¶œë ¥\n",
    "\n",
    "    ```markdown\n",
    "    âœ… API í‚¤ë¥¼ ì„±ê³µì ìœ¼ë¡œ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d224852",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# .env íŒŒì¼ì—ì„œ í™˜ê²½ë³€ìˆ˜ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "load_dotenv()\n",
    "\n",
    "# í™˜ê²½ë³€ìˆ˜ì—ì„œ API í‚¤ ê°€ì ¸ì˜¤ê¸°\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# OpenAI API í‚¤ ì„¤ì •\n",
    "openai.api_key = api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58747f06",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd58150",
   "metadata": {},
   "source": [
    "* ë²¡í„° ìŠ¤í† ì–´ ì´ˆê¸°í™”í•˜ê¸°"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cfab2a0",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* ì‚¬ì „ í„°ë¯¸ë„ì— ì„¤ì¹˜ í•„ìš”í•œ ë²¡í„°ìŠ¤í† ì–´ ê´€ë ¨ ë‚´ìš©\n",
    "\n",
    "  * CPU ver.\n",
    "\n",
    "  ```bash\n",
    "\n",
    "    pip install faiss-cpu\n",
    "  ```\n",
    "\n",
    "<br>\n",
    "\n",
    "* \n",
    "  * GPU ver.\n",
    "  ```bash\n",
    "\n",
    "    pip install faiss-gpu\n",
    "  ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb9c382",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss                                                # Meta AI Researchì—ì„œ ê°œë°œí•œ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.docstore import InMemoryDocstore\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "\n",
    "# ì„ë² ë”© ëª¨ë¸ ì •ì˜í•˜ê¸°\n",
    "embeddings_model = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-small\",                         # ì‹¤ì œ ì„ë² ë”© ëª¨ë¸ëª… ë„£ê¸°\n",
    "    api_key=api_key                                         # ì„ë² ë”© ëª¨ë¸ìš© api_keyë¥¼ í™˜ê²½ë³€ìˆ˜ ì²˜ë¦¬ í›„ ë„£ê¸°\n",
    ")\n",
    "\n",
    "# Vector Store ì´ˆê¸°í™”í•˜ê¸°\n",
    "embedding_size = 1536\n",
    "index = faiss.IndexFlatL2(embedding_size)\n",
    "vectorstore = FAISS(                                        # FAISS í˜•íƒœ ìµœì‹  ì½”ë“œ í˜•íƒœë¡œ ë°”ê¿”ì„œ ì¨ì•¼ ì˜¤ë¥˜ ìƒê¸°ì§€ ì•ŠìŒ\n",
    "    embedding_function=embeddings_model, \n",
    "    index=index, \n",
    "    docstore=InMemoryDocstore({}), \n",
    "    index_to_docstore_id={})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1788b1",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1623846",
   "metadata": {},
   "source": [
    "* **`K = 1`**\n",
    "\n",
    "  * ì‹¤ì œ ì‚¬ìš©ì—ì„œëŠ” `k`ë¥¼ ë” ë†’ì€ ê°’ìœ¼ë¡œ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3c22116a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import VectorStoreRetrieverMemory\n",
    "\n",
    "# ë²¡í„° ì¡°íšŒê°€ ì—¬ì „íˆ ì˜ë¯¸ì ìœ¼ë¡œ ê´€ë ¨ì„± ìˆëŠ” ì •ë³´ë¥¼ ë°˜í™˜í•œë‹¤ëŠ” ê²ƒì„ ë³´ì—¬ì£¼ê¸° ìœ„í•´ì„œ ì„¤ì •í•¨\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 1})\n",
    "memory = VectorStoreRetrieverMemory(retriever=retriever)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf298b3",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* ì…€ ì¶œë ¥\n",
    "\n",
    "    ```python\n",
    "    /var/folders/h3/l7wnkv352kqftv0t8ctl2ld40000gn/T/ipykernel_15381/1689916482.py:5: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
    "    memory = VectorStoreRetrieverMemory(retriever=retriever)\n",
    "    ```\n",
    "\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "<br>\n",
    "\n",
    "* ì…€ ì¶œë ¥ í•´ì„\n",
    "\n",
    "  * ê²½ê³  ë©”ì‹œì§€\n",
    "    ```markdown\n",
    "\n",
    "        LangChainDeprecationWarning: Please see the migration guide...\n",
    "    \n",
    "    ```\n",
    "    * `DeprecationWarning` = **`ì´ ê¸°ëŠ¥ì€ ê³§ ì—†ì–´ì§ˆ ì˜ˆì •ì´ë‹ˆ, ìƒˆ ë°©ë²•ì„ ì“°ì„¸ìš”`** ë¼ëŠ” ì˜ë¯¸\n",
    "  \n",
    "    * `VectorStoreRetrieverMemory`ë¼ëŠ” ê¸°ëŠ¥ì´ `ì•ìœ¼ë¡œ ì‚¬ë¼ì§ˆ ì˜ˆì •`ì´ë¼, ì§€ê¸ˆì€ ì“¸ ìˆ˜ ìˆì§€ë§Œ `ë¯¸ë˜ ë²„ì „ì—ì„œëŠ” ì—†ì–´ì§ˆ ìˆ˜ ìˆë‹¤`ëŠ” ì˜ë¯¸\n",
    "  \n",
    "    * `LangChain`ì˜ ìƒˆë¡œìš´ [ê°€ì´ë“œ ì‚¬ì´ë“œ](https://python.langchain.com/docs/versions/migrating_memory/) ì•ˆë‚´\n",
    "\n",
    "---\n",
    "\n",
    "<br>\n",
    "\n",
    "  * í•´ë‹¹ ê¸°ëŠ¥ì´ ì‚¬ë¼ì§€ëŠ” ì´ìœ \n",
    "\n",
    "    * `LangChain`ì˜ ë²„ì „ì´ ì˜¬ë¼ê°€ë©´ì„œ **`ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œ êµ¬ì¡°ë¥¼ ìƒˆë¡­ê²Œ í†µí•© ì¤‘`**\n",
    "\n",
    "    * ì´ì „ ë°©ì‹(`VectorStoreRetrieverMemory`): `ìœ ì§€â€¢ê´€ë¦¬ ì–´ë ¤ì›€` + `ìƒˆë¡œìš´ ê¸°ëŠ¥ë“¤ê³¼ì˜ í˜¸í™˜ì„±ì´ ë–¨ì–´ì§`\n",
    "\n",
    "    * **`ë” ìœ ì—°í•˜ê³  í‘œì¤€í™”ëœ ë©”ëª¨ë¦¬ êµ¬ì¡°ë¡œ êµì²´í•˜ëŠ” ì¤‘`**\n",
    "\n",
    "---\n",
    "\n",
    "<br>\n",
    "\n",
    "  * ìµœì‹  ì½”ë“œì—ì„œ ì“°ëŠ” ë°©ë²•\n",
    "    * ê¶Œì¥_1: `RunnableWithMessageHistory` + `VectorStoreRetriever` ì¡°í•©\n",
    "    * ê¶Œì¥_1ì˜ ì˜ˆì‹œ\n",
    "    ```python\n",
    "    # í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
    "      from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "      from langchain_community.vectorstores import FAISS\n",
    "      from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "      from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "      from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "      from langchain_core.chat_history import BaseChatMessageHistory\n",
    "\n",
    "      # 1. ë²¡í„°ìŠ¤í† ì–´ + ë¦¬íŠ¸ë¦¬ë²„ ì¤€ë¹„\n",
    "      embeddings = OpenAIEmbeddings()\n",
    "      # ì˜ˆì‹œ ë¬¸ì„œ\n",
    "      docs = [\n",
    "          {\"page_content\": \"Python is a programming language.\"},\n",
    "          {\"page_content\": \"LangChain helps build LLM-powered applications.\"},\n",
    "          {\"page_content\": \"FAISS is a vector database for similarity search.\"}\n",
    "      ]\n",
    "      vectorstore = FAISS.from_documents(docs, embedding=embeddings)\n",
    "      retriever = vectorstore.as_retriever()\n",
    "\n",
    "      # 2. í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ (ëŒ€í™” ê¸°ë¡ í¬í•¨)\n",
    "      prompt = ChatPromptTemplate.from_messages([\n",
    "          (\"system\", \"ë‹¹ì‹ ì€ ì¹œì ˆí•œ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ì§ˆë¬¸ì— ë‹µí•˜ì„¸ìš”.\"),\n",
    "          MessagesPlaceholder(variable_name=\"history\"),  # ëŒ€í™” ê¸°ë¡ ìë¦¬\n",
    "          (\"human\", \"{input}\"),\n",
    "      ])\n",
    "\n",
    "      # 3. LLM ëª¨ë¸\n",
    "      llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "      # 4. ë¦¬íŠ¸ë¦¬ë²„ì™€ LLMì„ ì—°ê²°í•˜ëŠ” Runnable\n",
    "      #    (ê²€ìƒ‰ ê²°ê³¼ë¥¼ contextë¡œ ë„£ì–´ì£¼ëŠ” ê°„ë‹¨í•œ ì²´ì¸)\n",
    "      def retrieval_chain(inputs):\n",
    "          query = inputs[\"input\"]\n",
    "          docs = retriever.get_relevant_documents(query)\n",
    "          context = \"\\n\".join([d.page_content for d in docs])\n",
    "          return prompt.format_messages(history=inputs[\"history\"], input=f\"{query}\\n\\nì°¸ê³ ìë£Œ:\\n{context}\")\n",
    "\n",
    "      # 5. ì„¸ì…˜ë³„ ëŒ€í™” ê¸°ë¡ ì €ì¥ì†Œ\n",
    "      store = {}\n",
    "      def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "          if session_id not in store:\n",
    "              store[session_id] = ChatMessageHistory()\n",
    "          return store[session_id]\n",
    "\n",
    "      # 6. RunnableWithMessageHistoryë¡œ ê°ì‹¸ê¸°\n",
    "      with_history = RunnableWithMessageHistory(\n",
    "          runnable = retrieval_chain | llm,\n",
    "          get_session_history = get_session_history,\n",
    "          input_messages_key = \"input\",       # ì‚¬ìš©ì ì…ë ¥ í‚¤\n",
    "          history_messages_key = \"history\"    # ëŒ€í™” ê¸°ë¡ í‚¤\n",
    "      )\n",
    "\n",
    "      # 7. ì‹¤í–‰ ì˜ˆì‹œ\n",
    "      session_id = \"user-123\"\n",
    "\n",
    "      response1 = with_history.invoke(\n",
    "          {\"input\": \"LangChainì´ ë­ì•¼?\"},\n",
    "          config={\"configurable\": {\"session_id\": session_id}}\n",
    "      )\n",
    "      print(response1)\n",
    "\n",
    "      response2 = with_history.invoke(\n",
    "          {\"input\": \"FAISSì— ëŒ€í•´ì„œë„ ì•Œë ¤ì¤˜\"},\n",
    "          config={\"configurable\": {\"session_id\": session_id}}\n",
    "      )\n",
    "      print(response2)\n",
    "    ```\n",
    "\n",
    "---\n",
    "\n",
    "<br>\n",
    "\n",
    "* \n",
    "    * ê¶Œì¥_2: `ConversationBufferMemory` ë˜ëŠ” `ConversationBufferWindowMemory` ê°™ì€ ìƒˆ ë©”ëª¨ë¦¬ í´ë˜ìŠ¤ë¥¼ ì“°ëŠ” ê±¸ ê¶Œì¥\n",
    "    * ê¶Œì¥_2ì˜ ì˜ˆì‹œ\n",
    "    ```python\n",
    "      from langchain.memory import ConversationBufferMemory\n",
    "      from langchain.chains import ConversationChain\n",
    "      from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "      memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "      llm = ChatOpenAI()\n",
    "      conversation = ConversationChain(llm=llm, memory=memory)\n",
    "\n",
    "      conversation.predict(input=\"ì•ˆë…•!\")\n",
    "    ```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecec572e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì„ì˜ì˜ ëŒ€í™” ì €ì¥í•´ë³´ê¸°\n",
    "\n",
    "memory.save_context(\n",
    "    inputs={\n",
    "        \"human\": \"ì•ˆë…•í•˜ì„¸ìš”, ì˜¤ëŠ˜ ë©´ì ‘ì— ì°¸ì„í•´ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤. ìê¸°ì†Œê°œ ë¶€íƒë“œë¦½ë‹ˆë‹¤.\"\n",
    "    },\n",
    "    outputs={\n",
    "        \"ai\": \"ì•ˆë…•í•˜ì„¸ìš”. ì €ëŠ” ì»´í“¨í„° ê³¼í•™ì„ ì „ê³µí•œ ì‹ ì… ê°œë°œìì…ë‹ˆë‹¤. ëŒ€í•™ì—ì„œëŠ” ì£¼ë¡œ ìë°”ì™€ íŒŒì´ì¬ì„ ì‚¬ìš©í–ˆìœ¼ë©°, ìµœê·¼ì—ëŠ” ì›¹ ê°œë°œ í”„ë¡œì íŠ¸ì— ì°¸ì—¬í•˜ì—¬ ì‹¤ì œ ì‚¬ìš©ìë¥¼ ìœ„í•œ ì„œë¹„ìŠ¤ë¥¼ ê°œë°œí•˜ëŠ” ê²½í—˜ì„ í–ˆìŠµë‹ˆë‹¤.\"\n",
    "    },\n",
    ")\n",
    "memory.save_context(\n",
    "    inputs={\"human\": \"í”„ë¡œì íŠ¸ì—ì„œ ì–´ë–¤ ì—­í• ì„ ë§¡ì•˜ë‚˜ìš”?\"},\n",
    "    outputs={\n",
    "        \"ai\": \"ì œê°€ ë§¡ì€ ì—­í• ì€ ë°±ì—”ë“œ ê°œë°œìì˜€ìŠµë‹ˆë‹¤. ì‚¬ìš©ì ë°ì´í„° ì²˜ë¦¬ì™€ ì„œë²„ ë¡œì§ ê°œë°œì„ ë‹´ë‹¹í–ˆìœ¼ë©°, RESTful APIë¥¼ êµ¬í˜„í•˜ì—¬ í”„ë¡ íŠ¸ì—”ë“œì™€ì˜ í†µì‹ ì„ ë‹´ë‹¹í–ˆìŠµë‹ˆë‹¤. ë˜í•œ, ë°ì´í„°ë² ì´ìŠ¤ ì„¤ê³„ì—ë„ ì°¸ì—¬í–ˆìŠµë‹ˆë‹¤.\"\n",
    "    },\n",
    ")\n",
    "memory.save_context(\n",
    "    inputs={\n",
    "        \"human\": \"íŒ€ í”„ë¡œì íŠ¸ì—ì„œ ì–´ë ¤ì›€ì„ ê²ªì—ˆë˜ ê²½í—˜ì´ ìˆë‹¤ë©´ ì–´ë–»ê²Œ í•´ê²°í–ˆë‚˜ìš”?\"\n",
    "    },\n",
    "    outputs={\n",
    "        \"ai\": \"í”„ë¡œì íŠ¸ ì´ˆê¸°ì— ì˜ì‚¬ì†Œí†µ ë¬¸ì œë¡œ ëª‡ ê°€ì§€ ì–´ë ¤ì›€ì´ ìˆì—ˆìŠµë‹ˆë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ì €í¬ íŒ€ì€ ì •ê¸°ì ì¸ ë¯¸íŒ…ì„ ê°–ê³  ê°ìì˜ ì§„í–‰ ìƒí™©ì„ ê³µìœ í–ˆìŠµë‹ˆë‹¤. ë˜í•œ, ë¬¸ì œê°€ ë°œìƒí–ˆì„ ë•ŒëŠ” ì ê·¹ì ìœ¼ë¡œ ì˜ê²¬ì„ ë‚˜ëˆ„ê³ , í•©ë¦¬ì ì¸ í•´ê²°ì±…ì„ ì°¾ê¸° ìœ„í•´ ë…¸ë ¥í–ˆìŠµë‹ˆë‹¤.\"\n",
    "    },\n",
    ")\n",
    "memory.save_context(\n",
    "    inputs={\"human\": \"ê°œë°œìë¡œì„œ ìì‹ ì˜ ê°•ì ì€ ë¬´ì—‡ì´ë¼ê³  ìƒê°í•˜ë‚˜ìš”?\"},\n",
    "    outputs={\n",
    "        \"ai\": \"ì œ ê°•ì ì€ ë¹ ë¥¸ í•™ìŠµ ëŠ¥ë ¥ê³¼ ë¬¸ì œ í•´ê²° ëŠ¥ë ¥ì…ë‹ˆë‹¤. ìƒˆë¡œìš´ ê¸°ìˆ ì´ë‚˜ ë„êµ¬ë¥¼ ë¹ ë¥´ê²Œ ìŠµë“í•  ìˆ˜ ìˆìœ¼ë©°, ë³µì¡í•œ ë¬¸ì œì— ì§ë©´í–ˆì„ ë•Œ ì°½ì˜ì ì¸ í•´ê²°ì±…ì„ ì œì‹œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ, íŒ€ì›Œí¬ë¥¼ ì¤‘ì‹œí•˜ë©° ë™ë£Œë“¤ê³¼ í˜‘ë ¥í•˜ëŠ” ê²ƒì„ ì¤‘ìš”í•˜ê²Œ ìƒê°í•©ë‹ˆë‹¤.\"\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6019409d",
   "metadata": {},
   "source": [
    "* ë‹¤ìŒì˜ ì§ˆë¬¸ì„ í–ˆì„ ë•Œ Vector Store ë¡œ ë¶€í„° 1ê°œ(k=1 ì´ê¸° ë•Œë¬¸)ì˜ ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ ëŒ€í™”ë¥¼ ë°˜í™˜\n",
    "\n",
    "    ```markdown\n",
    "    ì§ˆë¬¸: **\"ë©´ì ‘ì ì „ê³µì€ ë¬´ì—‡ì¸ê°€ìš”?\"**\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a0c9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë©”ëª¨ë¦¬ì— ì§ˆë¬¸ì„ í†µí•´ ê°€ì¥ ì—°ê´€ì„± ë†’ì€ 1ê°œ ëŒ€í™”ë¥¼ ì¶”ì¶œ\n",
    "\n",
    "print(memory.load_memory_variables({\"prompt\": \"ë©´ì ‘ì ì „ê³µì€ ë¬´ì—‡ì¸ê°€ìš”?\"})[\"history\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13bbe48f",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* ì…€ ì¶œë ¥\n",
    "\n",
    "    ```markdown\n",
    "    human: ì•ˆë…•í•˜ì„¸ìš”, ì˜¤ëŠ˜ ë©´ì ‘ì— ì°¸ì„í•´ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤. ìê¸°ì†Œê°œ ë¶€íƒë“œë¦½ë‹ˆë‹¤.\n",
    "    ai: ì•ˆë…•í•˜ì„¸ìš”. ì €ëŠ” ì»´í“¨í„° ê³¼í•™ì„ ì „ê³µí•œ ì‹ ì… ê°œë°œìì…ë‹ˆë‹¤. ëŒ€í•™ì—ì„œëŠ” ì£¼ë¡œ ìë°”ì™€ íŒŒì´ì¬ì„ ì‚¬ìš©í–ˆìœ¼ë©°, ìµœê·¼ì—ëŠ” ì›¹ ê°œë°œ í”„ë¡œì íŠ¸ì— ì°¸ì—¬í•˜ì—¬ ì‹¤ì œ ì‚¬ìš©ìë¥¼ ìœ„í•œ ì„œë¹„ìŠ¤ë¥¼ ê°œë°œí•˜ëŠ” ê²½í—˜ì„ í–ˆìŠµë‹ˆë‹¤.\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a457a85",
   "metadata": {},
   "source": [
    "* ì´ë²ˆì—ëŠ” ë‹¤ë¥¸ ì§ˆë¬¸ì„ í†µí•´ ê°€ì¥ ì—°ê´€ì„± ë†’ì€ 1ê°œ ëŒ€í™”ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.\n",
    "\n",
    "    ```markdown\n",
    "    ì§ˆë¬¸: **\"ë©´ì ‘ìê°€ í”„ë¡œì íŠ¸ì—ì„œ ë§¡ì€ ì—­í• ì€ ë¬´ì—‡ì¸ê°€ìš”?\"**\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef002c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    memory.load_memory_variables(\n",
    "        {\"human\": \"ë©´ì ‘ìê°€ í”„ë¡œì íŠ¸ì—ì„œ ë§¡ì€ ì—­í• ì€ ë¬´ì—‡ì¸ê°€ìš”?\"}\n",
    "    )[\"history\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc24202",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* ì…€ ì¶œë ¥\n",
    "\n",
    "    ```markdown\n",
    "    human: í”„ë¡œì íŠ¸ì—ì„œ ì–´ë–¤ ì—­í• ì„ ë§¡ì•˜ë‚˜ìš”?\n",
    "    ai: ì œê°€ ë§¡ì€ ì—­í• ì€ ë°±ì—”ë“œ ê°œë°œìì˜€ìŠµë‹ˆë‹¤. ì‚¬ìš©ì ë°ì´í„° ì²˜ë¦¬ì™€ ì„œë²„ ë¡œì§ ê°œë°œì„ ë‹´ë‹¹í–ˆìœ¼ë©°, RESTful APIë¥¼ êµ¬í˜„í•˜ì—¬ í”„ë¡ íŠ¸ì—”ë“œì™€ì˜ í†µì‹ ì„ ë‹´ë‹¹í–ˆìŠµë‹ˆë‹¤. ë˜í•œ, ë°ì´í„°ë² ì´ìŠ¤ ì„¤ê³„ì—ë„ ì°¸ì—¬í–ˆìŠµë‹ˆë‹¤.\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b463071",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7475faca",
   "metadata": {},
   "source": [
    "### **`ì—…ë°ì´íŠ¸ëœ ë°©ì‹`** ì‹œë„"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c0d2f7",
   "metadata": {},
   "source": [
    "* êµì¬ ì½”ë“œ ì˜¤ë¥˜ ë°œìƒ\n",
    "  \n",
    "  * ì›ì¸_1: ì„ë² ë”© ëª¨ë¸ ì œëŒ€ë¡œ ìƒì„± X\n",
    "\n",
    "    * `OpenAIEmbeddings()` ì´ˆê¸°í™” ì‹œ **`í•„ìˆ˜ ì¸ì ëˆ„ë½`**\n",
    "      * `langchain_openai.OpenAIEmbeddings`ëŠ” ê¸°ë³¸ê°’ ì—†ìŒ â†’ `model`ê³¼ `API í‚¤`ë¥¼ ì§€ì •í•´ì•¼ í•¨\n",
    "      * `gpt-4o-mini` = í…ìŠ¤íŠ¸ ìƒì„± ëª¨ë¸ â†’ ë²¡í„°ìŠ¤í† ì–´ì— ì“¸ ì„ë² ë”©ì€ **`ë³„ë„ì˜ ì„ë² ë”© ì „ìš© ëª¨ë¸ ì§€ì • í•„ìš”`**\n",
    "        * `GPT-4o-mini`ëŠ” ê·¸ëŒ€ë¡œ ëŒ€í™”/ìƒì„±ì— ì“°ê³ , `ê²€ìƒ‰ìš© ë²¡í„°`ëŠ” `ì„ë² ë”© ëª¨ë¸ë¡œ ìƒì„±í•˜ëŠ” êµ¬ì¡°`ê°€ ì¼ë°˜ì \n",
    "        * ì„ë² ë”© ëª¨ë¸ ì˜ˆì‹œ: **`text-embedding-3-small`** ë˜ëŠ” **`text-embedding-3-large`**\n",
    "\n",
    "  * ì›ì¸_2: **`FAISS` ìµœì‹  ì´ˆê¸°í™” ë°©ì‹ ë³€ê²½**\n",
    "    * ì˜ˆì „ì²˜ëŸ¼ `FAISS(embeddings_model, index, ...)`ë¡œ `ì§ì ‘ ìƒì„±`í•˜ëŠ” ë°©ì‹ì€ **`deprecated`**\n",
    "    * **`ìµœì‹ `** ë²„ì „ì—ì„œëŠ” `FAISS.from_texts()` ë˜ëŠ” `FAISS()ì— embedding_function=` í‚¤ì›Œë“œë¡œ ë„˜ê²¨ì•¼ í•¨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8011c8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d863a288",
   "metadata": {},
   "source": [
    "* ìµœì‹  ë°©ì‹ìœ¼ë¡œ ìˆ˜ì •í•œ ì½”ë“œë¡œ ë„ì „"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b855af0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# .env íŒŒì¼ì—ì„œ API í‚¤ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "def safe_chat_request(prompt, model=\"gpt-4o-mini\", max_retries=5):\n",
    "    \"\"\"429 ì—ëŸ¬ ë°©ì§€ë¥¼ ìœ„í•œ ì•ˆì „ í˜¸ì¶œ í•¨ìˆ˜\"\"\"\n",
    "    retries = 0\n",
    "    wait_time = 1  # ì²« ëŒ€ê¸° ì‹œê°„(ì´ˆ)\n",
    "\n",
    "    while retries < max_retries:\n",
    "        try:\n",
    "            response = openai.ChatCompletion.create(\n",
    "                model=model,\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                temperature=0.7\n",
    "            )\n",
    "            return response.choices[0].message[\"content\"]\n",
    "\n",
    "        except openai.error.RateLimitError:\n",
    "            print(f\"[ê²½ê³ ] ìš”ì²­ì´ ë„ˆë¬´ ë§ìŠµë‹ˆë‹¤. {wait_time}ì´ˆ í›„ ì¬ì‹œë„...\")\n",
    "            time.sleep(wait_time)\n",
    "            wait_time *= 2  # ì§€ìˆ˜ ë°±ì˜¤í”„\n",
    "            retries += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[ì—ëŸ¬] {e}\")\n",
    "            break\n",
    "\n",
    "    return \"ìš”ì²­ ì‹¤íŒ¨: ì¬ì‹œë„ íšŸìˆ˜ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤.\"\n",
    "\n",
    "# ì‚¬ìš© ì˜ˆì‹œ\n",
    "if __name__ == \"__main__\":\n",
    "    answer = safe_chat_request(\"ì•ˆë…•í•˜ì„¸ìš”, ì˜¤ëŠ˜ ë‚ ì”¨ì— ë§ëŠ” ì ì‹¬ ë©”ë‰´ ì¶”ì²œí•´ì¤˜\")\n",
    "    print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fb2e5f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì•ˆë…•í•˜ì„¸ìš”! ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ì–´ë–¤ì§€ì— ë”°ë¼ ì¶”ì²œí•´ë“œë¦´ ìˆ˜ ìˆëŠ” ì ì‹¬ ë©”ë‰´ê°€ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆì–´ìš”. ë‚ ì”¨ê°€ ë§‘ê³  ë”°ëœ»í•˜ë‹¤ë©´ ìƒëŸ¬ë“œë‚˜ ê°€ë²¼ìš´ íŒŒìŠ¤íƒ€ê°€ ì¢‹ê³ , ë¹„ë‚˜ ì¶”ìš´ ë‚ ì”¨ë¼ë©´ ë”°ëœ»í•œ êµ­ë¬¼ ìš”ë¦¬ë‚˜ ì°Œê°œê°€ ì¢‹ìŠµë‹ˆë‹¤. ì˜¤ëŠ˜ì˜ ë‚ ì”¨ëŠ” ì–´ë–¤ê°€ìš”?\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "from openai import OpenAI\n",
    "#from openai.error import RateLimitError  # ì˜ˆì™¸ ê²½ë¡œ ë³€ê²½ë¨\n",
    "from openai import RateLimitError\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "def safe_chat_request(prompt, model=\"gpt-4o-mini\", max_retries=5):\n",
    "    retries = 0\n",
    "    wait_time = 1\n",
    "\n",
    "    while retries < max_retries:\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                temperature=0.7\n",
    "            )\n",
    "            return response.choices[0].message.content\n",
    "\n",
    "        except RateLimitError:\n",
    "            print(f\"[ê²½ê³ ] ìš”ì²­ì´ ë„ˆë¬´ ë§ìŠµë‹ˆë‹¤. {wait_time}ì´ˆ í›„ ì¬ì‹œë„...\")\n",
    "            time.sleep(wait_time)\n",
    "            wait_time *= 2\n",
    "            retries += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[ì—ëŸ¬] {e}\")\n",
    "            break\n",
    "\n",
    "    return \"ìš”ì²­ ì‹¤íŒ¨: ì¬ì‹œë„ íšŸìˆ˜ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤.\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    answer = safe_chat_request(\"ì•ˆë…•í•˜ì„¸ìš”, ì˜¤ëŠ˜ ë‚ ì”¨ì— ë§ëŠ” ì ì‹¬ ë©”ë‰´ ì¶”ì²œí•´ì¤˜\")\n",
    "    print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4df2c9d",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* ì…€ ì¶œë ¥_1 (2.2s)\n",
    "\n",
    "    ```markdown\n",
    "    ì•ˆë…•í•˜ì„¸ìš”! ì˜¤ëŠ˜ ë‚ ì”¨ì— ë”°ë¼ ì ì‹¬ ë©”ë‰´ë¥¼ ì¶”ì²œí•´ë“œë¦´ê²Œìš”. ë‚ ì”¨ê°€ ë§‘ê³  ë”°ëœ»í•˜ë‹¤ë©´ ì‹ ì„ í•œ ìƒëŸ¬ë“œë‚˜ ëƒ‰ë©´ì´ ì¢‹ê³ , ë¹„ê°€ ì˜¤ê±°ë‚˜ ìŒ€ìŒ€í•˜ë‹¤ë©´ ë”°ëœ»í•œ êµ­ë¬¼ ìš”ë¦¬ì¸ ê¹€ì¹˜ì°Œê°œë‚˜ ìš°ë™ì´ ì¢‹ì„ ê²ƒ ê°™ì•„ìš”. ë‚ ì”¨ê°€ ì–´ë–¤ì§€ ì¢€ ë” êµ¬ì²´ì ìœ¼ë¡œ ë§ì”€í•´ì£¼ì‹œë©´ ë” ì¢‹ì€ ì¶”ì²œì„ í•´ë“œë¦´ ìˆ˜ ìˆì„ ê²ƒ ê°™ì•„ìš”!\n",
    "    ```\n",
    "\n",
    "---\n",
    "\n",
    "* ì…€ ì¶œë ¥_2 (2.1s)\n",
    "\n",
    "  * ëª¨ë“ˆ ì„í¬íŠ¸ ì¤‘ ê³¼ê±° ë²„ì „ â†’ ìµœì‹  ë°©ì‹ìœ¼ë¡œ ë³€ê²½ ì¶”ê°€ í›„ ë‹¤ì‹œ ì‹¤í–‰\n",
    "    * ê³¼ê±° ì„í¬íŠ¸ ë°©ë²• â†’ ì˜¤ë¥˜ ë°œìƒ â†’ `ì…€ ì¶œë ¥_1`ì—ì„œ ì œì™¸í•˜ê³  ì‹¤í–‰\n",
    "\n",
    "    ```python\n",
    "        from openai.error import RateLimitError \n",
    "    ```\n",
    "\n",
    "    * ìµœì‹  ì„í¬íŠ¸ ë°©ë²• â†’ ì¶”ê°€ â†’ `ì…€ ì¶œë ¥_2`ì—ì„œ ì¶”ê°€ ë° ì‹¤í–‰\n",
    "\n",
    "    ```python\n",
    "        from openai import RateLimitError\n",
    "    ```\n",
    "\n",
    "    ```markdown\n",
    "    ì•ˆë…•í•˜ì„¸ìš”! ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ì–´ë–¤ì§€ì— ë”°ë¼ ì¶”ì²œí•´ë“œë¦´ ìˆ˜ ìˆëŠ” ì ì‹¬ ë©”ë‰´ê°€ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆì–´ìš”. ë‚ ì”¨ê°€ ë§‘ê³  ë”°ëœ»í•˜ë‹¤ë©´ ìƒëŸ¬ë“œë‚˜ ê°€ë²¼ìš´ íŒŒìŠ¤íƒ€ê°€ ì¢‹ê³ , ë¹„ë‚˜ ì¶”ìš´ ë‚ ì”¨ë¼ë©´ ë”°ëœ»í•œ êµ­ë¬¼ ìš”ë¦¬ë‚˜ ì°Œê°œê°€ ì¢‹ìŠµë‹ˆë‹¤. ì˜¤ëŠ˜ì˜ ë‚ ì”¨ëŠ” ì–´ë–¤ê°€ìš”?\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025012aa",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4d2353",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "ğŸ“Œ ì‹¤í–‰ êµ¬ì¡°\n",
    "\n",
    "*  ë¬¸ì„œ ì„ë² ë”© ìƒì„± â†’ `OpenAI Embeddings API` ì‚¬ìš©\n",
    "*  ë²¡í„°ìŠ¤í† ì–´ì— ì €ì¥ â†’ ì˜ˆ: `FAISS`, `Chroma`, `Weaviate` ë“±\n",
    "*  ì§ˆì˜ ì‹œ â†’ `ì§ˆë¬¸`ì„ `ì„ë² ë”©`ìœ¼ë¡œ `ë³€í™˜` â†’ `ë²¡í„°ìŠ¤í† ì–´`ì—ì„œ `ìœ ì‚¬ë„ ê²€ìƒ‰`\n",
    "*  ê²€ìƒ‰ ê²°ê³¼ + ì‚¬ìš©ì ì§ˆë¬¸ì„ GPT ëª¨ë¸ì— ì „ë‹¬ â†’ `ìµœì¢… ë‹µë³€ ìƒì„±`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51353e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from openai import OpenAI, RateLimitError\n",
    "from dotenv import load_dotenv\n",
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "load_dotenv()\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# 1. ì•ˆì „ í˜¸ì¶œ í•¨ìˆ˜ (429 ë°©ì§€)\n",
    "def safe_chat_request(messages, model=\"gpt-4o-mini\", max_retries=5):\n",
    "    retries, wait_time = 0, 1\n",
    "    while retries < max_retries:\n",
    "        try:\n",
    "            resp = client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=messages,\n",
    "                temperature=0.7\n",
    "            )\n",
    "            return resp.choices[0].message.content\n",
    "        except RateLimitError:\n",
    "            print(f\"[ê²½ê³ ] ìš”ì²­ì´ ë§ìŠµë‹ˆë‹¤. {wait_time}ì´ˆ í›„ ì¬ì‹œë„...\")\n",
    "            time.sleep(wait_time)\n",
    "            wait_time *= 2\n",
    "            retries += 1\n",
    "        except Exception as e:\n",
    "            print(f\"[ì—ëŸ¬] {e}\")\n",
    "            break\n",
    "    return None\n",
    "\n",
    "# 2. í…ìŠ¤íŠ¸ â†’ ë²¡í„° ë³€í™˜\n",
    "def get_embedding(text, model=\"text-embedding-3-small\"):\n",
    "    emb = client.embeddings.create(\n",
    "        model=model,\n",
    "        input=text\n",
    "    )\n",
    "    return np.array(emb.data[0].embedding, dtype=\"float32\")\n",
    "\n",
    "# 3. ìƒ˜í”Œ ë¬¸ì„œ ë²¡í„°ìŠ¤í† ì–´ êµ¬ì¶•\n",
    "docs = [\n",
    "    \"íŒŒì´ì¬ì€ ë°ì´í„° ë¶„ì„ê³¼ AI ê°œë°œì— ë„ë¦¬ ì‚¬ìš©ë˜ëŠ” ì–¸ì–´ì…ë‹ˆë‹¤.\",\n",
    "    \"FAISSëŠ” Facebook AI Researchì—ì„œ ë§Œë“  ë²¡í„° ê²€ìƒ‰ ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤.\",\n",
    "    \"ë²¡í„°ìŠ¤í† ì–´ëŠ” ë¬¸ì„œ ê²€ìƒ‰ê³¼ ì¶”ì²œ ì‹œìŠ¤í…œì— í™œìš©ë©ë‹ˆë‹¤.\"\n",
    "]\n",
    "\n",
    "# FAISS ì´ˆê¸°í™”\n",
    "dimension = len(get_embedding(\"test\"))\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "\n",
    "# ë¬¸ì„œ ì„ë² ë”© ì €ì¥\n",
    "doc_embeddings = [get_embedding(doc) for doc in docs]\n",
    "index.add(np.array(doc_embeddings))\n",
    "\n",
    "# 4. ê²€ìƒ‰ + GPT ì—°ê²°\n",
    "def search_and_answer(query):\n",
    "    query_vec = get_embedding(query)\n",
    "    D, I = index.search(np.array([query_vec]), k=2)  # ìƒìœ„ 2ê°œ ê²€ìƒ‰\n",
    "    retrieved_docs = [docs[i] for i in I[0]]\n",
    "\n",
    "    # GPTì— ì „ë‹¬í•  ë©”ì‹œì§€ êµ¬ì„±\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"ë‹¹ì‹ ì€ ê²€ìƒ‰ ê¸°ë°˜ ì§ˆë¬¸ì— ë‹µí•˜ëŠ” AIì…ë‹ˆë‹¤.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"ë‹¤ìŒ ë¬¸ì„œë“¤ì„ ì°¸ê³ í•´ì„œ ë‹µë³€í•´ ì£¼ì„¸ìš”:\\n{retrieved_docs}\\n\\nì§ˆë¬¸: {query}\"}\n",
    "    ]\n",
    "    return safe_chat_request(messages)\n",
    "\n",
    "# ì‹¤í–‰ ì˜ˆì‹œ\n",
    "if __name__ == \"__main__\":\n",
    "    answer = search_and_answer(\"ë²¡í„°ìŠ¤í† ì–´ê°€ ë­ì•¼?\")\n",
    "    print(\"ë‹µë³€:\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2994d6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import faiss\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.memory import VectorStoreRetrieverMemory\n",
    "\n",
    "# =========================================\n",
    "# 1. OpenAI API í‚¤ ì„¤ì •\n",
    "# =========================================\n",
    "# í™˜ê²½ë³€ìˆ˜ì— API í‚¤ ì €ì¥\n",
    "# .env íŒŒì¼ì—ì„œ í™˜ê²½ë³€ìˆ˜ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "load_dotenv()\n",
    "\n",
    "# í™˜ê²½ë³€ìˆ˜ì—ì„œ API í‚¤ ê°€ì ¸ì˜¤ê¸°\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# OpenAI API í‚¤ ì„¤ì •\n",
    "openai.api_key = api_key\n",
    "\n",
    "# =========================================\n",
    "# 2. ì„ë² ë”© ëª¨ë¸ ì •ì˜\n",
    "# =========================================\n",
    "# gpt-4o-miniëŠ” í…ìŠ¤íŠ¸ ìƒì„±ìš©, ë²¡í„° ê²€ìƒ‰ì—ëŠ” ì„ë² ë”© ì „ìš© ëª¨ë¸ ì‚¬ìš©\n",
    "embeddings_model = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-small\",                 # ë˜ëŠ” \"text-embedding-3-large\"\n",
    "    api_key=api_key\n",
    ")\n",
    "\n",
    "# =========================================\n",
    "# 3. ë¹ˆ FAISS ì¸ë±ìŠ¤ ì´ˆê¸°í™”\n",
    "# =========================================\n",
    "embedding_size = len(embeddings_model.embed_query(\"í…ŒìŠ¤íŠ¸\"))      # ëª¨ë¸ ì°¨ì› ìë™ ê³„ì‚°\n",
    "index = faiss.IndexFlatL2(embedding_size)                       # L2 ê±°ë¦¬ ê¸°ë°˜ ì¸ë±ìŠ¤\n",
    "vectorstore = FAISS(                                            # FAISS ìµœì‹  ë°©ì‹ìœ¼ë¡œ ë³€ìˆ˜ ì§€ì •\n",
    "    embedding_function=embeddings_model,\n",
    "    index=index,\n",
    "    docstore=InMemoryDocstore({}),\n",
    "    index_to_docstore_id={}\n",
    ")\n",
    "\n",
    "# =========================================\n",
    "# 4. RetrieverMemory ì—°ê²°\n",
    "# =========================================\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 1})\n",
    "memory = VectorStoreRetrieverMemory(retriever=retriever)\n",
    "\n",
    "# =========================================\n",
    "# 5. ëŒ€í™” ë‚´ìš© ì €ì¥\n",
    "# =========================================\n",
    "memory.save_context(\n",
    "    inputs={\"human\": \"ì•ˆë…•í•˜ì„¸ìš”, ì˜¤ëŠ˜ ë©´ì ‘ì— ì°¸ì„í•´ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤. ìê¸°ì†Œê°œ ë¶€íƒë“œë¦½ë‹ˆë‹¤.\"},\n",
    "    outputs={\"ai\": \"ì•ˆë…•í•˜ì„¸ìš”. ì €ëŠ” ì»´í“¨í„° ê³¼í•™ì„ ì „ê³µí•œ ì‹ ì… ê°œë°œìì…ë‹ˆë‹¤. ëŒ€í•™ì—ì„œëŠ” ì£¼ë¡œ ìë°”ì™€ íŒŒì´ì¬ì„ ì‚¬ìš©í–ˆìœ¼ë©°, ìµœê·¼ì—ëŠ” ì›¹ ê°œë°œ í”„ë¡œì íŠ¸ì— ì°¸ì—¬í•˜ì—¬ ì‹¤ì œ ì‚¬ìš©ìë¥¼ ìœ„í•œ ì„œë¹„ìŠ¤ë¥¼ ê°œë°œí•˜ëŠ” ê²½í—˜ì„ í–ˆìŠµë‹ˆë‹¤.\"}\n",
    ")\n",
    "memory.save_context(\n",
    "    inputs={\"human\": \"í”„ë¡œì íŠ¸ì—ì„œ ì–´ë–¤ ì—­í• ì„ ë§¡ì•˜ë‚˜ìš”?\"},\n",
    "    outputs={\"ai\": \"ì œê°€ ë§¡ì€ ì—­í• ì€ ë°±ì—”ë“œ ê°œë°œìì˜€ìŠµë‹ˆë‹¤. ì‚¬ìš©ì ë°ì´í„° ì²˜ë¦¬ì™€ ì„œë²„ ë¡œì§ ê°œë°œì„ ë‹´ë‹¹í–ˆìœ¼ë©°, RESTful APIë¥¼ êµ¬í˜„í•˜ì—¬ í”„ë¡ íŠ¸ì—”ë“œì™€ì˜ í†µì‹ ì„ ë‹´ë‹¹í–ˆìŠµë‹ˆë‹¤. ë˜í•œ, ë°ì´í„°ë² ì´ìŠ¤ ì„¤ê³„ì—ë„ ì°¸ì—¬í–ˆìŠµë‹ˆë‹¤.\"}\n",
    ")\n",
    "memory.save_context(\n",
    "    inputs={\"human\": \"íŒ€ í”„ë¡œì íŠ¸ì—ì„œ ì–´ë ¤ì›€ì„ ê²ªì—ˆë˜ ê²½í—˜ì´ ìˆë‹¤ë©´ ì–´ë–»ê²Œ í•´ê²°í–ˆë‚˜ìš”?\"},\n",
    "    outputs={\"ai\": \"í”„ë¡œì íŠ¸ ì´ˆê¸°ì— ì˜ì‚¬ì†Œí†µ ë¬¸ì œë¡œ ëª‡ ê°€ì§€ ì–´ë ¤ì›€ì´ ìˆì—ˆìŠµë‹ˆë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ì €í¬ íŒ€ì€ ì •ê¸°ì ì¸ ë¯¸íŒ…ì„ ê°–ê³  ê°ìì˜ ì§„í–‰ ìƒí™©ì„ ê³µìœ í–ˆìŠµë‹ˆë‹¤. ë˜í•œ, ë¬¸ì œê°€ ë°œìƒí–ˆì„ ë•ŒëŠ” ì ê·¹ì ìœ¼ë¡œ ì˜ê²¬ì„ ë‚˜ëˆ„ê³ , í•©ë¦¬ì ì¸ í•´ê²°ì±…ì„ ì°¾ê¸° ìœ„í•´ ë…¸ë ¥í–ˆìŠµë‹ˆë‹¤.\"}\n",
    ")\n",
    "memory.save_context(\n",
    "    inputs={\"human\": \"ê°œë°œìë¡œì„œ ìì‹ ì˜ ê°•ì ì€ ë¬´ì—‡ì´ë¼ê³  ìƒê°í•˜ë‚˜ìš”?\"},\n",
    "    outputs={\"ai\": \"ì œ ê°•ì ì€ ë¹ ë¥¸ í•™ìŠµ ëŠ¥ë ¥ê³¼ ë¬¸ì œ í•´ê²° ëŠ¥ë ¥ì…ë‹ˆë‹¤. ìƒˆë¡œìš´ ê¸°ìˆ ì´ë‚˜ ë„êµ¬ë¥¼ ë¹ ë¥´ê²Œ ìŠµë“í•  ìˆ˜ ìˆìœ¼ë©°, ë³µì¡í•œ ë¬¸ì œì— ì§ë©´í–ˆì„ ë•Œ ì°½ì˜ì ì¸ í•´ê²°ì±…ì„ ì œì‹œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ, íŒ€ì›Œí¬ë¥¼ ì¤‘ì‹œí•˜ë©° ë™ë£Œë“¤ê³¼ í˜‘ë ¥í•˜ëŠ” ê²ƒì„ ì¤‘ìš”í•˜ê²Œ ìƒê°í•©ë‹ˆë‹¤.\"}\n",
    ")\n",
    "\n",
    "# =========================================\n",
    "# 6. ë©”ëª¨ë¦¬ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸\n",
    "# =========================================\n",
    "print(memory.load_memory_variables({\"prompt\": \"ë©´ì ‘ì ì „ê³µì€ ë¬´ì—‡ì¸ê°€ìš”?\"})[\"history\"])\n",
    "print(memory.load_memory_variables({\"human\": \"ë©´ì ‘ìê°€ í”„ë¡œì íŠ¸ì—ì„œ ë§¡ì€ ì—­í• ì€ ë¬´ì—‡ì¸ê°€ìš”?\"})[\"history\"])\n",
    "\n",
    "# =========================================\n",
    "# 7. gpt-4o-miniì™€ ê²°í•© ì˜ˆì‹œ\n",
    "# =========================================\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", api_key=os.environ[\"OPENAI_API_KEY\"])\n",
    "\n",
    "question = \"ì´ ë©´ì ‘ìì˜ ê°•ì ì„ í•œ ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•´ì¤˜.\"\n",
    "context = memory.load_memory_variables({\"human\": question})[\"history\"]\n",
    "\n",
    "response = llm.invoke(f\"ë‹¤ìŒ ëŒ€í™” ê¸°ë¡ì„ ì°¸ê³ í•´ì„œ ë‹µë³€í•´ì¤˜:\\n{context}\\n\\nì§ˆë¬¸: {question}\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd14b462",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* ì…€ ì¶œë ¥ ì˜¤ë¥˜: í¬ë ˆë”§ ì†Œì§„ìœ¼ë¡œ í˜„ì¬ í•´ê²° ì–´ë ¤ì›€ â†’ ë‹¤ë¥¸ ì„ë² ë”© ëª¨ë¸ ì‚¬ìš©í•´ë³´ê¸°ë¡œ í•¨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4cf791",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d6a340",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* **ì„ë² ë”© ëª¨ë¸ êµì²´ í•„ìš”: `OpenAI ëª¨ë¸` â†’ `all-MiniLM-L6-v2`**\n",
    "\n",
    "* **`sentence-transformers/all-MiniLM-L6-v2`**\n",
    "  * ì—­í• : ë¬¸ì¥ì´ë‚˜ ì§§ì€ ë¬¸ë‹¨ì„ 384ì°¨ì› ë²¡í„°ë¡œ ë³€í™˜ â†’ **ì˜ë¯¸ ê¸°ë°˜ ê²€ìƒ‰, ìœ ì‚¬ë„ ê³„ì‚°** ë“±ì— ì‚¬ìš©\n",
    "  * ê¸°ë°˜: `BERT` ê³„ì—´ì˜ `MiniLM` ì•„í‚¤í…ì²˜ë¥¼ `1B(10ì–µ) ë¬¸ì¥ ìŒ ë°ì´í„°ë¡œ íŒŒì¸íŠœë‹`\n",
    "  * ì–¸ì–´: `ì£¼ë¡œ ì˜ì–´`ì— ìµœì í™”, í•˜ì§€ë§Œ í•œêµ­ì–´ë„ ì–´ëŠ ì •ë„ ì²˜ë¦¬ ê°€ëŠ¥ (ë‹¤ë§Œ ì •í™•ë„ëŠ” ë‹¤êµ­ì–´ ëª¨ë¸ë³´ë‹¤ ë‚®ìŒ)\n",
    "  * ì†ë„: `CPUì—ì„œë„ ë¹ ë¥´ê²Œ ë™ì‘`, GPU ì‚¬ìš© ì‹œ ë” ë¹ ë¦„\n",
    "\n",
    "* ìš©ëŸ‰\n",
    "  * ëª¨ë¸ íŒŒì¼ í¬ê¸°: `ì•½ 90MB` (`PyTorch weights ê¸°ì¤€`)\n",
    "  * ì„¤ì¹˜ í›„ ìºì‹œ í¬í•¨: `ì•½ 100~120MB` ì •ë„ ì°¨ì§€\n",
    "  * ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: `CPU`ì—ì„œ ë¡œë“œ ì‹œ ì•½ `400~500MB` RAM ì‚¬ìš©\n",
    "\n",
    "* ì €ì¥ ìœ„ì¹˜: ì „ì•½ or í•´ë‹¹ í”„ë¡œì íŠ¸"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d452a7f0",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d210561e",
   "metadata": {},
   "source": [
    "* ì„ë² ë”© ëª¨ë¸ì„ í™œìš©í•œ ì „ì²´ ì½”ë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061e0c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_1\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "# ë¡œì»¬ ì„ë² ë”© ëª¨ë¸ ë¡œë“œ\n",
    "embed_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "docs = [\n",
    "    \"íŒŒì´ì¬ì€ ë°ì´í„° ë¶„ì„ê³¼ AI ê°œë°œì— ë„ë¦¬ ì‚¬ìš©ë˜ëŠ” ì–¸ì–´ì…ë‹ˆë‹¤.\",\n",
    "    \"FAISSëŠ” Facebook AI Researchì—ì„œ ë§Œë“  ë²¡í„° ê²€ìƒ‰ ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤.\",\n",
    "    \"ë²¡í„°ìŠ¤í† ì–´ëŠ” ë¬¸ì„œ ê²€ìƒ‰ê³¼ ì¶”ì²œ ì‹œìŠ¤í…œì— í™œìš©ë©ë‹ˆë‹¤.\"\n",
    "]\n",
    "\n",
    "# ë¬¸ì„œ ì„ë² ë”©\n",
    "doc_embeddings = embed_model.encode(docs, convert_to_numpy=True)\n",
    "\n",
    "# FAISS ì¸ë±ìŠ¤ ìƒì„±\n",
    "dimension = doc_embeddings.shape[1]\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "index.add(doc_embeddings)\n",
    "\n",
    "# ê²€ìƒ‰ í•¨ìˆ˜\n",
    "def search(query, k=2):\n",
    "    query_vec = embed_model.encode([query], convert_to_numpy=True)\n",
    "    D, I = index.search(query_vec, k)\n",
    "    return [docs[i] for i in I[0]]\n",
    "\n",
    "print(search(\"ë²¡í„°ìŠ¤í† ì–´ ì„¤ëª…í•´ì¤˜\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7319c28f",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* ì…€ ì¶œë ¥ (23.4s)\n",
    "\n",
    "    ```python\n",
    "    /Users/jay/.pyenv/versions/lc_env/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
    "    from .autonotebook import tqdm as notebook_tqdm\n",
    "    ['ë²¡í„°ìŠ¤í† ì–´ëŠ” ë¬¸ì„œ ê²€ìƒ‰ê³¼ ì¶”ì²œ ì‹œìŠ¤í…œì— í™œìš©ë©ë‹ˆë‹¤.', 'íŒŒì´ì¬ì€ ë°ì´í„° ë¶„ì„ê³¼ AI ê°œë°œì— ë„ë¦¬ ì‚¬ìš©ë˜ëŠ” ì–¸ì–´ì…ë‹ˆë‹¤.']\n",
    "    ```\n",
    "\n",
    "---\n",
    "\n",
    "* ì…€ ì¶œë ¥ ê²½ê³  ë©”ì‹œì§€ \n",
    "\n",
    "  * ë¶„ì„\n",
    "\n",
    "    * `/Users/jay/.pyenv/versions/lc_env/lib/python3.13/site-packages/tqdm/auto.py:21`\n",
    "      * ê²½ê³ ê°€ ë°œìƒí•œ íŒŒì¼ ê²½ë¡œì™€ ì¤„ ë²ˆí˜¸\n",
    "      * tqdm/auto.py â†’ tqdmì˜ ìë™ í™˜ê²½ ê°ì§€ ëª¨ë“œ íŒŒì¼\n",
    "      * :21 â†’ 21ë²ˆì§¸ ì¤„ì—ì„œ ê²½ê³ ë¥¼ ë°œìƒì‹œì¼°ë‹¤ëŠ” ëœ»\n",
    "  \n",
    "    * `TqdmWarning`\n",
    "      * `tqdm` ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì •ì˜í•œ ê²½ê³  í´ë˜ìŠ¤ ì´ë¦„\n",
    "      * `Warning`ì´ë¯€ë¡œ ì½”ë“œ ì‹¤í–‰ì€ ê³„ì†ë˜ì§€ë§Œ, ê¸°ëŠ¥ ì¼ë¶€ê°€ ì œí•œë  ìˆ˜ ìˆë‹¤ëŠ” ì‹ í˜¸\n",
    "\n",
    "    * `IProgress not found.`\n",
    "      * `IProgress` = **`Jupyter Notebook/Lab`ì—ì„œ ì§„í–‰ë°”ë¥¼ í‘œì‹œí•˜ëŠ” ìœ„ì ¯ í´ë˜ìŠ¤**\n",
    "      * `ipywidgets` íŒ¨í‚¤ì§€ ì•ˆì— í¬í•¨ë˜ì–´ ìˆìŒ\n",
    "      * í˜„ì¬ í™˜ê²½ì—ì„œ IProgressë¥¼ ì°¾ì§€ ëª»í–ˆë‹¤ëŠ” ëœ» â†’ ì¦‰, ipywidgetsê°€ ì—†ê±°ë‚˜ ë²„ì „ì´ ë§ì§€ ì•ŠìŒ\n",
    "\n",
    "\n",
    "    * `Please update jupyter and ipywidgets.`\n",
    "      * í•´ê²° ë°©ë²• ì•ˆë‚´_1: **`jupyter` (ë…¸íŠ¸ë¶ ì‹¤í–‰ í™˜ê²½)**\n",
    "      * í•´ê²° ë°©ë²• ì•ˆë‚´_2: **`ipywidgets` (ì§„í–‰ë°”, ìŠ¬ë¼ì´ë”, ë²„íŠ¼ ê°™ì€ UI ìœ„ì ¯ ì œê³µ)**\n",
    "      * ì´ ë‘˜ì„ ì„¤ì¹˜í•˜ê±°ë‚˜ ìµœì‹  ë²„ì „ìœ¼ë¡œ ì—…ë°ì´íŠ¸í•˜ë¼ëŠ” ì˜ë¯¸\n",
    "\n",
    "\n",
    "    * `See https://ipywidgets.readthedocs.io/en/stable/user_install.html`\n",
    "    * = [ê³µì‹ê°€ì´ë“œ](https://ipywidgets.readthedocs.io/en/stable/user_install.html) ì°¸ê³ í•˜ë¼ëŠ” ì˜ë¯¸\n",
    "\n",
    "\n",
    "    * `from .autonotebook import tqdm as notebook_tqdm`\n",
    "      * `tqdm`ì´ `Jupyter í™˜ê²½`ì´ë©´ `notebookìš© ì§„í–‰ë°”`ë¥¼, `í„°ë¯¸ë„ í™˜ê²½`ì´ë©´ `CLIìš© ì§„í–‰ë°”`ë¥¼ **ìë™ìœ¼ë¡œ ì„ íƒí•˜ë ¤ëŠ” ì½”ë“œ**\n",
    "      * ì—¬ê¸°ì„œ `notebookìš© ì§„í–‰ë°”ë¥¼ ì“°ë ¤ê³  í•˜ë‹¤ê°€` **IProgressê°€ ì—†ì–´ì„œ ê²½ê³  ë°œìƒ**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d829afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_2\n",
    "# vscode í„°ë¯¸ë„: `pip install ipywidgets` ì„¤ì¹˜ í›„\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "# ë¡œì»¬ ì„ë² ë”© ëª¨ë¸ ë¡œë“œ\n",
    "embed_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "docs = [\n",
    "    \"íŒŒì´ì¬ì€ ë°ì´í„° ë¶„ì„ê³¼ AI ê°œë°œì— ë„ë¦¬ ì‚¬ìš©ë˜ëŠ” ì–¸ì–´ì…ë‹ˆë‹¤.\",\n",
    "    \"FAISSëŠ” Facebook AI Researchì—ì„œ ë§Œë“  ë²¡í„° ê²€ìƒ‰ ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤.\",\n",
    "    \"ë²¡í„°ìŠ¤í† ì–´ëŠ” ë¬¸ì„œ ê²€ìƒ‰ê³¼ ì¶”ì²œ ì‹œìŠ¤í…œì— í™œìš©ë©ë‹ˆë‹¤.\"\n",
    "]\n",
    "\n",
    "# ë¬¸ì„œ ì„ë² ë”©\n",
    "doc_embeddings = embed_model.encode(docs, convert_to_numpy=True)\n",
    "\n",
    "# FAISS ì¸ë±ìŠ¤ ìƒì„±\n",
    "dimension = doc_embeddings.shape[1]\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "index.add(doc_embeddings)\n",
    "\n",
    "# ê²€ìƒ‰ í•¨ìˆ˜\n",
    "def search(query, k=2):\n",
    "    query_vec = embed_model.encode([query], convert_to_numpy=True)\n",
    "    D, I = index.search(query_vec, k)\n",
    "    return [docs[i] for i in I[0]]\n",
    "\n",
    "print(search(\"ë²¡í„°ìŠ¤í† ì–´ ì„¤ëª…í•´ì¤˜\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1e73f9",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* ì…€ ì¶œë ¥ (3.5s)\n",
    "\n",
    "    ```markdown\n",
    "    ['ë²¡í„°ìŠ¤í† ì–´ëŠ” ë¬¸ì„œ ê²€ìƒ‰ê³¼ ì¶”ì²œ ì‹œìŠ¤í…œì— í™œìš©ë©ë‹ˆë‹¤.', 'íŒŒì´ì¬ì€ ë°ì´í„° ë¶„ì„ê³¼ AI ê°œë°œì— ë„ë¦¬ ì‚¬ìš©ë˜ëŠ” ì–¸ì–´ì…ë‹ˆë‹¤.']\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b34ace",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7adf4887",
   "metadata": {},
   "source": [
    "* êµì¬ ì† ë‚´ìš©ìœ¼ë¡œ ì½”ë“œ ìˆ˜ì •í•´ë³´ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7f96f784",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.memory import VectorStoreRetrieverMemory\n",
    "from langchain_openai import ChatOpenAI                                     # GPT í˜¸ì¶œìš© (ì›í•˜ë©´ ì œê±° ê°€ëŠ¥)\n",
    "\n",
    "# =========================================\n",
    "# 1. ë¡œì»¬ ì„ë² ë”© ëª¨ë¸ ë¡œë“œ\n",
    "# =========================================\n",
    "# 'cache_folder'ë¥¼ ì§€ì •í•˜ë©´ ëª¨ë¸ì´ í”„ë¡œì íŠ¸ í´ë” ì•ˆì— ì €ì¥ë¨\n",
    "# ì²˜ìŒ ì‹¤í–‰ ì‹œ Hugging Face Hubì—ì„œ ë‹¤ìš´ë¡œë“œ í›„ ìºì‹œì— ì €ì¥\n",
    "embed_model = SentenceTransformer(\n",
    "    'sentence-transformers/all-MiniLM-L6-v2',\n",
    "    cache_folder=\"./models\"                                                 # í”„ë¡œì íŠ¸ ë£¨íŠ¸ì˜ models í´ë”ì— ì €ì¥\n",
    ")\n",
    "\n",
    "# =========================================\n",
    "# 2. ë¹ˆ FAISS ì¸ë±ìŠ¤ ì´ˆê¸°í™”\n",
    "# =========================================\n",
    "# ëª¨ë¸ì˜ ì„ë² ë”© ì°¨ì› ìˆ˜ë¥¼ ìë™ ê³„ì‚°\n",
    "embedding_size = embed_model.get_sentence_embedding_dimension()\n",
    "\n",
    "# L2 ê±°ë¦¬ ê¸°ë°˜ ì¸ë±ìŠ¤ ìƒì„±\n",
    "index = faiss.IndexFlatL2(embedding_size)\n",
    "\n",
    "# LangChainì˜ FAISS ë˜í¼ë¡œ ê°ì‹¸ê¸°\n",
    "vectorstore = FAISS(\n",
    "    embedding_function=embed_model.encode,                                  # ë¡œì»¬ ì„ë² ë”© í•¨ìˆ˜ ì‚¬ìš©\n",
    "    index=index,\n",
    "    docstore=InMemoryDocstore({}),\n",
    "    index_to_docstore_id={}\n",
    ")\n",
    "\n",
    "# =========================================\n",
    "# 3. RetrieverMemory ì—°ê²°\n",
    "# =========================================\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 1})                # k=1 â†’ ê°€ì¥ ìœ ì‚¬í•œ 1ê°œë§Œ ê²€ìƒ‰í•´ë³´ê¸°\n",
    "memory = VectorStoreRetrieverMemory(retriever=retriever)\n",
    "\n",
    "# =========================================\n",
    "# 4. ëŒ€í™” ë‚´ìš© ì €ì¥\n",
    "# =========================================\n",
    "memory.save_context(\n",
    "    inputs={\"human\": \"ì•ˆë…•í•˜ì„¸ìš”, ì˜¤ëŠ˜ ë©´ì ‘ì— ì°¸ì„í•´ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤. ìê¸°ì†Œê°œ ë¶€íƒë“œë¦½ë‹ˆë‹¤.\"},\n",
    "    outputs={\"ai\": \"ì•ˆë…•í•˜ì„¸ìš”. ì €ëŠ” ì»´í“¨í„° ê³¼í•™ì„ ì „ê³µí•œ ì‹ ì… ê°œë°œìì…ë‹ˆë‹¤. ëŒ€í•™ì—ì„œëŠ” ì£¼ë¡œ ìë°”ì™€ íŒŒì´ì¬ì„ ì‚¬ìš©í–ˆìœ¼ë©°, ìµœê·¼ì—ëŠ” ì›¹ ê°œë°œ í”„ë¡œì íŠ¸ì— ì°¸ì—¬í•˜ì—¬ ì‹¤ì œ ì‚¬ìš©ìë¥¼ ìœ„í•œ ì„œë¹„ìŠ¤ë¥¼ ê°œë°œí•˜ëŠ” ê²½í—˜ì„ í–ˆìŠµë‹ˆë‹¤.\"}\n",
    ")\n",
    "memory.save_context(\n",
    "    inputs={\"human\": \"í”„ë¡œì íŠ¸ì—ì„œ ì–´ë–¤ ì—­í• ì„ ë§¡ì•˜ë‚˜ìš”?\"},\n",
    "    outputs={\"ai\": \"ì œê°€ ë§¡ì€ ì—­í• ì€ ë°±ì—”ë“œ ê°œë°œìì˜€ìŠµë‹ˆë‹¤. ì‚¬ìš©ì ë°ì´í„° ì²˜ë¦¬ì™€ ì„œë²„ ë¡œì§ ê°œë°œì„ ë‹´ë‹¹í–ˆìœ¼ë©°, RESTful APIë¥¼ êµ¬í˜„í•˜ì—¬ í”„ë¡ íŠ¸ì—”ë“œì™€ì˜ í†µì‹ ì„ ë‹´ë‹¹í–ˆìŠµë‹ˆë‹¤. ë˜í•œ, ë°ì´í„°ë² ì´ìŠ¤ ì„¤ê³„ì—ë„ ì°¸ì—¬í–ˆìŠµë‹ˆë‹¤.\"}\n",
    ")\n",
    "memory.save_context(\n",
    "    inputs={\"human\": \"íŒ€ í”„ë¡œì íŠ¸ì—ì„œ ì–´ë ¤ì›€ì„ ê²ªì—ˆë˜ ê²½í—˜ì´ ìˆë‹¤ë©´ ì–´ë–»ê²Œ í•´ê²°í–ˆë‚˜ìš”?\"},\n",
    "    outputs={\"ai\": \"í”„ë¡œì íŠ¸ ì´ˆê¸°ì— ì˜ì‚¬ì†Œí†µ ë¬¸ì œë¡œ ëª‡ ê°€ì§€ ì–´ë ¤ì›€ì´ ìˆì—ˆìŠµë‹ˆë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ì €í¬ íŒ€ì€ ì •ê¸°ì ì¸ ë¯¸íŒ…ì„ ê°–ê³  ê°ìì˜ ì§„í–‰ ìƒí™©ì„ ê³µìœ í–ˆìŠµë‹ˆë‹¤. ë˜í•œ, ë¬¸ì œê°€ ë°œìƒí–ˆì„ ë•ŒëŠ” ì ê·¹ì ìœ¼ë¡œ ì˜ê²¬ì„ ë‚˜ëˆ„ê³ , í•©ë¦¬ì ì¸ í•´ê²°ì±…ì„ ì°¾ê¸° ìœ„í•´ ë…¸ë ¥í–ˆìŠµë‹ˆë‹¤.\"}\n",
    ")\n",
    "memory.save_context(\n",
    "    inputs={\"human\": \"ê°œë°œìë¡œì„œ ìì‹ ì˜ ê°•ì ì€ ë¬´ì—‡ì´ë¼ê³  ìƒê°í•˜ë‚˜ìš”?\"},\n",
    "    outputs={\"ai\": \"ì œ ê°•ì ì€ ë¹ ë¥¸ í•™ìŠµ ëŠ¥ë ¥ê³¼ ë¬¸ì œ í•´ê²° ëŠ¥ë ¥ì…ë‹ˆë‹¤. ìƒˆë¡œìš´ ê¸°ìˆ ì´ë‚˜ ë„êµ¬ë¥¼ ë¹ ë¥´ê²Œ ìŠµë“í•  ìˆ˜ ìˆìœ¼ë©°, ë³µì¡í•œ ë¬¸ì œì— ì§ë©´í–ˆì„ ë•Œ ì°½ì˜ì ì¸ í•´ê²°ì±…ì„ ì œì‹œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ, íŒ€ì›Œí¬ë¥¼ ì¤‘ì‹œí•˜ë©° ë™ë£Œë“¤ê³¼ í˜‘ë ¥í•˜ëŠ” ê²ƒì„ ì¤‘ìš”í•˜ê²Œ ìƒê°í•©ë‹ˆë‹¤.\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bfd4c1b",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* ì‹¤í–‰ ì‹œê°„ (8.2s)\n",
    "\n",
    "* `embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b82d884",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =========================================\n",
    "# 5. ë©”ëª¨ë¦¬ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸\n",
    "# =========================================\n",
    "print(\"ì§ˆë¬¸: ë©´ì ‘ì ì „ê³µì€ ë¬´ì—‡ì¸ê°€ìš”?\", \"\\n\")\n",
    "print(\"ê²€ìƒ‰ ê²°ê³¼:\", memory.load_memory_variables({\"prompt\": \"ë©´ì ‘ì ì „ê³µì€ ë¬´ì—‡ì¸ê°€ìš”?\"})[\"history\"])\n",
    "print(\"\\n\", \"===\"*50, \"\\n\")\n",
    "print(\"ì§ˆë¬¸: ë©´ì ‘ìê°€ í”„ë¡œì íŠ¸ì—ì„œ ë§¡ì€ ì—­í• ì€ ë¬´ì—‡ì¸ê°€ìš”?\", \"\\n\")\n",
    "print(\"ê²€ìƒ‰ ê²°ê³¼:\", memory.load_memory_variables({\"human\": \"ë©´ì ‘ìê°€ í”„ë¡œì íŠ¸ì—ì„œ ë§¡ì€ ì—­í• ì€ ë¬´ì—‡ì¸ê°€ìš”?\"})[\"history\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772db3b6",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* ì…€ ì¶œë ¥ (0.7s)\n",
    "\n",
    "    ```markdown\n",
    "    ì§ˆë¬¸: ë©´ì ‘ì ì „ê³µì€ ë¬´ì—‡ì¸ê°€ìš”? \n",
    "\n",
    "    ê²€ìƒ‰ ê²°ê³¼: human: í”„ë¡œì íŠ¸ì—ì„œ ì–´ë–¤ ì—­í• ì„ ë§¡ì•˜ë‚˜ìš”?\n",
    "    ai: ì œê°€ ë§¡ì€ ì—­í• ì€ ë°±ì—”ë“œ ê°œë°œìì˜€ìŠµë‹ˆë‹¤. ì‚¬ìš©ì ë°ì´í„° ì²˜ë¦¬ì™€ ì„œë²„ ë¡œì§ ê°œë°œì„ ë‹´ë‹¹í–ˆìœ¼ë©°, RESTful APIë¥¼ êµ¬í˜„í•˜ì—¬ í”„ë¡ íŠ¸ì—”ë“œì™€ì˜ í†µì‹ ì„ ë‹´ë‹¹í–ˆìŠµë‹ˆë‹¤. ë˜í•œ, ë°ì´í„°ë² ì´ìŠ¤ ì„¤ê³„ì—ë„ ì°¸ì—¬í–ˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "    ====================================================================================================================================================== \n",
    "\n",
    "    ì§ˆë¬¸: ë©´ì ‘ìê°€ í”„ë¡œì íŠ¸ì—ì„œ ë§¡ì€ ì—­í• ì€ ë¬´ì—‡ì¸ê°€ìš”? \n",
    "\n",
    "    ê²€ìƒ‰ ê²°ê³¼: human: í”„ë¡œì íŠ¸ì—ì„œ ì–´ë–¤ ì—­í• ì„ ë§¡ì•˜ë‚˜ìš”?\n",
    "    ai: ì œê°€ ë§¡ì€ ì—­í• ì€ ë°±ì—”ë“œ ê°œë°œìì˜€ìŠµë‹ˆë‹¤. ì‚¬ìš©ì ë°ì´í„° ì²˜ë¦¬ì™€ ì„œë²„ ë¡œì§ ê°œë°œì„ ë‹´ë‹¹í–ˆìœ¼ë©°, RESTful APIë¥¼ êµ¬í˜„í•˜ì—¬ í”„ë¡ íŠ¸ì—”ë“œì™€ì˜ í†µì‹ ì„ ë‹´ë‹¹í–ˆìŠµë‹ˆë‹¤. ë˜í•œ, ë°ì´í„°ë² ì´ìŠ¤ ì„¤ê³„ì—ë„ ì°¸ì—¬í–ˆìŠµë‹ˆë‹¤.\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f15fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================\n",
    "# 6. (ì„ íƒ) gpt-4o-miniì™€ ê²°í•© ì˜ˆì‹œ\n",
    "# =========================================\n",
    "# OpenAI API í‚¤ê°€ ìˆì–´ì•¼ ë™ì‘í•©ë‹ˆë‹¤. ì—†ìœ¼ë©´ ì´ ë¶€ë¶„ì€ ì£¼ì„ ì²˜ë¦¬í•˜ì„¸ìš”.\n",
    "# .env íŒŒì¼ì—ì„œ API í‚¤ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\", \n",
    "    api_key=api_key)\n",
    "\n",
    "question = \"ì´ ë©´ì ‘ìì˜ ê°•ì ì„ í•œ ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•´ì¤˜.\"\n",
    "context = memory.load_memory_variables({\"human\": question})[\"history\"]\n",
    "\n",
    "response = llm.invoke(f\"ë‹¤ìŒ ëŒ€í™” ê¸°ë¡ì„ ì°¸ê³ í•´ì„œ ë‹µë³€í•´ì¤˜:\\n{context}\\n\\nì§ˆë¬¸: {question}\")\n",
    "print(\"\\nGPT ì‘ë‹µ:\", response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8987e3",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* ì…€ ì¶œë ¥ (2.4s)\n",
    "\n",
    "    ```markdown\n",
    "    GPT ì‘ë‹µ: ë©´ì ‘ìëŠ” íŒ€ ë‚´ ì˜ì‚¬ì†Œí†µ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ì •ê¸°ì ì¸ ë¯¸íŒ…ê³¼ ì˜ê²¬ ê³µìœ ë¥¼ ì ê·¹ì ìœ¼ë¡œ í™œìš©í•œ ê°•ì ì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤.\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c00a0a8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29086ade",
   "metadata": {},
   "source": [
    "* *next: LCEL Chain ì— ë©”ëª¨ë¦¬ ì¶”ê°€*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec9567e",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lc_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
