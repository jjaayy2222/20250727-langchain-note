# 01_Test-Dataset-Generator-RAGAS_1.py
"""
llama3.2:3b êµì²´ ë° ê°„ë‹¨ í…ŒìŠ¤íŠ¸ìš©
ì†Œìš” ì‹œê°„: 5-8ë¶„
"""
import os
import warnings
warnings.filterwarnings("ignore")
os.environ["TOKENIZERS_PARALLELISM"] = "false"

from dotenv import load_dotenv
load_dotenv()

print("="*60)
print("llama3.2:3b ëª¨ë¸ RAGAS ê°„ë‹¨ í…ŒìŠ¤íŠ¸")
print("="*60)
print()

# íŒ¨í‚¤ì§€ ì„í¬íŠ¸
from ragas.testset.generator import TestsetGenerator
from ragas.testset.evolutions import simple
from ragas.llms import LangchainLLMWrapper
from ragas.embeddings import LangchainEmbeddingsWrapper
from ragas.testset.extractor import KeyphraseExtractor
from ragas.testset.docstore import InMemoryDocumentStore

from langchain_ollama import ChatOllama
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_community.document_loaders import PDFPlumberLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter

# ============================================
# 1. LLM ì„¤ì •
# ============================================
print("1. LLM ì„¤ì • ì¤‘...")

generator_llm = ChatOllama(
    model="llama3.2:3b",                    # ìì—°ì–´ ëª¨ë¸ë¡œ êµì²´
    temperature=0.7,
    num_predict=512,
)

# ê°„ë‹¨ í…ŒìŠ¤íŠ¸
try:
    test = generator_llm.invoke("Say hello")
    print(f"    âœ… LLM ì‘ë™: {test.content[:30]}...")
except Exception as e:
    print(f"   âŒ ì—ëŸ¬: {e}")
    print("   ğŸ’¡ í™•ì¸: ollama list")
    print("   ğŸ’¡ ë‹¤ìš´ë¡œë“œ: ollama pull llama3.2:3b")
    exit(1)

print()

# ============================================
# 2. Embeddings
# ============================================
print("2. Embeddings ì„¤ì • ì¤‘...")
embeddings = HuggingFaceEmbeddings(
    model_name="BAAI/bge-small-en-v1.5",
    model_kwargs={'device': 'cpu'},
)
print("    âœ… ì™„ë£Œ")
print()

# ============================================
# 3. ë¬¸ì„œ ë¡œë“œ (3í˜ì´ì§€ë§Œ!)
# ============================================
print("3. ë¬¸ì„œ ë¡œë“œ ì¤‘...")
loader = PDFPlumberLoader("../data/SPRI_AI_Brief_2023ë…„12ì›”í˜¸_F.pdf")
docs = loader.load()[3:6]                       # 3í˜ì´ì§€ë§Œ

for doc in docs:
    doc.metadata["filename"] = doc.metadata["source"]

print(f"    âœ… {len(docs)}í˜ì´ì§€ ë¡œë“œ")
print()

# ============================================
# 4. DocumentStore
# ============================================
print("4. DocumentStore ì´ˆê¸°í™” ì¤‘...")

splitter = RecursiveCharacterTextSplitter(
    chunk_size=300,             # ì‚¬ì´ì¦ˆ ê°ì†Œ
    chunk_overlap=30            # ì˜¤ë²„ë© ê°ì†Œ
)

langchain_llm = LangchainLLMWrapper(generator_llm)
keyphrase_extractor = KeyphraseExtractor(llm=langchain_llm)
ragas_embeddings = LangchainEmbeddingsWrapper(embeddings)

docstore = InMemoryDocumentStore(
    splitter=splitter,
    embeddings=ragas_embeddings,
    extractor=keyphrase_extractor,
)

print("    âœ… ì™„ë£Œ")
print()

# ============================================
# 5. Generator
# ============================================
print("5. Generator ìƒì„± ì¤‘...")

generator = TestsetGenerator.from_langchain(
    generator_llm,
    generator_llm,
    ragas_embeddings,
    docstore=docstore,
)

print("    âœ… ì™„ë£Œ")
print()

# ============================================
# 6. ë¶„í¬
# ============================================
distributions = {
    simple: 1.0,  # 100% ê°„ë‹¨í•œ ì§ˆë¬¸
}

# ============================================
# 7. ìƒì„± (1ê°œë§Œ!)
# ============================================
print("="*60)
print("ğŸ”„ í…ŒìŠ¤íŠ¸ì…‹ ìƒì„± ì‹œì‘")
print("="*60)
print("ì˜ˆìƒ ì‹œê°„: 5-8ë¶„")
print("ë©ˆì¶° ë³´ì—¬ë„ ì •ìƒì…ë‹ˆë‹¤!")
print()

try:
    testset = generator.generate_with_langchain_docs(
        documents=docs,
        test_size=1,                        # 1ê°œë§Œ!
        distributions=distributions,
        with_debugging_logs=False,
        raise_exceptions=True,
    )
    
    # ============================================
    # 8. ê²°ê³¼
    # ============================================
    test_df = testset.to_pandas()
    
    if len(test_df) > 0:
        print()
        print("="*60)
        print("âœ…âœ…âœ… ì„±ê³µ! âœ…âœ…âœ…")
        print("="*60)
        print()
        
        for idx, row in test_df.iterrows():
            print(f"ì§ˆë¬¸: {row['question']}")
            print(f"ë‹µë³€: {row['ground_truth'][:80]}...")
            print()
        
        test_df.to_csv("data/.csv", index=False)
        # test_df.to_csv("data/ragas_synthetic_dataset_1.csv", index=False, encoding='utf-8-sig')
        # í˜¹ì€ ë°ì´í„° ê²½ë¡œ: "../data/agas_synthetic_dataset_1.csv"
        print("âœ… ì €ì¥: data/jay_success.csv")

        
    else:
        print("âŒ ì§ˆë¬¸ ìƒì„± ì‹¤íŒ¨")
        
except Exception as e:
    print()
    print("âŒ ì—ëŸ¬:")
    print(f"    {e}")
    print()
    print("ğŸ’¡ ë‚˜ì—ê²Œ ì—ëŸ¬ ë©”ì‹œì§€ ë³´ë‚´ì¤˜!")

print()
print("="*60)
print("âœ… í…ŒìŠ¤íŠ¸ì…‹ ìƒì„± ì™„ë£Œ")
print("="*60)


"""
============================================================
llama3.2:3b ëª¨ë¸ RAGAS ê°„ë‹¨ í…ŒìŠ¤íŠ¸
============================================================

1. LLM ì„¤ì • ì¤‘...
    âœ… LLM ì‘ë™: Hello! It's nice to meet you. ...

2. Embeddings ì„¤ì • ì¤‘...
    âœ… ì™„ë£Œ

3. ë¬¸ì„œ ë¡œë“œ ì¤‘...
    âœ… 3í˜ì´ì§€ ë¡œë“œ

4. DocumentStore ì´ˆê¸°í™” ì¤‘...
    âœ… ì™„ë£Œ

5. Generator ìƒì„± ì¤‘...
    âœ… ì™„ë£Œ

============================================================
ğŸ”„ í…ŒìŠ¤íŠ¸ì…‹ ìƒì„± ì‹œì‘
============================================================
ì˜ˆìƒ ì‹œê°„: 5-8ë¶„
ë©ˆì¶° ë³´ì—¬ë„ ì •ìƒì…ë‹ˆë‹¤!

# embedding nodes:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 34/36 [04:09<00:39, 19.87s/it]

# Generating:   0%|                                                                                                    | 0/1 [00:00<?, ?it/s]

============================================================
âœ…âœ…âœ… ì„±ê³µ! âœ…âœ…âœ…
============================================================

ì§ˆë¬¸: context: "n \uc8fc\uc694 7\uac1c\uad6d(G7)*\uc740 2023\ub144 10\uc6d4 30\uc77c \u201â€™\ud788\ub85c\uc2dc\ub9c8 AI \ud504\ub85c\uc138\uc2a4â€™s\ud97c \ud1b5\ud574 AI \uae30\uc5c5 \ub300\uc0c1\uc758 AI \uad6d\uc81c\n\ud589\ub3d9\uac15\ub839(International Code of Conduct for Advanced AI Systems)\uc5d0 \ud569\uc758\n\u2219 G7\uc740 2023\ub144 5\uc6d4 \uc77c\ubcf8 \ud788\ub85c\uc2dc\ub9c8\uc5d0\uc11c \uac1c\ucd5c\ub41c \uc815\uc0c1\ud68c\uc758\uc5d0\uc11c \uc0dd\uc131 AI\uc5d0 \uad00\ud55c \uad6d\uc81c\uaddc\ubc94 \ub9c8\ub828\acfc\n\uc815\ubcf4\uacf5\uc720\ub97c \uc704\ud574 \u201â€™\ud788\ub85c\uc2dc\ub9c8 AI \ud504\ub85c\uc138\uc2a4â€™s\ud97c \ucd9c\ubc94**\n\u2219 \uae30\uc5c5\uc758 \uc790\ubc1c\uc801 \ucc44\ud0dd\uc744 \uc704\ud574 \ub9c8\ub828\ub41c \uc774\ubc88 \ud589\ub3d9\uac15\ub839\uc740 \uae30\ubc18\ubaa8\ub378\acfc \uc0dd\uc131 AI\ud97c \ud3ec\ud568\ud55c \ucca8\ub2e8 AI \uc2dc\uc2a4\ud15c\uc758\n\uc704\ud5d8 \uc2dd\ubcc4\uacfc \uc644\ud654\uc5d
ë‹µë³€: The answer to given question is not present in context...


âŒ ì—ëŸ¬:
    Cannot save file into a non-existent directory: 'data'

ğŸ’¡ ë‚˜ì—ê²Œ ì—ëŸ¬ ë©”ì‹œì§€ ë³´ë‚´ì¤˜!

============================================================
âœ… í…ŒìŠ¤íŠ¸ì…‹ ìƒì„± ì™„ë£Œ
============================================================



"""