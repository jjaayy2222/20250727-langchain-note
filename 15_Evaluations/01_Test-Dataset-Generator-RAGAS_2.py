# 01_Test-Dataset-Generator-RAGAS_2.py

"""
RAGAS í…ŒìŠ¤íŠ¸ì…‹ ìƒì„± - ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ìš©
"""

import os
import warnings
warnings.filterwarnings("ignore")
os.environ["TOKENIZERS_PARALLELISM"] = "false"

from dotenv import load_dotenv
load_dotenv()

print("="*60)
print("llama3.2:3b ëª¨ë¸ RAGAS ê°„ë‹¨ í…ŒìŠ¤íŠ¸")
print("="*60)
print()

print("ğŸ”§ RAGAS ì´ˆê¸°í™” ì¤‘...\n")

from ragas.testset.generator import TestsetGenerator
from ragas.testset.evolutions import simple, reasoning
from ragas.llms import LangchainLLMWrapper
from ragas.embeddings import LangchainEmbeddingsWrapper
from ragas.testset.extractor import KeyphraseExtractor
from ragas.testset.docstore import InMemoryDocumentStore

from langchain_ollama import ChatOllama
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_community.document_loaders import PDFPlumberLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter

# 1. LLM ì„¤ì • (ì˜¨ë„ 0.1ë¡œ ì¡°ê¸ˆ ë†’ì„ - ë” ì•ˆì •ì )
print("1. LLM ì„¤ì • ì¤‘...")

generator_llm = ChatOllama(
    model="llama3.2:3b",                    # ìì—°ì–´ ëª¨ë¸ë¡œ êµì²´
    temperature=0.7,
    num_predict=512,
)

critic_llm = ChatOllama(
    model="llama3.2:3b",
    temperature=0.1,
    num_predict=512,
)

# ê°„ë‹¨ í…ŒìŠ¤íŠ¸
try:
    test = generator_llm.invoke("Say hello")
    print(f"    âœ… LLM ì‘ë™: {test.content[:30]}...")
except Exception as e:
    print(f"   âŒ ì—ëŸ¬: {e}")
    print("   ğŸ’¡ í™•ì¸: ollama list")
    print("   ğŸ’¡ ë‹¤ìš´ë¡œë“œ: ollama pull llama3.2:3b")
    exit(1)


print("    âœ… Ollama LLM ì„¤ì • ì™„ë£Œ")
print()


# 2. Embeddings ì„¤ì •
print("2. Embeddings ì„¤ì • ì¤‘...")

embeddings = HuggingFaceEmbeddings(
    model_name="BAAI/bge-small-en-v1.5",
    model_kwargs={'device': 'cpu'},
    encode_kwargs={'normalize_embeddings': True}
)

print("    âœ… ì™„ë£Œ")
print()


# 3. ë¬¸ì„œ ë¡œë“œ
print("3. ë¬¸ì„œ ë¡œë“œ ì¤‘...")
loader = PDFPlumberLoader("data/SPRI_AI_Brief_2023ë…„12ì›”í˜¸_F.pdf")
docs = loader.load()
docs = docs[3:8]                            # 5í˜ì´ì§€ë§Œ!

# metadata ì„¤ì •
for doc in docs:
    doc.metadata["filename"] = doc.metadata["source"]

print(f"    âœ… {len(docs)}í˜ì´ì§€ ë¡œë“œ")
print()


# 4. DocumentStore ì´ˆê¸°í™”
print("4. DocumentStore ì´ˆê¸°í™” ì¤‘...")

splitter = RecursiveCharacterTextSplitter(
    #chunk_size=800,            # ì¡°ê¸ˆ ì¤„ì„
    #chunk_size=400,            # ë” ì‘ê²Œ ì¡°ì ˆ
    #chunk_overlap=50 
    chunk_size=300,             # ì‚¬ì´ì¦ˆ ê°ì†Œ
    chunk_overlap=30            # ì˜¤ë²„ë© ê°ì†Œ
)

langchain_llm = LangchainLLMWrapper(generator_llm)
keyphrase_extractor = KeyphraseExtractor(llm=langchain_llm)
ragas_embeddings = LangchainEmbeddingsWrapper(embeddings)

docstore = InMemoryDocumentStore(
    splitter=splitter,
    embeddings=ragas_embeddings,
    extractor=keyphrase_extractor,
)

print("    âœ… ì™„ë£Œ")
print()


# 5. TestsetGenerator ìƒì„±
print("5. Generator ìƒì„± ì¤‘...")

generator = TestsetGenerator.from_langchain(
    generator_llm,
    critic_llm,
    ragas_embeddings,
    docstore=docstore,
)

print("    âœ… ì™„ë£Œ")
print()


# 6. ë¶„í¬ (ê°„ë‹¨í•˜ê²Œ!)
distributions = {
    simple: 0.7,      # 70%
    reasoning: 0.3,   # 30%
}


# 7. ìƒì„± (2ê°œë§Œ!)
print("="*60)
print("ğŸ”„ í…ŒìŠ¤íŠ¸ì…‹ ìƒì„± ì‹œì‘")
print("="*60)
print("ğŸ”„ í…ŒìŠ¤íŠ¸ì…‹ ìƒì„± ì¤‘... (ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)")
print("    - ë¶„í¬: ê°„ë‹¨(70%), ì¶”ë¡ (30%)\n")
print("ğŸ”„ ë©ˆì¶° ë³´ì—¬ë„ ì •ìƒì…ë‹ˆë‹¤! ğŸ”„ ")
print("="*60)
print()

try:
    testset = generator.generate_with_langchain_docs(
        documents=docs,
        test_size=2,                        # 2ê°œë§Œ
        distributions=distributions,
        with_debugging_logs=False,          # ë¡œê·¸ ë¹„í™œì„±í™”
        raise_exceptions=False,             # ì—ëŸ¬ ë¬´ì‹œ
    )
    
    # 8. ê²°ê³¼ ì €ì¥
    test_df = testset.to_pandas()
    test_df.to_csv("data/ragas_synthetic_dataset_2.csv", index=False, encoding='utf-8-sig')
    
    if len(test_df) > 0:
        print()
        print("="*60)
        print("âœ…âœ…âœ… ì„±ê³µ! âœ…âœ…âœ…")
        print("="*60)
        print()
        
        for idx, row in test_df.iterrows():
            print(f"ì§ˆë¬¸: {row['question']}")
            print(f"ë‹µë³€: {row['ground_truth'][:80]}...")
            print()
        
        #test_df.to_csv("data/.csv", index=False, encoding='utf-8-sig')
        #test_df.to_csv("data/ragas_synthetic_dataset_2.csv", index=False, encoding='utf-8-sig')
        print("âœ… ì €ì¥: data/ragas_synthetic_dataset_2.csv")

    else:
        print("âŒ ì§ˆë¬¸ ìƒì„± ì‹¤íŒ¨")

    print()
    print("="*60)  
    print(f"\nâœ… í…ŒìŠ¤íŠ¸ì…‹ ìƒì„± ì™„ë£Œ!")
    print(f"   - ìƒì„±ëœ ì§ˆë¬¸ ìˆ˜: {len(test_df)}")
    print(f"   - ì €ì¥ ìœ„ì¹˜: ../15_Evaluations/data/ragas_synthetic_dataset.csv\n")
    print(test_df)
    
    # 9. ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°
    print("ğŸ“Š ìƒì„±ëœ ì§ˆë¬¸ ë¯¸ë¦¬ë³´ê¸°:")
    print("="*80)
    for idx, row in test_df.iterrows():
        print(f"\nì§ˆë¬¸ {idx+1}:")
        print(f"  {row['question']}")
        print(f"  Ground Truth: {row['ground_truth'][:100]}...")
    
except Exception as e:
    print(f"âŒ ì—ëŸ¬ ë°œìƒ: {e}")
    print("\nğŸ’¡ í•´ê²° ë°©ë²•:")
    print("    1. Ollamaê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸")
    print("    2. ëª¨ë¸ ë‹¤ìš´ë¡œë“œ: ollama pull llama3.2:3b")
    print("    3. langchain-ollama ë²„ì „ í™•ì¸: pip list | grep langchain-ollama")
    print("        â†’ 0.1.3ì´ì–´ì•¼ í•¨!")

print("\nâœ… ì •ìƒì ìœ¼ë¡œ í…ŒìŠ¤íŠ¸ì…‹ ìƒì„± ì™„ë£Œ!")


"""
try_1
    ğŸ”§ RAGAS ì´ˆê¸°í™” ì¤‘...

    âœ… Ollama LLM ì„¤ì • ì™„ë£Œ
    âœ… Embeddings ì„¤ì • ì™„ë£Œ
    âœ… ë¬¸ì„œ ë¡œë“œ ì™„ë£Œ: 5í˜ì´ì§€

    âœ… TestsetGenerator ìƒì„± ì™„ë£Œ

    ğŸ”„ ì‹œì‘... (10ë¶„ ì˜ˆìƒ)
    ğŸ”„ í…ŒìŠ¤íŠ¸ì…‹ ìƒì„± ì¤‘... (ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)
        - ë¶„í¬: ê°„ë‹¨(70%), ì¶”ë¡ (30%)
        
    # embedding nodes:  37%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                             | 17/46 [00:33<01:46,  3.68s/it]
    # embedding nodes:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ         | 40/46 [06:56<02:35, 25.91s/it]
    # embedding nodes:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 45/46 [09:26<00:29, 29.29s/it]

    # Generating:   0%|                                                                                       | 0/2 [00:00<?, ?it/s]
    # Generating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                       | 1/2 [06:24<06:24, 384.85s/it]

    Generating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                       | 1/2 [06:24<06:24, 384.85s/itFailed to parse output. Returning None.
    â†³ ë©ˆì¶¤ â†’ ê°•ì œì¢…ë£Œ    

"""

""" 
try_2

============================================================
llama3.2:3b ëª¨ë¸ RAGAS ê°„ë‹¨ í…ŒìŠ¤íŠ¸
============================================================

ğŸ”§ RAGAS ì´ˆê¸°í™” ì¤‘...

1. LLM ì„¤ì • ì¤‘...
    âœ… LLM ì‘ë™: Hello! It's nice to meet you. ...
    âœ… Ollama LLM ì„¤ì • ì™„ë£Œ

2. Embeddings ì„¤ì • ì¤‘...
    âœ… ì™„ë£Œ

3. ë¬¸ì„œ ë¡œë“œ ì¤‘...
    âœ… 5í˜ì´ì§€ ë¡œë“œ

4. DocumentStore ì´ˆê¸°í™” ì¤‘...
    âœ… ì™„ë£Œ

5. Generator ìƒì„± ì¤‘...
    âœ… ì™„ë£Œ

============================================================
ğŸ”„ í…ŒìŠ¤íŠ¸ì…‹ ìƒì„± ì‹œì‘
============================================================
ğŸ”„ í…ŒìŠ¤íŠ¸ì…‹ ìƒì„± ì¤‘... (ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)
    - ë¶„í¬: ê°„ë‹¨(70%), ì¶”ë¡ (30%)

ğŸ”„ ë©ˆì¶° ë³´ì—¬ë„ ì •ìƒì…ë‹ˆë‹¤! ğŸ”„ 
============================================================

# embedding nodes:  26%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                            | 15/58 [00:44<03:09,  4.40s/it
# embedding nodes:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                     | 43/58 [04:51<02:06,  8.45s/it]
# embedding nodes:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–     | 54/58 [09:42<01:50, 27.70s/it]

# Generating:   0%|                                                                                                 | 0/2 [00:00<?, ?it/s]
# Generating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                            | 1/2 [07:46<07:46, 466.04s/it]

Generating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [22:33<00:00, 676.72s/it]

============================================================
âœ…âœ…âœ… ì„±ê³µ! âœ…âœ…âœ…
============================================================

ì§ˆë¬¸: Here is a question that can be fully answered from the given context:

"What does 'FTC' stand for in the provided text?"

This question can be answered by referring to the key phrase "KEY Contents\nn \ubbf8\uad6d FTC..." in the context, which explicitly states what "FTC" stands for.
ë‹µë³€: FTC...

ì§ˆë¬¸: The goal is to create a rewritten question that conveys the same meaning as "What type of AI does the Federal Trade Commission possess?" without directly stating it.

Here's a revised version:

"What kind of AI system does the FTC use?"

This rewritten question achieves the same intent as the original but in a more concise and indirect manner, using abbreviation ("FTC" instead of "Federal Trade Commission") to make the question shorter.
ë‹µë³€: The Federal Trade Commission uses artificial intelligence primarily for regulati...

âœ… ì €ì¥: data/ragas_synthetic_dataset_2.csv

============================================================

âœ… í…ŒìŠ¤íŠ¸ì…‹ ìƒì„± ì™„ë£Œ!
    - ìƒì„±ëœ ì§ˆë¬¸ ìˆ˜: 2
    - ì €ì¥ ìœ„ì¹˜: ../15_Evaluations/data/ragas_synthetic_dataset.csv

                                            question  ... episode_done
0  Here is a question that can be fully answered ...  ...         True
1  The goal is to create a rewritten question tha...  ...         True

[2 rows x 6 columns]
ğŸ“Š ìƒì„±ëœ ì§ˆë¬¸ ë¯¸ë¦¬ë³´ê¸°:
================================================================================

ì§ˆë¬¸ 1:
  Here is a question that can be fully answered from the given context:

"What does 'FTC' stand for in the provided text?"

This question can be answered by referring to the key phrase "KEY Contents\nn \ubbf8\uad6d FTC..." in the context, which explicitly states what "FTC" stands for.
  Ground Truth: FTC...

ì§ˆë¬¸ 2:
  The goal is to create a rewritten question that conveys the same meaning as "What type of AI does the Federal Trade Commission possess?" without directly stating it.

Here's a revised version:

"What kind of AI system does the FTC use?"

This rewritten question achieves the same intent as the original but in a more concise and indirect manner, using abbreviation ("FTC" instead of "Federal Trade Commission") to make the question shorter.
  Ground Truth: The Federal Trade Commission uses artificial intelligence primarily for regulating privacy, trademar...

âœ… ì •ìƒì ìœ¼ë¡œ í…ŒìŠ¤íŠ¸ì…‹ ìƒì„± ì™„ë£Œ!

"""
