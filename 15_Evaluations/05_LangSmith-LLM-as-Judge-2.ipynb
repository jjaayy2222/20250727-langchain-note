{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "574f6502",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf366bf9",
   "metadata": {},
   "source": [
    "* 출처: LangChain 공식 문서 또는 해당 교재명\n",
    "* 원본 URL: https://smith.langchain.com/hub/teddynote/summary-stuff-documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31f7552",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af770941",
   "metadata": {},
   "source": [
    "### **5. `05. LLM-as-Judge`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb2944b",
   "metadata": {},
   "source": [
    "#### **2) `Question-Answer Evaluator`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300b2621",
   "metadata": {},
   "source": [
    "* 가장 기본 기능을 가진 `Evaluator` = `Query` - `Answer` 평가하기\n",
    "\n",
    "* 사용자 입력 = `input` → `LLM`이 생성한 답변 → `prediction`으로 정답 답변은 `reference`로 정의됨\n",
    "\n",
    "  * `Prompt`변수 \n",
    "    * `query`: 질문\n",
    "    * `result`: `LLM` 답변\n",
    "    * `answer`: 정답 답변"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213e7ff9",
   "metadata": {},
   "source": [
    "* **새로운 가상환경 생성 - `lc_eval_env`**\n",
    "\n",
    "  * `Python-3.12`\n",
    "  * `Pydantic`: `ver 1.10.18`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa96e875",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydantic\n",
    "print(f\"Pydantic 버전: {pydantic.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0a0018",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* **`Pydantic 버전: 1.10.18`** - (`0.1s`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f802a885",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb9c7b9",
   "metadata": {},
   "source": [
    "* **`환경 설정`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acf7ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API 키를 환경변수로 관리하기 위한 설정 파일\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API 키 정보 로드\n",
    "load_dotenv()                           # True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d33436",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import Client\n",
    "from langsmith import traceable\n",
    "\n",
    "import os\n",
    "\n",
    "# LangSmith 환경 변수 확인\n",
    "\n",
    "print(\"\\n--- LangSmith 환경 변수 확인 ---\")\n",
    "langchain_tracing_v2 = os.getenv('LANGCHAIN_TRACING_V2')\n",
    "langchain_project = os.getenv('LANGCHAIN_PROJECT')\n",
    "langchain_api_key_status = \"설정됨\" if os.getenv('LANGCHAIN_API_KEY') else \"설정되지 않음\" # API 키 값은 직접 출력하지 않음\n",
    "\n",
    "if langchain_tracing_v2 == \"true\" and os.getenv('LANGCHAIN_API_KEY') and langchain_project:\n",
    "    print(f\"✅ LangSmith 추적 활성화됨 (LANGCHAIN_TRACING_V2='{langchain_tracing_v2}')\")\n",
    "    print(f\"✅ LangSmith 프로젝트: '{langchain_project}'\")\n",
    "    print(f\"✅ LangSmith API Key: {langchain_api_key_status}\")\n",
    "    print(\"  -> 이제 LangSmith 대시보드에서 이 프로젝트를 확인해 보세요.\")\n",
    "else:\n",
    "    print(\"❌ LangSmith 추적이 완전히 활성화되지 않았습니다. 다음을 확인하세요:\")\n",
    "    if langchain_tracing_v2 != \"true\":\n",
    "        print(f\"  - LANGCHAIN_TRACING_V2가 'true'로 설정되어 있지 않습니다 (현재: '{langchain_tracing_v2}').\")\n",
    "    if not os.getenv('LANGCHAIN_API_KEY'):\n",
    "        print(\"  - LANGCHAIN_API_KEY가 설정되어 있지 않습니다.\")\n",
    "    if not langchain_project:\n",
    "        print(\"  - LANGCHAIN_PROJECT가 설정되어 있지 않습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3cee3b",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 셀 출력\n",
    "\n",
    "    ```bash\n",
    "    --- LangSmith 환경 변수 확인 ---\n",
    "    ✅ LangSmith 추적 활성화됨 (LANGCHAIN_TRACING_V2='true')\n",
    "    ✅ LangSmith 프로젝트: 'LangChain-prantice'\n",
    "    ✅ LangSmith API Key: 설정됨\n",
    "    -> 이제 LangSmith 대시보드에서 이 프로젝트를 확인해 보세요.\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c37fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from myrag import PDFRAG                        # local 임베딩 버전으로 수정한 myrag.py 불러오기\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "# API 키 확인\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "GOOGLE_API_KEY=os.getenv(\"GOOGLE_API_KEY2\")\n",
    "\n",
    "if not os.getenv(\"GOOGLE_API_KEY2\"):\n",
    "    os.environ[\"GOOGLE_API_KEY2\"] = input(\"Enter your GOOGLE_API_KEY2: \")\n",
    "\n",
    "if \"GOOGLE_API_KEY2\" not in os.environ:\n",
    "    print(\"❌ 경고: GOOGLE_API_KEY2 환경 변수가 설정되지 않았습니다. 반드시 설정해야 gemini LLM이 작동합니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0a2b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm2 = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash-lite\", temperature=0, api_key=os.getenv(\"GOOGLE_API_KEY2\"))\n",
    "\n",
    "print(\"✅ gemini-2.5-flash-lite 성공!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95081584",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* **`✅ 성공!`** \n",
    "\n",
    "  * *`API 할당량 부족으로 두번쨰 계정으로 다시 시도`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c51b692",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm2 = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash-lite\", temperature=0, api_key=os.getenv(\"GOOGLE_API_KEY2\"))\n",
    "\n",
    "rag = PDFRAG(\n",
    "    \"../15_Evaluations/data/SPRI_AI_Brief_2023년12월호_F.pdf\",\n",
    "    llm2,\n",
    ")\n",
    "\n",
    "print(\"✅ PDFRAG 생성 성공!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8dd84b",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* **`PDFRAG 생성`** - (`4.9s`)\n",
    "\n",
    "    ```markdown\n",
    "\n",
    "    ✅ 문서 로드 완료: 23개 페이지\n",
    "    ✅ 문서 분할 완료: 43개 청크\n",
    "    ✅ 임베딩 모델 로드: all-MiniLM-L6-v2\n",
    "    ✅ 벡터스토어 생성 완료\n",
    "    ✅ PDFRAG 생성 성공!\n",
    "\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d43340c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검색기(retriever) 생성\n",
    "retriever = rag.create_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344ce808",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* **`✅ 검색기 생성 완료 (k=4)`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9d8a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 체인(chain) 생성\n",
    "chain = rag.create_chain(retriever)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04637af",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* **`✅ RAG 체인 생성 완료`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869c8197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질문\n",
    "answer = chain.invoke(\"삼성전자가 자체 개발한 생성형 AI의 이름은 무엇인가요?\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f68a2e",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* **`삼성전자가 자체 개발한 생성형 AI의 이름은 '삼성 가우스'입니다.`** - (`2.0s`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47c2bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질문에 대한 답변하는 함수를 생성\n",
    "def ask_question(inputs: dict):\n",
    "    return {\"answer\": chain.invoke(inputs[\"question\"])}\n",
    "\n",
    "# 사용자 질문 예시\n",
    "llm_answer = ask_question(\n",
    "    {\"question\": \"삼성전자가 자체 개발한 생성형 AI의 이름은 무엇인가요?\"}\n",
    ")\n",
    "\n",
    "llm_answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0efe342",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* **`ask_question()`** - (`1.2s`)\n",
    "\n",
    "    ```python\n",
    "\n",
    "        {'answer': \"삼성전자가 자체 개발한 생성형 AI의 이름은 '삼성 가우스'입니다.\"}\n",
    "\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747018bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluator prompt 출력을 위한 함수\n",
    "def print_evaluator_prompt(evaluator):\n",
    "    return evaluator.evaluator.prompt.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf06b760",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith.evaluation import evaluate, LangChainStringEvaluator\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "# qa 평가자 생성\n",
    "qa_evalulator = LangChainStringEvaluator(\n",
    "    \"qa\",\n",
    "    config={\n",
    "        \"llm\":ChatGoogleGenerativeAI(\n",
    "            model=\"gemini-2.5-flash-lite\", \n",
    "            temperature=0, \n",
    "            google_api_key=os.getenv(\"GOOGLE_API_KEY2\"))\n",
    "        }\n",
    ")\n",
    "\n",
    "# 프롬프트 출력\n",
    "print_evaluator_prompt(qa_evalulator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafb79c3",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* **`qa_evaluator`** - (`0.1s`)\n",
    "\n",
    "    ```markdown\n",
    "\n",
    "    You are a teacher grading a quiz.\n",
    "    You are given a question, the student's answer, and the true answer, and are asked to score the student answer as either CORRECT or INCORRECT.\n",
    "\n",
    "    Example Format:\n",
    "    QUESTION: question here\n",
    "    STUDENT ANSWER: student's answer here\n",
    "    TRUE ANSWER: true answer here\n",
    "    GRADE: CORRECT or INCORRECT here\n",
    "\n",
    "    Grade the student answers based ONLY on their factual accuracy. Ignore differences in punctuation and phrasing between the student answer and true answer. It is OK if the student answer contains more information than the true answer, as long as it does not contain any conflicting statements. Begin! \n",
    "\n",
    "    QUESTION: *{query}*\n",
    "    STUDENT ANSWER: *{result}*\n",
    "    TRUE ANSWER: *{answer}*\n",
    "    GRADE:\n",
    "\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54472586",
   "metadata": {},
   "source": [
    "* **`평가 진행` → 출력한 `URL` 이동 → `결과 확인하기`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448b0dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"RAG_EVAL_DATASET\"\n",
    "\n",
    "# 평가 실행\n",
    "experiment_results = evaluate(\n",
    "    ask_question,\n",
    "    data=dataset_name,\n",
    "    evaluators=[qa_evalulator],\n",
    "    experiment_prefix=\"RAG_EVAL\",\n",
    "    # 실험 메타데이터 지정\n",
    "    metadata={\n",
    "        \"variant\": \"QA Evaluator 를 활용한 평가\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992242c1",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 결과 확인하기\n",
    "\n",
    "  * `RAG_EVAL` / *`COMPILED`* - (*`45s`*)\n",
    "  * ![`RAG_EVAL_COMPILED`](../15_Evaluations/assets/RAG_EVAL_1.png)\n",
    "\n",
    "  * \n",
    "\n",
    "  * `RAG_EVAL` / *`CORRECT=1`, `INCORRECT=4`* - (*`7.8s`*)\n",
    "  * ![`RAG_EVAL_MORE_INCORRECT`](../15_Evaluations/assets/RAG_EVAL_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa2a070",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1775b968",
   "metadata": {},
   "source": [
    "* **`RAG`** 시스템 개선하기\n",
    "\n",
    "  * **a. `Retriever` 개선하기**\n",
    "  * **b. `Chunk Size` 조정하기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96641657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# Chunk Size 조정\n",
    "# ========================================\n",
    "from myrag2 import PDFRAG\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv() \n",
    "\n",
    "# Chunk Size 조정\n",
    "rag2 = PDFRAG(\n",
    "    \"../15_Evaluations/data/SPRI_AI_Brief_2023년12월호_F.pdf\",\n",
    "    ChatGoogleGenerativeAI(\n",
    "        model=\"gemini-2.0-flash-lite\", \n",
    "        temperature=0, \n",
    "        google_api_key=os.getenv(\"GOOGLE_API_KEY2\")),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b022410",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* **`rag2 생성`** - (`12.2s`)\n",
    "\n",
    "    ```mardkwon\n",
    "\n",
    "    ✅ 문서 로드 완료: 23개 페이지\n",
    "    ✅ 문서 분할 완료: 72개 청크\n",
    "    ✅ 임베딩 모델 로드: all-MiniLM-L6-v2\n",
    "    ✅ 벡터스토어 생성 완료\n",
    "\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0b0126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# Top-K 증가\n",
    "# ========================================\n",
    "\n",
    "# 개선\n",
    "retriever2 = rag2.create_retriever()        # myrag2.py 불러오기\n",
    "\n",
    "# 체인 재생성\n",
    "chain2 = rag2.create_chain(retriever2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad59bb6c",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* **`✅ 검색기 생성 완료`**\n",
    "\n",
    "* **`✅ RAG 체인 생성 완료`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e94e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질문에 대한 답변 생성\n",
    "chain2.invoke(\"삼성전자가 자체 개발한 생성형 AI의 이름은 무엇인가요?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24623124",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* **`'삼성전자가 자체 개발한 생성형 AI의 이름은 제공된 문서에서 찾을 수 없습니다.'`** - (`1.4s`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b1ec0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질문에 대한 답변하는 함수를 생성\n",
    "def ask_question(inputs: dict):\n",
    "    return {\"answer\": chain2.invoke(inputs[\"question\"])}\n",
    "\n",
    "# 사용자 질문 예시\n",
    "llm_answer = ask_question(\n",
    "    {\"question\": \"삼성전자가 자체 개발한 생성형 AI의 이름은 무엇인가요?\"}\n",
    ")\n",
    "\n",
    "llm_answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d3d51e",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* **`ask_question()`** - (`1.3s`)\n",
    "\n",
    "    ```python\n",
    "\n",
    "    {'answer': '삼성전자가 자체 개발한 생성형 AI의 이름은 제공된 문서에서 찾을 수 없습니다.'}\n",
    "\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7798a392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluator prompt 출력을 위한 함수\n",
    "def print_evaluator_prompt(evaluator):\n",
    "    return evaluator.evaluator.prompt.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31c0c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith.evaluation import evaluate, LangChainStringEvaluator\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "\n",
    "# qa 평가자 생성\n",
    "qa_evalulator = LangChainStringEvaluator(\n",
    "    \"qa\",\n",
    "    config={\n",
    "        \"llm\":ChatGoogleGenerativeAI(\n",
    "            model=\"gemini-2.5-flash-lite\", \n",
    "            temperature=0, \n",
    "            google_api_key=os.getenv(\"GOOGLE_API_KEY2\"))\n",
    "        }\n",
    ")\n",
    "\n",
    "\n",
    "# 프롬프트 출력\n",
    "print_evaluator_prompt(qa_evalulator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45ec6e2",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* **`qa_evaluator`**\n",
    "\n",
    "    ```markdown\n",
    "\n",
    "    You are a teacher grading a quiz.\n",
    "    You are given a question, the student's answer, and the true answer, and are asked to score the student answer as either CORRECT or INCORRECT.\n",
    "\n",
    "    Example Format:\n",
    "    QUESTION: question here\n",
    "    STUDENT ANSWER: student's answer here\n",
    "    TRUE ANSWER: true answer here\n",
    "    GRADE: CORRECT or INCORRECT here\n",
    "\n",
    "    Grade the student answers based ONLY on their factual accuracy. Ignore differences in punctuation and phrasing between the student answer and true answer. It is OK if the student answer contains more information than the true answer, as long as it does not contain any conflicting statements. Begin! \n",
    "\n",
    "    QUESTION: *{query}*\n",
    "    STUDENT ANSWER: *{result}*\n",
    "    TRUE ANSWER: *{answer}*\n",
    "    GRADE:\n",
    "\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec610bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"RAG_EVAL_DATASET\"\n",
    "\n",
    "# 평가 실행\n",
    "experiment_results = evaluate(\n",
    "    ask_question,\n",
    "    data=dataset_name,\n",
    "    evaluators=[qa_evalulator],\n",
    "    experiment_prefix=\"RAG_EVAL_2\",\n",
    "    # 실험 메타데이터 지정\n",
    "    metadata={\n",
    "        \"variant\": \"myrag2.py 반영\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2154ce",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* **개선 시도: `RAG_EVAL_2`**\n",
    "\n",
    "  ```bash\n",
    "\n",
    "  View the evaluation results for experiment: 'RAG_EVAL_2-00c422bd' at:\n",
    "  https://smith.langchain.com/o/2c3342d3-1170-4ffa-86fd-f621199e0b9c/datasets/420dd308-2ebd-44c9-8ce8-9aff3886dc8e/compare?selectedSessions=cfb85525-ad18-4c76-9e47-4b2c1beb95fa\n",
    "\n",
    "\n",
    "  0it [00:00, ?it/s]\n",
    "\n",
    "  5it [00:04,  1.12it/s]\n",
    "\n",
    "  ```\n",
    "\n",
    "* 결과 확인하기\n",
    "\n",
    "<br>\n",
    "\n",
    "* \n",
    "  * `RAG_EVAL` / *`CORRECT=2`, `INCORRECT=3`* - (*`7.3s`*)\n",
    "  * ![`RAG_EVAL_MORE_INCORRECT`](../15_Evaluations/assets/RAG_EVAL_3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9620d711",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc52808b",
   "metadata": {},
   "source": [
    "* **`RAG`** 시스템 개선하기_2\n",
    "\n",
    "  * **c. `chunk_size` 조정**\n",
    "  * **d. 잦은 커널 충돌 → `python` 파일로 실행하기**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a7f716",
   "metadata": {},
   "source": [
    "* c.\n",
    "\n",
    "  * `chunck_size` 조절 test\n",
    "    * **`chunk_size` 지정 ❌** or **`chunk_size` = `4` → 검색 결과 없음**\n",
    "      * *`'죄송합니다. 제공된 문서에서 삼성전자가 자체 개발한 생성형 AI의 이름에 대한 정보를 찾을 수 없습니다.'`*\n",
    "\n",
    "    * **`chunk_size` = `7` → 검색 결과 ⭕️**\n",
    "      * *`\"삼성전자가 자체 개발한 생성형 AI의 이름은 '삼성 가우스'입니다.\"`*\n",
    "\n",
    "  * [**`myrag4.py`**](../15_Evaluations/myrag4.py)로 정리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8482815d",
   "metadata": {},
   "source": [
    "* d.\n",
    "  * **`잦은 커널 충돌로 인한 문제` → `python` 파일로 실행 → 터미널에서 직접 확인하기**\n",
    "\n",
    "  * [**`eval_script.py`**](../15_Evaluations/eval_script.py) 실행 → 터미널에서 결과 바로 확인\n",
    "\n",
    "  * ![`RAG_EVAL_4`](../15_Evaluations/assets/RAG_EVAL_4.png)\n",
    "\n",
    "<small>\n",
    "\n",
    "```bash\n",
    "\n",
    "      (가상환경)/15_Evaluations/eval_script.py\n",
    "\n",
    "      🚀 RAG 시스템 초기화 시작...\n",
    "\n",
    "      📂 스크립트 위치: ... /15_Evaluations\n",
    "\n",
    "      📄 PDF 경로: ... /data/SPRI_AI_Brief_2023년12월호_F.pdf\n",
    "\n",
    "      ✅ 파일 확인 완료!\n",
    "\n",
    "      ✅ LLM 생성 완료: gemini-2.5-flash-lite\n",
    "\n",
    "      ✅ PDF 로드 완료: 23 페이지\n",
    "\n",
    "      ✅ 청크 분할 완료: 119 청크 (크기=300, 오버랩=50)\n",
    "\n",
    "\n",
    "      ✅ LLM 생성 완료: gemini-2.5-flash-lite\n",
    "\n",
    "      ✅ 청크 분할 완료: 119 청크 (크기=300, 오버랩=50)\n",
    "      pytorch_model.bin: 100%|████████████████████████████████████████████████████████████████████| 2.27G/2.27G [00:03<00:00, 695MB/s]\n",
    "      tokenizer_config.json: 100%|███████████████████████████████████████████████████████████████████| 444/444 [00:00<00:00, 1.92MB/s]\n",
    "      sentencepiece.bpe.model: 100%|██████████████████████████████████████████████████████████████| 5.07M/5.07M [00:06<00:00, 781kB/s]\n",
    "      tokenizer.json: 100%|██████████████████████████████████████████████████████████████████████| 17.1M/17.1M [00:06<00:00, 2.70MB/s]\n",
    "      special_tokens_map.json: 100%|█████████████████████████████████████████████████████████████████| 964/964 [00:00<00:00, 3.61MB/s]\n",
    "      config.json: 100%|██████████████████████████████████████████████████████████████████████████████| 191/191 [00:00<00:00, 628kB/s]\n",
    "\n",
    "      ✅ 임베딩 모델 로드 완료: BAAI/bge-m3                                                                 | 0.00/191 [00:00<?, ?B/s]\n",
    "      model.safetensors:   0%|                                                                  | 2.19M/2.27G [00:24<1:26:03, 439kB/s]✅ 벡터스토어 생성 완료: FAISS\n",
    "\n",
    "      ✅ 검색기 생성 완료 (k=7, search_type=similarity)\n",
    "\n",
    "      ✅ RAG 체인 생성 완료\n",
    "\n",
    "      ==================================================\n",
    "      🧪 테스트 실행...\n",
    "      ==================================================\n",
    "\n",
    "      View the evaluation results for experiment: 'RAG_EVAL_K7-3a35bd45' at:\n",
    "      https://smith.langchain.com/o/2c3342d3-1170-4ffa-86fd-f621199e0b9c/datasets/420dd308-2ebd-44c9-8ce8-9aff3886dc8e/compare?selectedSessions=cdb9ea10-e3c1-47bc-bfe1-48f651364c28\n",
    "\n",
    "\n",
    "      5it [00:14,  2.90s/it]\n",
    "      5it [00:14,  2.18s/it]\n",
    "\n",
    "      ==================================================\n",
    "      ✅ 평가 완료!\n",
    "      ==================================================\n",
    "\n",
    "      결과: <ExperimentResults RAG_EVAL_K7-3a35bd45>\n",
    "\n",
    "      model.safetensors: 100%|███████████████████████████████████████████████████████████████████| 2.27G/2.27G [02:14<00:00, 16.9MB/s]\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f5e95d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06ace2f",
   "metadata": {},
   "source": [
    "* **`현재 상황 분석`**\n",
    "\n",
    "  | 항목 | 개수 | 정확도 |\n",
    "  |------|------|--------|\n",
    "  | **CORRECT** | 3/5 | 60% |\n",
    "  | **INCORRECT** | 2/5 | 40% |\n",
    "\n",
    "<br>\n",
    "\n",
    "* 진전\n",
    "  * 이전: 1/5 (20%)\n",
    "  * 현재: 3/5 (60%)\n",
    "  * **향상: +200%!**\n",
    "\n",
    "<br>\n",
    "\n",
    "* **`RAG` 평가**\n",
    "\n",
    "  * 어려움\n",
    "\n",
    "    | 이유 | 설명 |\n",
    "    |------|------|\n",
    "    | **초기 정확도** | 20-40%는 정상 |\n",
    "    | **반복 개선** | 60% → 80% → 90%로 점진적 향상 |\n",
    "    | **완벽은 없음** | 100%는 거의 불가능 |\n",
    "\n",
    "<br>\n",
    "\n",
    "* \n",
    "\n",
    "  * 현재 단계\n",
    "\n",
    "    ```markdown\n",
    "        일반적인 RAG 평가 발전:\n",
    "\n",
    "        1단계: 20-40% (초기)\n",
    "        2단계: 50-60% (개선 후)  ←  여기!\n",
    "        3단계: 70-80% (최적화)\n",
    "        4단계: 80-90% (완성)\n",
    "    ```\n",
    "\n",
    "<br>\n",
    "\n",
    "* **`향상 방법`**\n",
    "\n",
    "  * **a. `k값 증가`**\n",
    "\n",
    "  * **b. `chunk_size` 조정하기**\n",
    "\n",
    "  * **c. `프롬프트 개선하기`**\n",
    "\n",
    "  * **d. `다른 임베딩 모델 시도하기`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77e6d4d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3db68a",
   "metadata": {},
   "source": [
    "#### **3) `LangSmith 테스트를 위한 Dataset 생성`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb905c0",
   "metadata": {},
   "source": [
    "* **`Dataset & Testing`에 새로운 데이터셋 생성하기**\n",
    "\n",
    "<small>\n",
    "\n",
    "  * ![langsmith에 새로운 데이터셋 생성하기](../15_Evaluations/assets/eval-06.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a8bae4",
   "metadata": {},
   "source": [
    "* `csv` 파일에서 `LangSmith UI` 사용 → 직접 데이터셋 생성 가능\n",
    "\n",
    "* *참고: [`LangSmith UI 문서`](https://docs.langchain.com/langsmith/manage-datasets)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615871d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import Client\n",
    "\n",
    "client = Client()\n",
    "dataset_name = \"RAG_EVAL_DATASET\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509aaa95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 생성 함수\n",
    "\n",
    "def create_dataset(client, dataset_name, description=None):\n",
    "    for dataset in client.list_datasets():\n",
    "        if dataset.name == dataset_name:\n",
    "            return dataset\n",
    "\n",
    "    dataset = client.create_dataset(\n",
    "        dataset_name=dataset_name,\n",
    "        description=description,\n",
    "    )\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea80981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 생성\n",
    "dataset = create_dataset(client, dataset_name)          # 2.9s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef9d52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 생성된 데이터셋에 예제 추가\n",
    "\n",
    "client.create_examples(\n",
    "    inputs=[{\"question\": q} for q in df[\"question\"].tolist()],\n",
    "    outputs=[{\"answer\": a} for a in df[\"answer\"].tolist()],\n",
    "    dataset_id=dataset.id,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe3ee15",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* **`client.creat_examples() 추가하기`** - (`0.1s`)\n",
    "\n",
    "    ```python\n",
    "    {'example_ids': ['8d34ad4e-e3be-47ca-9a6a-9929608b60ca',\n",
    "    '71841ffc-cfbe-4e05-b0b0-ef85e8a6ebd4',\n",
    "    'e0d645a9-6d97-41da-8d45-cc5e8d6f0a37'],\n",
    "    'count': 3}\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3df2b1a",
   "metadata": {},
   "source": [
    "* **`데이터셋에 예제 나중에 추가 가능`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89400605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 새로운 질문 목록\n",
    "new_questions = [\n",
    "    \"삼성전자가 만든 생성형 AI의 이름은 무엇인가요?\",\n",
    "    \"구글이 테디노트에게 20억달러를 투자한 것이 사실입니까?\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1612eec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 새로운 답변 목록\n",
    "new_answers = [\n",
    "    \"삼성전자가 만든 생성형 AI의 이름은 테디노트 입니다.\",\n",
    "    \"사실이 아닙니다. 구글은 앤스로픽에 최대 20억 달러를 투자하기로 합의했으며, 이 중 5억 달러를 우선 투자하고 향후 15억 달러를 추가로 투자하기로 했습니다.\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7cb209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UI에서 업데이트된 버전 확인\n",
    "\n",
    "client.create_examples(\n",
    "    inputs=[{\"question\": q} for q in new_questions],\n",
    "    outputs=[{\"answer\": a} for a in new_answers],\n",
    "    dataset_id=dataset.id,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e8351c",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* **`UI에서 업데이트된 버전 확인하기`** - (`0.1s`)\n",
    "\n",
    "    ```python\n",
    "    {'example_ids': ['7080404f-878d-4e22-9256-70a5d1b86ab3',\n",
    "    'b8599d26-9990-4153-8a92-0dc779087f2c'],\n",
    "    'count': 2}\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9215acbf",
   "metadata": {},
   "source": [
    "* **✓ `데이터셋 준비 완료됨`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a333ef40",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff26a34",
   "metadata": {},
   "source": [
    "* next: ***`05. LLM-as-Judge`***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719f0c8c",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lc_eval_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
