{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "574f6502",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf366bf9",
   "metadata": {},
   "source": [
    "* ì¶œì²˜: LangChain ê³µì‹ ë¬¸ì„œ ë˜ëŠ” í•´ë‹¹ êµì¬ëª…\n",
    "* ì›ë³¸ URL: https://smith.langchain.com/hub/teddynote/summary-stuff-documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31f7552",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af770941",
   "metadata": {},
   "source": [
    "### **5. `05. LLM-as-Judge`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb2944b",
   "metadata": {},
   "source": [
    "#### **2) `Question-Answer Evaluator`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300b2621",
   "metadata": {},
   "source": [
    "* ê°€ì¥ ê¸°ë³¸ ê¸°ëŠ¥ì„ ê°€ì§„ `Evaluator` = `Query` - `Answer` í‰ê°€í•˜ê¸°\n",
    "\n",
    "* ì‚¬ìš©ì ì…ë ¥ = `input` â†’ `LLM`ì´ ìƒì„±í•œ ë‹µë³€ â†’ `prediction`ìœ¼ë¡œ ì •ë‹µ ë‹µë³€ì€ `reference`ë¡œ ì •ì˜ë¨\n",
    "\n",
    "  * `Prompt`ë³€ìˆ˜ \n",
    "    * `query`: ì§ˆë¬¸\n",
    "    * `result`: `LLM` ë‹µë³€\n",
    "    * `answer`: ì •ë‹µ ë‹µë³€"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213e7ff9",
   "metadata": {},
   "source": [
    "* **ìƒˆë¡œìš´ ê°€ìƒí™˜ê²½ ìƒì„± - `lc_eval_env`**\n",
    "\n",
    "  * `Python-3.12`\n",
    "  * `Pydantic`: `ver 1.10.18`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa96e875",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydantic\n",
    "print(f\"Pydantic ë²„ì „: {pydantic.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0a0018",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* **`Pydantic ë²„ì „: 1.10.18`** - (`0.1s`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f802a885",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb9c7b9",
   "metadata": {},
   "source": [
    "* **`í™˜ê²½ ì„¤ì •`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acf7ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API í‚¤ë¥¼ í™˜ê²½ë³€ìˆ˜ë¡œ ê´€ë¦¬í•˜ê¸° ìœ„í•œ ì„¤ì • íŒŒì¼\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API í‚¤ ì •ë³´ ë¡œë“œ\n",
    "load_dotenv()                           # True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d33436",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import Client\n",
    "from langsmith import traceable\n",
    "\n",
    "import os\n",
    "\n",
    "# LangSmith í™˜ê²½ ë³€ìˆ˜ í™•ì¸\n",
    "\n",
    "print(\"\\n--- LangSmith í™˜ê²½ ë³€ìˆ˜ í™•ì¸ ---\")\n",
    "langchain_tracing_v2 = os.getenv('LANGCHAIN_TRACING_V2')\n",
    "langchain_project = os.getenv('LANGCHAIN_PROJECT')\n",
    "langchain_api_key_status = \"ì„¤ì •ë¨\" if os.getenv('LANGCHAIN_API_KEY') else \"ì„¤ì •ë˜ì§€ ì•ŠìŒ\" # API í‚¤ ê°’ì€ ì§ì ‘ ì¶œë ¥í•˜ì§€ ì•ŠìŒ\n",
    "\n",
    "if langchain_tracing_v2 == \"true\" and os.getenv('LANGCHAIN_API_KEY') and langchain_project:\n",
    "    print(f\"âœ… LangSmith ì¶”ì  í™œì„±í™”ë¨ (LANGCHAIN_TRACING_V2='{langchain_tracing_v2}')\")\n",
    "    print(f\"âœ… LangSmith í”„ë¡œì íŠ¸: '{langchain_project}'\")\n",
    "    print(f\"âœ… LangSmith API Key: {langchain_api_key_status}\")\n",
    "    print(\"  -> ì´ì œ LangSmith ëŒ€ì‹œë³´ë“œì—ì„œ ì´ í”„ë¡œì íŠ¸ë¥¼ í™•ì¸í•´ ë³´ì„¸ìš”.\")\n",
    "else:\n",
    "    print(\"âŒ LangSmith ì¶”ì ì´ ì™„ì „íˆ í™œì„±í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë‹¤ìŒì„ í™•ì¸í•˜ì„¸ìš”:\")\n",
    "    if langchain_tracing_v2 != \"true\":\n",
    "        print(f\"  - LANGCHAIN_TRACING_V2ê°€ 'true'ë¡œ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤ (í˜„ì¬: '{langchain_tracing_v2}').\")\n",
    "    if not os.getenv('LANGCHAIN_API_KEY'):\n",
    "        print(\"  - LANGCHAIN_API_KEYê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.\")\n",
    "    if not langchain_project:\n",
    "        print(\"  - LANGCHAIN_PROJECTê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3cee3b",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* ì…€ ì¶œë ¥\n",
    "\n",
    "    ```bash\n",
    "    --- LangSmith í™˜ê²½ ë³€ìˆ˜ í™•ì¸ ---\n",
    "    âœ… LangSmith ì¶”ì  í™œì„±í™”ë¨ (LANGCHAIN_TRACING_V2='true')\n",
    "    âœ… LangSmith í”„ë¡œì íŠ¸: 'LangChain-prantice'\n",
    "    âœ… LangSmith API Key: ì„¤ì •ë¨\n",
    "    -> ì´ì œ LangSmith ëŒ€ì‹œë³´ë“œì—ì„œ ì´ í”„ë¡œì íŠ¸ë¥¼ í™•ì¸í•´ ë³´ì„¸ìš”.\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c37fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from myrag import PDFRAG                        # local ì„ë² ë”© ë²„ì „ìœ¼ë¡œ ìˆ˜ì •í•œ myrag.py ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "# API í‚¤ í™•ì¸\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "GOOGLE_API_KEY=os.getenv(\"GOOGLE_API_KEY2\")\n",
    "\n",
    "if not os.getenv(\"GOOGLE_API_KEY2\"):\n",
    "    os.environ[\"GOOGLE_API_KEY2\"] = input(\"Enter your GOOGLE_API_KEY2: \")\n",
    "\n",
    "if \"GOOGLE_API_KEY2\" not in os.environ:\n",
    "    print(\"âŒ ê²½ê³ : GOOGLE_API_KEY2 í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë°˜ë“œì‹œ ì„¤ì •í•´ì•¼ gemini LLMì´ ì‘ë™í•©ë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0a2b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm2 = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash-lite\", temperature=0, api_key=os.getenv(\"GOOGLE_API_KEY2\"))\n",
    "\n",
    "print(\"âœ… gemini-2.5-flash-lite ì„±ê³µ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95081584",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* **`âœ… ì„±ê³µ!`** \n",
    "\n",
    "  * *`API í• ë‹¹ëŸ‰ ë¶€ì¡±ìœ¼ë¡œ ë‘ë²ˆì¨° ê³„ì •ìœ¼ë¡œ ë‹¤ì‹œ ì‹œë„`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c51b692",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm2 = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash-lite\", temperature=0, api_key=os.getenv(\"GOOGLE_API_KEY2\"))\n",
    "\n",
    "rag = PDFRAG(\n",
    "    \"../15_Evaluations/data/SPRI_AI_Brief_2023ë…„12ì›”í˜¸_F.pdf\",\n",
    "    llm2,\n",
    ")\n",
    "\n",
    "print(\"âœ… PDFRAG ìƒì„± ì„±ê³µ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8dd84b",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* **`PDFRAG ìƒì„±`** - (`4.9s`)\n",
    "\n",
    "    ```markdown\n",
    "\n",
    "    âœ… ë¬¸ì„œ ë¡œë“œ ì™„ë£Œ: 23ê°œ í˜ì´ì§€\n",
    "    âœ… ë¬¸ì„œ ë¶„í•  ì™„ë£Œ: 43ê°œ ì²­í¬\n",
    "    âœ… ì„ë² ë”© ëª¨ë¸ ë¡œë“œ: all-MiniLM-L6-v2\n",
    "    âœ… ë²¡í„°ìŠ¤í† ì–´ ìƒì„± ì™„ë£Œ\n",
    "    âœ… PDFRAG ìƒì„± ì„±ê³µ!\n",
    "\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d43340c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê²€ìƒ‰ê¸°(retriever) ìƒì„±\n",
    "retriever = rag.create_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344ce808",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* **`âœ… ê²€ìƒ‰ê¸° ìƒì„± ì™„ë£Œ (k=4)`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9d8a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì²´ì¸(chain) ìƒì„±\n",
    "chain = rag.create_chain(retriever)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04637af",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* **`âœ… RAG ì²´ì¸ ìƒì„± ì™„ë£Œ`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869c8197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì§ˆë¬¸\n",
    "answer = chain.invoke(\"ì‚¼ì„±ì „ìê°€ ìì²´ ê°œë°œí•œ ìƒì„±í˜• AIì˜ ì´ë¦„ì€ ë¬´ì—‡ì¸ê°€ìš”?\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f68a2e",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* **`ì‚¼ì„±ì „ìê°€ ìì²´ ê°œë°œí•œ ìƒì„±í˜• AIì˜ ì´ë¦„ì€ 'ì‚¼ì„± ê°€ìš°ìŠ¤'ì…ë‹ˆë‹¤.`** - (`2.0s`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47c2bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€í•˜ëŠ” í•¨ìˆ˜ë¥¼ ìƒì„±\n",
    "def ask_question(inputs: dict):\n",
    "    return {\"answer\": chain.invoke(inputs[\"question\"])}\n",
    "\n",
    "# ì‚¬ìš©ì ì§ˆë¬¸ ì˜ˆì‹œ\n",
    "llm_answer = ask_question(\n",
    "    {\"question\": \"ì‚¼ì„±ì „ìê°€ ìì²´ ê°œë°œí•œ ìƒì„±í˜• AIì˜ ì´ë¦„ì€ ë¬´ì—‡ì¸ê°€ìš”?\"}\n",
    ")\n",
    "\n",
    "llm_answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0efe342",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* **`ask_question()`** - (`1.2s`)\n",
    "\n",
    "    ```python\n",
    "\n",
    "        {'answer': \"ì‚¼ì„±ì „ìê°€ ìì²´ ê°œë°œí•œ ìƒì„±í˜• AIì˜ ì´ë¦„ì€ 'ì‚¼ì„± ê°€ìš°ìŠ¤'ì…ë‹ˆë‹¤.\"}\n",
    "\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747018bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluator prompt ì¶œë ¥ì„ ìœ„í•œ í•¨ìˆ˜\n",
    "def print_evaluator_prompt(evaluator):\n",
    "    return evaluator.evaluator.prompt.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf06b760",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith.evaluation import evaluate, LangChainStringEvaluator\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "# qa í‰ê°€ì ìƒì„±\n",
    "qa_evalulator = LangChainStringEvaluator(\n",
    "    \"qa\",\n",
    "    config={\n",
    "        \"llm\":ChatGoogleGenerativeAI(\n",
    "            model=\"gemini-2.5-flash-lite\", \n",
    "            temperature=0, \n",
    "            google_api_key=os.getenv(\"GOOGLE_API_KEY2\"))\n",
    "        }\n",
    ")\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ ì¶œë ¥\n",
    "print_evaluator_prompt(qa_evalulator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafb79c3",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* **`qa_evaluator`** - (`0.1s`)\n",
    "\n",
    "    ```markdown\n",
    "\n",
    "    You are a teacher grading a quiz.\n",
    "    You are given a question, the student's answer, and the true answer, and are asked to score the student answer as either CORRECT or INCORRECT.\n",
    "\n",
    "    Example Format:\n",
    "    QUESTION: question here\n",
    "    STUDENT ANSWER: student's answer here\n",
    "    TRUE ANSWER: true answer here\n",
    "    GRADE: CORRECT or INCORRECT here\n",
    "\n",
    "    Grade the student answers based ONLY on their factual accuracy. Ignore differences in punctuation and phrasing between the student answer and true answer. It is OK if the student answer contains more information than the true answer, as long as it does not contain any conflicting statements. Begin! \n",
    "\n",
    "    QUESTION: *{query}*\n",
    "    STUDENT ANSWER: *{result}*\n",
    "    TRUE ANSWER: *{answer}*\n",
    "    GRADE:\n",
    "\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54472586",
   "metadata": {},
   "source": [
    "* **`í‰ê°€ ì§„í–‰` â†’ ì¶œë ¥í•œ `URL` ì´ë™ â†’ `ê²°ê³¼ í™•ì¸í•˜ê¸°`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448b0dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"RAG_EVAL_DATASET\"\n",
    "\n",
    "# í‰ê°€ ì‹¤í–‰\n",
    "experiment_results = evaluate(\n",
    "    ask_question,\n",
    "    data=dataset_name,\n",
    "    evaluators=[qa_evalulator],\n",
    "    experiment_prefix=\"RAG_EVAL\",\n",
    "    # ì‹¤í—˜ ë©”íƒ€ë°ì´í„° ì§€ì •\n",
    "    metadata={\n",
    "        \"variant\": \"QA Evaluator ë¥¼ í™œìš©í•œ í‰ê°€\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992242c1",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* ê²°ê³¼ í™•ì¸í•˜ê¸°\n",
    "\n",
    "  * `RAG_EVAL` / *`COMPILED`* - (*`45s`*)\n",
    "  * ![`RAG_EVAL_COMPILED`](../15_Evaluations/assets/RAG_EVAL_1.png)\n",
    "\n",
    "  * \n",
    "\n",
    "  * `RAG_EVAL` / *`CORRECT=1`, `INCORRECT=4`* - (*`7.8s`*)\n",
    "  * ![`RAG_EVAL_MORE_INCORRECT`](../15_Evaluations/assets/RAG_EVAL_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa2a070",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1775b968",
   "metadata": {},
   "source": [
    "* **`RAG`** ì‹œìŠ¤í…œ ê°œì„ í•˜ê¸°\n",
    "\n",
    "  * **a. `Retriever` ê°œì„ í•˜ê¸°**\n",
    "  * **b. `Chunk Size` ì¡°ì •í•˜ê¸°**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96641657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# Chunk Size ì¡°ì •\n",
    "# ========================================\n",
    "from myrag2 import PDFRAG\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv() \n",
    "\n",
    "# Chunk Size ì¡°ì •\n",
    "rag2 = PDFRAG(\n",
    "    \"../15_Evaluations/data/SPRI_AI_Brief_2023ë…„12ì›”í˜¸_F.pdf\",\n",
    "    ChatGoogleGenerativeAI(\n",
    "        model=\"gemini-2.0-flash-lite\", \n",
    "        temperature=0, \n",
    "        google_api_key=os.getenv(\"GOOGLE_API_KEY2\")),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b022410",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* **`rag2 ìƒì„±`** - (`12.2s`)\n",
    "\n",
    "    ```mardkwon\n",
    "\n",
    "    âœ… ë¬¸ì„œ ë¡œë“œ ì™„ë£Œ: 23ê°œ í˜ì´ì§€\n",
    "    âœ… ë¬¸ì„œ ë¶„í•  ì™„ë£Œ: 72ê°œ ì²­í¬\n",
    "    âœ… ì„ë² ë”© ëª¨ë¸ ë¡œë“œ: all-MiniLM-L6-v2\n",
    "    âœ… ë²¡í„°ìŠ¤í† ì–´ ìƒì„± ì™„ë£Œ\n",
    "\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0b0126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# Top-K ì¦ê°€\n",
    "# ========================================\n",
    "\n",
    "# ê°œì„ \n",
    "retriever2 = rag2.create_retriever()        # myrag2.py ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "\n",
    "# ì²´ì¸ ì¬ìƒì„±\n",
    "chain2 = rag2.create_chain(retriever2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad59bb6c",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* **`âœ… ê²€ìƒ‰ê¸° ìƒì„± ì™„ë£Œ`**\n",
    "\n",
    "* **`âœ… RAG ì²´ì¸ ìƒì„± ì™„ë£Œ`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e94e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ ìƒì„±\n",
    "chain2.invoke(\"ì‚¼ì„±ì „ìê°€ ìì²´ ê°œë°œí•œ ìƒì„±í˜• AIì˜ ì´ë¦„ì€ ë¬´ì—‡ì¸ê°€ìš”?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24623124",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* **`'ì‚¼ì„±ì „ìê°€ ìì²´ ê°œë°œí•œ ìƒì„±í˜• AIì˜ ì´ë¦„ì€ ì œê³µëœ ë¬¸ì„œì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'`** - (`1.4s`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b1ec0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€í•˜ëŠ” í•¨ìˆ˜ë¥¼ ìƒì„±\n",
    "def ask_question(inputs: dict):\n",
    "    return {\"answer\": chain2.invoke(inputs[\"question\"])}\n",
    "\n",
    "# ì‚¬ìš©ì ì§ˆë¬¸ ì˜ˆì‹œ\n",
    "llm_answer = ask_question(\n",
    "    {\"question\": \"ì‚¼ì„±ì „ìê°€ ìì²´ ê°œë°œí•œ ìƒì„±í˜• AIì˜ ì´ë¦„ì€ ë¬´ì—‡ì¸ê°€ìš”?\"}\n",
    ")\n",
    "\n",
    "llm_answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d3d51e",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* **`ask_question()`** - (`1.3s`)\n",
    "\n",
    "    ```python\n",
    "\n",
    "    {'answer': 'ì‚¼ì„±ì „ìê°€ ìì²´ ê°œë°œí•œ ìƒì„±í˜• AIì˜ ì´ë¦„ì€ ì œê³µëœ ë¬¸ì„œì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'}\n",
    "\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7798a392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluator prompt ì¶œë ¥ì„ ìœ„í•œ í•¨ìˆ˜\n",
    "def print_evaluator_prompt(evaluator):\n",
    "    return evaluator.evaluator.prompt.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31c0c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith.evaluation import evaluate, LangChainStringEvaluator\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "\n",
    "# qa í‰ê°€ì ìƒì„±\n",
    "qa_evalulator = LangChainStringEvaluator(\n",
    "    \"qa\",\n",
    "    config={\n",
    "        \"llm\":ChatGoogleGenerativeAI(\n",
    "            model=\"gemini-2.5-flash-lite\", \n",
    "            temperature=0, \n",
    "            google_api_key=os.getenv(\"GOOGLE_API_KEY2\"))\n",
    "        }\n",
    ")\n",
    "\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ ì¶œë ¥\n",
    "print_evaluator_prompt(qa_evalulator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45ec6e2",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* **`qa_evaluator`**\n",
    "\n",
    "    ```markdown\n",
    "\n",
    "    You are a teacher grading a quiz.\n",
    "    You are given a question, the student's answer, and the true answer, and are asked to score the student answer as either CORRECT or INCORRECT.\n",
    "\n",
    "    Example Format:\n",
    "    QUESTION: question here\n",
    "    STUDENT ANSWER: student's answer here\n",
    "    TRUE ANSWER: true answer here\n",
    "    GRADE: CORRECT or INCORRECT here\n",
    "\n",
    "    Grade the student answers based ONLY on their factual accuracy. Ignore differences in punctuation and phrasing between the student answer and true answer. It is OK if the student answer contains more information than the true answer, as long as it does not contain any conflicting statements. Begin! \n",
    "\n",
    "    QUESTION: *{query}*\n",
    "    STUDENT ANSWER: *{result}*\n",
    "    TRUE ANSWER: *{answer}*\n",
    "    GRADE:\n",
    "\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec610bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"RAG_EVAL_DATASET\"\n",
    "\n",
    "# í‰ê°€ ì‹¤í–‰\n",
    "experiment_results = evaluate(\n",
    "    ask_question,\n",
    "    data=dataset_name,\n",
    "    evaluators=[qa_evalulator],\n",
    "    experiment_prefix=\"RAG_EVAL_2\",\n",
    "    # ì‹¤í—˜ ë©”íƒ€ë°ì´í„° ì§€ì •\n",
    "    metadata={\n",
    "        \"variant\": \"myrag2.py ë°˜ì˜\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2154ce",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* **ê°œì„  ì‹œë„: `RAG_EVAL_2`**\n",
    "\n",
    "  ```bash\n",
    "\n",
    "  View the evaluation results for experiment: 'RAG_EVAL_2-00c422bd' at:\n",
    "  https://smith.langchain.com/o/2c3342d3-1170-4ffa-86fd-f621199e0b9c/datasets/420dd308-2ebd-44c9-8ce8-9aff3886dc8e/compare?selectedSessions=cfb85525-ad18-4c76-9e47-4b2c1beb95fa\n",
    "\n",
    "\n",
    "  0it [00:00, ?it/s]\n",
    "\n",
    "  5it [00:04,  1.12it/s]\n",
    "\n",
    "  ```\n",
    "\n",
    "* ê²°ê³¼ í™•ì¸í•˜ê¸°\n",
    "\n",
    "<br>\n",
    "\n",
    "* \n",
    "  * `RAG_EVAL` / *`CORRECT=2`, `INCORRECT=3`* - (*`7.3s`*)\n",
    "  * ![`RAG_EVAL_MORE_INCORRECT`](../15_Evaluations/assets/RAG_EVAL_3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9620d711",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc52808b",
   "metadata": {},
   "source": [
    "* **`RAG`** ì‹œìŠ¤í…œ ê°œì„ í•˜ê¸°_2\n",
    "\n",
    "  * **c. `chunk_size` ì¡°ì •**\n",
    "  * **d. ì¦ì€ ì»¤ë„ ì¶©ëŒ â†’ `python` íŒŒì¼ë¡œ ì‹¤í–‰í•˜ê¸°**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a7f716",
   "metadata": {},
   "source": [
    "* c.\n",
    "\n",
    "  * `chunck_size` ì¡°ì ˆ test\n",
    "    * **`chunk_size` ì§€ì • âŒ** or **`chunk_size` = `4` â†’ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ**\n",
    "      * *`'ì£„ì†¡í•©ë‹ˆë‹¤. ì œê³µëœ ë¬¸ì„œì—ì„œ ì‚¼ì„±ì „ìê°€ ìì²´ ê°œë°œí•œ ìƒì„±í˜• AIì˜ ì´ë¦„ì— ëŒ€í•œ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'`*\n",
    "\n",
    "    * **`chunk_size` = `7` â†’ ê²€ìƒ‰ ê²°ê³¼ â­•ï¸**\n",
    "      * *`\"ì‚¼ì„±ì „ìê°€ ìì²´ ê°œë°œí•œ ìƒì„±í˜• AIì˜ ì´ë¦„ì€ 'ì‚¼ì„± ê°€ìš°ìŠ¤'ì…ë‹ˆë‹¤.\"`*\n",
    "\n",
    "  * [**`myrag4.py`**](../15_Evaluations/myrag4.py)ë¡œ ì •ë¦¬"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8482815d",
   "metadata": {},
   "source": [
    "* d.\n",
    "  * **`ì¦ì€ ì»¤ë„ ì¶©ëŒë¡œ ì¸í•œ ë¬¸ì œ` â†’ `python` íŒŒì¼ë¡œ ì‹¤í–‰ â†’ í„°ë¯¸ë„ì—ì„œ ì§ì ‘ í™•ì¸í•˜ê¸°**\n",
    "\n",
    "  * [**`eval_script.py`**](../15_Evaluations/eval_script.py) ì‹¤í–‰ â†’ í„°ë¯¸ë„ì—ì„œ ê²°ê³¼ ë°”ë¡œ í™•ì¸\n",
    "\n",
    "  * ![`RAG_EVAL_4`](../15_Evaluations/assets/RAG_EVAL_4.png)\n",
    "\n",
    "<small>\n",
    "\n",
    "```bash\n",
    "\n",
    "      (ê°€ìƒí™˜ê²½)/15_Evaluations/eval_script.py\n",
    "\n",
    "      ğŸš€ RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹œì‘...\n",
    "\n",
    "      ğŸ“‚ ìŠ¤í¬ë¦½íŠ¸ ìœ„ì¹˜: ... /15_Evaluations\n",
    "\n",
    "      ğŸ“„ PDF ê²½ë¡œ: ... /data/SPRI_AI_Brief_2023ë…„12ì›”í˜¸_F.pdf\n",
    "\n",
    "      âœ… íŒŒì¼ í™•ì¸ ì™„ë£Œ!\n",
    "\n",
    "      âœ… LLM ìƒì„± ì™„ë£Œ: gemini-2.5-flash-lite\n",
    "\n",
    "      âœ… PDF ë¡œë“œ ì™„ë£Œ: 23 í˜ì´ì§€\n",
    "\n",
    "      âœ… ì²­í¬ ë¶„í•  ì™„ë£Œ: 119 ì²­í¬ (í¬ê¸°=300, ì˜¤ë²„ë©=50)\n",
    "\n",
    "\n",
    "      âœ… LLM ìƒì„± ì™„ë£Œ: gemini-2.5-flash-lite\n",
    "\n",
    "      âœ… ì²­í¬ ë¶„í•  ì™„ë£Œ: 119 ì²­í¬ (í¬ê¸°=300, ì˜¤ë²„ë©=50)\n",
    "      pytorch_model.bin: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.27G/2.27G [00:03<00:00, 695MB/s]\n",
    "      tokenizer_config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 444/444 [00:00<00:00, 1.92MB/s]\n",
    "      sentencepiece.bpe.model: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5.07M/5.07M [00:06<00:00, 781kB/s]\n",
    "      tokenizer.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17.1M/17.1M [00:06<00:00, 2.70MB/s]\n",
    "      special_tokens_map.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 964/964 [00:00<00:00, 3.61MB/s]\n",
    "      config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 191/191 [00:00<00:00, 628kB/s]\n",
    "\n",
    "      âœ… ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: BAAI/bge-m3                                                                 | 0.00/191 [00:00<?, ?B/s]\n",
    "      model.safetensors:   0%|                                                                  | 2.19M/2.27G [00:24<1:26:03, 439kB/s]âœ… ë²¡í„°ìŠ¤í† ì–´ ìƒì„± ì™„ë£Œ: FAISS\n",
    "\n",
    "      âœ… ê²€ìƒ‰ê¸° ìƒì„± ì™„ë£Œ (k=7, search_type=similarity)\n",
    "\n",
    "      âœ… RAG ì²´ì¸ ìƒì„± ì™„ë£Œ\n",
    "\n",
    "      ==================================================\n",
    "      ğŸ§ª í…ŒìŠ¤íŠ¸ ì‹¤í–‰...\n",
    "      ==================================================\n",
    "\n",
    "      View the evaluation results for experiment: 'RAG_EVAL_K7-3a35bd45' at:\n",
    "      https://smith.langchain.com/o/2c3342d3-1170-4ffa-86fd-f621199e0b9c/datasets/420dd308-2ebd-44c9-8ce8-9aff3886dc8e/compare?selectedSessions=cdb9ea10-e3c1-47bc-bfe1-48f651364c28\n",
    "\n",
    "\n",
    "      5it [00:14,  2.90s/it]\n",
    "      5it [00:14,  2.18s/it]\n",
    "\n",
    "      ==================================================\n",
    "      âœ… í‰ê°€ ì™„ë£Œ!\n",
    "      ==================================================\n",
    "\n",
    "      ê²°ê³¼: <ExperimentResults RAG_EVAL_K7-3a35bd45>\n",
    "\n",
    "      model.safetensors: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.27G/2.27G [02:14<00:00, 16.9MB/s]\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f5e95d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06ace2f",
   "metadata": {},
   "source": [
    "* **`í˜„ì¬ ìƒí™© ë¶„ì„`**\n",
    "\n",
    "  | í•­ëª© | ê°œìˆ˜ | ì •í™•ë„ |\n",
    "  |------|------|--------|\n",
    "  | **CORRECT** | 3/5 | 60% |\n",
    "  | **INCORRECT** | 2/5 | 40% |\n",
    "\n",
    "<br>\n",
    "\n",
    "* ì§„ì „\n",
    "  * ì´ì „: 1/5 (20%)\n",
    "  * í˜„ì¬: 3/5 (60%)\n",
    "  * **í–¥ìƒ: +200%!**\n",
    "\n",
    "<br>\n",
    "\n",
    "* **`RAG` í‰ê°€**\n",
    "\n",
    "  * ì–´ë ¤ì›€\n",
    "\n",
    "    | ì´ìœ  | ì„¤ëª… |\n",
    "    |------|------|\n",
    "    | **ì´ˆê¸° ì •í™•ë„** | 20-40%ëŠ” ì •ìƒ |\n",
    "    | **ë°˜ë³µ ê°œì„ ** | 60% â†’ 80% â†’ 90%ë¡œ ì ì§„ì  í–¥ìƒ |\n",
    "    | **ì™„ë²½ì€ ì—†ìŒ** | 100%ëŠ” ê±°ì˜ ë¶ˆê°€ëŠ¥ |\n",
    "\n",
    "<br>\n",
    "\n",
    "* \n",
    "\n",
    "  * í˜„ì¬ ë‹¨ê³„\n",
    "\n",
    "    ```markdown\n",
    "        ì¼ë°˜ì ì¸ RAG í‰ê°€ ë°œì „:\n",
    "\n",
    "        1ë‹¨ê³„: 20-40% (ì´ˆê¸°)\n",
    "        2ë‹¨ê³„: 50-60% (ê°œì„  í›„)  â†  ì—¬ê¸°!\n",
    "        3ë‹¨ê³„: 70-80% (ìµœì í™”)\n",
    "        4ë‹¨ê³„: 80-90% (ì™„ì„±)\n",
    "    ```\n",
    "\n",
    "<br>\n",
    "\n",
    "* **`í–¥ìƒ ë°©ë²•`**\n",
    "\n",
    "  * **a. `kê°’ ì¦ê°€`**\n",
    "\n",
    "  * **b. `chunk_size` ì¡°ì •í•˜ê¸°**\n",
    "\n",
    "  * **c. `í”„ë¡¬í”„íŠ¸ ê°œì„ í•˜ê¸°`**\n",
    "\n",
    "  * **d. `ë‹¤ë¥¸ ì„ë² ë”© ëª¨ë¸ ì‹œë„í•˜ê¸°`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77e6d4d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3db68a",
   "metadata": {},
   "source": [
    "#### **3) `LangSmith í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•œ Dataset ìƒì„±`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb905c0",
   "metadata": {},
   "source": [
    "* **`Dataset & Testing`ì— ìƒˆë¡œìš´ ë°ì´í„°ì…‹ ìƒì„±í•˜ê¸°**\n",
    "\n",
    "<small>\n",
    "\n",
    "  * ![langsmithì— ìƒˆë¡œìš´ ë°ì´í„°ì…‹ ìƒì„±í•˜ê¸°](../15_Evaluations/assets/eval-06.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a8bae4",
   "metadata": {},
   "source": [
    "* `csv` íŒŒì¼ì—ì„œ `LangSmith UI` ì‚¬ìš© â†’ ì§ì ‘ ë°ì´í„°ì…‹ ìƒì„± ê°€ëŠ¥\n",
    "\n",
    "* *ì°¸ê³ : [`LangSmith UI ë¬¸ì„œ`](https://docs.langchain.com/langsmith/manage-datasets)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615871d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import Client\n",
    "\n",
    "client = Client()\n",
    "dataset_name = \"RAG_EVAL_DATASET\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509aaa95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë°ì´í„°ì…‹ ìƒì„± í•¨ìˆ˜\n",
    "\n",
    "def create_dataset(client, dataset_name, description=None):\n",
    "    for dataset in client.list_datasets():\n",
    "        if dataset.name == dataset_name:\n",
    "            return dataset\n",
    "\n",
    "    dataset = client.create_dataset(\n",
    "        dataset_name=dataset_name,\n",
    "        description=description,\n",
    "    )\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea80981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë°ì´í„°ì…‹ ìƒì„±\n",
    "dataset = create_dataset(client, dataset_name)          # 2.9s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef9d52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìƒì„±ëœ ë°ì´í„°ì…‹ì— ì˜ˆì œ ì¶”ê°€\n",
    "\n",
    "client.create_examples(\n",
    "    inputs=[{\"question\": q} for q in df[\"question\"].tolist()],\n",
    "    outputs=[{\"answer\": a} for a in df[\"answer\"].tolist()],\n",
    "    dataset_id=dataset.id,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe3ee15",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* **`client.creat_examples() ì¶”ê°€í•˜ê¸°`** - (`0.1s`)\n",
    "\n",
    "    ```python\n",
    "    {'example_ids': ['8d34ad4e-e3be-47ca-9a6a-9929608b60ca',\n",
    "    '71841ffc-cfbe-4e05-b0b0-ef85e8a6ebd4',\n",
    "    'e0d645a9-6d97-41da-8d45-cc5e8d6f0a37'],\n",
    "    'count': 3}\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3df2b1a",
   "metadata": {},
   "source": [
    "* **`ë°ì´í„°ì…‹ì— ì˜ˆì œ ë‚˜ì¤‘ì— ì¶”ê°€ ê°€ëŠ¥`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89400605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìƒˆë¡œìš´ ì§ˆë¬¸ ëª©ë¡\n",
    "new_questions = [\n",
    "    \"ì‚¼ì„±ì „ìê°€ ë§Œë“  ìƒì„±í˜• AIì˜ ì´ë¦„ì€ ë¬´ì—‡ì¸ê°€ìš”?\",\n",
    "    \"êµ¬ê¸€ì´ í…Œë””ë…¸íŠ¸ì—ê²Œ 20ì–µë‹¬ëŸ¬ë¥¼ íˆ¬ìí•œ ê²ƒì´ ì‚¬ì‹¤ì…ë‹ˆê¹Œ?\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1612eec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìƒˆë¡œìš´ ë‹µë³€ ëª©ë¡\n",
    "new_answers = [\n",
    "    \"ì‚¼ì„±ì „ìê°€ ë§Œë“  ìƒì„±í˜• AIì˜ ì´ë¦„ì€ í…Œë””ë…¸íŠ¸ ì…ë‹ˆë‹¤.\",\n",
    "    \"ì‚¬ì‹¤ì´ ì•„ë‹™ë‹ˆë‹¤. êµ¬ê¸€ì€ ì•¤ìŠ¤ë¡œí”½ì— ìµœëŒ€ 20ì–µ ë‹¬ëŸ¬ë¥¼ íˆ¬ìí•˜ê¸°ë¡œ í•©ì˜í–ˆìœ¼ë©°, ì´ ì¤‘ 5ì–µ ë‹¬ëŸ¬ë¥¼ ìš°ì„  íˆ¬ìí•˜ê³  í–¥í›„ 15ì–µ ë‹¬ëŸ¬ë¥¼ ì¶”ê°€ë¡œ íˆ¬ìí•˜ê¸°ë¡œ í–ˆìŠµë‹ˆë‹¤.\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7cb209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UIì—ì„œ ì—…ë°ì´íŠ¸ëœ ë²„ì „ í™•ì¸\n",
    "\n",
    "client.create_examples(\n",
    "    inputs=[{\"question\": q} for q in new_questions],\n",
    "    outputs=[{\"answer\": a} for a in new_answers],\n",
    "    dataset_id=dataset.id,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e8351c",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* **`UIì—ì„œ ì—…ë°ì´íŠ¸ëœ ë²„ì „ í™•ì¸í•˜ê¸°`** - (`0.1s`)\n",
    "\n",
    "    ```python\n",
    "    {'example_ids': ['7080404f-878d-4e22-9256-70a5d1b86ab3',\n",
    "    'b8599d26-9990-4153-8a92-0dc779087f2c'],\n",
    "    'count': 2}\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9215acbf",
   "metadata": {},
   "source": [
    "* **âœ“ `ë°ì´í„°ì…‹ ì¤€ë¹„ ì™„ë£Œë¨`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a333ef40",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff26a34",
   "metadata": {},
   "source": [
    "* next: ***`05. LLM-as-Judge`***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719f0c8c",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lc_eval_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
