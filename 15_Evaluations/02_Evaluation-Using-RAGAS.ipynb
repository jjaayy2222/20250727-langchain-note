{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba52bed0",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65001001",
   "metadata": {},
   "source": [
    "* 출처: LangChain 공식 문서 또는 해당 교재명\n",
    "* 원본 URL: https://smith.langchain.com/hub/teddynote/summary-stuff-documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb2ea90",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb18b49c",
   "metadata": {},
   "source": [
    "### **02. `RAGAS`를 활용한 `평가`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f936725",
   "metadata": {},
   "source": [
    "#### **1) `RAGAS를 활용한 평가`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6ede17",
   "metadata": {},
   "source": [
    "* 참고: [RAGAS](https://cal.com/docs/developing/introduction)\n",
    "\n",
    "  * **`API v1`**: [API v1](https://cal.com/docs/api-reference/v1/introduction)\n",
    "\n",
    "  * **`API v2`**: [API v2](https://cal.com/docs/api-reference/v2/introduction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd6b318",
   "metadata": {},
   "source": [
    "* 사전에 `VS Code` 터미널에 설치할 것\n",
    "\n",
    "```bash\n",
    "\n",
    "        pip install -qU faiss-cpu ragas\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d763fc98",
   "metadata": {},
   "source": [
    "##### **`➀ 기본설정`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b354960e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"          # 토크나이저 병렬 처리 경고 억제\n",
    "os.environ[\"TQDM_DISABLE\"] = \"1\"                        # 진행바 비활성화\n",
    "logging.disable(logging.WARNING)                        # 파이썬 로깅 레벨 조정 (WARNING 이하 출력 억제)\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "print(\"✅ 환경 설정 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2178c5",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* ✅ 환경 설정 완료"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a36bcf",
   "metadata": {},
   "source": [
    "##### **`➁ LangSmith 설정`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ef86f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import Client\n",
    "from langsmith import traceable\n",
    "\n",
    "import os\n",
    "\n",
    "# LangSmith 환경 변수 확인\n",
    "\n",
    "print(\"\\n--- LangSmith 환경 변수 확인 ---\")\n",
    "langchain_tracing_v2 = os.getenv('LANGCHAIN_TRACING_V2')\n",
    "langchain_project = os.getenv('LANGCHAIN_PROJECT')\n",
    "langchain_api_key_status = \"설정됨\" if os.getenv('LANGCHAIN_API_KEY') else \"설정되지 않음\" # API 키 값은 직접 출력하지 않음\n",
    "\n",
    "if langchain_tracing_v2 == \"true\" and os.getenv('LANGCHAIN_API_KEY') and langchain_project:\n",
    "    print(f\"✅ LangSmith 추적 활성화됨 (LANGCHAIN_TRACING_V2='{langchain_tracing_v2}')\")\n",
    "    print(f\"✅ LangSmith 프로젝트: '{langchain_project}'\")\n",
    "    print(f\"✅ LangSmith API Key: {langchain_api_key_status}\")\n",
    "    print(\"  -> 이제 LangSmith 대시보드에서 이 프로젝트를 확인해 보세요.\")\n",
    "else:\n",
    "    print(\"❌ LangSmith 추적이 완전히 활성화되지 않았습니다. 다음을 확인하세요:\")\n",
    "    if langchain_tracing_v2 != \"true\":\n",
    "        print(f\"  - LANGCHAIN_TRACING_V2가 'true'로 설정되어 있지 않습니다 (현재: '{langchain_tracing_v2}').\")\n",
    "    if not os.getenv('LANGCHAIN_API_KEY'):\n",
    "        print(\"  - LANGCHAIN_API_KEY가 설정되어 있지 않습니다.\")\n",
    "    if not langchain_project:\n",
    "        print(\"  - LANGCHAIN_PROJECT가 설정되어 있지 않습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f14d715",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 셀 출력\n",
    "\n",
    "    ```bash\n",
    "    --- LangSmith 환경 변수 확인 ---\n",
    "    ✅ LangSmith 추적 활성화됨 (LANGCHAIN_TRACING_V2='true')\n",
    "    ✅ LangSmith 프로젝트: 'LangChain-prantice'\n",
    "    ✅ LangSmith API Key: 설정됨\n",
    "    -> 이제 LangSmith 대시보드에서 이 프로젝트를 확인해 보세요.\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6c12e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 패키지 임포트\n",
    "\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "print(\"✅ 패키지 임포트 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037917aa",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* ✅ 패키지 임포트 완료 - (`0.6s`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775b2967",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13582956",
   "metadata": {},
   "source": [
    "##### **`➂ 교재 원본 파일로 로드해보기`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a54ab5",
   "metadata": {},
   "source": [
    "* **`저장한 CSV 파일로부터 로드하기`**\n",
    "\n",
    "  * `data/ragas_synthetic_dataset_original.csv` 파일 로드하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372bbe76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 데이터 로드하기\n",
    "df = pd.read_csv(\"../15_Evaluations/data/ragas_synthetic_dataset_original.csv\")\n",
    "\n",
    "# 일부 정보 읽어보기\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5618d47",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* **`df.head()`** - (`0.7s`)\n",
    "\n",
    "  * ![df.head()](../15_Evaluations/assets/02_original_df_head.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570515da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "test_dataset = Dataset.from_pandas(df)\n",
    "\n",
    "test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b4bb91",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* **`test_dataset`** - (`0.4s`)\n",
    "\n",
    "```python\n",
    "\n",
    "        Dataset({\n",
    "            features: ['question', 'contexts', 'ground_truth', 'evolution_type', 'metadata', 'episode_done'],\n",
    "            num_rows: 10\n",
    "            })\n",
    "\n",
    "```\n",
    "\n",
    "  * `test_dataset` 확인해보기\n",
    "\n",
    "    * ![test_dataset](../15_Evaluations/assets/02_original_test_dataset.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130cd22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast                                  # 문자열을 파이썬 리터럴로 안전하게 평가하는 데 사용\n",
    "\n",
    "# 주어진 예제 딕셔너리의 'contexts' 키에 저장된 문자열을 파이썬 리스트로 변환하는 함수\n",
    "def convert_to_list(example):\n",
    "    # 문자열 = 파이썬 리터럴로 변환함\n",
    "    contexts = ast.literal_eval(example[\"contexts\"])\n",
    "    # 변환된 리스트 = 딕셔너리로 반환함\n",
    "    return {\"contexts\": contexts}\n",
    "\n",
    "# test_dataset의 각 요소에 convert_to_list 함수 적용하기\n",
    "# map 함수 = 데이터셋의 각 행에 함수를 적용하는 데 사용\n",
    "test_dataset = test_dataset.map(convert_to_list)\n",
    "\n",
    "# 변환된 데이터셋을 출력하기\n",
    "print(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8dd12af",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* **`변환된 데이터셋`** - (`0.1s`)\n",
    "\n",
    "```bash\n",
    "\n",
    "        Map:   100%|████████████████████████████████████████| 10/10 [00:00<00:00, 362.11 examples/s]\n",
    "\n",
    "```\n",
    "\n",
    "```python\n",
    "\n",
    "        Dataset({\n",
    "            features: ['question', 'contexts', 'ground_truth', 'evolution_type', 'metadata', 'episode_done'],\n",
    "            num_rows: 10\n",
    "        })\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8d65d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset[1][\"contexts\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8e37da",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "```bash\n",
    "\n",
    "['Ⅱ\\n. 주요 행사 일정\\n행사명 행사 주요 개요\\n- 미국 소비자기술 협회(CTA)가 주관하는 세계 최대 가전·IT·소\\n비재 전시회로 5G, AR&VR, 디지털헬스, 교통·모빌리티 등\\n주요 카테고리 중심으로 기업들이 최신의 기술 제품군을 전시\\n- CTA 사피로 회장은 가장 주목받는 섹터로 AI를 조명하였으며,\\n모든 산업을 포괄한다는 의미에서 ‘올 온(All on)’을 주제로 한\\nCES 2024\\n이번 전시에는 500곳 이상의 한국기업 참가 예정\\n기간 장소 홈페이지\\n2024.1.9~12 미국, 라스베가스 https://www.ces.tech/\\n- 머신러닝 및 응용에 관한 국제 컨퍼런스(AIMLA 2024)는\\n인공지능 및 머신러닝의 이론, 방법론 및 실용적 접근에 관한\\n지식과 최신 연구 결과 공유\\n- 이론 및 실무 측면에서 인공지능, 기계학습의 주요 분야를\\n논의하고, 학계, 산업계의 연구자와 실무자들에게 해당 분\\nAIMLA 2024\\n야의 최첨단 개발 소식 공유\\n기간 장소 홈페이지\\nhttps://ccnet2024.org/aimla\\n2024.1.27~28 덴마크, 코펜하겐\\n/index\\n- AI 발전 협회 컨퍼런스(AAAI)는 AI 연구를 촉진하고, AI 분야\\n연구원, 실무자, 과학자, 학생 및 공학자 간 교류의 기회 제공\\n- 컨퍼런스에서 AI 관련 기술 발표, 특별 트랙, 초청 연사,\\nAAAI Conference\\n워크숍, 튜토리얼, 포스터 세션, 주제 발표, 대회, 전시 프\\non Artificial\\n로그램 등 진행\\nIntelligence\\n기간 장소 홈페이지\\nhttps://aaai.org/aaai-confere\\n2024.2.20~27 캐나다, 밴쿠버\\nnce/']\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3101c02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단계 1: 문서 로드(Load Documents)\n",
    "loader = PyMuPDFLoader(\"../15_Evaluations/data/SPRI_AI_Brief_2023년12월호_F.pdf\")\n",
    "docs = loader.load()                                                    # 0.3s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b41039",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단계 2: 문서 분할(Split Documents)\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=50)\n",
    "split_documents = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcaae524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단계 3: 임베딩(Embedding) 생성\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"BAAI/bge-small-en-v1.5\",\n",
    "    model_kwargs={'device': 'cpu'},\n",
    "    encode_kwargs={'normalize_embeddings': True}\n",
    ")\n",
    "\n",
    "print(\"✅ 임베딩 생성 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967a82e6",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* ✅ 임베딩 생성 완료 - (`8.8s`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a82b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단계 4: DB 생성(Create DB) 및 저장\n",
    "# 벡터스토어 생성하기\n",
    "\n",
    "vectorstore = FAISS.from_documents(\n",
    "    documents=split_documents,\n",
    "    embedding=embeddings\n",
    "    )\n",
    "\n",
    "print(\"✅ vectorstore 생성 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8735fe06",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* ✅ vectorstore 생성 완료 - (`5.1s`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1508b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단계 5: 검색기(Retriever) 생성\n",
    "# 문서에 포함되어 있는 정보 → 검색 및 생성\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "print(\"✅ retriever 생성 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a166ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단계 6: 프롬프트 생성(Create Prompt)\n",
    "# 프롬프트 생성하기\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"You are an assistant for question-answering tasks. \n",
    "Use the following pieces of retrieved context to answer the question. \n",
    "If you don't know the answer, just say that you don't know. \n",
    "\n",
    "#Context: \n",
    "{context}\n",
    "\n",
    "#Question:\n",
    "{question}\n",
    "\n",
    "#Answer:\"\"\"\n",
    ")\n",
    "\n",
    "print(\"✅ prompt 생성 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b810a4",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* ✅ prompt 생성 완료"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105bf4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단계 7: 언어모델(LLM) 생성\n",
    "llm=ChatOllama(\n",
    "    model=\"llama3.2:3b\",\n",
    "    temperature=0.1,\n",
    ")\n",
    "\n",
    "print(\"✅ Ollama LLM 초기화 완료 (모델: llama3.2:3b)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22d264c",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* ✅ Ollama LLM 초기화 완료 (모델: llama3.2:3b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fea109c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단계 8: 체인(Chain) 생성\n",
    "\n",
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(\"✅ Chain 생성 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fabc8f4",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* ✅ Chain 생성 완료"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3029afdd",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475c271e",
   "metadata": {},
   "source": [
    "* **`배치 데이터셋` 생성하기**\n",
    "\n",
    "  * **`다량의 질문을 한 번에 처리할 때 용이함`**\n",
    "\n",
    "  * [**`배치`**](https://wikidocs.net/233345): (`https://wikidocs.net/233345`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081c7edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 배치 데이터셋 생성하기\n",
    "\n",
    "batch_dataset = [question for question in test_dataset[\"question\"]]\n",
    "\n",
    "batch_dataset[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a2f770",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* **`batch_dataset[:3]`**\n",
    "\n",
    "```python\n",
    "\n",
    "        ['What specific recent developments in generative AI have been highlighted by TechRepublic in their November 2023 articles?',\n",
    "        'What are the dates and location for CES 2024?',\n",
    "        \"What are the key aspects of AI global cooperation highlighted in the G7's approach to ethical considerations and regulatory frameworks for advanced AI systems?\"]\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea9fc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(batch_dataset))              # <class 'list'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96075509",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(batch_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8488f190",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* **`print(batch_dataset)`**\n",
    "\n",
    "<small> <small>\n",
    "\n",
    "```python\n",
    "\n",
    "        ['What specific recent developments in generative AI have been highlighted by TechRepublic in their November 2023 articles?', 'What are the dates and location for CES 2024?', \"What are the key aspects of AI global cooperation highlighted in the G7's approach to ethical considerations and regulatory frameworks for advanced AI systems?\", 'What measures are suggested to enhance data privacy in the context of advanced AI systems?', 'What were the main takeaways from the AI Safety Summit on global AI testing?', 'What links data provenance, model efficiency, and NLP accuracy?', 'What’s the MMLU benchmark, and how does it evaluate AI models like Tongyi Qianwen 2.0 for generative AI?', 'How does the MMLU benchmark assess AI models like Tongyi Qianwen 2.0?', 'How do changes in AI eval criteria affect LLMs?', 'What factors matter for ethical AI innovation?']\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7716810",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a9c0c2",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* before\n",
    "\n",
    "* `batch_dataset[:3]`\n",
    "\n",
    "```python\n",
    "\n",
    "    ['What specific recent developments in generative AI have been highlighted by TechRepublic in their November 2023 articles?',\n",
    "    'What are the dates and location for CES 2024?',\n",
    "    \"What are the key aspects of AI global cooperation highlighted in the G7's approach to ethical considerations and regulatory frameworks for advanced AI systems?\"]\n",
    "\n",
    "```\n",
    "\n",
    "* `batch_dataset`\n",
    "\n",
    "<small> <small>\n",
    "\n",
    "```python\n",
    "\n",
    "    ['What specific recent developments in generative AI have been highlighted by TechRepublic in their November 2023 articles?', 'What are the dates and location for CES 2024?', \"What are the key aspects of AI global cooperation highlighted in the G7's approach to ethical considerations and regulatory frameworks for advanced AI systems?\", 'What measures are suggested to enhance data privacy in the context of advanced AI systems?', 'What were the main takeaways from the AI Safety Summit on global AI testing?', 'What links data provenance, model efficiency, and NLP accuracy?', 'What’s the MMLU benchmark, and how does it evaluate AI models like Tongyi Qianwen 2.0 for generative AI?', 'How does the MMLU benchmark assess AI models like Tongyi Qianwen 2.0?', 'How do changes in AI eval criteria affect LLMs?', 'What factors matter for ethical AI innovation?']\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3d146e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392f0214",
   "metadata": {},
   "source": [
    "* **`batch()` 호출 → 배치 데이터셋에 대한 답변 얻기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8a599d",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = chain.batch(batch_dataset)\n",
    "\n",
    "answer[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae5972e",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* **`try_4`** - (`5m 49.3s`)\n",
    "\n",
    "```python\n",
    "\n",
    "        ['According to the provided context, TechRepublic has highlighted that Samsung has developed a generative AI called \"Samsung Gauss\" and has revealed its research on it. Additionally, they mentioned that Samsung\\'s Llama2 is being used in Qualcomm devices and Google Assistant is being applied to Google Pixel phones, which are competing with each other in the market.',\n",
    "        'According to the retrieved context, the dates and location for CES 2024 are:\\n\\n* Dates: 2024.1.9~12\\n* Location: 미국 (United States), 라스베가스 (Las Vegas)',\n",
    "        'The key aspects of AI global cooperation highlighted in the G7\\'s approach to ethical considerations and regulatory frameworks for advanced AI systems include:\\n\\n1. International Code of Conduct for Advanced AI Systems: The G7 has agreed on an international code of conduct for advanced AI systems, which includes provisions for identifying and mitigating risks, ensuring transparency and accountability, and promoting responsible AI development and use.\\n2. Voluntary Adoption: The G7 is encouraging companies to voluntarily adopt the international code of conduct, with a focus on developing and deploying safe and secure AI systems.\\n3. Risk Evaluation and Mitigation: The G7 is emphasizing the need for risk evaluation and mitigation measures to be taken during the development and deployment of advanced AI systems.\\n4. Transparency and Accountability: The G7 is promoting transparency and accountability in AI decision-making, including the publication of model performance data and the establishment of mechanisms for addressing bias and errors.\\n5. International Cooperation: The G7 is encouraging international cooperation on AI-related issues, including the sharing of best practices and the development of common standards.\\n6. Regulatory Frameworks: The G7 is exploring regulatory frameworks to ensure that advanced AI systems are developed and deployed in a responsible and safe manner.\\n7. Model Card: Three countries (France, Germany, and Italy) have proposed the use of a \"model card\" to regulate foundation models, which would require companies to provide information about their models and ensure compliance with regulations.\\n\\nThese aspects highlight the G7\\'s commitment to promoting responsible AI development and use, while also acknowledging the need for international cooperation and regulatory frameworks to ensure that advanced AI systems are developed and deployed in a safe and secure manner.']\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6405fe25",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043739ca",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* **`try_1`** - (`5m 56.1s`)\n",
    "\n",
    "<small> <small>\n",
    "\n",
    "```python\n",
    "\n",
    "    ['According to the provided context, TechRepublic has highlighted that Samsung has developed a generative AI called \"Samsung Gauss\" and has revealed its research on it. Additionally, they mentioned that Meta\\'s Llama 2 is being used in Qualcomm devices and Google Assistant is being applied to Google Pixel phones, which are competing with Samsung\\'s new device.',\n",
    "    'According to the retrieved context, the dates and location for CES 2024 are:\\n\\n* Dates: 2024.1.9~12\\n* Location: 미국 (United States), 라스베가스 (Las Vegas)',\n",
    "    \"The key aspects of AI global cooperation highlighted in the G7's approach to ethical considerations and regulatory frameworks for advanced AI systems include:\\n\\n1. International Code of Conduct for Advanced AI Systems: The G7 has agreed on an international code of conduct for advanced AI systems, which includes provisions for identifying and mitigating risks, ensuring transparency and accountability, and promoting responsible AI development and use.\\n2. Voluntary Adoption: The G7 encourages companies to adopt the international code of conduct voluntarily, with a focus on self-regulation and industry-led initiatives.\\n3. Risk Evaluation and Mitigation: The code requires companies to evaluate and mitigate risks associated with advanced AI systems, including those related to bias, transparency, and accountability.\\n4. Transparency and Accountability: The code emphasizes the importance of transparency and accountability in AI development and use, including the disclosure of model performance and limitations.\\n5. Collaboration and Cooperation: The G7 encourages collaboration and cooperation among governments, industry, and civil society to address AI-related challenges and promote responsible AI development and use.\\n6. Information Sharing: The code promotes information sharing among countries and stakeholders to facilitate the development of effective regulatory frameworks and ensure consistent application of standards.\\n7. Standardization: The G7 aims to establish common standards for advanced AI systems, including those related to model performance, bias, and transparency.\\n\\nThese key aspects highlight the G7's commitment to promoting responsible AI development and use through international cooperation, voluntary adoption, and industry-led initiatives.\"]\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a92a1b2",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* **`try_2`** - (`5m 36.0s`)\n",
    "\n",
    "  * `request_timeout=None,`, `format=\"json\"` 옵션 추가했을 때의 답변 \n",
    "\n",
    "<small> <small>\n",
    "\n",
    "```python\n",
    "\n",
    "        ['{\"name\": \"Samsung Gauss\", \"text\": \"TechRepublic reported that Samsung Research has revealed a generative AI called \\'Samsung Gauss\\'.\"}',\n",
    "        '{\\n\"기간\": \"2024.1.9~12\",\\n\"장소\": \"미국, 라스베가스\",\\n\"홈페이지\": \"https://www.ces.tech/\"\\n}',\n",
    "        '{\\n\"위험 평가 및 완화\": \"G7은 AI 수명주기 전반에 걸쳐 위험을 평가 및 완화하는 조치를 채택하고, 취약점과 오용 사고, 오용 유형을 파악해 완화합니다.\",\\n\"투명성과 책임성의 보장\": \"G7은 첨단 AI 시스템의 성능과 한계를 공개하고 적절하거나 부적절한 사용영역을 알리는 방법으로 투명성을 보장하고 책임성을 강화합니다.\",\\n\"정보공유와 이해관계자 간 협력\": \"G7은 관련된 경우 해당 국가와 결과를 공유하며, 적절한 시기에 공동 표준 개발을 위해 노력하기로 합의합니다.\",\\n\"기반모델과 생성 AI를 포함한 첨단 AI 시스템의 위험 식별과 완화\": \"G7은 기반모델과 생성 AI를 포함한 첨단 AI 시스템의 위험 식별과 완화를 위한 조치를 포함하여 행동강령을 마련합니다.\"\\n}']\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8474e019",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* **`try_3`** - (`5m 40.2s`)\n",
    "\n",
    "<small> <small>\n",
    "\n",
    "```python\n",
    "\n",
    "    ['According to the retrieved context, TechRepublic has highlighted that Samsung has developed a generative AI called \"Samsung Gauss\" which is expected to compete with Meta\\'s Llama2 and Google\\'s Assistant on recent smartphones.',\n",
    "    'According to the retrieved context, the dates and location for CES 2024 are:\\n\\n* Dates: 2024.1.9~12\\n* Location: 미국 (United States), 라스베가스 (Las Vegas)',\n",
    "    'The key aspects of AI global cooperation highlighted in the G7\\'s approach to ethical considerations and regulatory frameworks for advanced AI systems include:\\n\\n1. International Code of Conduct for Advanced AI Systems: The G7 has agreed on an international code of conduct for advanced AI systems, which includes provisions for identifying and mitigating risks, ensuring transparency and accountability, and promoting responsible AI development and use.\\n2. Voluntary Adoption: The G7 is encouraging voluntary adoption of the international code of conduct by companies developing advanced AI systems.\\n3. Risk Evaluation and Mitigation: The G7 is requiring a risk evaluation and mitigation process for advanced AI systems, including the identification of potential risks and the implementation of measures to mitigate them.\\n4. Transparency and Accountability: The G7 is promoting transparency and accountability in AI development and use, including the disclosure of information about AI systems and their limitations.\\n5. Cooperation with International Organizations: The G7 is encouraging cooperation with international organizations, such as the United Nations, to promote global coordination on AI issues.\\n6. Development of a Global Framework: The G7 is working towards developing a global framework for regulating advanced AI systems, which would provide a common set of standards and guidelines for countries to follow.\\n7. Collaboration with Other Countries: The G7 is engaging in collaboration with other countries, including through the \"Hyorishima AI Process\", to promote global cooperation on AI issues.\\n\\nThese aspects highlight the G7\\'s commitment to promoting responsible AI development and use, while also recognizing the need for international cooperation and coordination to address the challenges posed by advanced AI systems.']\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc621f19",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d76982a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(answer))                     # <class 'list'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90ae41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed32bc93",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* **`print(answer)`**\n",
    "\n",
    "<small> <small>\n",
    "\n",
    "```python\n",
    "\n",
    "        ['According to the provided context, TechRepublic has highlighted that Samsung has developed a generative AI called \"Samsung Gauss\" and has revealed its research on it. Additionally, they mentioned that Samsung\\'s Llama2 is being used in Qualcomm devices and Google Assistant is being applied to Google Pixel phones, which are competing with each other in the market.', 'According to the retrieved context, the dates and location for CES 2024 are:\\n\\n* Dates: 2024.1.9~12\\n* Location: 미국 (United States), 라스베가스 (Las Vegas)', 'The key aspects of AI global cooperation highlighted in the G7\\'s approach to ethical considerations and regulatory frameworks for advanced AI systems include:\\n\\n1. International Code of Conduct for Advanced AI Systems: The G7 has agreed on an international code of conduct for advanced AI systems, which includes provisions for identifying and mitigating risks, ensuring transparency and accountability, and promoting responsible AI development and use.\\n2. Voluntary Adoption: The G7 is encouraging companies to voluntarily adopt the international code of conduct, with a focus on developing and deploying safe and secure AI systems.\\n3. Risk Evaluation and Mitigation: The G7 is emphasizing the need for risk evaluation and mitigation measures to be taken during the development and deployment of advanced AI systems.\\n4. Transparency and Accountability: The G7 is promoting transparency and accountability in AI decision-making, including the publication of model performance data and the establishment of mechanisms for addressing bias and errors.\\n5. International Cooperation: The G7 is encouraging international cooperation on AI-related issues, including the sharing of best practices and the development of common standards.\\n6. Regulatory Frameworks: The G7 is exploring regulatory frameworks to ensure that advanced AI systems are developed and deployed in a responsible and safe manner.\\n7. Model Card: Three countries (France, Germany, and Italy) have proposed the use of a \"model card\" to regulate foundation models, which would require companies to provide information about their models and ensure compliance with regulations.\\n\\nThese aspects highlight the G7\\'s commitment to promoting responsible AI development and use, while also acknowledging the need for international cooperation and regulatory frameworks to ensure that advanced AI systems are developed and deployed in a safe and secure manner.', 'I don\\'t know the specific answer to your question based on the provided context. However, I can suggest that you may want to look into the documents related to \"보건복지 부문\" (Health and Welfare Department) or \"혁신과 경쟁 촉진\" (Innovation and Competition Promotion) sections in the PDF file, as they seem to be related to AI development and deployment strategies.', 'The main takeaways from the AI Safety Summit on global AI testing include:\\n\\n1. The importance of cooperation among nations, international organizations, companies, civil society, and academia in ensuring AI safety.\\n2. The need for transparency and accountability in AI development, particularly from advanced AI systems developers.\\n3. The establishment of a framework for evaluating and testing AI systems to ensure their safety and security.\\n4. The creation of a global network of research institutions, governments, and industries to share knowledge and best practices on AI safety.\\n5. The commitment to develop and implement standards for AI system evaluation and testing.\\n\\nAdditionally, the summit also agreed on the following key points:\\n\\n* Each country will invest in public sector capabilities to test and evaluate AI systems.\\n* Advanced AI systems developers will take responsibility for ensuring the safety of their systems.\\n* A global network of research institutions, governments, and industries will be established to share knowledge and best practices on AI safety.\\n\\nIt is worth noting that these points were agreed upon by 28 countries participating in the summit.', \"I don't know.\", \"I don't know what the MMLU benchmark is or how it evaluates AI models like Tongyi Qianwen 2.0 for generative AI. The provided context only mentions Alibaba Cloud's launch of Tongyi Qianwen 2.0 and its plans to open-source a model with 720 billion parameters, but does not mention the MMLU benchmark.\", \"I don't know how the MMLU benchmark assesses AI models like Tongyi Qianwen 2.0. The provided context only mentions Alibaba Cloud's launch of Tongyi Qianwen 2.0 and its plans to open-source it, but does not mention the MMLU benchmark or its assessment method.\", \"I don't know how changes in AI evaluation criteria would specifically affect Large Language Models (LLMs). The provided context discusses the framework for evaluating Artificial General Intelligence (AGI) and its implications, but it doesn't directly address the impact of changes in AI evaluation criteria on LLMs. If you have more specific information or context about the changes in AI evaluation criteria, I might be able to provide a more informed answer.\", 'The provided context mentions several factors related to responsible AI deployment and use, but it does not explicitly mention \"ethical AI innovation\" as a specific topic.\\n\\nHowever, some relevant points can be inferred:\\n\\n1. The document emphasizes the importance of creating a strategy for responsible AI deployment and use in the healthcare sector.\\n2. It highlights the need to promote trustworthy AI development and use, with a focus on protecting consumers and workers.\\n3. The Executive Order on the Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence (E.O. 14110) mentions principles for ensuring responsible AI innovation.\\n\\nWhile these points touch on aspects of responsible AI development, they do not explicitly address all factors that might be relevant to \"ethical AI innovation.\" Therefore, I don\\'t know the answer to this question based on the provided context.']\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560f9d85",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7793693d",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* before\n",
    "\n",
    "* `print(answer)`\n",
    "\n",
    "<small> <small> <small>\n",
    "\n",
    "```python\n",
    "\n",
    "    ['According to the retrieved context, TechRepublic has highlighted that Samsung has developed a generative AI called \"Samsung Gauss\" which is expected to compete with Meta\\'s Llama2 and Google\\'s Assistant on recent smartphones.', 'According to the retrieved context, the dates and location for CES 2024 are:\\n\\n* Dates: 2024.1.9~12\\n* Location: 미국 (United States), 라스베가스 (Las Vegas)', 'The key aspects of AI global cooperation highlighted in the G7\\'s approach to ethical considerations and regulatory frameworks for advanced AI systems include:\\n\\n1. International Code of Conduct for Advanced AI Systems: The G7 has agreed on an international code of conduct for advanced AI systems, which includes provisions for identifying and mitigating risks, ensuring transparency and accountability, and promoting responsible AI development and use.\\n2. Voluntary Adoption: The G7 is encouraging voluntary adoption of the international code of conduct by companies developing advanced AI systems.\\n3. Risk Evaluation and Mitigation: The G7 is requiring a risk evaluation and mitigation process for advanced AI systems, including the identification of potential risks and the implementation of measures to mitigate them.\\n4. Transparency and Accountability: The G7 is promoting transparency and accountability in AI development and use, including the disclosure of information about AI systems and their limitations.\\n5. Cooperation with International Organizations: The G7 is encouraging cooperation with international organizations, such as the United Nations, to promote global coordination on AI issues.\\n6. Development of a Global Framework: The G7 is working towards developing a global framework for regulating advanced AI systems, which would provide a common set of standards and guidelines for countries to follow.\\n7. Collaboration with Other Countries: The G7 is engaging in collaboration with other countries, including through the \"Hyorishima AI Process\", to promote global cooperation on AI issues.\\n\\nThese aspects highlight the G7\\'s commitment to promoting responsible AI development and use, while also recognizing the need for international cooperation and coordination to address the challenges posed by advanced AI systems.', 'I don\\'t know the specific answer to your question based on the provided context. However, I can suggest that you may want to look into the documents related to \"보건복지 부문\" (Health and Welfare Department) or \"혁신과 경쟁 촉진\" (Innovation and Competition Promotion) sections in the PDF file, as they seem to be related to AI development and deployment strategies.', \"The main takeaways from the AI Safety Summit on global AI testing include:\\n\\n1. The importance of cooperation among nations, international organizations, companies, civil society, and academia in ensuring AI safety.\\n2. The need for transparency and accountability in AI development, particularly from advanced AI systems developers.\\n3. The agreement to develop and implement standardized evaluation methods and test tools for AI systems.\\n4. The commitment to enhance public awareness and understanding of AI risks and benefits through education and outreach initiatives.\\n5. The establishment of a global framework for testing and evaluating AI systems, with the involvement of governments, research institutions, and industry partners.\\n\\nAdditionally, it was announced that the UK would lead the development of a new AI safety test plan, which would be conducted by the UK's AI Safety Research Institute, in collaboration with other countries.\", \"I don't know. The provided context does not mention any link between data provenance, model efficiency, and NLP accuracy.\", \"I don't know what the MMLU benchmark is or how it evaluates AI models like Tongyi Qianwen 2.0 for generative AI. The provided context only mentions Alibaba Cloud's launch of Tongyi Qianwen 2.0 and its plans to open-source a model with 720 billion parameters, but does not mention the MMLU benchmark.\", \"I don't know. The provided context doesn't mention the MMLU benchmark or how it assesses AI models like Tongyi Qianwen 2.0. It only discusses the classification framework for AGI proposed by Google DeepMind and its relation to AI development and use.\", \"I don't know how changes in AI evaluation criteria would specifically affect Large Language Models (LLMs). The provided context discusses the framework for evaluating Artificial General Intelligence (AGI) and its implications, but it does not directly address the impact of changes in AI evaluation criteria on LLMs.\", 'According to the provided context, the following factors are mentioned as being important for ethical AI innovation:\\n\\n1. 책임 있는 AI 배포와 사용을 위한 전략 (strategies for responsible AI deployment and use)\\n2. 소비자 보호와 근로자 지원 (protection of consumers and workers)\\n3. 맞춤형 개인교습 등 학교 내 AI 교육 도구 관련 자원 개발 (development of tailored education resources for schools)\\n4. AI로 인한 근로자 피해를 완화하고 이점을 극대화하는 원칙 (principles to mitigate worker harm and maximize benefits from AI)\\n5. 혁신과 경쟁 촉진 (innovation and competition promotion)\\n\\nThese factors are mentioned in the context of Executive Order 14110, which aims to promote safe, secure, and trustworthy development and use of artificial intelligence.']\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd020a3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1625571c",
   "metadata": {},
   "source": [
    "* **`LLM`이 생성한 답변 = `answer` 컬럼에 저장하기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5024bce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'answer' 컬럼 덮어쓰기 또는 추가\n",
    "\n",
    "if \"answer\" in test_dataset.column_names:\n",
    "    test_dataset = test_dataset.remove_columns([\"answer\"]).add_column(\"answer\", answer)\n",
    "\n",
    "else:\n",
    "    test_dataset = test_dataset.add_column(\"answer\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ba779f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8614aad",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* **`print(test_dataset)`**\n",
    "\n",
    "```python\n",
    "\n",
    "        Dataset({\n",
    "            features: ['question', 'contexts', 'ground_truth', 'evolution_type', 'metadata', 'episode_done', 'answer'],\n",
    "            num_rows: 10\n",
    "        })\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7e04fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(test_dataset))                       # <class 'datasets.arrow_dataset.Dataset'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb99de7e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d6477f",
   "metadata": {},
   "source": [
    "#### **2) `답변 평가`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1224a71a",
   "metadata": {},
   "source": [
    "##### **`➀ Context Recall`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea2e51c",
   "metadata": {},
   "source": [
    "* **`검색된 context`가 `LLM`이 생성한 `답변`과 `얼마나 일치`하는지를 측정**\n",
    "\n",
    "  * `question`, `ground truth` 및 `검색된 context` → 계산\n",
    "\n",
    "  * 값 = `0 ~ 1` 사이 → **`높을수록 더 나은 성능`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cde75a2",
   "metadata": {},
   "source": [
    "* ![context_recall](../15_Evaluations/assets/02_context_recall.png)\n",
    "\n",
    "  * `Ground truth` 답변에서 `context recall`을 추정하기 위해, `ground truth` 답변의 `각 주장이 검색된 context`에 `귀속`될 수 있는지 분석\n",
    "\n",
    "  * 이상적인 시나리오: `ground truth 답변`의 `모든 주장`이 `검색된 context`에 `귀속`될 수 있어야 함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd56b97",
   "metadata": {},
   "source": [
    "##### **`➁ Context Precision`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56ea1bc",
   "metadata": {},
   "source": [
    "* **`contexts` 내의 `ground-truth` `관련 항목`들이 `상위 순위`에 있는지를 평가하는 지표**\n",
    "\n",
    "  * 이상적: `모든 관련 chunks` = `상위 순위`에 나타나야 함 \n",
    "\n",
    "  * `question`, `ground_truth`, `contexts` → 계산\n",
    "\n",
    "  * 값 = **`0 ~ 1` 사이** → **`높은 점수일수록 더 나은 정밀도`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211d4462",
   "metadata": {},
   "source": [
    "* 게산식\n",
    "\n",
    "  * `Context Precision@K`의 계산식\n",
    "\n",
    "  * ![Context Precision@K](../15_Evaluations/assets/02_context_precision.png)\n",
    "\n",
    "<br>\n",
    "\n",
    "* \n",
    "  * `Precision@k`의 계산식\n",
    "\n",
    "  * ![Precision@k](../15_Evaluations/assets/02_precision.png)\n",
    "\n",
    "    * `k` = **`contexta`의 총 `chunk` 수**\n",
    "\n",
    "    * `vₖ ∈ {0, 1}` = 순위 k에서의 관련성 지표\n",
    "\n",
    "<br>\n",
    "\n",
    "* 정보 검색 시스템에서 검색된 컨텍스트의 품질을 평가하는 데 사용\n",
    "\n",
    "  * 관련 정보가 얼마나 `정확하게 상위 순위`에 `배치`되었는지를 측정 → 시스템의 성능 판단"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df900c0",
   "metadata": {},
   "source": [
    "##### **`➂ Answer Relevancy`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **`생성된 답변`이 주어진 `prompt`에 `얼마나 적절한지`를 `평가`하는 지표** \n",
    "\n",
    "* 주요 특징\n",
    "\n",
    "  * 목적: 생성된 `답변`의 `관련성 평가`\n",
    "\n",
    "  * 점수 해석: \n",
    "    * 낮은 점수 = `불완전`하거나 `중복 정보`를 `포함`한 답변\n",
    "    * 높은 점수 = `더 나은 관련성`을 나타냄\n",
    "\n",
    "  * 계산에 사용되는 요소: `question`, `context`, `answer`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 게산 방법\n",
    "\n",
    "  * 원래 `question`과 `answer`를 기반으로 생성된 `인공적인 질문들 간`의 `평균 코사인 유사도`로 정의\n",
    "\n",
    "  * 수식 ➀\n",
    "\n",
    "    * ![answer_relevancy_1](../15_Evaluations/assets/02_answer_relevancy_1.png)\n",
    "\n",
    "  * 수식 ➁\n",
    "\n",
    "    * ![answer_relevancy_2](../15_Evaluations/assets/02_answer_relevancy_2.png)\n",
    "\n",
    "  * 참고\n",
    "\n",
    "    * **`E₀`** = 생성된 질문 `i`의 임베딩\n",
    "\n",
    "    * **`Eᵍᵢ`** ($E_{g_i}$) = 원래 질문의 임베딩\n",
    "\n",
    "    * ***`N`*** = 원래 질문의 임베딩 (*기본값 = 3*)\n",
    "\n",
    "    * 주의사항: 실제로는 점수가 대부분 0과 1 사이 → 코사인 유사도의 특성상 수학적으로 -1에서 1 사이의 값을 가질 수도 있음\n",
    "\n",
    "<br>\n",
    "\n",
    "* 질문-답변 시스템의 성능을 평가하는 데 유용\n",
    "\n",
    "  * `생성된 답변`이 `원래 질문의 의도`를 얼마나 잘 `반영`하는지를 측정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb190f1",
   "metadata": {},
   "source": [
    "##### **`➃ Faithfulness`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66bb6dc5",
   "metadata": {},
   "source": [
    "* **`생성된 답변의 사실적 일관성을 주어진 컨텍스트와 비교하여 측정하는 지표`**\n",
    "\n",
    "* 주요 특징\n",
    "\n",
    "  * 목적: `답변`의 `사실적 일관성`을 `컨텍스트`와 `비교` → 평가\n",
    "\n",
    "  * 계산 요소: `답변`과 `검색된 컨텍스트` 사용\n",
    "\n",
    "  * 점수 범위: `0 ~ 1 사이`로 조정 → **`높을수록 더 좋음`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2833590e",
   "metadata": {},
   "source": [
    "* 계산 방법\n",
    "\n",
    "  * 수식\n",
    "\n",
    "  * ![faithfulness](../15_Evaluations/assets/02_faithfulness.png)\n",
    "\n",
    "<br>\n",
    "\n",
    "* \n",
    "  * 계산 과정 ➀: `생성된 답변`에서 `주장`(claims)들을 `식별`\n",
    "\n",
    "  * 계산 과정 ➁: `각 주장`을 주어진 `컨텍스트`와 `대조` `검증` → `컨텍스트`에서 `추론 가능`한지 `확인`\n",
    "\n",
    "  * 계산 과정 ➂: 위 `수식`을 사용하여 `점수 계산`\n",
    "\n",
    "<br>\n",
    "\n",
    "* \n",
    "  * 예시\n",
    "\n",
    "    * 질문: **`\"아인슈타인은 어디서, 언제 태어났나요?\"`**\n",
    "\n",
    "    * 컨텍스트: **`\"알버트 아인슈타인(1879년 3월 14일 출생)은 독일 출신의 이론 물리학자로, 역사상 가장 위대하고 영향력 있는 과학자 중 한 명으로 여겨집니다.\"`**\n",
    "\n",
    "    * **`높은`** 충실도 답변: **`\"아인슈타인은 1879년 3월 14일 독일에서 태어났습니다.\"`**\n",
    "\n",
    "    * *`낮은`* 충실도 답변: *`\"아인슈타인은 1879년 3월 20일 독일에서 태어났습니다.\"`*\n",
    "\n",
    "<br>\n",
    "\n",
    "* `생성된 답변`이 주어진 `컨텍스트`에 얼마나 `충실`한지를 `평가`하는 데 유용\n",
    "  * 특히 `질문-답변` 시스템의 `정확성`과 `신뢰성`을 측정하는 데 중요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37d5b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas import evaluate\n",
    "\n",
    "from ragas.metrics import (\n",
    "    answer_relevancy,\n",
    "    faithfulness,\n",
    "    context_recall,\n",
    "    context_precision,\n",
    ")\n",
    "\n",
    "print(\"✅ 모험 평가 함수 생성 완료\")\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 2. 모든 Ragas Metrics에 LangChain LLM 객체 'llm' 직접 주입\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os \n",
    "\n",
    "# API 키 확인\n",
    "if not os.getenv(\"GOOGLE_API_KEY\"):\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = input(\"Enter your Google API key: \")    \n",
    "\n",
    "# gemini LLM 정의\n",
    "llm2 = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash-lite\",\n",
    "    temperature=0,\n",
    "    google_api_key=os.getenv(\"GOOGLE_API_KEY\")\n",
    "    )\n",
    "\n",
    "print(\"✅ gemini Critic LLM 정의 완료. (모델: gemini-2.5-flash-lite) \")\n",
    "\n",
    "result = evaluate(\n",
    "    dataset=test_dataset,\n",
    "    metrics=[\n",
    "        context_precision,\n",
    "        faithfulness,\n",
    "        answer_relevancy,\n",
    "        context_recall,\n",
    "    ],\n",
    "    llm=llm2,\n",
    ")\n",
    "\n",
    "print()\n",
    "print(\"=\"*60)\n",
    "print(\"✅ 평가 완료!\")\n",
    "print(\"=\"*60)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0063f5af",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* ✅ 모험 평가 함수 생성 완료 - (`0.2s`)\n",
    "\n",
    "* ✅ Ollama Critic LLM 정의 완료. (모델: llama3.2:3b, JSON 출력 강제)\n",
    "\n",
    "* ✅ Ragas Metrics에 LLM 주입 완료. 이제 평가를 시작할 준비가 되었습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a2c724",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* ✅ 모험 평가 함수 생성 완료 - (`0.5s`)\n",
    "\n",
    "* ✅ gemini Critic LLM 정의 완료. (모델: gemini-2.5-flash-lite) \n",
    "\n",
    "* ✅ Ragas Metrics에 LLM 주입 완료. 이제 평가를 시작할 준비가 되었습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cf943e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------\n",
    "# 데이터셋 첫번째 로우 확인하기\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "try:\n",
    "    print(\"\\n--- 1. 데이터셋 전체 컬럼 이름 확인 ---\")\n",
    "    \n",
    "    # 데이터셋의 실제 컬럼 이름 출력\n",
    "    actual_columns = test_dataset.column_names\n",
    "    print(f\"실제 컬럼 목록: {actual_columns}\")\n",
    "\n",
    "    # Ragas 필수 컬럼의 포함 여부 확인\n",
    "    required_cols = ['question', 'answer', 'contexts', 'ground_truth']\n",
    "    missing_cols = [col for col in required_cols if col not in actual_columns]\n",
    "    \n",
    "    if missing_cols:\n",
    "        print(f\"\\n❌ [치명적 오류]: Ragas 필수 컬럼 중 다음이 누락되었습니다: {missing_cols}\")\n",
    "    else:\n",
    "        print(\"\\n✅ [컬럼 이름 확인]: Ragas 필수 컬럼이 모두 존재합니다.\")\n",
    "\n",
    "    print(\"\\n--- 2. 첫 번째 로우의 값 및 타입 확인 (가장 중요) ---\")\n",
    "    first_row = test_dataset[0]\n",
    "\n",
    "    for col in required_cols:\n",
    "        value = first_row.get(col)\n",
    "        value_type = type(value)\n",
    "\n",
    "        # contexts 컬럼에 대한 특별 검사\n",
    "        if col == 'contexts':\n",
    "            # contexts가 리스트인지 확인\n",
    "            if value_type is list:\n",
    "                # 리스트의 첫 번째 요소가 문자열인지 확인\n",
    "                inner_type = type(value[0]) if value and len(value) > 0 else 'Empty List'\n",
    "                print(f\"  - {col} (타입: {value_type}, 내부 타입: {inner_type})\")\n",
    "                if inner_type != str:\n",
    "                    print(\"    🚨 경고: contexts 내부 요소는 반드시 문자열(str)이어야 합니다.\")\n",
    "            else:\n",
    "                print(f\"  - {col} (타입: {value_type})\")\n",
    "                print(\"    ❌ 치명적 오류: contexts 컬럼은 반드시 리스트(list)여야 합니다.\")\n",
    "        else:\n",
    "            # question, answer, ground_truth는 문자열인지 확인\n",
    "            print(f\"  - {col} (타입: {value_type})\")\n",
    "            if value_type is not str:\n",
    "                print(f\"    🚨 경고: {col} 컬럼은 반드시 문자열(str)이어야 합니다.\")\n",
    "\n",
    "except NameError:\n",
    "    print(\"\\n❌ 오류: 'test_dataset'이 정의되지 않았습니다. 데이터셋 로드를 먼저 실행해 주세요.\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n❌ 진단 중 예상치 못한 오류 발생:\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552f1837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------\n",
    "# 3. 평가 실행\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "print(\"평가 점수:\")\n",
    "for metric, score in result.items():\n",
    "    print(f\"  {metric}: {score:.4f}\")\n",
    "\n",
    "# DataFrame 변환\n",
    "result_df = result.to_pandas()\n",
    "print()\n",
    "print(\"결과 DataFrame:\")\n",
    "print(result_df.head())\n",
    "\n",
    "# 저장\n",
    "result_df.to_csv(\"../15_Evaluations/data/ragas_evaluation_result_2.csv\", index=False)\n",
    "print()\n",
    "print(\"✅ 저장 완료: data/ragas_evaluation_result.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bfd8ff3",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* **`try_1` → ❌** - (`9m 1.7s`)\n",
    "\n",
    "```bash\n",
    "\n",
    "        Evaluating:   100%|████████████████████████████████████████| 40/40 [09:00<00:00, 17.15s/it]\n",
    "\n",
    "```\n",
    "\n",
    "```python\n",
    "\n",
    "        {'context_precision': 1.0000, 'faithfulness': nan, 'answer_relevancy': nan, 'context_recall': 1.0000}\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c19f79a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c5c2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터프레임 형태로 확인하여 nan 발생 여부 확인\n",
    "result_df = result.to_pandas()\n",
    "result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad865a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.loc[:, \"context_precision\":\"context_recall\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009251c4",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7626d2",
   "metadata": {},
   "source": [
    "* next: ***`03. 생성한 평가용 데이터셋 업로드 (HuggingFace Dataset)`***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f4de16",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lc_eval_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
