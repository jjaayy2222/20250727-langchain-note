# eval_script.py

from dotenv import load_dotenv
load_dotenv()

import os
from myrag4 import PDFRAG
from langchain_google_genai import ChatGoogleGenerativeAI
from langsmith.evaluation import evaluate, LangChainStringEvaluator

print("ğŸš€ RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹œì‘...\n")

# í˜„ì¬ ìŠ¤í¬ë¦½íŠ¸ ìœ„ì¹˜ í™•ì¸
script_dir = os.path.dirname(os.path.abspath(__file__))
print(f"ğŸ“‚ ìŠ¤í¬ë¦½íŠ¸ ìœ„ì¹˜: {script_dir}\n")

# PDF íŒŒì¼ ì ˆëŒ€ ê²½ë¡œ ìƒì„±
pdf_path = os.path.join(script_dir, "data", "SPRI_AI_Brief_2023ë…„12ì›”í˜¸_F.pdf")
print(f"ğŸ“„ PDF ê²½ë¡œ: {pdf_path}")

# íŒŒì¼ ì¡´ì¬ í™•ì¸
if not os.path.exists(pdf_path):
    print(f"âŒ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤!")
    print(f"âŒ ê²½ë¡œ: {pdf_path}\n")
    
    # data í´ë” ë‚´ìš© í™•ì¸
    data_dir = os.path.join(script_dir, "data")
    if os.path.exists(data_dir):
        print(f"ğŸ“ data í´ë” ë‚´ìš©:")
        for file in os.listdir(data_dir):
            print(f"   - {file}")
    else:
        print(f"âŒ data í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤!")
    
    exit(1)

print(f"âœ… íŒŒì¼ í™•ì¸ ì™„ë£Œ!\n")

# LLM ìƒì„±
llm = ChatGoogleGenerativeAI(
    model="gemini-2.5-flash-lite",
    temperature=0
)
print("âœ… LLM ìƒì„± ì™„ë£Œ: gemini-2.5-flash-lite\n")

# RAG ìƒì„±
rag = PDFRAG(
    pdf_path,  # ì ˆëŒ€ ê²½ë¡œ ì‚¬ìš©!
    llm,
    chunk_size=300,
    chunk_overlap=50,
)

# Retriever & Chain (k=7!)
retriever = rag.create_retriever(k=7)
chain = rag.create_chain(retriever)

print("\n" + "="*50)
print("ğŸ§ª í…ŒìŠ¤íŠ¸ ì‹¤í–‰...")
print("="*50 + "\n")

# í…ŒìŠ¤íŠ¸
test_question = "ì‚¼ì„±ì „ìê°€ ìì²´ ê°œë°œí•œ ìƒì„±í˜• AIì˜ ì´ë¦„ì€ ë¬´ì—‡ì¸ê°€ìš”?"
test_answer = chain.invoke(test_question)
print(f"ì§ˆë¬¸: {test_question}")
print(f"ë‹µë³€: {test_answer}\n")

print("="*50)
print("ğŸ“Š í‰ê°€ ì‹œì‘...")
print("="*50 + "\n")

# ì§ˆë¬¸ í•¨ìˆ˜
def ask_question(inputs: dict):
    return {"answer": chain.invoke(inputs["question"])}

# í‰ê°€ì ìƒì„±
qa_evaluator = LangChainStringEvaluator(
    "qa",
    config={"llm": llm}
)


# í‰ê°€ ì‹¤í–‰
try:
    experiment_results = evaluate(
        ask_question,
        data="RAG_EVAL_DATASET",
        evaluators=[qa_evaluator],
        experiment_prefix="RAG_EVAL_K7",
        metadata={
            "variant": "k=7, chunk_size=300",
        },
        max_concurrency=1,
    )
    
    print("\n" + "="*50)
    print("âœ… í‰ê°€ ì™„ë£Œ!")
    print("="*50)
    print(f"\nê²°ê³¼: {experiment_results}\n")
    
except Exception as e:
    print(f"\nâŒ ì—ëŸ¬ ë°œìƒ: {e}\n")
