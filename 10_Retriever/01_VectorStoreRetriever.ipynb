{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf989cca",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5587735",
   "metadata": {},
   "source": [
    "* 출처: LangChain 공식 문서 또는 해당 교재명\n",
    "* 원본 URL: https://smith.langchain.com/hub/teddynote/summary-stuff-documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48fe9ecc",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827aa7b4",
   "metadata": {},
   "source": [
    "## **`CH10 검색기 (Retriever)`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d118df",
   "metadata": {},
   "source": [
    "* 벡터스토어 저장 단계 = **`RAG`** 의 **`5번째 단계`**\n",
    "\n",
    "  * 저장된 벡터 데이터베이스에서 **`사용자의 질문과 관련된 문서를 검색하는 과정`**\n",
    "  * 목표: 사용자 질문에 **`가장 적합한 정보를 신속하게 찾아내는 것`**\n",
    "  * `RAG` 시스템의 전반적인 성능과 직결되는 매우 중요한 과정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63361d89",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f40ca9",
   "metadata": {},
   "source": [
    "* 검색기의 **`필요성`**\n",
    "\n",
    "  * **`정확한 정보 제공`**\n",
    "\n",
    "    * 사용자의 질문과 **`가장 관련성 높은 정보를 검색` → 시스템이 `정확하고 유용한 답변을 생성`할 수 있도록 함**\n",
    "\n",
    "    * 이 과정이 효과적으로 이루어지지 않으면, 결과적으로 제공되는 **`답변의 품질이 떨어질 수 있음`**\n",
    "\n",
    "  * **`응답 시간 단축`**\n",
    "\n",
    "    * 효율적인 검색 알고리즘 사용 → 데이터베이스에서 적절한 **`정보를 빠르게 검색`** → 전체적인 **`시스템 응답 시간 단축`**\n",
    "\n",
    "    * 사용자 경험 향상에 직접적인 영향을 미침\n",
    "\n",
    "  * **`최적화`**\n",
    "\n",
    "    * 효과적인 검색 과정을 통해 **`필요한 정보만을 추출`** → 시스템 자원의 사용최적화, **`불필요한 데이터 처리 ↓`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22af638b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095e478b",
   "metadata": {},
   "source": [
    "* **`동작 방식`**\n",
    "\n",
    "  * **`질문의 벡터화`**\n",
    "\n",
    "    * 사용자의 질문을 벡터 형태로 변환\n",
    "\n",
    "    * 임베딩 단계와 유사한 기술을 사용해 진행\n",
    "\n",
    "    * 반환된 질문 벡터 = 후속 검색 작업의 기준점으로 사용됨\n",
    "\n",
    "  * **`벡터 유사성 비교`**\n",
    "\n",
    "    * 저장된 문서 벡터들과 질문 벡터 사이의 **`유사성을 계산`**\n",
    "      * *유사성 계산*: 주로 **`cosine similarity`**, **`MMR`** (`Max Marginal Relevance`) 등\n",
    "\n",
    "  * **`상위 문서 선정`**\n",
    "\n",
    "    * 계산된 유사성 점수를 기준으로 **`상위 N개의 가장 관련성 높은 문서를 선정`**\n",
    "\n",
    "    * 이 문서들은 다음 단계에서 사용자의 질문에 대한 답변을 생성하는 데 사용\n",
    "\n",
    "  * **`문서 정보 반환`**\n",
    "\n",
    "    * 선정된 문서들의 정보 → 다음 단계(`프롬프트 생성`)로 전달\n",
    "\n",
    "    * **`문서의 내용`, `위치`, `메타데이터` 등이 포함될 수 있음**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21aaae6e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85837f5",
   "metadata": {},
   "source": [
    "* **`검색기의 중요성`**\n",
    "\n",
    "  * `RAG` 시스템에서 **`정보 검색의 질을 결정하는 핵심적인 역할`**\n",
    "\n",
    "    * 효율적인 검색기 없이는 대규모 데이터베이스에서 관련 정보를 신속하고 정확하게 찾아내는 것 = 매우 어려움\n",
    "\n",
    "  * **`사용자의 질문에 대한 적절한 컨텍스트 제공` → 언어 모델이 보다 `정확한 답변을 생성`할 수 있도록 도움 → `RAG` 시스템의 전반적인 효율성과 사용자 만족도에 직접적인 영향을 미침**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa79166",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0e7c3b",
   "metadata": {},
   "source": [
    "* **`주요 두 가지 방법`**\n",
    "\n",
    "  * **`Sparse Retriever`** \n",
    "\n",
    "    * 문서, 질문(`query`)를 이산적인 **`키워드 벡터로 변환하여 처리`** \n",
    "    * 주로 텀 빈도-역문서 빈도(`TF-IDF`)나 `BM25` 같은 전통적인 정보 검색 기법 사용\n",
    "\n",
    "    <br>\n",
    "\n",
    "    * **`TF-IDF`** (`Term Frequency-Inverse Document Frequency`)\n",
    "      * 단어가 문서에 나타나는 빈도와 그 단어가 몇 개의 문서에서 나타나는지를 반영하여 단어의 중요도를 계산\n",
    "      * 자주 나타나면서도 문서 집합 전체에서 드물게 나타나는 단어가 높은 가중치를 받음\n",
    "  \n",
    "    * **`BM25`**\n",
    "      * `TF-IDF`를 개선한 모델 → 문서의 길이를 고려하여 검색 정확도를 향상시킴\n",
    "      * 긴 문서와 짧은 문서 간의 가중치 조정 → 단어 빈도의 영향을 상대적으로 조절 \n",
    "\n",
    "    <br>\n",
    "\n",
    "    * 특징\n",
    "      * 각 단어의 존재 여부만을 고려 → 계산 비용이 낮고, 구현이 간단\n",
    "      * 단어의 의미적 연관성을 고려하지 않음 → **`검색 결과의 품질이 키워드의 선택에 크게 의존`**\n",
    "\n",
    "<br>\n",
    "\n",
    "  * **`Dense Retriever`**\n",
    "\n",
    "    * 최신 딥러닝 기법을 사용 → 문서, `query`를 연속적인 고차원 벡터로 인코딩\n",
    "    * 문서의 의미적 내용을 보다 풍부하게 표현 가능 → **`키워드가 완벽히 일치하지 않더라고 의미적으로 관련된 문서를 검색 가능`**\n",
    "\n",
    "    <br>\n",
    "\n",
    "    * 벡터 공간에서의 거리 (예시: `코사인 유사도`)를 사용 → **`쿼리와 가장 관련성이 높은 문서를 찾음`**\n",
    "      * 언어의 뉘앙스와 문맥을 이해하는 데 유리\n",
    "      * **`복잡한 쿼리에 대해 더 정확한 검색 결과를 제공 가능`**\n",
    "\n",
    "<br>\n",
    "\n",
    "  * **`차이점`**\n",
    "\n",
    "    * **`표현 방식`**\n",
    "      * `Sparse Retriever`: 이산적인 키워드 기반의 표현을 사용\n",
    "      * `Dense Retriever`: 연속적인 벡터 공간에서의 의미적 표현 사용\n",
    "\n",
    "    * **`의미적 처리 능력`**\n",
    "      * `Dense Retriever`: 문맥, 의미 더 깊이 파악 → 키워드가 정확히 일치하지 않아도 관련 문서 검색 가능\n",
    "      * `Sparse Retiever`: 의미적 뉘앙스 덜 반영함\n",
    "\n",
    "    * **`적용 범위`**\n",
    "      * `Dense Retriever`: 복합한 질문, 자연어 쿼리에 더 적합\n",
    "      * `Sparse Retriever`: 간단, 명확한 키워드 검색에 더 유용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507003e2",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aaf2d75",
   "metadata": {},
   "source": [
    "* **코드**\n",
    "\n",
    "  * **`Dense Retriever`**\n",
    "\n",
    "```python\n",
    "\n",
    "        from langchain_community.vectorstores import FAISS\n",
    "\n",
    "        # 단계 4: DB 생성(Create DB) 및 저장\n",
    "        # 벡터스토어 생성하기\n",
    "        vectorstore = FAISS.from_documents(documents=split_documents, embedding=embeddings)\n",
    "\n",
    "        # 단계 5: Dense Retriever 생성\n",
    "        # 문서에 포함되어 있는 정보를 검색하고 생성하기\n",
    "        faiss_retriever = vectorstore.as_retriever()\n",
    "\n",
    "```\n",
    "\n",
    "*  * **`Sparse Retriever`**\n",
    "\n",
    "```python\n",
    "\n",
    "        from langchain_community.retrievers import BM25Retriever\n",
    "\n",
    "        # 단계 5: Sparse Retriever 생성\n",
    "        # 문서에 포함되어 있는 정보를 검색하고 생성하기\n",
    "        bm25_retriever = BM25Retriever.from_documents(split_documents)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00db166b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3faed0fd",
   "metadata": {},
   "source": [
    "* **참고**\n",
    "\n",
    "  * *[**`벡터저장소 지원 검색기`**](https://wikidocs.net/234016)*\n",
    "\n",
    "  * *[**`LangChain Retriever`**](https://python.langchain.com/v0.1/docs/modules/data_connection/retrievers/)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eaf4fcb",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e46434a",
   "metadata": {},
   "source": [
    "### **1. `VectorStore-backed Retriever`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2724843",
   "metadata": {},
   "source": [
    "#### **1) `벡터스토어 기반 검색기`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ebe135",
   "metadata": {},
   "source": [
    "* `Vector Store`를 사용해 문서를 검색하는 `Retriever`\n",
    "\n",
    "* `Vector Store`에 구현된 **`유사도 검색` (`similarity search`)**, **`MMR`** 같은 검색 메서드를 사용 → `Vector Store` 내의 텍스트를 쿼리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d5a301",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8748488",
   "metadata": {},
   "source": [
    "#### **2) `설정`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36b37773",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# API 키를 환경변수로 관리하기 위한 설정 파일\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API 키 정보 로드\n",
    "load_dotenv()                               # True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b64773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- LangSmith 환경 변수 확인 ---\n",
      "✅ LangSmith 추적 활성화됨 (LANGCHAIN_TRACING_V2='true')\n",
      "✅ LangSmith 프로젝트: 'LangChain-prantice'\n",
      "✅ LangSmith API Key: 설정됨\n",
      "  -> 이제 LangSmith 대시보드에서 이 프로젝트를 확인해 보세요.\n"
     ]
    }
   ],
   "source": [
    "from langsmith import Client\n",
    "from langsmith import traceable\n",
    "\n",
    "import os\n",
    "\n",
    "# LangSmith 환경 변수 확인\n",
    "\n",
    "print(\"\\n--- LangSmith 환경 변수 확인 ---\")\n",
    "langchain_tracing_v2 = os.getenv('LANGCHAIN_TRACING_V2')\n",
    "langchain_project = os.getenv('LANGCHAIN_PROJECT')\n",
    "langchain_api_key_status = \"설정됨\" if os.getenv('LANGCHAIN_API_KEY') else \"설정되지 않음\" # API 키 값은 직접 출력하지 않음\n",
    "\n",
    "if langchain_tracing_v2 == \"true\" and os.getenv('LANGCHAIN_API_KEY') and langchain_project:\n",
    "    print(f\"✅ LangSmith 추적 활성화됨 (LANGCHAIN_TRACING_V2='{langchain_tracing_v2}')\")\n",
    "    print(f\"✅ LangSmith 프로젝트: '{langchain_project}'\")\n",
    "    print(f\"✅ LangSmith API Key: {langchain_api_key_status}\")\n",
    "    print(\"  -> 이제 LangSmith 대시보드에서 이 프로젝트를 확인해 보세요.\")\n",
    "else:\n",
    "    print(\"❌ LangSmith 추적이 완전히 활성화되지 않았습니다. 다음을 확인하세요:\")\n",
    "    if langchain_tracing_v2 != \"true\":\n",
    "        print(f\"  - LANGCHAIN_TRACING_V2가 'true'로 설정되어 있지 않습니다 (현재: '{langchain_tracing_v2}').\")\n",
    "    if not os.getenv('LANGCHAIN_API_KEY'):\n",
    "        print(\"  - LANGCHAIN_API_KEY가 설정되어 있지 않습니다.\")\n",
    "    if not langchain_project:\n",
    "        print(\"  - LANGCHAIN_PROJECT가 설정되어 있지 않습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ecadfe5",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 셀 출력\n",
    "\n",
    "    ```markdown\n",
    "    --- LangSmith 환경 변수 확인 ---\n",
    "    ✅ LangSmith 추적 활성화됨 (LANGCHAIN_TRACING_V2='true')\n",
    "    ✅ LangSmith 프로젝트: 'LangChain-prantice'\n",
    "    ✅ LangSmith API Key: 설정됨\n",
    "    -> 이제 LangSmith 대시보드에서 이 프로젝트를 확인해 보세요.\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf86c0a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8974e187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384\n"
     ]
    }
   ],
   "source": [
    "# 허깅페이스 임베딩 모델 \n",
    "import gc\n",
    "import numpy as np\n",
    "import time\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.documents import Document\n",
    "import warnings\n",
    "\n",
    "# 경고 무시\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    model_kwargs={'device': 'cpu'},\n",
    "    encode_kwargs={'normalize_embeddings': True}\n",
    "    )\n",
    "\n",
    "# 임베딩\n",
    "embeddings = embeddings\n",
    "\n",
    "# 임베딩 차원 크기를 계산\n",
    "dimension_size = len(embeddings.embed_query(\"hello world\"))\n",
    "print(dimension_size)                                   # 384"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18e7e1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "# TextLoader를 사용하여 파일 로드하기\n",
    "loader = TextLoader(\"../10_Retriever/data/appendix-keywords.txt\")\n",
    "\n",
    "# 문서 로드하기\n",
    "documents = loader.load()\n",
    "\n",
    "# 문자 기반으로 텍스트를 분할하는 CharacterTextSplitter를 생성하기\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    chunk_size=300,                         # 청크 크기 = 300\n",
    "    chunk_overlap=0                         # 청크 간 중복 없음\n",
    "    )\n",
    "\n",
    "# 로드된 문서 분할하기\n",
    "split_docs = text_splitter.split_documents(documents)\n",
    "\n",
    "# 허깅페이스 임베딩 모델로 임베딩 생성하기\n",
    "embeddings = embeddings\n",
    "\n",
    "# 분할된 텍스트와 임베딩을 사용하여 FAISS 벡터 데이터베이스 생성하기\n",
    "db = FAISS.from_documents(split_docs, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c3e410",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91281dcb",
   "metadata": {},
   "source": [
    "#### **3) `VectorStore에서 VectorStoreRetriever 초기화`** (`as_retriever`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16686a3",
   "metadata": {},
   "source": [
    "* **`as_retriever`** 메서드: `VectorStore` 객체를 기반으로 `VectorStoreRetriever` 초기화 → 반환"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d4578d",
   "metadata": {},
   "source": [
    "* **`매개변수`**\n",
    "\n",
    "  * **`kwargs`**: 검색 함수에 전달할 키워드 인자\n",
    "\n",
    "  * **`search_type`**: 검색 유형\n",
    "    * `similarity`\n",
    "    * `MMR`\n",
    "    * `similarity_score_threshold`\n",
    "\n",
    "  * **`search_kwargs`**: 추가 검색 옵션 \n",
    "    * **`k`**: 반환할 문서 수 *(`기본값 = 4`)*\n",
    "    * **`score_threshold`**: `similarity_score_threshold` 검색의 최소 유사도 임계값\n",
    "    * **`fetch_k`**: `MMR` 알고리즘에 전달할 문서 수 *(`기본값 = 20`)*\n",
    "    * **`lambda_mult`**: `MMR` 결과의 다양성 조절 *(`0~1 사이`, `기본값=0.5`)*\n",
    "    * **`filter`**: 문서 메타데이터 기반 필터링"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d92d9c",
   "metadata": {},
   "source": [
    "* **`반환값`**\n",
    "  * **`VectorStoreRetriever`**: 초기화된 `VectorStoreRetriever` 객체"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ea1f53",
   "metadata": {},
   "source": [
    "* **`참고`**\n",
    "\n",
    "  * 다양한 검색 전략 구현 가능: `유사도`, `MMR`, `임계값 기반`\n",
    "  * `MMR` (`Maximal Marginal Relevance`) 알고리즘으로 검색 결과의 다양성 조절 가능\n",
    "  * 메타데이터 필터링으로 특정 조건의 문서만 검색 가능\n",
    "  * `tag` 매개변수를 통해 검색기에 태그 추가 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfe9017",
   "metadata": {},
   "source": [
    "* **`주의사항`**\n",
    "\n",
    "  * **`search_type`**, **`search_kwargs`** 적절한 조합 필요\n",
    "  * `MMR` 사용 시: **`fetch_k`**, **`k`** 값의 균형 조절 필요\n",
    "  * **`score_threshold`** 설정 시 너무 높은 값은 검색 결과가 없을 수 있음\n",
    "  * 필터 사용 시 데이터 셋의 메타데이터 구조를 정확히 파악할 필요가 있음\n",
    "  * **`lambda_mult`** 값이 `0`에 가까울수록 다양성이 높아지고, `1`에 가까울수록 유사성이 높아짐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "848f6c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터베이스를 검색기로 사용하기 위해 retriever 변수에 할당\n",
    "\n",
    "retriever = db.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68e9bbc",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6fef0d",
   "metadata": {},
   "source": [
    "#### **4) `Retriever의 invoke()`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a7fbfb",
   "metadata": {},
   "source": [
    "* **`invoke`** 메서드\n",
    "\n",
    "  * `Retriever`의 주요 진입점 → 관련 문서를 점색하는 데 사용\n",
    "  * 동기적으로 `Retriever`를 호출 → 주어진 쿼리에 대한 관련 문서 반환"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2194d95",
   "metadata": {},
   "source": [
    "* **`매개변수`**\n",
    "\n",
    "  * **`input`**: 검색 쿼리 문자열\n",
    "  * **`config`**: `Retriever` 구성 (`Optional`[`RunnableConfig`])\n",
    "  * **`kwargs`**: `Retriever`에 전달할 추가 인자"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd207b9",
   "metadata": {},
   "source": [
    "* **`반환값`**\n",
    "\n",
    "  * **`List` [`Document`]**: 관련 문서 목록"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9137e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 관련 문서를 검색해보기\n",
    "docs = retriever.invoke(\"임베딩(Embedding)은 무엇인가요?\")\n",
    "\n",
    "# 출력해보기\n",
    "for doc in docs:\n",
    "    print(doc.page_content)\n",
    "    print(\"=========================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b74ef9",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 셀 출력 (0.5s)\n",
    "\n",
    "    ```markdown\n",
    "    정의: JSON(JavaScript Object Notation)은 경량의 데이터 교환 형식으로, 사람과 기계 모두에게 읽기 쉬운 텍스트를 사용하여 데이터 객체를 표현합니다.\n",
    "    예시: {\"이름\": \"홍길동\", \"나이\": 30, \"직업\": \"개발자\"}는 JSON 형식의 데이터입니다.\n",
    "    연관키워드: 데이터 교환, 웹 개발, API\n",
    "\n",
    "    Transformer\n",
    "    =========================================================\n",
    "    정의: 토큰은 텍스트를 더 작은 단위로 분할하는 것을 의미합니다. 이는 일반적으로 단어, 문장, 또는 구절일 수 있습니다.\n",
    "    예시: 문장 \"나는 학교에 간다\"를 \"나는\", \"학교에\", \"간다\"로 분할합니다.\n",
    "    연관키워드: 토큰화, 자연어 처리, 구문 분석\n",
    "\n",
    "    Tokenizer\n",
    "    =========================================================\n",
    "    정의: 토크나이저는 텍스트 데이터를 토큰으로 분할하는 도구입니다. 이는 자연어 처리에서 데이터를 전처리하는 데 사용됩니다.\n",
    "    예시: \"I love programming.\"이라는 문장을 [\"I\", \"love\", \"programming\", \".\"]으로 분할합니다.\n",
    "    연관키워드: 토큰화, 자연어 처리, 구문 분석\n",
    "\n",
    "    VectorStore\n",
    "    =========================================================\n",
    "    정의: HuggingFace는 자연어 처리를 위한 다양한 사전 훈련된 모델과 도구를 제공하는 라이브러리입니다. 이는 연구자와 개발자들이 쉽게 NLP 작업을 수행할 수 있도록 돕습니다.\n",
    "    예시: HuggingFace의 Transformers 라이브러리를 사용하여 감정 분석, 텍스트 생성 등의 작업을 수행할 수 있습니다.\n",
    "    연관키워드: 자연어 처리, 딥러닝, 라이브러리\n",
    "\n",
    "    Digital Transformation\n",
    "    =========================================================\n",
    "    huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
    "    To disable this warning, you can either:\n",
    "        - Avoid using `tokenizers` before the fork if possible\n",
    "        - Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7399346",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e63d5c",
   "metadata": {},
   "source": [
    "#### **5) `MMR`** `Max Marginal Relevance`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8618a5e",
   "metadata": {},
   "source": [
    "* **`MMR`** (`Maximal Marginal Relevance`) 방식: 쿼리에 대한 관련 항목을 검색할 때 검색된 문서의 **`중복`** 을 피하는 방법 중 하나\n",
    "\n",
    "* 단순히 가장 관련성 높은 항목들만을 검색하는 대신, `MMR`은 쿼리에 대한 **`문서의 관련성`** 과 이미 선택된 **`문서들과의 차별성을 동시에 고려`**\n",
    "\n",
    "  * **`search_type`** 매개 변수: **`mmr`** 로 설정 → **`MMR`** (`Maximal Marginal Relevance`) 검색 알고리즘 사용하기\n",
    "  * **`k`**: 반환할 문서 수 *(`기본값 = 4`)*\n",
    "  * **`fetch_k`**: `MMR` 알고리즘에 전달할 문서 수 *(`기본값 = 20`)*\n",
    "  * **`lambda_mult`**: `MMR` 결과의 다양성 조절 *(`0~1`,`기본값 = 0.5`, `0: 유사도 점수만 고려`, `1: 다양성만 고려`)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e74b6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MMR(Maximal Marginal Relevance) 검색 유형을 지정\n",
    "retriever = db.as_retriever(\n",
    "    search_type=\"mmr\",                          # 검색유형 = MMR\n",
    "    search_kwargs={     \n",
    "        \"k\": 2,                                 # 반환할 문서 수 = 2\n",
    "        \"fetch_k\": 10,                          # 전달할 문서 수 = 10\n",
    "        \"lambda_mult\": 0.6                      # MMR 다양성 조절 = 0.6\n",
    "        }\n",
    ")\n",
    "\n",
    "# 관련 문서 검색하기\n",
    "docs = retriever.invoke(\"임베딩(Embedding)은 무엇인가요?\")\n",
    "\n",
    "# 관련 문서 출력하기\n",
    "for doc in docs:\n",
    "    print(doc.page_content)\n",
    "    print(\"=========================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432d326a",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 셀 출력\n",
    "\n",
    "    ```markdown\n",
    "    정의: JSON(JavaScript Object Notation)은 경량의 데이터 교환 형식으로, 사람과 기계 모두에게 읽기 쉬운 텍스트를 사용하여 데이터 객체를 표현합니다.\n",
    "    예시: {\"이름\": \"홍길동\", \"나이\": 30, \"직업\": \"개발자\"}는 JSON 형식의 데이터입니다.\n",
    "    연관키워드: 데이터 교환, 웹 개발, API\n",
    "\n",
    "    Transformer\n",
    "    =========================================================\n",
    "    정의: 토크나이저는 텍스트 데이터를 토큰으로 분할하는 도구입니다. 이는 자연어 처리에서 데이터를 전처리하는 데 사용됩니다.\n",
    "    예시: \"I love programming.\"이라는 문장을 [\"I\", \"love\", \"programming\", \".\"]으로 분할합니다.\n",
    "    연관키워드: 토큰화, 자연어 처리, 구문 분석\n",
    "\n",
    "    VectorStore\n",
    "    =========================================================\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756bfda9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7ff2f9",
   "metadata": {},
   "source": [
    "#### **6) `유사도 점수 임계값 검색`** (`similarity_score_threshold`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c11983c",
   "metadata": {},
   "source": [
    "* 유사도 점수 임계값을 설정하고 해당 임계값 이상의 점수를 가진 문서만 반환하는 검색 방법을 설정할 수 있음\n",
    "\n",
    "* 임계값을 적절히 설정 → **`관련성이 낮은 문서를 필터링`**, 질의와 **`가장 유사한 문서만 선별 가능`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a552e1",
   "metadata": {},
   "source": [
    "* **`search_type`** 매개변수 = **`similarity_score_threshold`**\n",
    "\n",
    "* **`search_kwargs`** 매개변수: **`{\"score_threshold\": 0.8}`** 전달 → 유사도 점수 임계값 = 0.8 으로 설정\n",
    "  * **`검색 결과의 유사도 점수가 0.8 이상인 문서만 반한됨을 의미`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad3a1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 유사도 점수 임계값으로 설정하기\n",
    "retriever = db.as_retriever(\n",
    "    search_type=\"similarity_score_threshold\",           # 검색 유형: \"similarity_score_threshold\" 으로 설정\n",
    "    search_kwargs={\"score_threshold\": 0.2},             # 유사도 점수 임계값: 0.2\n",
    ")\n",
    "\n",
    "# 출력하기\n",
    "for doc in retriever.invoke(\"Word2Vec 은 무엇인가요?\"):\n",
    "    print(doc.page_content)\n",
    "    print(\"=========================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819e70a5",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 셀 출력 (0.2s) (임계값 = 0.2)\n",
    "\n",
    "    ```markdown\n",
    "    정의: Word2Vec은 단어를 벡터 공간에 매핑하여 단어 간의 의미적 관계를 나타내는 자연어 처리 기술입니다. 이는 단어의 문맥적 유사성을 기반으로 벡터를 생성합니다.\n",
    "    예시: Word2Vec 모델에서 \"왕\"과 \"여왕\"은 서로 가까운 위치에 벡터로 표현됩니다.\n",
    "    연관키워드: 자연어 처리, 임베딩, 의미론적 유사성\n",
    "    LLM (Large Language Model)\n",
    "    =========================================================\n",
    "    ```\n",
    "\n",
    "<br>\n",
    "\n",
    "* 셀 출력 (임계값 > 0.3)\n",
    "  * `0.3`이상으로 설정하니 값이 나오지 않음\n",
    "  * 교재 내용처럼 `임계값을 0.8`로 설정했을 경우의 메시지\n",
    "  \n",
    "    ```markdown\n",
    "    No relevant docs were retrieved using the relevance score threshold 0.8\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2f44e7",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc25f699",
   "metadata": {},
   "source": [
    "#### **7) `top_k 설정`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef995f0",
   "metadata": {},
   "source": [
    "* 검색 시 사용할 **`k`** 같은 검색 키워드 인자 (`kwargs`) 지정할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196f90dd",
   "metadata": {},
   "source": [
    "* **`k`** 매개변수: 검색 결과에서 반환할 상위 결과의 개수\n",
    "\n",
    "  * **`search_kwargs`** 에서 **`k`** 매개변수를 **`1`** 로 설정 → 검색 결과로 반환할 문서의 수를 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffac44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# k 설정\n",
    "retriever = db.as_retriever(search_kwargs={\"k\": 1})\n",
    "\n",
    "# 관련 문서를 검색\n",
    "docs = retriever.invoke(\"임베딩(Embedding)은 무엇인가요?\")\n",
    "\n",
    "# 관련 문서를 검색\n",
    "for doc in docs:\n",
    "    print(doc.page_content)\n",
    "    print(\"=========================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f587b143",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 셀 출력\n",
    "\n",
    "    ```markdown\n",
    "    정의: JSON(JavaScript Object Notation)은 경량의 데이터 교환 형식으로, 사람과 기계 모두에게 읽기 쉬운 텍스트를 사용하여 데이터 객체를 표현합니다.\n",
    "    예시: {\"이름\": \"홍길동\", \"나이\": 30, \"직업\": \"개발자\"}는 JSON 형식의 데이터입니다.\n",
    "    연관키워드: 데이터 교환, 웹 개발, API\n",
    "\n",
    "    Transformer\n",
    "    =========================================================\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a013e0a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a73382",
   "metadata": {},
   "source": [
    "#### **8) `동적 설정` (`Configurable`)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2283928d",
   "metadata": {},
   "source": [
    "* 검색 설정을 동적으로 조정하기 위해 **`ConfigurableField`** 를 사용\n",
    "* **`ConfigurableField`** = 검색 매개변수의 `고유 식별자`, `이름`, `설명`을 설정하는 역할\n",
    "* 검색 설정을 조정하기 위해 **`config`** 매개변수 사용 → 검색 설정 지정\n",
    "* 검색 설정: \n",
    "  * **`config`** 매개변수에 전달된 `딕셔너리`의 **`configurable`** `키`에 저장\n",
    "  * **`검색 쿼리`** 와 함께 전달 → 검색 `쿼리`에 따라 **`동적`으로 조정**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "744ccd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import ConfigurableField\n",
    "\n",
    "# k 설정\n",
    "retriever = db.as_retriever(search_kwargs={\"k\": 1}).configurable_fields(\n",
    "    search_type=ConfigurableField(\n",
    "        id=\"search_type\",\n",
    "        name=\"Search Type\",\n",
    "        description=\"The search type to use\",\n",
    "    ),\n",
    "    search_kwargs=ConfigurableField(\n",
    "        id=\"search_kwargs\",                         # 검색 매개변수의 고유 식별자를 설정\n",
    "        name=\"Search Kwargs\",                       # 검색 매개변수의 이름을 설정\n",
    "        description=\"The search kwargs to use\",     # 검색 매개변수에 대한 설명을 작성\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec538e10",
   "metadata": {},
   "source": [
    "* 동적 검색설정을 적용한 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e91a033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검색 설정을 지정. Faiss 검색에서 k=3로 설정하여 가장 유사한 문서 3개를 반환\n",
    "config = {\"configurable\": {\"search_kwargs\": {\"k\": 3}}}\n",
    "\n",
    "# 관련 문서를 검색\n",
    "docs = retriever.invoke(\"임베딩(Embedding)은 무엇인가요?\", config=config)\n",
    "\n",
    "# 관련 문서를 검색\n",
    "for doc in docs:\n",
    "    print(doc.page_content)\n",
    "    print(\"=========================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff80de4a",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 셀 출력\n",
    "\n",
    "    ```markdown\n",
    "    정의: JSON(JavaScript Object Notation)은 경량의 데이터 교환 형식으로, 사람과 기계 모두에게 읽기 쉬운 텍스트를 사용하여 데이터 객체를 표현합니다.\n",
    "    예시: {\"이름\": \"홍길동\", \"나이\": 30, \"직업\": \"개발자\"}는 JSON 형식의 데이터입니다.\n",
    "    연관키워드: 데이터 교환, 웹 개발, API\n",
    "\n",
    "    Transformer\n",
    "    =========================================================\n",
    "    정의: 토큰은 텍스트를 더 작은 단위로 분할하는 것을 의미합니다. 이는 일반적으로 단어, 문장, 또는 구절일 수 있습니다.\n",
    "    예시: 문장 \"나는 학교에 간다\"를 \"나는\", \"학교에\", \"간다\"로 분할합니다.\n",
    "    연관키워드: 토큰화, 자연어 처리, 구문 분석\n",
    "\n",
    "    Tokenizer\n",
    "    =========================================================\n",
    "    정의: 토크나이저는 텍스트 데이터를 토큰으로 분할하는 도구입니다. 이는 자연어 처리에서 데이터를 전처리하는 데 사용됩니다.\n",
    "    예시: \"I love programming.\"이라는 문장을 [\"I\", \"love\", \"programming\", \".\"]으로 분할합니다.\n",
    "    연관키워드: 토큰화, 자연어 처리, 구문 분석\n",
    "\n",
    "    VectorStore\n",
    "    =========================================================\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d6505f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검색 설정을 지정: mmr 검색 설정\n",
    "config = {\n",
    "    \"configurable\": {\n",
    "        \"search_type\": \"mmr\",\n",
    "        \"search_kwargs\": {\"k\": 2, \"fetch_k\": 10, \"lambda_mult\": 0.6},\n",
    "    }\n",
    "}\n",
    "\n",
    "# 관련 문서를 검색\n",
    "docs = retriever.invoke(\"Word2Vec 은 무엇인가요?\", config=config)\n",
    "\n",
    "# 관련 문서를 검색\n",
    "for doc in docs:\n",
    "    print(doc.page_content)\n",
    "    print(\"=========================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7079686",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 셀 출력\n",
    "\n",
    "    ```markdown\n",
    "    정의: Word2Vec은 단어를 벡터 공간에 매핑하여 단어 간의 의미적 관계를 나타내는 자연어 처리 기술입니다. 이는 단어의 문맥적 유사성을 기반으로 벡터를 생성합니다.\n",
    "    예시: Word2Vec 모델에서 \"왕\"과 \"여왕\"은 서로 가까운 위치에 벡터로 표현됩니다.\n",
    "    연관키워드: 자연어 처리, 임베딩, 의미론적 유사성\n",
    "    LLM (Large Language Model)\n",
    "    =========================================================\n",
    "    정의: JSON(JavaScript Object Notation)은 경량의 데이터 교환 형식으로, 사람과 기계 모두에게 읽기 쉬운 텍스트를 사용하여 데이터 객체를 표현합니다.\n",
    "    예시: {\"이름\": \"홍길동\", \"나이\": 30, \"직업\": \"개발자\"}는 JSON 형식의 데이터입니다.\n",
    "    연관키워드: 데이터 교환, 웹 개발, API\n",
    "\n",
    "    Transformer\n",
    "    =========================================================\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463a02b0",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d904c3",
   "metadata": {},
   "source": [
    "#### **9) `Upstage 임베딩과 같이 Query & Passage embedding model이 분리된 경우`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c1a2ad",
   "metadata": {},
   "source": [
    "* 기본 retriever는 쿼리와 문서에 대해 동일한 임베딩 모델을 사용\n",
    "\n",
    "* 하지만 쿼리와 문서에 대해 서로 다른 임베딩 모델을 사용하는 경우가 있음\n",
    "\n",
    "  * 이러한 경우에는 쿼리 임베딩 모델을 사용하여 쿼리를 임베딩하고, 문서 임베딩 모델을 사용하여 문서를 임베딩함\n",
    "\n",
    "  * 이렇게 하면 쿼리와 문서에 대해 서로 다른 임베딩 모델을 사용할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd81af31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_upstage import UpstageEmbeddings\n",
    "\n",
    "# TextLoader를 사용하여 파일을 로드하기\n",
    "loader = TextLoader(\"../10_Retriever/data/appendix-keywords.txt\")\n",
    "\n",
    "# 문서를 로드하기\n",
    "documents = loader.load()\n",
    "\n",
    "# 문자 기반으로 텍스트를 분할하는 CharacterTextSplitter를 생성하기\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    chunk_size=300,                             # 청크 크기 = 300\n",
    "    chunk_overlap=0                             # 청크 간 중복 없음\n",
    "    )\n",
    "\n",
    "# 로드된 문서 분할하기\n",
    "split_docs = text_splitter.split_documents(documents)\n",
    "\n",
    "# Upstage 임베딩 생성하기\n",
    "doc_embedder = UpstageEmbeddings(model=\"solar-embedding-1-large-passage\")   # 문서용 모델 사용하기\n",
    "\n",
    "# 분할된 텍스트와 임베딩을 사용하여 FAISS 벡터 데이터베이스를 생성하기\n",
    "db = FAISS.from_documents(split_docs, doc_embedder)                         # 4.5s 소요"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d01cae",
   "metadata": {},
   "source": [
    "* 쿼리용 Upstage 임베딩 생성 → 쿼리 문장을 벡터로 변환 → 벡터 유사도 검색 수행하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf9bb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 쿼리용 Upstage 임베딩 생성하기\n",
    "query_embedder = UpstageEmbeddings(model=\"solar-embedding-1-large-query\")   # 쿼리용 모델 사용하기\n",
    "\n",
    "# 쿼리 문장을 벡터로 변환하기\n",
    "query_vector = query_embedder.embed_query(\"임베딩(Embedding)은 무엇인가요?\")\n",
    "\n",
    "# 벡터 유사도 검색을 수행하여 가장 유사한 2개의 문서를 반환하기\n",
    "db.similarity_search_by_vector(query_vector, k=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5012a450",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 셀 출력 (0.6s)\n",
    "\n",
    "    ```python\n",
    "    [Document(id='e3a78902-0a79-4851-a532-4a8c48d9c2dd', metadata={'source': '../10_Retriever/data/appendix-keywords.txt'}, page_content='정의: 임베딩은 단어나 문장 같은 텍스트 데이터를 저차원의 연속적인 벡터로 변환하는 과정입니다. 이를 통해 컴퓨터가 텍스트를 이해하고 처리할 수 있게 합니다.\\n예시: \"사과\"라는 단어를 [0.65, -0.23, 0.17]과 같은 벡터로 표현합니다.\\n연관키워드: 자연어 처리, 벡터화, 딥러닝\\n\\nToken'),\n",
    "    Document(id='bbc6b2cc-270a-4f2f-8171-b6b7b1f2f960', metadata={'source': '../10_Retriever/data/appendix-keywords.txt'}, page_content='정의: Word2Vec은 단어를 벡터 공간에 매핑하여 단어 간의 의미적 관계를 나타내는 자연어 처리 기술입니다. 이는 단어의 문맥적 유사성을 기반으로 벡터를 생성합니다.\\n예시: Word2Vec 모델에서 \"왕\"과 \"여왕\"은 서로 가까운 위치에 벡터로 표현됩니다.\\n연관키워드: 자연어 처리, 임베딩, 의미론적 유사성\\nLLM (Large Language Model)')]\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe4a46b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9480ef",
   "metadata": {},
   "source": [
    "* *next: **`문맥 압축 검색기 (ContextualCompressionRetriever)`***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c888d3dc",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lc_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
