{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf989cca",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5587735",
   "metadata": {},
   "source": [
    "* ì¶œì²˜: LangChain ê³µì‹ ë¬¸ì„œ ë˜ëŠ” í•´ë‹¹ êµì¬ëª…\n",
    "* ì›ë³¸ URL: https://smith.langchain.com/hub/teddynote/summary-stuff-documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48fe9ecc",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e46434a",
   "metadata": {},
   "source": [
    "#### **2. `ContextualCompressionRetriever`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2724843",
   "metadata": {},
   "source": [
    "#### **1) `ë¬¸ë§¥ ì••ì¶• ê²€ìƒ‰ê¸°`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480d76a2",
   "metadata": {},
   "source": [
    "* **`ê²€ìƒ‰ ì‹œìŠ¤í…œì˜ ì–´ë ¤ì›€ê³¼ ë¬¸ì œì `**\n",
    "\n",
    "  * ì‚¬ìš©ìê°€ **`ì–´ë–¤ ì§ˆë¬¸`(`ì§ˆì˜`)ì„ í• ì§€ `ë¯¸ë¦¬ ì•Œ ìˆ˜ ì—†ë‹¤`ëŠ” ì **\n",
    "\n",
    "  * **`ë¬¸ì œì `**: **`ì§ˆë¬¸ì— ê°€ì¥ ê´€ë ¨ ìˆëŠ” ì •ë³´`ê°€ *`ë§¤ìš° ë§ì€ ë¶ˆí•„ìš”í•œ í…ìŠ¤íŠ¸ê°€ ë‹´ê¸´ ë¬¸ì„œ`* ì†ì— ì„ì—¬ ìˆì„ ìˆ˜ ìˆìŒ**\n",
    "\n",
    "  * **`ê²°ê³¼`**: **`ì „ì²´ ë¬¸ì„œ`ë¥¼ `ì–¸ì–´ ëª¨ë¸`(`LLM`)ì— ê·¸ëŒ€ë¡œ ì „ë‹¬ ì‹œ â†’ `ë¹„ìš©ì´ ë§ì´ ë“¤ê³ `, `ë‹µë³€ì˜ í’ˆì§ˆì´ ë‚®ì•„ì§`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726b8d99",
   "metadata": {},
   "source": [
    "* ![ë¬¸ë§¥ ì••ì¶• ê²€ìƒ‰ê¸°](../10_Retriever/images/01-Contextual-Compression.jpeg)\n",
    "  * *[ì¶œì²˜](https://drive.google.com/uc?id=1CtNgWODXZudxAWSRiWgSGEoTNrUFT98v):* *https://drive.google.com/uc?id=1CtNgWODXZudxAWSRiWgSGEoTNrUFT98v*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48cb0322",
   "metadata": {},
   "source": [
    "* **`ContextualCompressionRetriever` = í•´ê²°ì±…**\n",
    "\n",
    "  * **`ê¸°ë³¸ ì•„ì´ë””ì–´`**: ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ ë°”ë¡œ ë°˜í™˜ X â†’ **`ì‚¬ìš©ìì˜ ì§ˆë¬¸(ì§ˆì˜)ì˜ ë§¥ë½`ì„ ì‚¬ìš©** â†’ ë¬¸ì„œì˜ ë‚´ìš©ì„ **`ì••ì¶•`**\n",
    "\n",
    "  * **`ì••ì¶•`ì˜ ì˜ë¯¸**:\n",
    "\n",
    "    * ê°œë³„ ë¬¸ì„œì—ì„œ `ê´€ë ¨ ì—†ëŠ” ë‚´ìš©`ì„ `ì œê±°` â†’ ë‚´ìš©ì„ ì¤„ì„\n",
    "\n",
    "    * `ë¶ˆí•„ìš”í•œ ë¬¸ì„œ`ë¥¼ `ëª©ë¡`ì—ì„œ `ì œì™¸`í•˜ëŠ” ê²ƒì„ ëª¨ë‘ í¬í•¨\n",
    "\n",
    "  * **`ì‘ë™ ë°©ì‹`**:\n",
    "\n",
    "    * ì§ˆì˜ë¥¼ **`ê¸°ë³¸ ê²€ìƒ‰ê¸°`(`base retriever`)** ì— ì „ë‹¬\n",
    "\n",
    "    * ê¸°ë³¸ ê²€ìƒ‰ê¸°ì—ì„œ ì´ˆê¸° ë¬¸ì„œë¥¼ ê°€ì ¸ì˜´\n",
    "\n",
    "    * ì´ ë¬¸ì„œë¥¼ `Document Compressor`ì— í†µê³¼ì‹œì¼œ ê°€ì¥ ê´€ë ¨ ìˆëŠ” ì •ë³´ë§Œ ë‚¨ë„ë¡ ë‚´ìš©ì„ ì¤„ì´ê±°ë‚˜ ë¬¸ì„œë¥¼ ì œê±°\n",
    "\n",
    "  * **`ëª©í‘œ`**: ê´€ë ¨ ìˆëŠ” ì •ë³´ë§Œ ì‘ìš© í”„ë¡œê·¸ë¨ì— ì „ë‹¬ë˜ê²Œ í•˜ì—¬, LLM í˜¸ì¶œ ë¹„ìš©ì„ ì¤„ì´ê³  ë‹µë³€ í’ˆì§ˆì„ ë†’ì´ëŠ” ê²ƒ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d5a301",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8748488",
   "metadata": {},
   "source": [
    "#### **2) `ì„¤ì •`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b37773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API í‚¤ë¥¼ í™˜ê²½ë³€ìˆ˜ë¡œ ê´€ë¦¬í•˜ê¸° ìœ„í•œ ì„¤ì • íŒŒì¼\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API í‚¤ ì •ë³´ ë¡œë“œ\n",
    "load_dotenv()                               # True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b64773",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import Client\n",
    "from langsmith import traceable\n",
    "\n",
    "import os\n",
    "\n",
    "# LangSmith í™˜ê²½ ë³€ìˆ˜ í™•ì¸\n",
    "\n",
    "print(\"\\n--- LangSmith í™˜ê²½ ë³€ìˆ˜ í™•ì¸ ---\")\n",
    "langchain_tracing_v2 = os.getenv('LANGCHAIN_TRACING_V2')\n",
    "langchain_project = os.getenv('LANGCHAIN_PROJECT')\n",
    "langchain_api_key_status = \"ì„¤ì •ë¨\" if os.getenv('LANGCHAIN_API_KEY') else \"ì„¤ì •ë˜ì§€ ì•ŠìŒ\" # API í‚¤ ê°’ì€ ì§ì ‘ ì¶œë ¥í•˜ì§€ ì•ŠìŒ\n",
    "\n",
    "if langchain_tracing_v2 == \"true\" and os.getenv('LANGCHAIN_API_KEY') and langchain_project:\n",
    "    print(f\"âœ… LangSmith ì¶”ì  í™œì„±í™”ë¨ (LANGCHAIN_TRACING_V2='{langchain_tracing_v2}')\")\n",
    "    print(f\"âœ… LangSmith í”„ë¡œì íŠ¸: '{langchain_project}'\")\n",
    "    print(f\"âœ… LangSmith API Key: {langchain_api_key_status}\")\n",
    "    print(\"  -> ì´ì œ LangSmith ëŒ€ì‹œë³´ë“œì—ì„œ ì´ í”„ë¡œì íŠ¸ë¥¼ í™•ì¸í•´ ë³´ì„¸ìš”.\")\n",
    "else:\n",
    "    print(\"âŒ LangSmith ì¶”ì ì´ ì™„ì „íˆ í™œì„±í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë‹¤ìŒì„ í™•ì¸í•˜ì„¸ìš”:\")\n",
    "    if langchain_tracing_v2 != \"true\":\n",
    "        print(f\"  - LANGCHAIN_TRACING_V2ê°€ 'true'ë¡œ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤ (í˜„ì¬: '{langchain_tracing_v2}').\")\n",
    "    if not os.getenv('LANGCHAIN_API_KEY'):\n",
    "        print(\"  - LANGCHAIN_API_KEYê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.\")\n",
    "    if not langchain_project:\n",
    "        print(\"  - LANGCHAIN_PROJECTê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ecadfe5",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* ì…€ ì¶œë ¥\n",
    "\n",
    "    ```markdown\n",
    "    --- LangSmith í™˜ê²½ ë³€ìˆ˜ í™•ì¸ ---\n",
    "    âœ… LangSmith ì¶”ì  í™œì„±í™”ë¨ (LANGCHAIN_TRACING_V2='true')\n",
    "    âœ… LangSmith í”„ë¡œì íŠ¸: 'LangChain-prantice'\n",
    "    âœ… LangSmith API Key: ì„¤ì •ë¨\n",
    "    -> ì´ì œ LangSmith ëŒ€ì‹œë³´ë“œì—ì„œ ì´ í”„ë¡œì íŠ¸ë¥¼ í™•ì¸í•´ ë³´ì„¸ìš”.\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff86048e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë¬¸ì„œë¥¼ ì˜ˆì˜ê²Œ ì¶œë ¥í•˜ê¸° ìœ„í•œ ë„ìš°ë¯¸ í•¨ìˆ˜\n",
    "def pretty_print_docs(docs):\n",
    "    print(\n",
    "        f\"\\n{'-' * 100}\\n\".join(\n",
    "            [f\"ë¬¸ì„œ {i+1}:\\n\\n\" + d.page_content for i, d in enumerate(docs)]\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf86c0a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9c8342",
   "metadata": {},
   "source": [
    "#### **3) `ê¸°ë³¸ Retriever ì„¤ì •`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b47e92e",
   "metadata": {},
   "source": [
    "* ê°„ë‹¨í•œ ë²¡í„° ìŠ¤í† ì–´ `retriever` ì´ˆê¸°í™” â†’ í…ìŠ¤íŠ¸ ë¬¸ì„œë¥¼ ì²­í¬ ë‹¨ìœ„ë¡œ ì €ì¥í•˜ëŠ” ê²ƒë¶€í„° ì‹œì‘\n",
    "\n",
    "* ì˜ˆì‹œ ì§ˆë¬¸: `retriever`ëŠ” ê´€ë ¨ ìˆëŠ” ë¬¸ì„œ `1~2`ê°œì™€ ê´€ë ¨ ì—†ëŠ” ë¬¸ì„œ ëª‡ ê°œë¥¼ ë°˜í™˜í•˜ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆìŒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf3a08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "import warnings\n",
    "\n",
    "# ê²½ê³  ë¬´ì‹œ\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    model_kwargs={'device': 'cpu'},\n",
    "    encode_kwargs={'normalize_embeddings': True}\n",
    "    )\n",
    "\n",
    "# 1ë‹¨ê³„: Fake Embeddings ì‚¬ìš©\n",
    "embeddings = embeddings\n",
    "\n",
    "# ì„ë² ë”© ì°¨ì› í¬ê¸°ë¥¼ ê³„ì‚°\n",
    "dimension_size = len(embeddings.embed_query(\"hello world\"))\n",
    "print(dimension_size)                                                     # 384\n",
    "print(\"âœ… HuggingFaceEmbeddings ì´ˆê¸°í™” ì™„ë£Œ!\")                               # âœ… HuggingFaceEmbeddings ì´ˆê¸°í™” ì™„ë£Œ!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29107ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2ë‹¨ê³„: ë¬¸ì„œ ë¡œë” ë° ë¶„í• \n",
    "\n",
    "loader = TextLoader(\"../10_Retriever/data/appendix-keywords.txt\")\n",
    "documents = loader.load()\n",
    "\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    chunk_size=300,\n",
    "    chunk_overlap=0\n",
    ")\n",
    "split_docs = text_splitter.split_documents(documents)            # split_documents() ì‚¬ìš©!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8242992b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3ë‹¨ê³„: ë²¡í„°ìŠ¤í† ì–´ ìƒì„±\n",
    "\n",
    "db = FAISS.from_documents(split_docs, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f5864aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4ë‹¨ê³„: ê²€ìƒ‰ê¸°(Retriever) ìƒì„±\n",
    "\n",
    "retriever = db.as_retriever()                      # ë²¡í„°ìŠ¤í† ì–´ì—ì„œ as_retriever() í˜¸ì¶œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "156036c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5ë‹¨ê³„: ê²€ìƒ‰ ì‹¤í–‰\n",
    "\n",
    "docs = retriever.invoke(\"Semantic Search ì— ëŒ€í•´ì„œ ì•Œë ¤ì¤˜.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78c75d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6ë‹¨ê³„: ê²°ê³¼ ì¶œë ¥\n",
    "def pretty_print_docs(docs):\n",
    "    for i, doc in enumerate(docs):\n",
    "        print(f\"Document {i+1}:\")\n",
    "        print(doc.page_content)\n",
    "        print(\"=\" * 50)\n",
    "\n",
    "pretty_print_docs(docs)\n",
    "print(\"ğŸ‰ âœ… HuggingFaceEmbeddingsë¡œ ì™„ë²½ ì‹¤í–‰!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00966f8",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* ì…€ ì¶œë ¥\n",
    "\n",
    "    ```markdown\n",
    "    Document 1:\n",
    "    Semantic Search\n",
    "\n",
    "    ì •ì˜: ì˜ë¯¸ë¡ ì  ê²€ìƒ‰ì€ ì‚¬ìš©ìì˜ ì§ˆì˜ë¥¼ ë‹¨ìˆœí•œ í‚¤ì›Œë“œ ë§¤ì¹­ì„ ë„˜ì–´ì„œ ê·¸ ì˜ë¯¸ë¥¼ íŒŒì•…í•˜ì—¬ ê´€ë ¨ëœ ê²°ê³¼ë¥¼ ë°˜í™˜í•˜ëŠ” ê²€ìƒ‰ ë°©ì‹ì…ë‹ˆë‹¤.\n",
    "    ì˜ˆì‹œ: ì‚¬ìš©ìê°€ \"íƒœì–‘ê³„ í–‰ì„±\"ì´ë¼ê³  ê²€ìƒ‰í•˜ë©´, \"ëª©ì„±\", \"í™”ì„±\" ë“±ê³¼ ê°™ì´ ê´€ë ¨ëœ í–‰ì„±ì— ëŒ€í•œ ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
    "    ì—°ê´€í‚¤ì›Œë“œ: ìì—°ì–´ ì²˜ë¦¬, ê²€ìƒ‰ ì•Œê³ ë¦¬ì¦˜, ë°ì´í„° ë§ˆì´ë‹\n",
    "\n",
    "    Embedding\n",
    "    ==================================================\n",
    "    Document 2:\n",
    "    ì •ì˜: í† í¬ë‚˜ì´ì €ëŠ” í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ í† í°ìœ¼ë¡œ ë¶„í• í•˜ëŠ” ë„êµ¬ì…ë‹ˆë‹¤. ì´ëŠ” ìì—°ì–´ ì²˜ë¦¬ì—ì„œ ë°ì´í„°ë¥¼ ì „ì²˜ë¦¬í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤.\n",
    "    ì˜ˆì‹œ: \"I love programming.\"ì´ë¼ëŠ” ë¬¸ì¥ì„ [\"I\", \"love\", \"programming\", \".\"]ìœ¼ë¡œ ë¶„í• í•©ë‹ˆë‹¤.\n",
    "    ì—°ê´€í‚¤ì›Œë“œ: í† í°í™”, ìì—°ì–´ ì²˜ë¦¬, êµ¬ë¬¸ ë¶„ì„\n",
    "\n",
    "    VectorStore\n",
    "    ==================================================\n",
    "    Document 3:\n",
    "    ì •ì˜: JSON(JavaScript Object Notation)ì€ ê²½ëŸ‰ì˜ ë°ì´í„° êµí™˜ í˜•ì‹ìœ¼ë¡œ, ì‚¬ëŒê³¼ ê¸°ê³„ ëª¨ë‘ì—ê²Œ ì½ê¸° ì‰¬ìš´ í…ìŠ¤íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ë°ì´í„° ê°ì²´ë¥¼ í‘œí˜„í•©ë‹ˆë‹¤.\n",
    "    ì˜ˆì‹œ: {\"ì´ë¦„\": \"í™ê¸¸ë™\", \"ë‚˜ì´\": 30, \"ì§ì—…\": \"ê°œë°œì\"}ëŠ” JSON í˜•ì‹ì˜ ë°ì´í„°ì…ë‹ˆë‹¤.\n",
    "    ì—°ê´€í‚¤ì›Œë“œ: ë°ì´í„° êµí™˜, ì›¹ ê°œë°œ, API\n",
    "\n",
    "    Transformer\n",
    "    ==================================================\n",
    "    Document 4:\n",
    "    ì •ì˜: SQL(Structured Query Language)ì€ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ë°ì´í„°ë¥¼ ê´€ë¦¬í•˜ê¸° ìœ„í•œ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ì…ë‹ˆë‹¤. ë°ì´í„° ì¡°íšŒ, ìˆ˜ì •, ì‚½ì…, ì‚­ì œ ë“± ë‹¤ì–‘í•œ ì‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "    ì˜ˆì‹œ: SELECT * FROM users WHERE age > 18;ì€ 18ì„¸ ì´ìƒì˜ ì‚¬ìš©ì ì •ë³´ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.\n",
    "    ì—°ê´€í‚¤ì›Œë“œ: ë°ì´í„°ë² ì´ìŠ¤, ì¿¼ë¦¬, ë°ì´í„° ê´€ë¦¬\n",
    "\n",
    "    CSV\n",
    "    ==================================================\n",
    "    ğŸ‰ âœ… HuggingFaceEmbeddingsë¡œ ì™„ë²½ ì‹¤í–‰!\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635048b7",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4047d45c",
   "metadata": {},
   "source": [
    "#### **4) `ë§¥ë½ì  ì••ì¶•`** (`Contextual Compression`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23f74cd",
   "metadata": {},
   "source": [
    "* **`LLM Chain Extractor` â†’ ìƒì„±í•œ `DocumentCompressor`ë¥¼ `retriever`ë¥¼ ì ìš©í•œ ê²ƒ = `ContextualCompressionaRetriever`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e7d558",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "# LLM ì´ˆê¸°í™”\n",
    "gemini_lc = ChatGoogleGenerativeAI(\n",
    "        model=\"gemini-2.5-flash-lite\",\n",
    "        temperature=0,                                    \n",
    "        max_output_tokens=4096,\n",
    "    )\n",
    "\n",
    "# LLMì„ ì‚¬ìš©í•˜ì—¬ ë¬¸ì„œ ì••ì¶•ê¸° ìƒì„±\n",
    "compressor = LLMChainExtractor.from_llm(gemini_lc)\n",
    "\n",
    "# Contextual Compression Retriever ìƒì„±\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    # ë¬¸ì„œ ì••ì¶•ê¸°ì™€ ë¦¬íŠ¸ë¦¬ë²„ë¥¼ ì‚¬ìš©í•˜ì—¬ ì»¨í…ìŠ¤íŠ¸ ì••ì¶• ë¦¬íŠ¸ë¦¬ë²„ ìƒì„±\n",
    "    base_compressor=compressor,\n",
    "    base_retriever=retriever,\n",
    ")\n",
    "\n",
    "# ë¹„êµ ì‹¤í–‰\n",
    "def pretty_print_docs(docs):\n",
    "    for i, doc in enumerate(docs):\n",
    "        print(f\"Document {i+1}:\")\n",
    "        print(doc.page_content)\n",
    "        print(\"=\" * 50)\n",
    "        print()\n",
    "\n",
    "print(\"ğŸ” ê¸°ë³¸ Retriever ê²°ê³¼:\")\n",
    "basic_docs = retriever.invoke(\"Semantic Search ì— ëŒ€í•´ì„œ ì•Œë ¤ì¤˜.\")\n",
    "pretty_print_docs(basic_docs)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"ğŸ§  LLMChainExtractor ì••ì¶• í›„ ê²°ê³¼:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "compressed_docs = compression_retriever.invoke(\"Semantic Search ì— ëŒ€í•´ì„œ ì•Œë ¤ì¤˜.\")\n",
    "pretty_print_docs(compressed_docs)\n",
    "\n",
    "print(\"âœ… Contextual Compression ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f432765",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* ì…€ ì¶œë ¥ (3.4s)\n",
    "\n",
    "    ```bash\n",
    "    E0000 00:00:1759054106.473395 2024367 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n",
    "    ```\n",
    "    ```markdown\n",
    "    ğŸ” ê¸°ë³¸ Retriever ê²°ê³¼:\n",
    "    Document 1:\n",
    "    ì •ì˜: InstructGPTëŠ” ì‚¬ìš©ìì˜ ì§€ì‹œì— ë”°ë¼ íŠ¹ì •í•œ ì‘ì—…ì„ ìˆ˜í–‰í•˜ê¸° ìœ„í•´ ìµœì í™”ëœ GPT ëª¨ë¸ì…ë‹ˆë‹¤. ì´ ëª¨ë¸ì€ ë³´ë‹¤ ì •í™•í•˜ê³  ê´€ë ¨ì„± ë†’ì€ ê²°ê³¼ë¥¼ ìƒì„±í•˜ë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
    "    ì˜ˆì‹œ: ì‚¬ìš©ìê°€ \"ì´ë©”ì¼ ì´ˆì•ˆ ì‘ì„±\"ê³¼ ê°™ì€ íŠ¹ì • ì§€ì‹œë¥¼ ì œê³µí•˜ë©´, InstructGPTëŠ” ê´€ë ¨ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ì´ë©”ì¼ì„ ì‘ì„±í•©ë‹ˆë‹¤.\n",
    "    ì—°ê´€í‚¤ì›Œë“œ: ì¸ê³µì§€ëŠ¥, ìì—°ì–´ ì´í•´, ëª…ë ¹ ê¸°ë°˜ ì²˜ë¦¬\n",
    "\n",
    "    Keyword Search\n",
    "    ==================================================\n",
    "\n",
    "    Document 2:\n",
    "    ì •ì˜: êµ¬ì¡°í™”ëœ ë°ì´í„°ëŠ” ì •í•´ì§„ í˜•ì‹ì´ë‚˜ ìŠ¤í‚¤ë§ˆì— ë”°ë¼ ì¡°ì§ëœ ë°ì´í„°ì…ë‹ˆë‹¤. ì´ëŠ” ë°ì´í„°ë² ì´ìŠ¤, ìŠ¤í”„ë ˆë“œì‹œíŠ¸ ë“±ì—ì„œ ì‰½ê²Œ ê²€ìƒ‰í•˜ê³  ë¶„ì„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "    ì˜ˆì‹œ: ê´€ê³„í˜• ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥ëœ ê³ ê° ì •ë³´ í…Œì´ë¸”ì€ êµ¬ì¡°í™”ëœ ë°ì´í„°ì˜ ì˜ˆì…ë‹ˆë‹¤.\n",
    "    ì—°ê´€í‚¤ì›Œë“œ: ë°ì´í„°ë² ì´ìŠ¤, ë°ì´í„° ë¶„ì„, ë°ì´í„° ëª¨ë¸ë§\n",
    "\n",
    "    Parser\n",
    "    ==================================================\n",
    "\n",
    "    Document 3:\n",
    "    ì •ì˜: í˜ì´ì§€ ë­í¬ëŠ” ì›¹ í˜ì´ì§€ì˜ ì¤‘ìš”ë„ë¥¼ í‰ê°€í•˜ëŠ” ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ, ì£¼ë¡œ ê²€ìƒ‰ ì—”ì§„ ê²°ê³¼ì˜ ìˆœìœ„ë¥¼ ê²°ì •í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤. ì´ëŠ” ì›¹ í˜ì´ì§€ ê°„ì˜ ë§í¬ êµ¬ì¡°ë¥¼ ë¶„ì„í•˜ì—¬ í‰ê°€í•©ë‹ˆë‹¤.\n",
    "    ì˜ˆì‹œ: êµ¬ê¸€ ê²€ìƒ‰ ì—”ì§„ì€ í˜ì´ì§€ ë­í¬ ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•˜ì—¬ ê²€ìƒ‰ ê²°ê³¼ì˜ ìˆœìœ„ë¥¼ ì •í•©ë‹ˆë‹¤.\n",
    "    ì—°ê´€í‚¤ì›Œë“œ: ê²€ìƒ‰ ì—”ì§„ ìµœì í™”, ì›¹ ë¶„ì„, ë§í¬ ë¶„ì„\n",
    "\n",
    "    ë°ì´í„° ë§ˆì´ë‹\n",
    "    ==================================================\n",
    "\n",
    "    Document 4:\n",
    "    ì •ì˜: í¬ë¡¤ë§ì€ ìë™í™”ëœ ë°©ì‹ìœ¼ë¡œ ì›¹ í˜ì´ì§€ë¥¼ ë°©ë¬¸í•˜ì—¬ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ëŠ” ê³¼ì •ì…ë‹ˆë‹¤. ì´ëŠ” ê²€ìƒ‰ ì—”ì§„ ìµœì í™”ë‚˜ ë°ì´í„° ë¶„ì„ì— ìì£¼ ì‚¬ìš©ë©ë‹ˆë‹¤.\n",
    "    ì˜ˆì‹œ: êµ¬ê¸€ ê²€ìƒ‰ ì—”ì§„ì´ ì¸í„°ë„· ìƒì˜ ì›¹ì‚¬ì´íŠ¸ë¥¼ ë°©ë¬¸í•˜ì—¬ ì½˜í…ì¸ ë¥¼ ìˆ˜ì§‘í•˜ê³  ì¸ë±ì‹±í•˜ëŠ” ê²ƒì´ í¬ë¡¤ë§ì…ë‹ˆë‹¤.\n",
    "    ì—°ê´€í‚¤ì›Œë“œ: ë°ì´í„° ìˆ˜ì§‘, ì›¹ ìŠ¤í¬ë˜í•‘, ê²€ìƒ‰ ì—”ì§„\n",
    "\n",
    "    Word2Vec\n",
    "    ==================================================\n",
    "\n",
    "    ============================================================\n",
    "    ğŸ§  LLMChainExtractor ì••ì¶• í›„ ê²°ê³¼:\n",
    "    ============================================================\n",
    "    âœ… Contextual Compression ì™„ë£Œ!\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d923c31",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4f1924",
   "metadata": {},
   "source": [
    "#### **5) `LLMì„ í™œìš©í•œ ë¬¸ì„œ í•„í„°ë§`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02023431",
   "metadata": {},
   "source": [
    "* **`LLM Chain Filter`**\n",
    "\n",
    "  *  ì´ˆê¸°ì— ê²€ìƒ‰ëœ ë¬¸ì„œ ì¤‘ ì–´ë–¤ ë¬¸ì„œë¥¼ í•„í„°ë§í•˜ê³ , ì–´ë–¤ ë¬¸ì„œë¥¼ ë°˜í™˜í• ì§€ ê²°ì •í•˜ê¸° ìœ„í•´ **`LLM ì²´ì¸` ì„ ì‚¬ìš©**\n",
    "\n",
    "  *  ë³´ë‹¤ ë‹¨ìˆœí•˜ì§€ë§Œ ê°•ë ¥í•œ ì••ì¶•ê¸°\n",
    "\n",
    "  *  ë¬¸ì„œ ë‚´ìš©ì„ **`ë³€ê²½` or `ì••ì¶•`í•˜ì§€ ì•Šê³  ë¬¸ì„œë¥¼ `ì„ íƒì ìœ¼ë¡œ ë°˜í™˜`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b8f413",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainFilter\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "# LLM ì‚¬ìš©í•´ LLM Chain Filter ê°ì²´ ìƒì„±í•˜ê¸°\n",
    "_filter =  LLMChainFilter.from_llm(gemini_lc)\n",
    "\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    # LLMChainFilterì™€ retrieverë¥¼ ì‚¬ìš©í•˜ì—¬ ContextualCompressionRetriever ê°ì²´ ìƒì„±í•˜ê¸°\n",
    "    base_compressor=_filter,\n",
    "    base_retriever=retriever,\n",
    ")\n",
    "\n",
    "compressed_docs = compression_retriever.invoke(\n",
    "    # ì¿¼ë¦¬\n",
    "    \"Semantic Search ì— ëŒ€í•´ì„œ ì•Œë ¤ì¤˜.\"\n",
    ")\n",
    "\n",
    "# ì••ì¶•ëœ ë¬¸ì„œë¥¼ ì˜ˆì˜ê²Œ ì¶œë ¥í•´ë³´ê¸°\n",
    "pretty_print_docs(compressed_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0121b8",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* ì…€ ì¶œë ¥ (1.4s)\n",
    "\n",
    "    ```markdown\n",
    "    Document 1:\n",
    "    ì •ì˜: ì„ë² ë”©ì€ ë‹¨ì–´ë‚˜ ë¬¸ì¥ ê°™ì€ í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ì €ì°¨ì›ì˜ ì—°ì†ì ì¸ ë²¡í„°ë¡œ ë³€í™˜í•˜ëŠ” ê³¼ì •ì…ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ì»´í“¨í„°ê°€ í…ìŠ¤íŠ¸ë¥¼ ì´í•´í•˜ê³  ì²˜ë¦¬í•  ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤.\n",
    "    ì˜ˆì‹œ: \"ì‚¬ê³¼\"ë¼ëŠ” ë‹¨ì–´ë¥¼ [0.65, -0.23, 0.17]ê³¼ ê°™ì€ ë²¡í„°ë¡œ í‘œí˜„í•©ë‹ˆë‹¤.\n",
    "    ì—°ê´€í‚¤ì›Œë“œ: ìì—°ì–´ ì²˜ë¦¬, ë²¡í„°í™”, ë”¥ëŸ¬ë‹\n",
    "\n",
    "    Token\n",
    "    ==================================================\n",
    "\n",
    "    Document 2:\n",
    "    ì •ì˜: FAISSëŠ” í˜ì´ìŠ¤ë¶ì—ì„œ ê°œë°œí•œ ê³ ì† ìœ ì‚¬ì„± ê²€ìƒ‰ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œ, íŠ¹íˆ ëŒ€ê·œëª¨ ë²¡í„° ì§‘í•©ì—ì„œ ìœ ì‚¬ ë²¡í„°ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ê²€ìƒ‰í•  ìˆ˜ ìˆë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
    "    ì˜ˆì‹œ: ìˆ˜ë°±ë§Œ ê°œì˜ ì´ë¯¸ì§€ ë²¡í„° ì¤‘ì—ì„œ ë¹„ìŠ·í•œ ì´ë¯¸ì§€ë¥¼ ë¹ ë¥´ê²Œ ì°¾ëŠ” ë° FAISSê°€ ì‚¬ìš©ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "    ì—°ê´€í‚¤ì›Œë“œ: ë²¡í„° ê²€ìƒ‰, ë¨¸ì‹ ëŸ¬ë‹, ë°ì´í„°ë² ì´ìŠ¤ ìµœì í™”\n",
    "\n",
    "    Open Source\n",
    "    ==================================================\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108e74f0",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55d5e89",
   "metadata": {},
   "source": [
    "* **`EmbeddingFilter`**\n",
    "\n",
    "  * `EmbeddingFilter`: ë¬¸ì„œ, ì¿¼ë¦¬ ì„ë² ë”© â†’ ì¿¼ë¦¬ì™€ ì¶©ë¶„íˆ ìœ ì‚¬í•œ ì„ë² ë”©ì„ ê°€ì§„ ë¬¸ì„œë§Œ ë°˜í™˜ \n",
    "    * `ë” ì €ë ´, ë¹ ë¥¸ ì˜µì…˜ ì œê³µ`\n",
    "    * `ê²€ìƒ‰ ê²°ê³¼ì˜ ê´€ë ¨ì„±ì„ ìœ ì§€í•˜ë©´ì„œë„ ê³„ì‚° ë¹„ìš©ê³¼ ì‹œê°„ì„ ì ˆì•½í•  ìˆ˜ ìˆìŒ`\n",
    "\n",
    "  * **`EmbeddingsFilter` + `ContextualCompressionRetriever`**\n",
    "    * `EmbeddingsFilter` ì‚¬ìš©, **`ìœ ì‚¬ë„ ì„ê³„ê°’ (0.86) ì´ìƒì¸ ë¬¸ì„œ í•„í„°ë§`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac04244",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers.document_compressors import EmbeddingsFilter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "# 1ë‹¨ê³„: ì„ë² ë”© ì´ˆê¸°í™”\n",
    "embeddings = embeddings\n",
    "\n",
    "print(\"âœ… HuggingFaceEmbeddings ì´ˆê¸°í™” ì™„ë£Œ\")                          # âœ… HuggingFaceEmbeddings ì´ˆê¸°í™” ì™„ë£Œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8139a00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2ë‹¨ê³„: EmbeddingsFilter ê°ì²´ ìƒì„±í•˜ê¸°\n",
    "embeddings_filter = EmbeddingsFilter(\n",
    "    embeddings=embeddings,                                          # ì„ë² ë”© ëª¨ë¸\n",
    "    similarity_threshold=0.86                                       # ìœ ì‚¬ë„ ì„ê³„ê°’ = 0.86\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "947a33d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3ë‹¨ê³„: ContextualCompressionRetriever ê°ì²´ ìƒì„±í•˜ê¸°\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=embeddings_filter,                              # ê¸°ë³¸ ì••ì¶•ê¸° = embedding_filter\n",
    "    base_retriever=retriever                                        # ê¸°ë³¸ ê²€ìƒ‰ê¸° = retrirever\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3dcf7755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4ë‹¨ê³„: ContextualCompressionRetriever ê°ì²´ë¥¼ ì‚¬ìš©í•˜ì—¬ ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰í•˜ê¸°\n",
    "compressed_docs = compression_retriever.invoke(\n",
    "    # ì¿¼ë¦¬\n",
    "    \"Semantic Search ì— ëŒ€í•´ì„œ ì•Œë ¤ì¤˜.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "55adb5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5ë‹¨ê³„: ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ ì˜ˆì˜ê²Œ ì¶œë ¥í•˜ê¸°\n",
    "\n",
    "pretty_print_docs(compressed_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0872919",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* ì°¨ì›ì´ ë‚®ì€ ì„ë² ë”© ëª¨ë¸, ë†’ì€ ìœ ì‚¬ë„ ì„ê³„ê°’ â†’ ê°’ì´ ì¶œë ¥ë˜ì§€ ì•ŠìŒ \n",
    "\n",
    "* ìœ ì‚¬ë„ ì„ê³„ê°’ì„ ë‚®ê²Œ ì„¤ì •í•´ì„œ ë‹¤ì‹œ ì‹œë„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab1e3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers.document_compressors import EmbeddingsFilter\n",
    "from langchain_core.embeddings import FakeEmbeddings\n",
    "\n",
    "# 1ë‹¨ê³„: í—ˆê¹…í˜ì´ìŠ¤ Embeddings ì‚¬ìš©\n",
    "embeddings = embeddings\n",
    "\n",
    "# 2ë‹¨ê³„: EmbeddingsFilter ê°ì²´ ìƒì„±í•˜ê¸°\n",
    "embeddings_filter = EmbeddingsFilter(\n",
    "    embeddings=embeddings,                                          # ì„ë² ë”© ëª¨ë¸\n",
    "    similarity_threshold=0.01                                       # ìœ ì‚¬ë„ ì„ê³„ê°’ = 0.01\n",
    "    )\n",
    "\n",
    "# 3ë‹¨ê³„: ContextualCompressionRetriever ê°ì²´ ìƒì„±í•˜ê¸°\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=embeddings_filter,                              # ê¸°ë³¸ ì••ì¶•ê¸° = embedding_filter\n",
    "    base_retriever=retriever                                        # ê¸°ë³¸ ê²€ìƒ‰ê¸° = retrirever\n",
    ")\n",
    "\n",
    "# 4ë‹¨ê³„: ContextualCompressionRetriever ê°ì²´ë¥¼ ì‚¬ìš©í•˜ì—¬ ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰í•˜ê¸°\n",
    "compressed_docs = compression_retriever.invoke(\n",
    "    \"Semantic Search ì— ëŒ€í•´ì„œ ì•Œë ¤ì¤˜.\"                                 # ì¿¼ë¦¬\n",
    ")\n",
    "\n",
    "# 5ë‹¨ê³„: ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ ì˜ˆì˜ê²Œ ì¶œë ¥í•˜ê¸°\n",
    "pretty_print_docs(compressed_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d9fea9",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* ì…€ ì¶œë ¥\n",
    "\n",
    "    ```markdown\n",
    "    Document 1:\n",
    "    ì •ì˜: SQL(Structured Query Language)ì€ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ë°ì´í„°ë¥¼ ê´€ë¦¬í•˜ê¸° ìœ„í•œ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ì…ë‹ˆë‹¤. ë°ì´í„° ì¡°íšŒ, ìˆ˜ì •, ì‚½ì…, ì‚­ì œ ë“± ë‹¤ì–‘í•œ ì‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "    ì˜ˆì‹œ: SELECT * FROM users WHERE age > 18;ì€ 18ì„¸ ì´ìƒì˜ ì‚¬ìš©ì ì •ë³´ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.\n",
    "    ì—°ê´€í‚¤ì›Œë“œ: ë°ì´í„°ë² ì´ìŠ¤, ì¿¼ë¦¬, ë°ì´í„° ê´€ë¦¬\n",
    "\n",
    "    CSV\n",
    "    ==================================================\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c864b8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers.document_compressors import EmbeddingsFilter\n",
    "from langchain_core.embeddings import FakeEmbeddings\n",
    "\n",
    "# 1ë‹¨ê³„: Fake Embeddings ì‚¬ìš©\n",
    "embeddings = FakeEmbeddings(size=384)                               # 384ì°¨ì› ê°€ì§œ ì„ë² ë”©\n",
    "\n",
    "# 2ë‹¨ê³„: EmbeddingsFilter ê°ì²´ ìƒì„±í•˜ê¸°\n",
    "embeddings_filter = EmbeddingsFilter(\n",
    "    embeddings=embeddings,                                          # ì„ë² ë”© ëª¨ë¸\n",
    "    similarity_threshold=0.01                                       # ìœ ì‚¬ë„ ì„ê³„ê°’ = 0.01\n",
    "    )\n",
    "\n",
    "# 3ë‹¨ê³„: ContextualCompressionRetriever ê°ì²´ ìƒì„±í•˜ê¸°\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=embeddings_filter,                              # ê¸°ë³¸ ì••ì¶•ê¸° = embedding_filter\n",
    "    base_retriever=retriever                                        # ê¸°ë³¸ ê²€ìƒ‰ê¸° = retrirever\n",
    ")\n",
    "\n",
    "# 4ë‹¨ê³„: ContextualCompressionRetriever ê°ì²´ë¥¼ ì‚¬ìš©í•˜ì—¬ ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰í•˜ê¸°\n",
    "compressed_docs = compression_retriever.invoke(\n",
    "    \"Semantic Search ì— ëŒ€í•´ì„œ ì•Œë ¤ì¤˜.\"                                 # ì¿¼ë¦¬\n",
    ")\n",
    "\n",
    "# 5ë‹¨ê³„: ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ ì˜ˆì˜ê²Œ ì¶œë ¥í•˜ê¸°\n",
    "pretty_print_docs(compressed_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50378826",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* ì…€ ì¶œë ¥ (**`ìµœëŒ€ ìœ ì‚¬ë„ ì„ê³„ê°’ = 0.08`**)\n",
    "\n",
    "    ```markdown\n",
    "    Document 1:\n",
    "    ì •ì˜: JSON(JavaScript Object Notation)ì€ ê²½ëŸ‰ì˜ ë°ì´í„° êµí™˜ í˜•ì‹ìœ¼ë¡œ, ì‚¬ëŒê³¼ ê¸°ê³„ ëª¨ë‘ì—ê²Œ ì½ê¸° ì‰¬ìš´ í…ìŠ¤íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ë°ì´í„° ê°ì²´ë¥¼ í‘œí˜„í•©ë‹ˆë‹¤.\n",
    "    ì˜ˆì‹œ: {\"ì´ë¦„\": \"í™ê¸¸ë™\", \"ë‚˜ì´\": 30, \"ì§ì—…\": \"ê°œë°œì\"}ëŠ” JSON í˜•ì‹ì˜ ë°ì´í„°ì…ë‹ˆë‹¤.\n",
    "    ì—°ê´€í‚¤ì›Œë“œ: ë°ì´í„° êµí™˜, ì›¹ ê°œë°œ, API\n",
    "\n",
    "    Transformer\n",
    "    ==================================================\n",
    "    Document 2:\n",
    "    ì •ì˜: í† í¬ë‚˜ì´ì €ëŠ” í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ í† í°ìœ¼ë¡œ ë¶„í• í•˜ëŠ” ë„êµ¬ì…ë‹ˆë‹¤. ì´ëŠ” ìì—°ì–´ ì²˜ë¦¬ì—ì„œ ë°ì´í„°ë¥¼ ì „ì²˜ë¦¬í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤.\n",
    "    ì˜ˆì‹œ: \"I love programming.\"ì´ë¼ëŠ” ë¬¸ì¥ì„ [\"I\", \"love\", \"programming\", \".\"]ìœ¼ë¡œ ë¶„í• í•©ë‹ˆë‹¤.\n",
    "    ì—°ê´€í‚¤ì›Œë“œ: í† í°í™”, ìì—°ì–´ ì²˜ë¦¬, êµ¬ë¬¸ ë¶„ì„\n",
    "\n",
    "    VectorStore\n",
    "    ==================================================\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d599eb",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1e7b26",
   "metadata": {},
   "source": [
    "#### **6) `íŒŒì´í”„ë¼ì¸ ìƒì„±`** (`ì••ì¶•ê¸° + ë¬¸ì„œ ë³€í™˜ê¸°`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea20f8db",
   "metadata": {},
   "source": [
    "* **`DocumentCompressionPipeline`** â†’ ì—¬ëŸ¬ `compressor`ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ê²°í•© ê°€ëŠ¥\n",
    "\n",
    "  * `Compressor`ì™€ í•¨ê»˜ **`BaseDocumentTransformer`** ë¥¼ íŒŒì´í”„ë¼ì¸ì— ì¶”ê°€í•  ìˆ˜ ìˆìŒ\n",
    "  * **`ë§¥ë½ì  ì••ì¶•ì„ ìˆ˜í–‰í•˜ì§€ ì•Šê³  ë‹¨ìˆœí•œ ë¬¸ì„œ ì§‘í•©ì— ëŒ€í•œ ë³€í™˜ ìˆ˜í–‰`**\n",
    "\n",
    "  <br>\n",
    "\n",
    "  * **`TextSplitter`** = ë” ì‘ì€ ì¡°ê°ìœ¼ë¡œ ë¶„í• í•˜ê¸° ìœ„í•´ `document transformer`ë¡œ ì‚¬ìš© ê°€ëŠ¥\n",
    "  * **`EmbeddingsRedundantFilter`** = **`ë¬¸ì„œ ê°„ ì„ë² ë”© ìœ ì‚¬ì„± (ê¸°ë³¸ê°’ = 0.95 ìœ ì‚¬ë„ ì´ìƒì„ ì¤‘ë³µ ë¬¸ì„œë¡œ ê°„ì£¼) ì„ ê¸°ë°˜ìœ¼ë¡œ ì¤‘ë³µ ë¬¸ì„œë¥¼ í•„í„°ë§í•˜ëŠ” ë° ì‚¬ìš©`**\n",
    "\n",
    "  <br>\n",
    "\n",
    "* ìˆœì„œ: ë¬¸ì„œë¥¼ ë” ì‘ì€ ì²­í¬ë¡œ ë¶„í•  â†’ ì¤‘ë³µ ë¬¸ì„œ ì œê±° â†’ ì¿¼ë¦¬ì™€ì˜ ê´€ë ¨ì„± ê¸°ì¤€ìœ¼ë¡œ í•„í„°ë§ â†’ `compressor pipeline` ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1addb007",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers.document_compressors import DocumentCompressorPipeline\n",
    "from langchain_community.document_transformers import EmbeddingsRedundantFilter\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "# 1ë‹¨ê³„: ë¬¸ì ê¸°ë°˜ í…ìŠ¤íŠ¸ ë¶„í• ê¸° ìƒì„±í•˜ê¸°\n",
    "splitter = CharacterTextSplitter(\n",
    "    chunk_size=300,                             # ì²­í¬ í¬ê¸° = 300\n",
    "    chunk_overlap=0                             # ì²­í¬ ê°„ ì¤‘ë³µ X \n",
    "    )\n",
    "\n",
    "# 2ë‹¨ê³„: ì¤‘ë³µ í•„í„° ìƒì„±í•˜ê¸°\n",
    "redundant_filter = EmbeddingsRedundantFilter(embeddings=embeddings)     # ì„ë² ë”© ì‚¬ìš©\n",
    "\n",
    "# 3ë‹¨ê³„: ê´€ë ¨ì„± í•„í„° ìƒì„±í•˜ê¸°\n",
    "relevant_filter = EmbeddingsFilter(\n",
    "    embeddings=embeddings,                      # ì„ë² ë”© ì‚¬ìš©\n",
    "    similarity_threshold=0.86                   # ìœ ì‚¬ë„ ì„ê³„ê°’ì„ 0.86ìœ¼ë¡œ ì„¤ì •\n",
    ")\n",
    "\n",
    "# 4ë‹¨ê³„: ë¬¸ì„œ ì••ì¶• íŒŒì´í”„ë¼ì¸ ìƒì„±í•˜ê¸°\n",
    "pipeline_compressor = DocumentCompressorPipeline(\n",
    "    # ë³€í™˜ê¸°ë¡œ ì„¤ì •í•˜ê¸°\n",
    "    transformers = [\n",
    "        splitter,                               # í…ìŠ¤íŠ¸ ë¶„í• ê¸°\n",
    "        redundant_filter,                       # ì¤‘ë³µ í•„í„°\n",
    "        relevant_filter,                        # ê´€ë ¨ì„± í•„í„°\n",
    "        LLMChainExtractor.from_llm(gemini_lc)   # LLM\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644c8ab5",
   "metadata": {},
   "source": [
    "* **`ContextualCompressionRetriever`** ì´ˆê¸°í™”\n",
    "\n",
    "* **`base_compressor`** = **`pipeline_compressor`**\n",
    "\n",
    "* **`base_retriever`** = **`retriever`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6150cc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5ë‹¨ê³„: ContextualCompressionRetriever ê°ì²´ ìƒì„±í•˜ê¸°\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=pipeline_compressor,\n",
    "    base_retriever=retriever,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "aec3b584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6ë‹¨ê³„: ContextualCompressionRetriever ê°ì²´ë¥¼ ì‚¬ìš©í•˜ì—¬ ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰í•˜ê¸°\n",
    "\n",
    "compressed_docs = compression_retriever.invoke(\n",
    "    \"Semantic Search ì— ëŒ€í•´ì„œ ì•Œë ¤ì¤˜.\"                                 # ì¿¼ë¦¬\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a9af9a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7ë‹¨ê³„: ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ ì˜ˆì˜ê²Œ ì¶œë ¥í•˜ê¸°\n",
    "\n",
    "pretty_print_docs(compressed_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c79d71",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* ìœ ì‚¬ë„ ì„ê³„ê°’ì˜ ì°¨ì´ë¡œ ì¸í•´ ê²°ê³¼ê°’ì´ ë‚˜ì˜¤ì§€ ì•ŠìŒ\n",
    "\n",
    "* ì„ë² ë”© ëª¨ë¸ë“¤ì˜ ìœ ì‚¬ë„ ë²”ìœ„\n",
    "  * `OpenAI_embeddings`ì˜ ìœ ì‚¬ë„: **`0.3 ~ 0.95`**\n",
    "  * `HuggingFace_embeddings`ì˜ ìœ ì‚¬ë„: **`0.2 ~ 0.90`**\n",
    "  * `Google_Gemini`ì˜ ìœ ì‚¬ë„: **`0.4 ~ 0.85`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac244126",
   "metadata": {},
   "source": [
    "* ì‹œë„_1 : í—ˆê¹…í˜ì´ìŠ¤ ì„ë² ë”© ëª¨ë¸ ì‚¬ìš©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba30ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers.document_compressors import DocumentCompressorPipeline\n",
    "from langchain_community.document_transformers import EmbeddingsRedundantFilter\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "# 1ë‹¨ê³„: ë¬¸ì ê¸°ë°˜ í…ìŠ¤íŠ¸ ë¶„í• ê¸° ìƒì„±í•˜ê¸°\n",
    "splitter = CharacterTextSplitter(\n",
    "    chunk_size=300,                             # ì²­í¬ í¬ê¸° = 300\n",
    "    chunk_overlap=0                             # ì²­í¬ ê°„ ì¤‘ë³µ X \n",
    "    )\n",
    "\n",
    "# 2ë‹¨ê³„: ì¤‘ë³µ í•„í„° ìƒì„±í•˜ê¸°\n",
    "redundant_filter = EmbeddingsRedundantFilter(embeddings=embeddings)     # ì„ë² ë”© ì‚¬ìš©\n",
    "\n",
    "# 3ë‹¨ê³„: ê´€ë ¨ì„± í•„í„° ìƒì„±í•˜ê¸°\n",
    "relevant_filter = EmbeddingsFilter(\n",
    "    embeddings=embeddings,                       # ì„ë² ë”© ì‚¬ìš©\n",
    "    similarity_threshold=0.009                   # ìœ ì‚¬ë„ ì„ê³„ê°’ì„ 0.009ë¡œ ì„¤ì •\n",
    ")\n",
    "\n",
    "# 4ë‹¨ê³„: ë¬¸ì„œ ì••ì¶• íŒŒì´í”„ë¼ì¸ ìƒì„±í•˜ê¸°\n",
    "pipeline_compressor = DocumentCompressorPipeline(\n",
    "    # ë³€í™˜ê¸°ë¡œ ì„¤ì •í•˜ê¸°\n",
    "    transformers = [\n",
    "        splitter,                               # í…ìŠ¤íŠ¸ ë¶„í• ê¸°\n",
    "        redundant_filter,                       # ì¤‘ë³µ í•„í„°\n",
    "        relevant_filter,                        # ê´€ë ¨ì„± í•„í„°\n",
    "        LLMChainExtractor.from_llm(gemini_lc)   # LLM\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 5ë‹¨ê³„: ContextualCompressionRetriever ê°ì²´ ìƒì„±í•˜ê¸°\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=pipeline_compressor,\n",
    "    base_retriever=retriever,\n",
    ")\n",
    "\n",
    "# 6ë‹¨ê³„: ContextualCompressionRetriever ê°ì²´ë¥¼ ì‚¬ìš©í•˜ì—¬ ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰í•˜ê¸°\n",
    "compressed_docs = compression_retriever.invoke(\n",
    "    \"Semantic Search ì— ëŒ€í•´ì„œ ì•Œë ¤ì¤˜.\"                                 # ì¿¼ë¦¬\n",
    ")\n",
    "\n",
    "# 7ë‹¨ê³„: ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ ì˜ˆì˜ê²Œ ì¶œë ¥í•˜ê¸°\n",
    "pretty_print_docs(compressed_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae7715f",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* ì…€ ì¶œë ¥ (2.6s)\n",
    "\n",
    "    ```markdown\n",
    "    Document 1:\n",
    "    Semantic Search\n",
    "\n",
    "    ì •ì˜: ì˜ë¯¸ë¡ ì  ê²€ìƒ‰ì€ ì‚¬ìš©ìì˜ ì§ˆì˜ë¥¼ ë‹¨ìˆœí•œ í‚¤ì›Œë“œ ë§¤ì¹­ì„ ë„˜ì–´ì„œ ê·¸ ì˜ë¯¸ë¥¼ íŒŒì•…í•˜ì—¬ ê´€ë ¨ëœ ê²°ê³¼ë¥¼ ë°˜í™˜í•˜ëŠ” ê²€ìƒ‰ ë°©ì‹ì…ë‹ˆë‹¤.\n",
    "    ì˜ˆì‹œ: ì‚¬ìš©ìê°€ \"íƒœì–‘ê³„ í–‰ì„±\"ì´ë¼ê³  ê²€ìƒ‰í•˜ë©´, \"ëª©ì„±\", \"í™”ì„±\" ë“±ê³¼ ê°™ì´ ê´€ë ¨ëœ í–‰ì„±ì— ëŒ€í•œ ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
    "    ì—°ê´€í‚¤ì›Œë“œ: ìì—°ì–´ ì²˜ë¦¬, ê²€ìƒ‰ ì•Œê³ ë¦¬ì¦˜, ë°ì´í„° ë§ˆì´ë‹\n",
    "    ==================================================\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219b5b2e",
   "metadata": {},
   "source": [
    "* ì‹œë„_2 : í—ˆê¹…í˜ì´ìŠ¤ fake ì„ë² ë”© ëª¨ë¸ ì‚¬ìš©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c719109",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers.document_compressors import DocumentCompressorPipeline\n",
    "from langchain_community.document_transformers import EmbeddingsRedundantFilter\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain_core.embeddings import FakeEmbeddings\n",
    "\n",
    "# 1ë‹¨ê³„: ë¬¸ì ê¸°ë°˜ í…ìŠ¤íŠ¸ ë¶„í• ê¸° ìƒì„±í•˜ê¸°\n",
    "splitter = CharacterTextSplitter(\n",
    "    chunk_size=300,                             # ì²­í¬ í¬ê¸° = 300\n",
    "    chunk_overlap=0                             # ì²­í¬ ê°„ ì¤‘ë³µ X \n",
    "    )\n",
    "\n",
    "# 2ë‹¨ê³„: ì¤‘ë³µ í•„í„° ìƒì„±í•˜ê¸°\n",
    "redundant_filter = EmbeddingsRedundantFilter(embeddings=embeddings)     # ì„ë² ë”© ì‚¬ìš©\n",
    "\n",
    "# 3ë‹¨ê³„: ê´€ë ¨ì„± í•„í„° ìƒì„±í•˜ê¸°\n",
    "relevant_filter = EmbeddingsFilter(\n",
    "    embeddings=FakeEmbeddings(size=384),         # fake ì„ë² ë”© ì‚¬ìš©\n",
    "    similarity_threshold=0.009                   # ìœ ì‚¬ë„ ì„ê³„ê°’ì„ 0.009ë¡œ ì„¤ì •\n",
    ")\n",
    "\n",
    "# 4ë‹¨ê³„: ë¬¸ì„œ ì••ì¶• íŒŒì´í”„ë¼ì¸ ìƒì„±í•˜ê¸°\n",
    "pipeline_compressor = DocumentCompressorPipeline(\n",
    "    # ë³€í™˜ê¸°ë¡œ ì„¤ì •í•˜ê¸°\n",
    "    transformers = [\n",
    "        splitter,                               # í…ìŠ¤íŠ¸ ë¶„í• ê¸°\n",
    "        redundant_filter,                       # ì¤‘ë³µ í•„í„°\n",
    "        relevant_filter,                        # ê´€ë ¨ì„± í•„í„°\n",
    "        LLMChainExtractor.from_llm(gemini_lc)   # LLM\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 5ë‹¨ê³„: ContextualCompressionRetriever ê°ì²´ ìƒì„±í•˜ê¸°\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=pipeline_compressor,\n",
    "    base_retriever=retriever,\n",
    ")\n",
    "\n",
    "# 6ë‹¨ê³„: ContextualCompressionRetriever ê°ì²´ë¥¼ ì‚¬ìš©í•˜ì—¬ ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰í•˜ê¸°\n",
    "compressed_docs = compression_retriever.invoke(\n",
    "    \"Semantic Search ì— ëŒ€í•´ì„œ ì•Œë ¤ì¤˜.\"                                 # ì¿¼ë¦¬\n",
    ")\n",
    "\n",
    "# 7ë‹¨ê³„: ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ ì˜ˆì˜ê²Œ ì¶œë ¥í•˜ê¸°\n",
    "pretty_print_docs(compressed_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6e6bde",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* ì…€ ì¶œë ¥ (1.3s)\n",
    "\n",
    "    ```markdown\n",
    "    Document 1:\n",
    "    Semantic Search\n",
    "\n",
    "    ì •ì˜: ì˜ë¯¸ë¡ ì  ê²€ìƒ‰ì€ ì‚¬ìš©ìì˜ ì§ˆì˜ë¥¼ ë‹¨ìˆœí•œ í‚¤ì›Œë“œ ë§¤ì¹­ì„ ë„˜ì–´ì„œ ê·¸ ì˜ë¯¸ë¥¼ íŒŒì•…í•˜ì—¬ ê´€ë ¨ëœ ê²°ê³¼ë¥¼ ë°˜í™˜í•˜ëŠ” ê²€ìƒ‰ ë°©ì‹ì…ë‹ˆë‹¤.\n",
    "    ì˜ˆì‹œ: ì‚¬ìš©ìê°€ \"íƒœì–‘ê³„ í–‰ì„±\"ì´ë¼ê³  ê²€ìƒ‰í•˜ë©´, \"ëª©ì„±\", \"í™”ì„±\" ë“±ê³¼ ê°™ì´ ê´€ë ¨ëœ í–‰ì„±ì— ëŒ€í•œ ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
    "    ì—°ê´€í‚¤ì›Œë“œ: ìì—°ì–´ ì²˜ë¦¬, ê²€ìƒ‰ ì•Œê³ ë¦¬ì¦˜, ë°ì´í„° ë§ˆì´ë‹\n",
    "    ==================================================\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1dd9cd",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720a7bf8",
   "metadata": {},
   "source": [
    "#### **7) `ìœ ë™ì  ìœ ì‚¬ë„ ë¶„í¬ ë¶„ì„`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559236e7",
   "metadata": {},
   "source": [
    "* ì‹¤ì‹œê°„ ìœ ì‚¬ë„ ë¶„í¬ ë¶„ì„í•´ë³´ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ead855",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.retrievers.document_compressors import EmbeddingsFilter\n",
    "from typing import List, Tuple\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "class SimilarityThresholdCalculator:\n",
    "    \"\"\"ìœ ì‚¬ë„ ì„ê³„ê°’ ìë™ ê³„ì‚°ê¸°\"\"\"\n",
    "    \n",
    "    def __init__(self, embeddings, retriever):\n",
    "        self.embeddings = embeddings\n",
    "        self.retriever = retriever\n",
    "        \n",
    "    def analyze_similarity_distribution(self, query: str, top_k: int = 10) -> dict:\n",
    "        \"\"\"ì¿¼ë¦¬ì— ëŒ€í•œ ìœ ì‚¬ë„ ë¶„í¬ ë¶„ì„\"\"\"\n",
    "        \n",
    "        print(f\"ğŸ” ì¿¼ë¦¬ ë¶„ì„: '{query}'\")\n",
    "        \n",
    "        # ê¸°ë³¸ ê²€ìƒ‰ ê²°ê³¼\n",
    "        docs = self.retriever.invoke(query)\n",
    "        if not docs:\n",
    "            print(\"âŒ ê²€ìƒ‰ëœ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "            return {}\n",
    "        \n",
    "        # ì¿¼ë¦¬ ì„ë² ë”©\n",
    "        query_embedding = self.embeddings.embed_query(query)\n",
    "        \n",
    "        # ê° ë¬¸ì„œì˜ ìœ ì‚¬ë„ ê³„ì‚°\n",
    "        similarities = []\n",
    "        for doc in docs:\n",
    "            doc_embedding = self.embeddings.embed_documents([doc.page_content])[0]\n",
    "            \n",
    "            # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°\n",
    "            similarity = self._cosine_similarity(query_embedding, doc_embedding)\n",
    "            similarities.append(similarity)\n",
    "            \n",
    "            print(f\"  ğŸ“„ ìœ ì‚¬ë„: {similarity:.4f} | {doc.page_content[:50]}...\")\n",
    "        \n",
    "        # í†µê³„ ê³„ì‚°\n",
    "        similarities = np.array(similarities)\n",
    "        stats = {\n",
    "            'similarities': similarities,\n",
    "            'mean': np.mean(similarities),\n",
    "            'std': np.std(similarities),\n",
    "            'min': np.min(similarities),\n",
    "            'max': np.max(similarities),\n",
    "            'median': np.median(similarities),\n",
    "            'q25': np.percentile(similarities, 25),\n",
    "            'q75': np.percentile(similarities, 75)\n",
    "        }\n",
    "        \n",
    "        print(f\"\\nğŸ“Š ìœ ì‚¬ë„ í†µê³„:\")\n",
    "        print(f\"  í‰ê· : {stats['mean']:.4f}\")\n",
    "        print(f\"  í‘œì¤€í¸ì°¨: {stats['std']:.4f}\")\n",
    "        print(f\"  ìµœì†Œê°’: {stats['min']:.4f}\")\n",
    "        print(f\"  ìµœëŒ€ê°’: {stats['max']:.4f}\")\n",
    "        print(f\"  ì¤‘ê°„ê°’: {stats['median']:.4f}\")\n",
    "        \n",
    "        return stats\n",
    "    \n",
    "    def _cosine_similarity(self, vec1: List[float], vec2: List[float]) -> float:\n",
    "        \"\"\"ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°\"\"\"\n",
    "        vec1, vec2 = np.array(vec1), np.array(vec2)\n",
    "        dot_product = np.dot(vec1, vec2)\n",
    "        norms = np.linalg.norm(vec1) * np.linalg.norm(vec2)\n",
    "        return dot_product / norms if norms != 0 else 0\n",
    "    \n",
    "    def suggest_optimal_threshold(self, query: str, target_retention: float = 0.5) -> float:\n",
    "        \"\"\"ìµœì  ì„ê³„ê°’ ì œì•ˆ (target_retention: ìœ ì§€í•˜ê³  ì‹¶ì€ ë¬¸ì„œ ë¹„ìœ¨)\"\"\"\n",
    "        \n",
    "        stats = self.analyze_similarity_distribution(query)\n",
    "        if not stats:\n",
    "            return 0.01\n",
    "        \n",
    "        similarities = stats['similarities']\n",
    "        \n",
    "        # ë°©ë²• 1: ë¶„ìœ„ìˆ˜ ê¸°ë°˜\n",
    "        threshold_percentile = (1 - target_retention) * 100\n",
    "        threshold_quantile = np.percentile(similarities, threshold_percentile)\n",
    "        \n",
    "        # ë°©ë²• 2: í‰ê·  - n*í‘œì¤€í¸ì°¨ ê¸°ë°˜  \n",
    "        threshold_std = stats['mean'] - 0.5 * stats['std']\n",
    "        \n",
    "        # ë°©ë²• 3: ì•ˆì „ ì„ê³„ê°’ (ìµœì†Œê°’ì˜ 80%)\n",
    "        threshold_safe = stats['min'] * 0.8\n",
    "        \n",
    "        # ì„¸ ë°©ë²• ì¤‘ ì¤‘ê°„ê°’ ì„ íƒ\n",
    "        candidates = [threshold_quantile, threshold_std, threshold_safe]\n",
    "        optimal_threshold = np.median(candidates)\n",
    "        \n",
    "        # ìµœì†Œ 0.001, ìµœëŒ€ 0.95 ì œí•œ\n",
    "        optimal_threshold = max(0.001, min(0.95, optimal_threshold))\n",
    "        \n",
    "        print(f\"\\nğŸ¯ ì¶”ì²œ ì„ê³„ê°’:\")\n",
    "        print(f\"  ë¶„ìœ„ìˆ˜ ê¸°ë°˜: {threshold_quantile:.4f}\")\n",
    "        print(f\"  í‘œì¤€í¸ì°¨ ê¸°ë°˜: {threshold_std:.4f}\")\n",
    "        print(f\"  ì•ˆì „ ê¸°ë°˜: {threshold_safe:.4f}\")\n",
    "        print(f\"  âœ… ìµœì¢… ì¶”ì²œ: {optimal_threshold:.4f}\")\n",
    "        \n",
    "        return optimal_threshold\n",
    "    \n",
    "    def test_threshold_performance(self, query: str, thresholds: List[float]) -> dict:\n",
    "        \"\"\"ë‹¤ì–‘í•œ ì„ê³„ê°’ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸\"\"\"\n",
    "        \n",
    "        base_docs = self.retriever.invoke(query)\n",
    "        base_count = len(base_docs)\n",
    "        \n",
    "        print(f\"\\nğŸ§ª ì„ê³„ê°’ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ (ê¸°ì¤€: {base_count}ê°œ ë¬¸ì„œ)\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        results = {}\n",
    "        \n",
    "        for threshold in thresholds:\n",
    "            try:\n",
    "                # EmbeddingsFilter ìƒì„±\n",
    "                embeddings_filter = EmbeddingsFilter(\n",
    "                    embeddings=self.embeddings,\n",
    "                    similarity_threshold=threshold\n",
    "                )\n",
    "                \n",
    "                # í•„í„°ë§ í…ŒìŠ¤íŠ¸\n",
    "                filtered_docs = embeddings_filter.compress_documents(base_docs, query)\n",
    "                filtered_count = len(filtered_docs)\n",
    "                retention_rate = filtered_count / base_count if base_count > 0 else 0\n",
    "                \n",
    "                results[threshold] = {\n",
    "                    'filtered_count': filtered_count,\n",
    "                    'retention_rate': retention_rate\n",
    "                }\n",
    "                \n",
    "                print(f\"ì„ê³„ê°’ {threshold:6.3f}: {filtered_count:2d}ê°œ ({retention_rate:5.1%})\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"ì„ê³„ê°’ {threshold:6.3f}: âŒ ì˜¤ë¥˜ - {e}\")\n",
    "                results[threshold] = {'filtered_count': 0, 'retention_rate': 0}\n",
    "        \n",
    "        return results\n",
    "\n",
    "# ğŸ¬ ì‚¬ìš© ì˜ˆì‹œ\n",
    "def auto_threshold_pipeline():\n",
    "    \"\"\"ìë™ ì„ê³„ê°’ ê³„ì‚° íŒŒì´í”„ë¼ì¸\"\"\"\n",
    "    \n",
    "    # ì„¤ì •\n",
    "    embeddings = HuggingFaceEmbeddings(\n",
    "        model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "        model_kwargs={'device': 'cpu'}\n",
    "    )\n",
    "    \n",
    "    # ê¸°ì¡´ retriever ì‚¬ìš© (ì´ë¯¸ ìƒì„±ëœ ê²ƒ)\n",
    "    # retriever = your_existing_retriever\n",
    "    \n",
    "    # ê³„ì‚°ê¸° ìƒì„±\n",
    "    calc = SimilarityThresholdCalculator(embeddings, retriever)\n",
    "    \n",
    "    query = \"Semantic Search ì— ëŒ€í•´ì„œ ì•Œë ¤ì¤˜.\"\n",
    "    \n",
    "    # 1ë‹¨ê³„: ìœ ì‚¬ë„ ë¶„í¬ ë¶„ì„\n",
    "    stats = calc.analyze_similarity_distribution(query)\n",
    "    \n",
    "    # 2ë‹¨ê³„: ìµœì  ì„ê³„ê°’ ì œì•ˆ\n",
    "    optimal_threshold = calc.suggest_optimal_threshold(query, target_retention=0.6)\n",
    "    \n",
    "    # 3ë‹¨ê³„: ë‹¤ì–‘í•œ ì„ê³„ê°’ í…ŒìŠ¤íŠ¸\n",
    "    test_thresholds = [0.001, 0.01, 0.05, 0.1, 0.2, 0.3, 0.5, 0.7, optimal_threshold]\n",
    "    results = calc.test_threshold_performance(query, sorted(set(test_thresholds)))\n",
    "    \n",
    "    return optimal_threshold\n",
    "\n",
    "# ì‹¤í–‰\n",
    "optimal_threshold = auto_threshold_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf68fcb7",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* ì…€ ì¶œë ¥ (5.1s)\n",
    "\n",
    "    ```markdown\n",
    "    ğŸ” ì¿¼ë¦¬ ë¶„ì„: 'Semantic Search ì— ëŒ€í•´ì„œ ì•Œë ¤ì¤˜.'\n",
    "    ğŸ“„ ìœ ì‚¬ë„: 0.4923 | Semantic Search\n",
    "\n",
    "    ì •ì˜: ì˜ë¯¸ë¡ ì  ê²€ìƒ‰ì€ ì‚¬ìš©ìì˜ ì§ˆì˜ë¥¼ ë‹¨ìˆœí•œ í‚¤ì›Œë“œ ë§¤ì¹­ì„...\n",
    "    ğŸ“„ ìœ ì‚¬ë„: 0.3349 | ì •ì˜: í† í¬ë‚˜ì´ì €ëŠ” í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ í† í°ìœ¼ë¡œ ë¶„í• í•˜ëŠ” ë„êµ¬ì…ë‹ˆë‹¤. ì´ëŠ” ìì—°ì–´ ì²˜ë¦¬ì—ì„œ ë°...\n",
    "    ğŸ“„ ìœ ì‚¬ë„: 0.3063 | ì •ì˜: JSON(JavaScript Object Notation)ì€ ê²½ëŸ‰ì˜ ë°ì´í„° êµí™˜ í˜•...\n",
    "    ğŸ“„ ìœ ì‚¬ë„: 0.2875 | ì •ì˜: SQL(Structured Query Language)ì€ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ë°ì´í„°ë¥¼ ...\n",
    "\n",
    "    ğŸ“Š ìœ ì‚¬ë„ í†µê³„:\n",
    "    í‰ê· : 0.3553\n",
    "    í‘œì¤€í¸ì°¨: 0.0809\n",
    "    ìµœì†Œê°’: 0.2875\n",
    "    ìµœëŒ€ê°’: 0.4923\n",
    "    ì¤‘ê°„ê°’: 0.3206\n",
    "    ğŸ” ì¿¼ë¦¬ ë¶„ì„: 'Semantic Search ì— ëŒ€í•´ì„œ ì•Œë ¤ì¤˜.'\n",
    "    ğŸ“„ ìœ ì‚¬ë„: 0.4923 | Semantic Search\n",
    "\n",
    "    ì •ì˜: ì˜ë¯¸ë¡ ì  ê²€ìƒ‰ì€ ì‚¬ìš©ìì˜ ì§ˆì˜ë¥¼ ë‹¨ìˆœí•œ í‚¤ì›Œë“œ ë§¤ì¹­ì„...\n",
    "    ğŸ“„ ìœ ì‚¬ë„: 0.3349 | ì •ì˜: í† í¬ë‚˜ì´ì €ëŠ” í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ í† í°ìœ¼ë¡œ ë¶„í• í•˜ëŠ” ë„êµ¬ì…ë‹ˆë‹¤. ì´ëŠ” ìì—°ì–´ ì²˜ë¦¬ì—ì„œ ë°...\n",
    "    ğŸ“„ ìœ ì‚¬ë„: 0.3063 | ì •ì˜: JSON(JavaScript Object Notation)ì€ ê²½ëŸ‰ì˜ ë°ì´í„° êµí™˜ í˜•...\n",
    "    ğŸ“„ ìœ ì‚¬ë„: 0.2875 | ì •ì˜: SQL(Structured Query Language)ì€ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ë°ì´í„°ë¥¼ ...\n",
    "\n",
    "    ğŸ“Š ìœ ì‚¬ë„ í†µê³„:\n",
    "    í‰ê· : 0.3553\n",
    "    í‘œì¤€í¸ì°¨: 0.0809\n",
    "    ìµœì†Œê°’: 0.2875\n",
    "    ìµœëŒ€ê°’: 0.4923\n",
    "    ì¤‘ê°„ê°’: 0.3206\n",
    "\n",
    "    ğŸ¯ ì¶”ì²œ ì„ê³„ê°’:\n",
    "    ë¶„ìœ„ìˆ˜ ê¸°ë°˜: 0.3120\n",
    "    í‘œì¤€í¸ì°¨ ê¸°ë°˜: 0.3148\n",
    "    ì•ˆì „ ê¸°ë°˜: 0.2300\n",
    "    âœ… ìµœì¢… ì¶”ì²œ: 0.3120\n",
    "\n",
    "    ğŸ§ª ì„ê³„ê°’ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ (ê¸°ì¤€: 4ê°œ ë¬¸ì„œ)\n",
    "    ============================================================\n",
    "    ì„ê³„ê°’  0.001:  4ê°œ (100.0%)\n",
    "    ì„ê³„ê°’  0.010:  4ê°œ (100.0%)\n",
    "    ì„ê³„ê°’  0.050:  4ê°œ (100.0%)\n",
    "    ì„ê³„ê°’  0.100:  4ê°œ (100.0%)\n",
    "    ì„ê³„ê°’  0.200:  4ê°œ (100.0%)\n",
    "    ì„ê³„ê°’  0.300:  3ê°œ (75.0%)\n",
    "    ì„ê³„ê°’  0.312:  2ê°œ (50.0%)\n",
    "    ì„ê³„ê°’  0.500:  0ê°œ ( 0.0%)\n",
    "    ì„ê³„ê°’  0.700:  0ê°œ ( 0.0%)\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c21c58",
   "metadata": {},
   "source": [
    "* ì„ê³„ê°’ ìë™ ì„¤ì • í•¨ìˆ˜ ë§Œë“¤ì–´ë³´ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3233e1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers.document_compressors import DocumentCompressorPipeline, EmbeddingsFilter\n",
    "from langchain_community.document_transformers import EmbeddingsRedundantFilter\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "\n",
    "def create_auto_threshold_pipeline(embeddings, retriever, gemini_lc, query_sample=\"Semantic Search\"):\n",
    "    \"\"\"ìë™ ì„ê³„ê°’ ê³„ì‚°ìœ¼ë¡œ íŒŒì´í”„ë¼ì¸ ìƒì„±\"\"\"\n",
    "    \n",
    "    print(\"ğŸ¤– ìë™ ì„ê³„ê°’ ê³„ì‚° ì‹œì‘...\")\n",
    "    \n",
    "    # 1ë‹¨ê³„: ì„ê³„ê°’ ìë™ ê³„ì‚°\n",
    "    calc = SimilarityThresholdCalculator(embeddings, retriever)\n",
    "    optimal_threshold = calc.suggest_optimal_threshold(query_sample, target_retention=0.4)\n",
    "    \n",
    "    print(f\"âœ… ê³„ì‚°ëœ ìµœì  ì„ê³„ê°’: {optimal_threshold:.4f}\")\n",
    "    \n",
    "    # 2ë‹¨ê³„: ì»´í¬ë„ŒíŠ¸ ìƒì„±\n",
    "    splitter = CharacterTextSplitter(chunk_size=300, chunk_overlap=0)\n",
    "    redundant_filter = EmbeddingsRedundantFilter(embeddings=embeddings)\n",
    "    relevant_filter = EmbeddingsFilter(\n",
    "        embeddings=embeddings,\n",
    "        similarity_threshold=optimal_threshold  # ìë™ ê³„ì‚°ëœ ê°’ ì‚¬ìš©!\n",
    "    )\n",
    "    \n",
    "    # 3ë‹¨ê³„: íŒŒì´í”„ë¼ì¸ ìƒì„±\n",
    "    try:\n",
    "        from langchain.retrievers.document_compressors import LLMChainExtractor\n",
    "        llm_extractor = LLMChainExtractor.from_llm(gemini_lc)\n",
    "        \n",
    "        pipeline_compressor = DocumentCompressorPipeline(\n",
    "            transformers=[\n",
    "                splitter,\n",
    "                redundant_filter,\n",
    "                relevant_filter,\n",
    "                llm_extractor\n",
    "            ]\n",
    "        )\n",
    "    except ImportError:\n",
    "        # LLMChainExtractorê°€ ì—†ìœ¼ë©´ ì œì™¸\n",
    "        pipeline_compressor = DocumentCompressorPipeline(\n",
    "            transformers=[\n",
    "                splitter,\n",
    "                redundant_filter,\n",
    "                relevant_filter,\n",
    "            ]\n",
    "        )\n",
    "    \n",
    "    # 4ë‹¨ê³„: ìµœì¢… ê²€ìƒ‰ê¸° ìƒì„±\n",
    "    compression_retriever = ContextualCompressionRetriever(\n",
    "        base_compressor=pipeline_compressor,\n",
    "        base_retriever=retriever,\n",
    "    )\n",
    "    \n",
    "    print(\"ğŸ‰ ìë™ ìµœì í™” íŒŒì´í”„ë¼ì¸ ìƒì„± ì™„ë£Œ!\")\n",
    "    return compression_retriever, optimal_threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c229eb",
   "metadata": {},
   "source": [
    "* ì ì‘í˜• ì„ê³„ê°’ í•„í„°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0098ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaptiveThresholdFilter:\n",
    "    \"\"\"ì„ë² ë”© ëª¨ë¸ë³„ ì ì‘í˜• ì„ê³„ê°’ í•„í„°\"\"\"\n",
    "    \n",
    "    # ì„ë² ë”© ëª¨ë¸ë³„ ê¸°ë³¸ ì„ê³„ê°’ ë°ì´í„°ë² ì´ìŠ¤\n",
    "    MODEL_THRESHOLDS = {\n",
    "        'sentence-transformers/all-MiniLM-L6-v2': 0.15,\n",
    "        'sentence-transformers/all-MiniLM-L12-v2': 0.20,\n",
    "        'sentence-transformers/paraphrase-MiniLM-L3-v2': 0.12,\n",
    "        'text-embedding-3-small': 0.75,                 # OpenAI\n",
    "        'text-embedding-3-large': 0.80,                 # OpenAI  \n",
    "        'models/embedding-001': 0.70,                   # Google\n",
    "        'fake': 0.01,                                   # FakeEmbeddings\n",
    "    }\n",
    "    \n",
    "    def __init__(self, embeddings):\n",
    "        self.embeddings = embeddings\n",
    "        self.model_name = self._detect_model_name()\n",
    "        \n",
    "    def _detect_model_name(self) -> str:\n",
    "        \"\"\"ì„ë² ë”© ëª¨ë¸ëª… ê°ì§€\"\"\"\n",
    "        embedding_type = str(type(self.embeddings))\n",
    "        \n",
    "        if 'Fake' in embedding_type:\n",
    "            return 'fake'\n",
    "        elif hasattr(self.embeddings, 'model_name'):\n",
    "            return self.embeddings.model_name\n",
    "        elif 'OpenAI' in embedding_type:\n",
    "            return 'text-embedding-3-small'\n",
    "        elif 'Google' in embedding_type:\n",
    "            return 'models/embedding-001'\n",
    "        else:\n",
    "            return 'sentence-transformers/all-MiniLM-L6-v2'  # ê¸°ë³¸ê°’\n",
    "    \n",
    "    def get_recommended_threshold(self) -> float:\n",
    "        \"\"\"ëª¨ë¸ë³„ ì¶”ì²œ ì„ê³„ê°’ ë°˜í™˜\"\"\"\n",
    "        threshold = self.MODEL_THRESHOLDS.get(self.model_name, 0.15)\n",
    "        print(f\"ğŸ¯ ëª¨ë¸ '{self.model_name}' ì¶”ì²œ ì„ê³„ê°’: {threshold}\")\n",
    "        return threshold\n",
    "    \n",
    "    def create_filter(self, custom_threshold: float = None) -> EmbeddingsFilter:\n",
    "        \"\"\"ìµœì í™”ëœ EmbeddingsFilter ìƒì„±\"\"\"\n",
    "        threshold = custom_threshold if custom_threshold else self.get_recommended_threshold()\n",
    "        \n",
    "        return EmbeddingsFilter(\n",
    "            embeddings=self.embeddings,\n",
    "            similarity_threshold=threshold\n",
    "        )\n",
    "\n",
    "# ğŸ¬ Jayë¥¼ ìœ„í•œ ì™„ë²½í•œ ì‚¬ìš©ë²•\n",
    "def jay_optimized_pipeline(embeddings, retriever, gemini_lc):\n",
    "    \"\"\"Jay ì „ìš© ìµœì í™” íŒŒì´í”„ë¼ì¸\"\"\"\n",
    "    \n",
    "    print(\"ğŸ¯ Jay ì „ìš© ìµœì í™” íŒŒì´í”„ë¼ì¸ ì‹œì‘...\")\n",
    "    \n",
    "    # 1ë‹¨ê³„: ì ì‘í˜• ì„ê³„ê°’ ê³„ì‚°\n",
    "    adaptive_filter = AdaptiveThresholdFilter(embeddings)\n",
    "    optimal_threshold = adaptive_filter.get_recommended_threshold()\n",
    "    \n",
    "    # 2ë‹¨ê³„: ì‹¤ì‹œê°„ ê²€ì¦ (ì„ íƒì‚¬í•­)\n",
    "    query_test = \"Semantic Search ì— ëŒ€í•´ì„œ ì•Œë ¤ì¤˜.\"\n",
    "    calc = SimilarityThresholdCalculator(embeddings, retriever)\n",
    "    \n",
    "    # ë¹ ë¥¸ ê²€ì¦\n",
    "    test_results = calc.test_threshold_performance(query_test, [optimal_threshold])\n",
    "    retention_rate = test_results[optimal_threshold]['retention_rate']\n",
    "    \n",
    "    # ì„ê³„ê°’ ì¡°ì • (ë³´ì •)\n",
    "    if retention_rate < 0.1:                                        # ë„ˆë¬´ ì ê²Œ í†µê³¼\n",
    "        optimal_threshold *= 0.5\n",
    "        print(f\"âš ï¸ ì„ê³„ê°’ ë„ˆë¬´ ë†’ìŒ. ì¡°ì •: {optimal_threshold:.4f}\")\n",
    "    elif retention_rate > 0.9:                                      # ë„ˆë¬´ ë§ì´ í†µê³¼\n",
    "        optimal_threshold *= 1.5\n",
    "        print(f\"âš ï¸ ì„ê³„ê°’ ë„ˆë¬´ ë‚®ìŒ. ì¡°ì •: {optimal_threshold:.4f}\")\n",
    "    \n",
    "    print(f\"âœ… ìµœì¢… ìµœì í™”ëœ ì„ê³„ê°’: {optimal_threshold:.4f}\")\n",
    "    \n",
    "    # 3ë‹¨ê³„: íŒŒì´í”„ë¼ì¸ êµ¬ì„±\n",
    "    splitter = CharacterTextSplitter(chunk_size=300, chunk_overlap=0)\n",
    "    redundant_filter = EmbeddingsRedundantFilter(embeddings=embeddings)\n",
    "    relevant_filter = EmbeddingsFilter(\n",
    "        embeddings=embeddings,\n",
    "        similarity_threshold=optimal_threshold\n",
    "    )\n",
    "    \n",
    "    # LLM Extractor ì¶”ê°€ (ê°€ëŠ¥í•˜ë©´)\n",
    "    transformers = [splitter, redundant_filter, relevant_filter]\n",
    "    \n",
    "    try:\n",
    "        from langchain.retrievers.document_compressors import LLMChainExtractor\n",
    "        llm_extractor = LLMChainExtractor.from_llm(gemini_lc)\n",
    "        transformers.append(llm_extractor)\n",
    "        print(\"âœ… LLM ì••ì¶•ê¸° ì¶”ê°€ë¨\")\n",
    "    except:\n",
    "        print(\"âš ï¸ LLM ì••ì¶•ê¸° ì œì™¸ (ê¸°ë³¸ í•„í„°ë§Œ ì‚¬ìš©)\")\n",
    "    \n",
    "    # 4ë‹¨ê³„: ìµœì¢… íŒŒì´í”„ë¼ì¸\n",
    "    pipeline_compressor = DocumentCompressorPipeline(transformers=transformers)\n",
    "    \n",
    "    compression_retriever = ContextualCompressionRetriever(\n",
    "        base_compressor=pipeline_compressor,\n",
    "        base_retriever=retriever,\n",
    "    )\n",
    "    \n",
    "    return compression_retriever, optimal_threshold\n",
    "\n",
    "# ğŸ¬ ì‹¤í–‰ ì˜ˆì‹œ\n",
    "compression_retriever, threshold = jay_optimized_pipeline(embeddings, retriever, gemini_lc)\n",
    "print(f\"ğŸ‰ ìµœì í™” ì™„ë£Œ! ì‚¬ìš©ëœ ì„ê³„ê°’: {threshold}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35dae56",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* ì…€ ì¶œë ¥\n",
    "\n",
    "    ```markdown\n",
    "    ğŸ¯ Jay ì „ìš© ìµœì í™” íŒŒì´í”„ë¼ì¸ ì‹œì‘...\n",
    "    ğŸ¯ ëª¨ë¸ 'fake' ì¶”ì²œ ì„ê³„ê°’: 0.01\n",
    "\n",
    "    ğŸ§ª ì„ê³„ê°’ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ (ê¸°ì¤€: 4ê°œ ë¬¸ì„œ)\n",
    "    ============================================================\n",
    "    ì„ê³„ê°’  0.010:  2ê°œ (50.0%)\n",
    "    âœ… ìµœì¢… ìµœì í™”ëœ ì„ê³„ê°’: 0.0100\n",
    "    âœ… LLM ì••ì¶•ê¸° ì¶”ê°€ë¨\n",
    "    ğŸ‰ ìµœì í™” ì™„ë£Œ! ì‚¬ìš©ëœ ì„ê³„ê°’: 0.01\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18fa25f4",
   "metadata": {},
   "source": [
    "* ìœ ì‚¬ë„ ì„ê³„ê°’ ê³„ì‚° ìë™í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "912da475",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_click_contextual_compression(embeddings, retriever, gemini_lc, query=\"Semantic Search\"):\n",
    "    \"\"\"ì›í´ë¦­ ì™„ì „ ìë™í™” ì‹œìŠ¤í…œ\"\"\"\n",
    "    \n",
    "    print(\"ğŸš€ ì›í´ë¦­ ìë™ ìµœì í™” ì‹œì‘!\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # 1ë‹¨ê³„: ì„ë² ë”© ëª¨ë¸ ë¶„ì„\n",
    "    model_type = str(type(embeddings))\n",
    "    print(f\"ğŸ” ê°ì§€ëœ ëª¨ë¸: {model_type}\")\n",
    "    \n",
    "    # 2ë‹¨ê³„: ê¸°ë³¸ ì„ê³„ê°’ ì¶”ì •\n",
    "    if 'Fake' in model_type:\n",
    "        base_threshold = 0.01\n",
    "        print(\"  ğŸ“ FakeEmbeddings ê°ì§€ â†’ ì´ˆì € ì„ê³„ê°’ ëª¨ë“œ\")\n",
    "    elif 'HuggingFace' in model_type:\n",
    "        base_threshold = 0.15\n",
    "        print(\"  ğŸ¤— HuggingFace ëª¨ë¸ ê°ì§€ â†’ ì¤‘ê°„ ì„ê³„ê°’ ëª¨ë“œ\") \n",
    "    elif 'OpenAI' in model_type:\n",
    "        base_threshold = 0.75\n",
    "        print(\"  ğŸ¤– OpenAI ëª¨ë¸ ê°ì§€ â†’ ê³  ì„ê³„ê°’ ëª¨ë“œ\")\n",
    "    elif 'Google' in model_type:\n",
    "        base_threshold = 0.70\n",
    "        print(\"  ğŸŒŸ Google ëª¨ë¸ ê°ì§€ â†’ ê³  ì„ê³„ê°’ ëª¨ë“œ\")\n",
    "    else:\n",
    "        base_threshold = 0.20\n",
    "        print(\"  â“ ì•Œ ìˆ˜ ì—†ëŠ” ëª¨ë¸ â†’ ê¸°ë³¸ ì„ê³„ê°’ ëª¨ë“œ\")\n",
    "    \n",
    "    # 3ë‹¨ê³„: ì‹¤ì‹œê°„ ê²€ì¦ ë° ì¡°ì •\n",
    "    print(f\"\\nğŸ§ª ì„ê³„ê°’ {base_threshold} ê²€ì¦ ì¤‘...\")\n",
    "    \n",
    "    # í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ë¡œ ì„±ëŠ¥ í™•ì¸\n",
    "    base_docs = retriever.invoke(query)\n",
    "    if not base_docs:\n",
    "        print(\"âŒ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ - ê¸°ë³¸ ì„¤ì • ì‚¬ìš©\")\n",
    "        final_threshold = base_threshold\n",
    "    else:\n",
    "        # ì„ê³„ê°’ í…ŒìŠ¤íŠ¸\n",
    "        test_filter = EmbeddingsFilter(embeddings=embeddings, similarity_threshold=base_threshold)\n",
    "        filtered_docs = test_filter.compress_documents(base_docs, query)\n",
    "        retention_rate = len(filtered_docs) / len(base_docs)\n",
    "        \n",
    "        print(f\"  ğŸ“Š í…ŒìŠ¤íŠ¸ ê²°ê³¼: {len(base_docs)}ê°œ â†’ {len(filtered_docs)}ê°œ ({retention_rate:.1%})\")\n",
    "        \n",
    "        # ë™ì  ì¡°ì •\n",
    "        if retention_rate < 0.1:\n",
    "            final_threshold = base_threshold * 0.3\n",
    "            print(f\"  â¬‡ï¸ ì„ê³„ê°’ ë‚®ì¶¤: {final_threshold:.4f}\")\n",
    "        elif retention_rate > 0.9:\n",
    "            final_threshold = base_threshold * 1.5\n",
    "            print(f\"  â¬†ï¸ ì„ê³„ê°’ ë†’ì„: {final_threshold:.4f}\")\n",
    "        else:\n",
    "            final_threshold = base_threshold\n",
    "            print(f\"  âœ… ì„ê³„ê°’ ì ì •: {final_threshold:.4f}\")\n",
    "    \n",
    "    # 4ë‹¨ê³„: íŒŒì´í”„ë¼ì¸ ìë™ êµ¬ì„±\n",
    "    print(f\"\\nğŸ”§ íŒŒì´í”„ë¼ì¸ êµ¬ì„± ì¤‘...\")\n",
    "    \n",
    "    transformers = [\n",
    "        CharacterTextSplitter(chunk_size=300, chunk_overlap=0),\n",
    "        EmbeddingsRedundantFilter(embeddings=embeddings),\n",
    "        EmbeddingsFilter(embeddings=embeddings, similarity_threshold=final_threshold)\n",
    "    ]\n",
    "    \n",
    "    # LLM ì••ì¶•ê¸° ì¶”ê°€ ì‹œë„\n",
    "    try:\n",
    "        from langchain.retrievers.document_compressors import LLMChainExtractor\n",
    "        transformers.append(LLMChainExtractor.from_llm(gemini_lc))\n",
    "        print(\"  âœ… LLM ì••ì¶•ê¸° ì¶”ê°€\")\n",
    "    except:\n",
    "        print(\"  âš ï¸ LLM ì••ì¶•ê¸° ìƒëµ\")\n",
    "    \n",
    "    # 5ë‹¨ê³„: ìµœì¢… ê²€ìƒ‰ê¸° ìƒì„±\n",
    "    pipeline = DocumentCompressorPipeline(transformers=transformers)\n",
    "    final_retriever = ContextualCompressionRetriever(\n",
    "        base_compressor=pipeline,\n",
    "        base_retriever=retriever\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nğŸ‰ ìë™ ìµœì í™” ì™„ë£Œ!\")\n",
    "    print(f\"ğŸ“Š ìµœì¢… ì„¤ì •:\")\n",
    "    print(f\"  - ì„ê³„ê°’: {final_threshold:.4f}\")\n",
    "    print(f\"  - íŒŒì´í”„ë¼ì¸ ë‹¨ê³„: {len(transformers)}ê°œ\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    return final_retriever, final_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a227f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ¯ ìµœì¢… ì‚¬ìš©ë²•\n",
    "def pretty_print_docs(docs):\n",
    "    if docs:\n",
    "        for i, doc in enumerate(docs):\n",
    "            print(f\"Document {i+1}:\")\n",
    "            print(doc.page_content)\n",
    "            print(\"=\"*50)\n",
    "    else:\n",
    "        print(\"ğŸ“­ í•„í„°ë§ëœ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "# ì‹¤í–‰ (ê¸°ì¡´ ë³€ìˆ˜ë“¤ ì‚¬ìš©)\n",
    "compression_retriever, used_threshold = one_click_contextual_compression(\n",
    "    embeddings=embeddings,                          # ê¸°ì¡´ embeddings\n",
    "    retriever=retriever,                            # ê¸°ì¡´ retriever  \n",
    "    gemini_lc=gemini_lc,                            # ê¸°ì¡´ gemini_lc\n",
    "    query=\"Semantic Search ì— ëŒ€í•´ì„œ ì•Œë ¤ì¤˜.\"\n",
    ")\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸\n",
    "print(\"\\nğŸ” ìµœì í™”ëœ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸: \\n\")\n",
    "compressed_docs = compression_retriever.invoke(\"Semantic Search ì— ëŒ€í•´ì„œ ì•Œë ¤ì¤˜.\")\n",
    "pretty_print_docs(compressed_docs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c82f0b",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* ì…€ ì¶œë ¥ (1.0s)\n",
    "\n",
    "    ```markdown\n",
    "    ğŸš€ ì›í´ë¦­ ìë™ ìµœì í™” ì‹œì‘!\n",
    "    ==================================================\n",
    "    ğŸ” ê°ì§€ëœ ëª¨ë¸: <class 'langchain_core.embeddings.fake.FakeEmbeddings'>\n",
    "    ğŸ“ FakeEmbeddings ê°ì§€ â†’ ì´ˆì € ì„ê³„ê°’ ëª¨ë“œ\n",
    "\n",
    "    ğŸ§ª ì„ê³„ê°’ 0.01 ê²€ì¦ ì¤‘...\n",
    "    ğŸ“Š í…ŒìŠ¤íŠ¸ ê²°ê³¼: 4ê°œ â†’ 2ê°œ (50.0%)\n",
    "    âœ… ì„ê³„ê°’ ì ì •: 0.0100\n",
    "\n",
    "    ğŸ”§ íŒŒì´í”„ë¼ì¸ êµ¬ì„± ì¤‘...\n",
    "    âœ… LLM ì••ì¶•ê¸° ì¶”ê°€\n",
    "\n",
    "    ğŸ‰ ìë™ ìµœì í™” ì™„ë£Œ!\n",
    "    ğŸ“Š ìµœì¢… ì„¤ì •:\n",
    "    - ì„ê³„ê°’: 0.0100\n",
    "    - íŒŒì´í”„ë¼ì¸ ë‹¨ê³„: 4ê°œ\n",
    "    ==================================================\n",
    "\n",
    "    ğŸ” ìµœì í™”ëœ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸: \n",
    "\n",
    "    Document 1:\n",
    "    Semantic Search\n",
    "\n",
    "    ì •ì˜: ì˜ë¯¸ë¡ ì  ê²€ìƒ‰ì€ ì‚¬ìš©ìì˜ ì§ˆì˜ë¥¼ ë‹¨ìˆœí•œ í‚¤ì›Œë“œ ë§¤ì¹­ì„ ë„˜ì–´ì„œ ê·¸ ì˜ë¯¸ë¥¼ íŒŒì•…í•˜ì—¬ ê´€ë ¨ëœ ê²°ê³¼ë¥¼ ë°˜í™˜í•˜ëŠ” ê²€ìƒ‰ ë°©ì‹ì…ë‹ˆë‹¤.\n",
    "    ì˜ˆì‹œ: ì‚¬ìš©ìê°€ \"íƒœì–‘ê³„ í–‰ì„±\"ì´ë¼ê³  ê²€ìƒ‰í•˜ë©´, \"ëª©ì„±\", \"í™”ì„±\" ë“±ê³¼ ê°™ì´ ê´€ë ¨ëœ í–‰ì„±ì— ëŒ€í•œ ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
    "    ì—°ê´€í‚¤ì›Œë“œ: ìì—°ì–´ ì²˜ë¦¬, ê²€ìƒ‰ ì•Œê³ ë¦¬ì¦˜, ë°ì´í„° ë§ˆì´ë‹\n",
    "    ==================================================\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcfa68ee",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9480ef",
   "metadata": {},
   "source": [
    "* *next: **`ì•™ìƒë¸” ê²€ìƒ‰ê¸° (EnsembleRetriever)`***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c888d3dc",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lc_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
