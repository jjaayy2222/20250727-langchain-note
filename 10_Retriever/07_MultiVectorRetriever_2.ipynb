{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "678aef2c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b818a65",
   "metadata": {},
   "source": [
    "* 출처: LangChain 공식 문서 또는 해당 교재명\n",
    "* 원본 URL: https://smith.langchain.com/hub/teddynote/summary-stuff-documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a93c94e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74e7030",
   "metadata": {},
   "source": [
    "### **7. `MultiVectorRetriever`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb012a79",
   "metadata": {},
   "source": [
    "#### **5) `LLM 모델로 재시도`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa85b9f",
   "metadata": {},
   "source": [
    "* **`로컬 LLM 모델로 재시도`**\n",
    "\n",
    "  * `API` 비용 걱정 X \n",
    "\n",
    "  * **`일관된 품질`** → 동일 모델 사용\n",
    "\n",
    "  * **`한국어 지원`**: 한국어 지원 특화 모델 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc50a1a",
   "metadata": {},
   "source": [
    "* 한국어 지원 `LLM` 모델 \n",
    "\n",
    "  * 추천 모델 1: `Qwen2.5`\n",
    "    * 약 `7b`\n",
    "    * 품질: `한국어`, `영어` 모두 우수 / `Chat-GPT-3.5` 수준\n",
    "    * 속도: 약 `20~30` 토큰/초 *(로컬이라 약간 느릴 수 있으나 무제한)*\n",
    "  ```bash\n",
    "\n",
    "    ollama pull qwen2.5:7b\n",
    "\n",
    "  ```\n",
    "\n",
    "  * 추천 모델 2: `Gemma 3` (구글, 140개 언어 지원)\n",
    "    * 품질: `140개 언어` 지원 / `Chat-GPT-3.5` 수준\n",
    "    * 속도: 약 `15~25` 토큰/초\n",
    "  ```bash\n",
    "\n",
    "      ollama pull gemma2:9b\n",
    "\n",
    "  ```\n",
    "\n",
    "  * 추천 모델 3: `DeepSeek-R1` (코딩, 추론 강력)\n",
    "  ```bash\n",
    "\n",
    "      ollama pull deepseek-r1:8b\n",
    "\n",
    "  ```\n",
    "\n",
    "  * 추천 모델 4: **`Llama 3.3`** (메타, 범용)\n",
    "  ```bash\n",
    "\n",
    "      ollama pull llama3.3:8b\n",
    "\n",
    "  ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7894ef1",
   "metadata": {},
   "source": [
    "* **📊 로컬 LLM 모델 성능 비교표**\n",
    "\n",
    "    | 모델 | 한국어 | 영어 | 보안 | 속도 | 추천도 |\n",
    "    |------|--------|------|------|------|--------|\n",
    "    | **EXAONE 3.5** | ⭐⭐⭐⭐⭐ | ⭐⭐⭐⭐ | ⭐⭐⭐⭐⭐ | ⭐⭐⭐⭐ | **최강 추천** |\n",
    "    | Llama-3-Ko | ⭐⭐⭐⭐⭐ | ⭐⭐⭐⭐⭐ | ⭐⭐⭐⭐ | ⭐⭐⭐⭐ | 차선책 |\n",
    "    | Bllossom | ⭐⭐⭐⭐⭐ | ⭐⭐⭐⭐ | ⭐⭐⭐⭐ | ⭐⭐⭐ | 교육용 |\n",
    "    | DeepSeek | ⭐⭐⭐ | ⭐⭐⭐⭐⭐ | ⚠️ | ⭐⭐⭐⭐ | 보안 우려 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69fda9a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30cbb20",
   "metadata": {},
   "source": [
    "* `한국어 로컬 LLM 모델`\n",
    "\n",
    "  * **a. `EXAONE 3.5`** *(LG AI Research)*\n",
    "  ```bash\n",
    "\n",
    "              # Ollama에서 설치\n",
    "              ollama pull exaone3.5:7.8b\n",
    "\n",
    "              # HuggingFace\n",
    "              LGAI-EXAONE/EXAONE-3.5-7.8B-Instruct\n",
    "\n",
    "  ```\n",
    "\n",
    "  * * 장점: \n",
    "        * `LG AI Research` 개발\n",
    "        * `한국어 최고 성능`: *벤치마크 1위*\n",
    "        * `MeCab` 기반 토크나이저: 한국어 교착어 특성 완벽 반영\n",
    "        * `실사용 검증`: `LG` 계열사 실무 적용 중\n",
    "        * `오픈소스`: `HuggingFace` 공개\n",
    "\n",
    "    * 성능:\n",
    "        * 한국어: ★★★★★\n",
    "        * 영어: ★★★★\n",
    "        * 코딩: ★★★★\n",
    "        * 추론: ★★★★★\n",
    "\n",
    "<br>\n",
    "\n",
    "* * **b. `Llama-3-Open-Ko-8B`** *(beomi)*\n",
    "  ```bash\n",
    "\n",
    "              # Ollama에서 설치\n",
    "              ollama pull beomi/llama-3-open-ko-8b\n",
    "\n",
    "              # HuggingFace\n",
    "              beomi/Llama-3-Open-Ko-8B\n",
    "              beomi/Llama-3-Open-Ko-8B-Instruct-preview\n",
    "\n",
    "  ```\n",
    "\n",
    "  * * 장점: \n",
    "        * `Meta Llama 3 기반`: 세계 최고 모델 파인 튜닝\n",
    "        * `beomi(이준범님) 개발`: *한국 LLM 커뮤니티 신뢰도 1위*\n",
    "        * `지속적 업데이트`: 활발한 개발\n",
    "        * `범용성`: 다양한 태스크 우수\n",
    "\n",
    "  * * 성능:\n",
    "        * 한국어: ★★★★★ *(최상급)*\n",
    "        * 영어: ★★★★★ *(`Llama 3 성능`)*\n",
    "        * 코딩: ★★★★ *(우수)*\n",
    "        * 추론: ★★★★ *(우수)*\n",
    "\n",
    "<br>\n",
    "\n",
    "*  * **c. `Korean-Bllossom-8B`** *(서울과기대)*\n",
    "  ```bash\n",
    "\n",
    "              # Ollama에서 설치\n",
    "              ollama pull korean-bllossom-8b\n",
    "\n",
    "              # HuggingFace\n",
    "              MLP-KTLim/llama-3-Korean-Bllossom-8B\n",
    "\n",
    "  ```\n",
    "\n",
    "* * * 장점: \n",
    "        * `100GB+ 한국어 풀 튜닝`: 대용량 한국어 한습\n",
    "        * `서울과기대 슈퍼컴퓨팅`: *공신력 있는 기관*\n",
    "        * `한국어 특화`: 이중언어 모델\n",
    "        * `교육/연구용 최적`: 학습 목적 완벽\n",
    "\n",
    "* * * 성능:\n",
    "        * 한국어: ★★★★★ *(최상급)*\n",
    "        * 영어: ★★★★★ *(`Llama 3 성능`)*\n",
    "        * 코딩: ★★★ *(양호)*\n",
    "        * 추론: ★★★★ *(우수)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15daddb2",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb88e3b6",
   "metadata": {},
   "source": [
    "#### **2) `로컬 LLM 설치`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5254d4a9",
   "metadata": {},
   "source": [
    "* **`EXAONE 3.5`** 선택\n",
    "\n",
    "  * **`보안 안전성`**\n",
    "    * `LG AI Research`: 대기업 공식 개발\n",
    "    * `국내 기업`: 한국 법률/보안 기준 준수\n",
    "    * `실사용 검증`: `LG` 계열사 실무 적용\n",
    "    * `DeepSeek 우려 해소`: 보안 우려 해소\n",
    "<br>\n",
    "\n",
    "* * **`한국어 성능 우수`**\n",
    "    * `MeCab 토크나이저`: 교착어 특성 완벽\n",
    "    * `한국어 벤치마크`: 세계 최고 성능\n",
    "    * `한국어 코퍼스`: 대량 학습\n",
    "    * `실제 테스트`: 커뮤니티 인정\n",
    "\n",
    "<br>\n",
    "\n",
    "* * **`MultiVectorRetriever 최적`**\n",
    "    * `요약 생성`: 뛰어난 이해력\n",
    "    * `가설 쿼리`: 창의적 질문 생성\n",
    "    * `일관성`: 동일 모델 사용\n",
    "    * `속도`: `7.8b`로 빠름"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ac9c92",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987e35e9",
   "metadata": {},
   "source": [
    "* 설치 가이드\n",
    "\n",
    "  * 1단계: **`Ollma` 설치**\n",
    "\n",
    "```bash\n",
    "      # Windows/Mac\n",
    "      https://ollama.com/download\n",
    "\n",
    "      # 설치 확인\n",
    "      ollama --version\n",
    "```\n",
    "<br>\n",
    "\n",
    "* * 2단게: **`EXAONE 3.5` 다운로드**\n",
    "\n",
    "```bash\n",
    "      # 최강 한국어 모델!\n",
    "      ollama pull exaone3.5:7.8b\n",
    "\n",
    "      # 다운로드 확인\n",
    "      ollama list\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "* * 3단계: **`LangChain` 통합**\n",
    "\n",
    "```python\n",
    "\n",
    "      # 랭체인 통합하기\n",
    "      from langchain_ollama import OllamaLLM\n",
    "\n",
    "      # EXAONE 3.5 초기화\n",
    "      llm = OllamaLLM(\n",
    "          model=\"exaone3.5:7.8b\",\n",
    "          temperature=0\n",
    "      )\n",
    "\n",
    "      # 요약 생성 체인\n",
    "      summary_chain = (\n",
    "          {\"doc\": lambda x: x.page_content}\n",
    "          | ChatPromptTemplate.from_template(\n",
    "              \"다음 문서를 3-4문장으로 요약하세요:\\n\\n{doc}\"\n",
    "          )\n",
    "          | llm\n",
    "          | StrOutputParser()\n",
    "      )\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5442b3c5",
   "metadata": {},
   "source": [
    "* 사전 `VS Code` 터미널에 설치할 것\n",
    "\n",
    "```bash\n",
    "        pip install langchain-ollama\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82dc44d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaLLM\n",
    "\n",
    "# Ollama 전역 서버에 연결!\n",
    "llm_lama = OllamaLLM(model=\"exaone3.5:7.8b\")\n",
    "\n",
    "# 테스트\n",
    "response = llm_lama.invoke(\"안녕하세요!\")\n",
    "print(response)                                                 # 12.1s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66018e51",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 셀 출력 *(`12.1s`)*\n",
    "\n",
    "    ```markdown\n",
    "    안녕하세요! LG AI Research에서 개발된 EXAONE입니다. 어떻게 도와드릴까요? 어떤 도움이 필요하신지 말씀해 주세요. 😊\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b418d88",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0208351a",
   "metadata": {},
   "source": [
    "#### **3) `설정`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e86abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API 키를 환경변수로 관리하기 위한 설정 파일\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API 키 정보 로드\n",
    "load_dotenv()                               # True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bffc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import Client\n",
    "from langsmith import traceable\n",
    "\n",
    "import os\n",
    "\n",
    "# LangSmith 환경 변수 확인\n",
    "\n",
    "print(\"\\n--- LangSmith 환경 변수 확인 ---\")\n",
    "langchain_tracing_v2 = os.getenv('LANGCHAIN_TRACING_V2')\n",
    "langchain_project = os.getenv('LANGCHAIN_PROJECT')\n",
    "langchain_api_key_status = \"설정됨\" if os.getenv('LANGCHAIN_API_KEY') else \"설정되지 않음\" # API 키 값은 직접 출력하지 않음\n",
    "\n",
    "if langchain_tracing_v2 == \"true\" and os.getenv('LANGCHAIN_API_KEY') and langchain_project:\n",
    "    print(f\"✅ LangSmith 추적 활성화됨 (LANGCHAIN_TRACING_V2='{langchain_tracing_v2}')\")\n",
    "    print(f\"✅ LangSmith 프로젝트: '{langchain_project}'\")\n",
    "    print(f\"✅ LangSmith API Key: {langchain_api_key_status}\")\n",
    "    print(\"  -> 이제 LangSmith 대시보드에서 이 프로젝트를 확인해 보세요.\")\n",
    "else:\n",
    "    print(\"❌ LangSmith 추적이 완전히 활성화되지 않았습니다. 다음을 확인하세요:\")\n",
    "    if langchain_tracing_v2 != \"true\":\n",
    "        print(f\"  - LANGCHAIN_TRACING_V2가 'true'로 설정되어 있지 않습니다 (현재: '{langchain_tracing_v2}').\")\n",
    "    if not os.getenv('LANGCHAIN_API_KEY'):\n",
    "        print(\"  - LANGCHAIN_API_KEY가 설정되어 있지 않습니다.\")\n",
    "    if not langchain_project:\n",
    "        print(\"  - LANGCHAIN_PROJECT가 설정되어 있지 않습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c214c9",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 셀 출력\n",
    "\n",
    "  ```markdown\n",
    "  --- LangSmith 환경 변수 확인 ---\n",
    "  ✅ LangSmith 추적 활성화됨 (LANGCHAIN_TRACING_V2='true')\n",
    "  ✅ LangSmith 프로젝트: 'LangChain-prantice'\n",
    "  ✅ LangSmith API Key: 설정됨\n",
    "    -> 이제 LangSmith 대시보드에서 이 프로젝트를 확인해 보세요.\n",
    "  ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7861359",
   "metadata": {},
   "source": [
    "* **`전처리 과정`**\n",
    "\n",
    "  * 텍스트 파일에서 데이터 로드 → 로드된 문서들을 지정된 크기로 분할\n",
    "\n",
    "  * 분할된 문서들 = 추구 벡터화 및 검색 등의 작업에 사용 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58b05f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "\n",
    "loader = PyMuPDFLoader(\"../10_Retriever/data/SPRI_AI_Brief_2023년12월호_F.pdf\")\n",
    "docs = loader.load()                                    # 0.3s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc409d44",
   "metadata": {},
   "source": [
    "* **`docs`** 변수 = 데이터로부터 로드한 원본 도큐먼트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc144a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(docs))                                        # 23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6128d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(docs[5].page_content[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d66881",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 6번째 페이지 일부 출력해보기\n",
    "\n",
    "    ```markdown\n",
    "    1. 정책/법제  \n",
    "    2. 기업/산업 \n",
    "    3. 기술/연구 \n",
    "    4. 인력/교육\n",
    "    영국 AI 안전성 정상회의에 참가한 28개국, AI 위험에 공동 대응 선언\n",
    "    n 영국 블레츨리 파크에서 개최된 AI 안전성 정상회의에 참가한 28개국들이 AI 안전 보장을 \n",
    "    위한 협력 방안을 담은 블레츨리 선언을 발표\n",
    "    n 첨단 AI를 개발하는 국가와 기업들은 AI 시스템에 대한 안전 테스트 계획에 합의했으며, \n",
    "    영국의 AI 안전 연구소가 전 세계 국가와 협력해 테스트를 주도할 예정 \n",
    "    KEY Contents\n",
    "    £ AI 안전성 정상회의 참가국들, 블레츨리 선언 통해 AI 안전 보장을 위한 협력에 합의\n",
    "    n 2023년 11월 1~2일 영국 블레츨리 파크에서 열린 AI 안전성 정상회의(AI Safety Summit)에 \n",
    "    참가한 28개국 대표들이 AI 위험 관리를 위한 ‘블레츨리 선언’을 발표 \n",
    "    ∙선언은 AI 안전 보장을 위해 국가, 국제기구, 기업, 시민사회, 학계를 포함한 모든 이해관계자의 협력이 \n",
    "    중요하다고 강조했으며,\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9740c1",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4142d7a8",
   "metadata": {},
   "source": [
    "#### **4) `Chunk + 원본 문서 검색`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5a30cf",
   "metadata": {},
   "source": [
    "* 대용량 정보 검색 시: `더 작은 단위`로 정보를 `임베딩`하는 것이 유용할 수 있음\n",
    "\n",
    "  * **`MultiVectorRetriever`** → 문서를 `여러 벡터`로 `저장`하고 `관리` 가능\n",
    "\n",
    "  * **`docstore`** = 원본 문서 저장\n",
    "\n",
    "  * **`vectoresotre`** = *`임베딩된 문서 저장`*\n",
    "\n",
    "    * 문서룰 더 작은 단위로 나눠 더 정확한 검색이 가능 \n",
    "    * 원본 문서의 내용도 조회 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697bf522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 자식 청크를 인덱싱하는 데 사용할 벡터 저장소\n",
    "import uuid\n",
    "from langchain.storage import InMemoryStore\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.retrievers.multi_vector import MultiVectorRetriever\n",
    "\n",
    "# 기존 임베딩 모델: sentence-transformers/all-mpnet-base-v2 (768차원)\n",
    "# 업그레이드된 임베딩 모델 사용하기: 다국어 고성능 모델 (1024차원)\n",
    "multilingual_embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\",  # 1024차원\n",
    "    model_kwargs={'device': 'cpu'},\n",
    "    encode_kwargs={'normalize_embeddings': True}\n",
    ")\n",
    "\n",
    "print(\"🎯 고성능 임베딩 모델 준비 완료!\")\n",
    "\n",
    "vectorstore = Chroma(\n",
    "    collection_name=\"small_bigger_chunks\",\n",
    "    embedding_function=multilingual_embeddings,\n",
    ")\n",
    "\n",
    "# 부모 문서의 저장소 계층\n",
    "store = InMemoryStore()\n",
    "\n",
    "id_key = \"doc_id\"\n",
    "\n",
    "# 검색기 (시작 시 비어 있음)\n",
    "retriever = MultiVectorRetriever(\n",
    "    vectorstore=vectorstore,\n",
    "    byte_store=store,\n",
    "    id_key=id_key,\n",
    ")\n",
    "\n",
    "# 문서 ID 생성하기\n",
    "doc_ids = [str(uuid.uuid4()) for _ in docs]\n",
    "\n",
    "# 두개의 생성된 id 확인하기\n",
    "doc_ids                                                                         # 5.6s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d4dfd6",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 🎯 고성능 임베딩 모델 준비 완료! *(`5.6s`)*\n",
    "\n",
    "    ```python\n",
    "    ['f379a1c3-87d2-4c15-b993-1530cc12abff',\n",
    "    '309a6564-de98-4e33-a956-fabf9dd6a127',\n",
    "    'c743a429-9f88-4fcd-877d-70a9ec1fbd56',\n",
    "    '701310ba-f32e-4d15-8793-cb08a735774a',\n",
    "    '07f0b926-2472-46d5-b389-00329af04c66',\n",
    "    'c641e3e6-fae2-4eb1-8371-a49cf7e1a48c',\n",
    "    '4f1ebe8e-1426-407b-a798-064fc52d32c3',\n",
    "    'bde03cd1-9d66-49c2-a935-53c7cffe5f89',\n",
    "    'e31b5bf0-73d8-4329-8900-2489a37b94c2',\n",
    "    '7602af6f-a4af-4095-b98a-3ae351c7670a',\n",
    "    'ed729bf3-f9a6-49ca-b931-123c095f43d7',\n",
    "    'bfa9b89d-0cdd-4dd8-8a17-2fc5db340b0e',\n",
    "    'a7d79032-3b81-4687-bde0-6134d2dded1f',\n",
    "    '77fd3a60-7ef7-48c5-b8a7-e7696fc7dba4',\n",
    "    '3fa67910-842a-429a-b56c-180c611dd3d4',\n",
    "    '0cced66f-d690-4a81-8d79-39b35c05fa85',\n",
    "    '63de1be1-dba0-43c8-80fc-f98a8d2e2527',\n",
    "    '15999e87-d074-46f3-9fec-2d9cab88c294',\n",
    "    '4fa52a8d-b1fb-450c-90eb-f05f8522782a',\n",
    "    '0fff2d32-8584-4565-982c-b354878dfad8',\n",
    "    '9d919616-dc81-4750-be0a-d81bca4618eb',\n",
    "    '6a8e0a8f-8431-4b7a-9d7d-6b07a809fd65',\n",
    "    '50b81f53-cb6c-46bc-9875-b0a211f86115']\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8819193c",
   "metadata": {},
   "source": [
    "* **`문서 계층 분할기 생성`**\n",
    "\n",
    "  * **`parent_text_splitter`**: 큰 청크로 분할하기 위한 객체\n",
    "\n",
    "  * **`chile_text_splitter`**: 더 작은 청크로 분할하기 위한 객체"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0991eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RecursiveCharacterTextSplitter 객체 생성하기\n",
    "parent_text_splitter = RecursiveCharacterTextSplitter(chunk_size=600)\n",
    "\n",
    "# 더 작은 청크를 생성하는 데 사용할 분할기\n",
    "child_text_splitter = RecursiveCharacterTextSplitter(chunk_size=200)        # 부모보다 작게 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21e1c55",
   "metadata": {},
   "source": [
    "* 더 큰 `Chunk` 인 `Parent` 문서 생성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee8e5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_docs = []\n",
    "\n",
    "for i, doc in enumerate(docs):\n",
    "    _id = doc_ids[i]                                            # 현재 문서의 ID 가져오기\n",
    "    parent_doc = parent_text_splitter.split_documents([doc])    # 현재 문서를 하위 문서로 분할\n",
    "\n",
    "    for _doc in parent_doc:\n",
    "        _doc.metadata[id_key] = _id                             # metadata에 문서 ID 를 저장\n",
    "    parent_docs.extend(parent_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5266c8a9",
   "metadata": {},
   "source": [
    "* **`parent_docs`** 에 기입된 **`doc_id`** 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf702693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 생성된 Parent 문서의 메타데이터 확인하기\n",
    "\n",
    "parent_docs[0].metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c368da2",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* `parent_docs`의 `doc_id` 확인하기\n",
    "\n",
    "    ```python\n",
    "    {'producer': 'Hancom PDF 1.3.0.542',\n",
    "    'creator': 'Hwp 2018 10.0.0.13462',\n",
    "    'creationdate': '2023-12-08T13:28:38+09:00',\n",
    "    'source': '../10_Retriever/data/SPRI_AI_Brief_2023년12월호_F.pdf',\n",
    "    'file_path': '../10_Retriever/data/SPRI_AI_Brief_2023년12월호_F.pdf',\n",
    "    'total_pages': 23,\n",
    "    'format': 'PDF 1.4',\n",
    "    'title': '',\n",
    "    'author': 'dj',\n",
    "    'subject': '',\n",
    "    'keywords': '',\n",
    "    'moddate': '2023-12-08T13:28:38+09:00',\n",
    "    'trapped': '',\n",
    "    'modDate': \"D:20231208132838+09'00'\",\n",
    "    'creationDate': \"D:20231208132838+09'00'\",\n",
    "    'page': 0,\n",
    "    'doc_id': 'f379a1c3-87d2-4c15-b993-1530cc12abff'}           # ✓ doc_id 확인하기\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37bf384",
   "metadata": {},
   "source": [
    "* 상대적으로 더 작은 **`Chunk`** 인 **`Child`** 문서 생성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413348b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "child_docs = []\n",
    "\n",
    "for i, doc in enumerate(docs):\n",
    "    _id = doc_ids[i]                                            # 현재 문서의 ID 가져오기\n",
    "    child_doc = child_text_splitter.split_documents([doc])      # 현재 문서를 하위 문서로 분할  \n",
    "    \n",
    "    for _doc in child_doc:\n",
    "        _doc.metadata[id_key] = _id                             # metadata에 문서 ID 를 저장\n",
    "    child_docs.extend(child_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e46527",
   "metadata": {},
   "source": [
    "* **`child_docs`** 에 기입된 **`doc_id`** 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d6ca1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 생성된 Child 문서의 메타데이터 확인하기\n",
    "\n",
    "child_docs[0].metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce944ef",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* `child_docs`의 `doc_id` 확인하기 \n",
    "\n",
    "    ```python\n",
    "    {'producer': 'Hancom PDF 1.3.0.542',\n",
    "    'creator': 'Hwp 2018 10.0.0.13462',\n",
    "    'creationdate': '2023-12-08T13:28:38+09:00',\n",
    "    'source': '../10_Retriever/data/SPRI_AI_Brief_2023년12월호_F.pdf',\n",
    "    'file_path': '../10_Retriever/data/SPRI_AI_Brief_2023년12월호_F.pdf',\n",
    "    'total_pages': 23,\n",
    "    'format': 'PDF 1.4',\n",
    "    'title': '',\n",
    "    'author': 'dj',\n",
    "    'subject': '',\n",
    "    'keywords': '',\n",
    "    'moddate': '2023-12-08T13:28:38+09:00',\n",
    "    'trapped': '',\n",
    "    'modDate': \"D:20231208132838+09'00'\",\n",
    "    'creationDate': \"D:20231208132838+09'00'\",\n",
    "    'page': 0,\n",
    "    'doc_id': 'f379a1c3-87d2-4c15-b993-1530cc12abff'}           # ✓ doc_id 확인하기\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc880536",
   "metadata": {},
   "source": [
    "* 각각 분할된 청크의 수 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24fcda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"분할된 parent_docs의 개수: {len(parent_docs)}\")\n",
    "print(f\"분할된 child_docs의 개수: {len(child_docs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77fd196",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 각 분할된 청크의 수 확인하기\n",
    "\n",
    "    ```markdown\n",
    "    분할된 parent_docs의 개수: 73\n",
    "    분할된 child_docs의 개수: 440\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26753596",
   "metadata": {},
   "source": [
    "* 벡터저장소에 새롭게 생성한 작게 쪼개진 하위문서 집합 추가하기\n",
    "\n",
    "* 다음: 상위 문서는 생성한 `UUID`와 맵핑하여 **`docstore`** 에 추가하기\n",
    "\n",
    "  * **`mset()`** 메서드 → 문서 `ID`, 문서 내용 = **`key-value`** 쌍으로 문서 저장소에 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc11b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 벡터 저장소에 parent + child 문서를 추가\n",
    "retriever.vectorstore.add_documents(parent_docs)\n",
    "retriever.vectorstore.add_documents(child_docs)\n",
    "\n",
    "# docstore 에 원본 문서를 저장\n",
    "retriever.docstore.mset(list(zip(doc_ids, docs)))                       # 22.3s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce8ee20",
   "metadata": {},
   "source": [
    "* 유사도 검색 수행하기\n",
    "\n",
    "  * 가장 유사도가 높은 첫 번째 문서 조각 출력하기\n",
    "\n",
    "  * **`retriever.vectorstore.similarity_search`** 메서드 → `child` + `parent` 문서 `chunk` 내에서 검색을 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc8dff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorstore의 유사도 검색 수행하기 \n",
    "relevant_chunks = retriever.vectorstore.similarity_search(\n",
    "    \"삼성전자가 만든 생성형 AI 의 이름은?\"\n",
    ")\n",
    "\n",
    "# 출력하기\n",
    "print(f\"검색된 문서의 개수: {len(relevant_chunks)}\")                        # 0.1s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a48cd7",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 검색된 문서의 개수: 4   *(`0.1s`)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64630154",
   "metadata": {},
   "outputs": [],
   "source": [
    "for chunk in relevant_chunks:\n",
    "    print(chunk.page_content, end=\"\\n\\n\")\n",
    "    print(\">\" * 100, end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3a5f65",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 셀 출력\n",
    "\n",
    "    ```markdown\n",
    "    ☞ 출처 : 삼성전자, ‘삼성 AI 포럼’서 자체 개발 생성형 AI ‘삼성 가우스’ 공개, 2023.11.08.\n",
    "    삼성전자, ‘삼성 개발자 콘퍼런스 코리아 2023’ 개최, 2023.11.14.\n",
    "    TechRepublic, Samsung Gauss: Samsung Research Reveals Generative AI, 2023.11.08.\n",
    "\n",
    "    >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "\n",
    "    SPRi AI Brief |  \n",
    "    2023-12월호\n",
    "    10\n",
    "    삼성전자, 자체 개발 생성 AI ‘삼성 가우스’ 공개\n",
    "    n 삼성전자가 온디바이스에서 작동 가능하며 언어, 코드, 이미지의 3개 모델로 구성된 자체 개발 생성 \n",
    "    AI 모델 ‘삼성 가우스’를 공개\n",
    "    n 삼성전자는 삼성 가우스를 다양한 제품에 단계적으로 탑재할 계획으로, 온디바이스 작동이 가능한\n",
    "\n",
    "    >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "\n",
    "    SPRi AI Brief |  \n",
    "    2023-12월호\n",
    "    10\n",
    "    삼성전자, 자체 개발 생성 AI ‘삼성 가우스’ 공개\n",
    "    n 삼성전자가 온디바이스에서 작동 가능하며 언어, 코드, 이미지의 3개 모델로 구성된 자체 개발 생성 \n",
    "    AI 모델 ‘삼성 가우스’를 공개\n",
    "    n 삼성전자는 삼성 가우스를 다양한 제품에 단계적으로 탑재할 계획으로, 온디바이스 작동이 가능한 \n",
    "    삼성 가우스는 외부로 사용자 정보가 유출될 위험이 없다는 장점을 보유\n",
    "    KEY Contents\n",
    "    £ 언어, 코드, 이미지의 3개 모델로 구성된 삼성 가우스, 온디바이스 작동 지원\n",
    "    n 삼성전자가 2023년 11월 8일 열린 ‘삼성 AI 포럼 2023’ 행사에서 자체 개발한 생성 AI 모델 \n",
    "    ‘삼성 가우스’를 최초 공개\n",
    "    ∙정규분포 이론을 정립한 천재 수학자 가우스(Gauss)의 이름을 본뜬 삼성 가우스는 다양한 상황에 \n",
    "    최적화된 크기의 모델 선택이 가능\n",
    "    ∙삼성 가우스는 라이선스나 개인정보를 침해하지 않는 안전한 데이터를 통해 학습되었으며, \n",
    "    온디바이스에서 작동하도록 설계되어 외부로 사용자의 정보가 유출되지 않는 장점을 보유\n",
    "    ∙삼성전자는 삼성 가우스를 활용한 온디바이스 AI 기술도 소개했으며, 생성 AI 모델을 다양한 제품에\n",
    "\n",
    "    >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "\n",
    "    온디바이스에서 작동하도록 설계되어 외부로 사용자의 정보가 유출되지 않는 장점을 보유\n",
    "    ∙삼성전자는 삼성 가우스를 활용한 온디바이스 AI 기술도 소개했으며, 생성 AI 모델을 다양한 제품에 \n",
    "    단계적으로 탑재할 계획\n",
    "    n 삼성 가우스는 △텍스트를 생성하는 언어모델 △코드를 생성하는 코드 모델 △이미지를 생성하는 \n",
    "    이미지 모델의 3개 모델로 구성\n",
    "\n",
    "    >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eed9954",
   "metadata": {},
   "source": [
    "* **`retriever.invoke()`** 메서드 → 쿼리 실행 (원본 문서의 전체 내용 검색함)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678bb27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_docs = retriever.invoke(\"삼성전자가 만든 생성형 AI 의 이름은?\")\n",
    "\n",
    "print(f\"검색된 문서의 개수: {len(relevant_docs)}\", end=\"\\n\\n\")\n",
    "print(\"=\" * 100, end=\"\\n\\n\")\n",
    "print(relevant_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8bed49",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 셀 출력\n",
    "\n",
    "    ```markdown\n",
    "    검색된 문서의 개수: 1\n",
    "\n",
    "    ====================================================================================================\n",
    "\n",
    "    SPRi AI Brief |  \n",
    "    2023-12월호\n",
    "    10\n",
    "    삼성전자, 자체 개발 생성 AI ‘삼성 가우스’ 공개\n",
    "    n 삼성전자가 온디바이스에서 작동 가능하며 언어, 코드, 이미지의 3개 모델로 구성된 자체 개발 생성 \n",
    "    AI 모델 ‘삼성 가우스’를 공개\n",
    "    n 삼성전자는 삼성 가우스를 다양한 제품에 단계적으로 탑재할 계획으로, 온디바이스 작동이 가능한 \n",
    "    삼성 가우스는 외부로 사용자 정보가 유출될 위험이 없다는 장점을 보유\n",
    "    KEY Contents\n",
    "    £ 언어, 코드, 이미지의 3개 모델로 구성된 삼성 가우스, 온디바이스 작동 지원\n",
    "    n 삼성전자가 2023년 11월 8일 열린 ‘삼성 AI 포럼 2023’ 행사에서 자체 개발한 생성 AI 모델 \n",
    "    ‘삼성 가우스’를 최초 공개\n",
    "    ∙정규분포 이론을 정립한 천재 수학자 가우스(Gauss)의 이름을 본뜬 삼성 가우스는 다양한 상황에 \n",
    "    최적화된 크기의 모델 선택이 가능\n",
    "    ∙삼성 가우스는 라이선스나 개인정보를 침해하지 않는 안전한 데이터를 통해 학습되었으며, \n",
    "    온디바이스에서 작동하도록 설계되어 외부로 사용자의 정보가 유출되지 않는 장점을 보유\n",
    "    ∙삼성전자는 삼성 가우스를 활용한 온디바이스 AI 기술도 소개했으며, 생성 AI 모델을 다양한 제품에 \n",
    "    단계적으로 탑재할 계획\n",
    "    n 삼성 가우스는 △텍스트를 생성하는 언어모델 △코드를 생성하는 코드 모델 △이미지를 생성하는 \n",
    "    이미지 모델의 3개 모델로 구성\n",
    "    ∙언어 모델은 클라우드와 온디바이스 대상 다양한 모델로 구성되며, 메일 작성, 문서 요약, 번역 업무의 \n",
    "    처리를 지원\n",
    "    ∙코드 모델 기반의 AI 코딩 어시스턴트 ‘코드아이(code.i)’는 대화형 인터페이스로 서비스를 제공하며 \n",
    "    사내 소프트웨어 개발에 최적화\n",
    "    ∙이미지 모델은 창의적인 이미지를 생성하고 기존 이미지를 원하는 대로 바꿀 수 있도록 지원하며 \n",
    "    저해상도 이미지의 고해상도 전환도 지원\n",
    "    n IT 전문지 테크리퍼블릭(TechRepublic)은 온디바이스 AI가 주요 기술 트렌드로 부상했다며, \n",
    "    2024년부터 가우스를 탑재한 삼성 스마트폰이 메타의 라마(Llama)2를 탑재한 퀄컴 기기 및 구글 \n",
    "    어시스턴트를 적용한 구글 픽셀(Pixel)과 경쟁할 것으로 예상\n",
    "    ☞ 출처 : 삼성전자, ‘삼성 AI 포럼’서 자체 개발 생성형 AI ‘삼성 가우스’ 공개, 2023.11.08.\n",
    "    삼성전자, ‘삼성 개발자 콘퍼런스 코리아 2023’ 개최, 2023.11.14.\n",
    "    TechRepublic, Samsung Gauss: Samsung Research Reveals Generative AI, 2023.11.08.\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa1e141",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5077ccd2",
   "metadata": {},
   "source": [
    "* [**`MMR`**](https://api.python.langchain.com/en/latest/vectorstores/langchain_core.vectorstores.VectorStore.html#langchain_core.vectorstores.VectorStore.max_marginal_relevance_search) 지원\n",
    "\n",
    "  * `retriever`가 벡터 데이터베이스에서 기본적으로 수행하는 검색 유형: *`유사도 검색`*\n",
    "\n",
    "  * `LangChain Vector Store`: **`MMR`** (`Max Marginal Relevance`) 검색도 지원 → **`search_type`** 속성 설정\n",
    "\n",
    "    * `retriever` 객체의 `search_type` 속성 = **`SearchType.mmr`** 로 설정하기\n",
    "    * 검색 시 `MMR` (`Maximal Marginal Relevance`) 알고리즘 사용하도록 지정하는 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23428410",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers.multi_vector import SearchType\n",
    "\n",
    "# 검색 유형을 MMR(Maximal Marginal Relevance)로 설정하기\n",
    "retriever.search_type = SearchType.mmr\n",
    "\n",
    "# 관련 문서 전체 검색하기\n",
    "print(retriever.invoke(\"삼성전자가 만든 생성형 AI 의 이름은?\")[0].page_content)             # 0.1s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af8c86b",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* `MMR`로 검색해보기 (0.1s)\n",
    "\n",
    "    ```markdown\n",
    "    SPRi AI Brief |  \n",
    "    2023-12월호\n",
    "    10\n",
    "    삼성전자, 자체 개발 생성 AI ‘삼성 가우스’ 공개\n",
    "    n 삼성전자가 온디바이스에서 작동 가능하며 언어, 코드, 이미지의 3개 모델로 구성된 자체 개발 생성 \n",
    "    AI 모델 ‘삼성 가우스’를 공개\n",
    "    n 삼성전자는 삼성 가우스를 다양한 제품에 단계적으로 탑재할 계획으로, 온디바이스 작동이 가능한 \n",
    "    삼성 가우스는 외부로 사용자 정보가 유출될 위험이 없다는 장점을 보유\n",
    "    KEY Contents\n",
    "    £ 언어, 코드, 이미지의 3개 모델로 구성된 삼성 가우스, 온디바이스 작동 지원\n",
    "    n 삼성전자가 2023년 11월 8일 열린 ‘삼성 AI 포럼 2023’ 행사에서 자체 개발한 생성 AI 모델 \n",
    "    ‘삼성 가우스’를 최초 공개\n",
    "    ∙정규분포 이론을 정립한 천재 수학자 가우스(Gauss)의 이름을 본뜬 삼성 가우스는 다양한 상황에 \n",
    "    최적화된 크기의 모델 선택이 가능\n",
    "    ∙삼성 가우스는 라이선스나 개인정보를 침해하지 않는 안전한 데이터를 통해 학습되었으며, \n",
    "    온디바이스에서 작동하도록 설계되어 외부로 사용자의 정보가 유출되지 않는 장점을 보유\n",
    "    ∙삼성전자는 삼성 가우스를 활용한 온디바이스 AI 기술도 소개했으며, 생성 AI 모델을 다양한 제품에 \n",
    "    단계적으로 탑재할 계획\n",
    "    n 삼성 가우스는 △텍스트를 생성하는 언어모델 △코드를 생성하는 코드 모델 △이미지를 생성하는 \n",
    "    이미지 모델의 3개 모델로 구성\n",
    "    ∙언어 모델은 클라우드와 온디바이스 대상 다양한 모델로 구성되며, 메일 작성, 문서 요약, 번역 업무의 \n",
    "    처리를 지원\n",
    "    ∙코드 모델 기반의 AI 코딩 어시스턴트 ‘코드아이(code.i)’는 대화형 인터페이스로 서비스를 제공하며 \n",
    "    사내 소프트웨어 개발에 최적화\n",
    "    ∙이미지 모델은 창의적인 이미지를 생성하고 기존 이미지를 원하는 대로 바꿀 수 있도록 지원하며 \n",
    "    저해상도 이미지의 고해상도 전환도 지원\n",
    "    n IT 전문지 테크리퍼블릭(TechRepublic)은 온디바이스 AI가 주요 기술 트렌드로 부상했다며, \n",
    "    2024년부터 가우스를 탑재한 삼성 스마트폰이 메타의 라마(Llama)2를 탑재한 퀄컴 기기 및 구글 \n",
    "    어시스턴트를 적용한 구글 픽셀(Pixel)과 경쟁할 것으로 예상\n",
    "    ☞ 출처 : 삼성전자, ‘삼성 AI 포럼’서 자체 개발 생성형 AI ‘삼성 가우스’ 공개, 2023.11.08.\n",
    "    삼성전자, ‘삼성 개발자 콘퍼런스 코리아 2023’ 개최, 2023.11.14.\n",
    "    TechRepublic, Samsung Gauss: Samsung Research Reveals Generative AI, 2023.11.08.\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49490966",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers.multi_vector import SearchType\n",
    "\n",
    "# 검색 유형을 similarity_score_threshold로 설정\n",
    "retriever.search_type = SearchType.similarity_score_threshold\n",
    "retriever.search_kwargs = {\"score_threshold\": 0.3}\n",
    "\n",
    "# 관련 문서 전체를 검색\n",
    "print(retriever.invoke(\"삼성전자가 만든 생성형 AI 의 이름은?\")[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001489c4",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* `similarity_score_threshold = 0.3`으로 설정\n",
    "\n",
    "    ```markdown\n",
    "    SPRi AI Brief |  \n",
    "    2023-12월호\n",
    "    10\n",
    "    삼성전자, 자체 개발 생성 AI ‘삼성 가우스’ 공개\n",
    "    n 삼성전자가 온디바이스에서 작동 가능하며 언어, 코드, 이미지의 3개 모델로 구성된 자체 개발 생성 \n",
    "    AI 모델 ‘삼성 가우스’를 공개\n",
    "    n 삼성전자는 삼성 가우스를 다양한 제품에 단계적으로 탑재할 계획으로, 온디바이스 작동이 가능한 \n",
    "    삼성 가우스는 외부로 사용자 정보가 유출될 위험이 없다는 장점을 보유\n",
    "    KEY Contents\n",
    "    £ 언어, 코드, 이미지의 3개 모델로 구성된 삼성 가우스, 온디바이스 작동 지원\n",
    "    n 삼성전자가 2023년 11월 8일 열린 ‘삼성 AI 포럼 2023’ 행사에서 자체 개발한 생성 AI 모델 \n",
    "    ‘삼성 가우스’를 최초 공개\n",
    "    ∙정규분포 이론을 정립한 천재 수학자 가우스(Gauss)의 이름을 본뜬 삼성 가우스는 다양한 상황에 \n",
    "    최적화된 크기의 모델 선택이 가능\n",
    "    ∙삼성 가우스는 라이선스나 개인정보를 침해하지 않는 안전한 데이터를 통해 학습되었으며, \n",
    "    온디바이스에서 작동하도록 설계되어 외부로 사용자의 정보가 유출되지 않는 장점을 보유\n",
    "    ∙삼성전자는 삼성 가우스를 활용한 온디바이스 AI 기술도 소개했으며, 생성 AI 모델을 다양한 제품에 \n",
    "    단계적으로 탑재할 계획\n",
    "    n 삼성 가우스는 △텍스트를 생성하는 언어모델 △코드를 생성하는 코드 모델 △이미지를 생성하는 \n",
    "    이미지 모델의 3개 모델로 구성\n",
    "    ∙언어 모델은 클라우드와 온디바이스 대상 다양한 모델로 구성되며, 메일 작성, 문서 요약, 번역 업무의 \n",
    "    처리를 지원\n",
    "    ∙코드 모델 기반의 AI 코딩 어시스턴트 ‘코드아이(code.i)’는 대화형 인터페이스로 서비스를 제공하며 \n",
    "    사내 소프트웨어 개발에 최적화\n",
    "    ∙이미지 모델은 창의적인 이미지를 생성하고 기존 이미지를 원하는 대로 바꿀 수 있도록 지원하며 \n",
    "    저해상도 이미지의 고해상도 전환도 지원\n",
    "    n IT 전문지 테크리퍼블릭(TechRepublic)은 온디바이스 AI가 주요 기술 트렌드로 부상했다며, \n",
    "    2024년부터 가우스를 탑재한 삼성 스마트폰이 메타의 라마(Llama)2를 탑재한 퀄컴 기기 및 구글 \n",
    "    어시스턴트를 적용한 구글 픽셀(Pixel)과 경쟁할 것으로 예상\n",
    "    ☞ 출처 : 삼성전자, ‘삼성 AI 포럼’서 자체 개발 생성형 AI ‘삼성 가우스’ 공개, 2023.11.08.\n",
    "    삼성전자, ‘삼성 개발자 콘퍼런스 코리아 2023’ 개최, 2023.11.14.\n",
    "    TechRepublic, Samsung Gauss: Samsung Research Reveals Generative AI, 2023.11.08.\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133c5bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers.multi_vector import SearchType\n",
    "\n",
    "# 검색 유형을 similarity로 설정, k값을 1로 설정\n",
    "retriever.search_type = SearchType.similarity\n",
    "retriever.search_kwargs = {\"k\": 1}\n",
    "\n",
    "# 관련 문서 전체 검색하기\n",
    "print(len(retriever.invoke(\"삼성전자가 만든 생성형 AI 의 이름은?\")))                # 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d07f03",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15523440",
   "metadata": {},
   "source": [
    "#### **5) `요약본 (summary)을 벡터저장소에 저장`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba6ebc1",
   "metadata": {},
   "source": [
    "* 요약의 이점\n",
    "\n",
    "  * 종종 `chunk`의 내용을 `보다 정확하게 추출` 가능 → 더 나은 검색 결과를 얻을 수 있음\n",
    "\n",
    "  * 요약을 생성하는 방법, 임베딩하는 방법 알아보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663e2d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDF 파일을 로드하고 텍스트를 분할하기 위한 라이브러리 임포트\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# PDF 파일 로더 초기화\n",
    "loader = PyMuPDFLoader(\"../10_Retriever/data/SPRI_AI_Brief_2023년12월호_F.pdf\")\n",
    "\n",
    "# 텍스트 분할\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=600, chunk_overlap=50)\n",
    "\n",
    "# PDF 파일 로드 및 텍스트 분할 실행\n",
    "split_docs = loader.load_and_split(text_splitter)\n",
    "\n",
    "# 분할된 문서의 개수 출력\n",
    "print(f\"분할된 문서의 개수: {len(split_docs)}\")                                 # 0.1s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58531e9",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 분할된 문서의 개수: 61"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17135eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_ollama import OllamaLLM\n",
    "\n",
    "llm_lama2 = OllamaLLM(temperature=0, model=\"exaone3.5:7.8b\")\n",
    "\n",
    "summary_chain = (\n",
    "    {\"doc\": lambda x: x.page_content}\n",
    "    # 문서 요약을 위한 프롬프트 템플릿 생성\n",
    "    | ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", \"You are an expert in summarizing documents in Korean.\"),\n",
    "            (\n",
    "                \"user\",\n",
    "                \"Summarize the following documents in 3 sentences in bullet points format.\\n\\n{doc}\",\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "    # Ollama 한국어 모델을 사용하여 요약 생성\n",
    "    | llm_lama2\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4651d2f3",
   "metadata": {},
   "source": [
    "* **`chain.batch`** 메서드 사용 → **`docs`** 리스트의 문서들을 일괄 요약"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94985469",
   "metadata": {},
   "source": [
    "* 교재 내용: \n",
    "\n",
    "  * **`max_concurrency` = `10`** → 최대 10개의 문서를 동시에 처리할 수 있도록 설정\n",
    "```python\n",
    "\n",
    "        # 문서 배치 처리\n",
    "        summaries = summary_chain.batch(split_docs, {\"max_concurrency\": 10})\n",
    "        # Ollama server에 문서 10개를 동시에(병렬로) 처리해달라는 요청\n",
    "        # m1의 CPU, GPU, RAM 등의 메모리 자원을 동원해 최대한 동시에 처리하려고 함\n",
    "\n",
    "```\n",
    "\n",
    "* * 30분이 넘도록 완료되지 않음 → 강제 종료\n",
    "\n",
    "<br>\n",
    "\n",
    "* **`배치 처리와 동시성`** (`max_concurrency`)\n",
    "  * **`max_concurrency`** 조절하기 → **`1`** 로 조절해서 진행해보고, **`시간 체크해보기`** 로 결정\n",
    "\n",
    "  | 설정      | 장점                        | 단점                                                | 예상 결과 (M1, 7.8B 모델)               |\n",
    "  |---------|---------------------------|---------------------------------------------------|-----------------------------------|\n",
    "  | 10 (현재) | 이론상 가장 빠름                 | 과도한 자원 경합으로 인해 오히려 비효율적이고 불안정함.                   | 23분 이상 소요 및 지연 발생 (현재 경험 중)       |\n",
    "  | 5 (제안)  | 10보다는 자원 경합이 덜함           | 여전히 자원 경합이 발생하여, 1개씩 처리할 때보다 총 시간이 더 길어질 가능성이 높음. | 10보다는 빠르겠지만, 최적의 순차 처리보다 느릴 수 있음. |\n",
    "  | 1 (권장)  | 가장 안정적이고 효율적이며 자원 경합이 없음. | 이론상 병렬 처리의 이점을 포기함.                               | 가장 예측 가능한 속도 (예: 20분 내외)로 완료 가능.  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c12d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "OPTIMIZED_CONCURRENCY = 1 \n",
    "print(f\"Ollama 모델 로드 중: exaone3.5:7.8b (최적 동시성: {OPTIMIZED_CONCURRENCY})\")\n",
    "\n",
    "# 배치 처리 실행 (최적화 적용)\n",
    "start_time = time.time()\n",
    "print(\"\\n▶️ 요약 배치 처리를 시작합니다...\")\n",
    "\n",
    "# max_concurrency=1로 설정하여 M1 Mac의 자원 과부하를 막고 효율적인 순차 처리를 유도하기\n",
    "summaries = summary_chain.batch(split_docs, {\"max_concurrency\": OPTIMIZED_CONCURRENCY})    \n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c86d39d",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 배치 처리 시작 *(`34m 6.1s`)*\n",
    "\n",
    "    ```markdown\n",
    "    Ollama 모델 로드 중: exaone3.5:7.8b (최적 동시성: 1)\n",
    "\n",
    "    ▶️ 요약 배치 처리를 시작합니다...\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787c7b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 출력\n",
    "print(\"\\n--- 결과 ---\")\n",
    "print(f\"✅ 요약 작업이 완료되었습니다!\")\n",
    "print(f\"요약된 문서 개수는: {len(summaries)}개입니다.\")\n",
    "print(f\"총 소요 시간: {elapsed_time:.2f}초 ({elapsed_time / 60:.2f}분)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00cd4684",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 셀 출력\n",
    "\n",
    "    ```markdown\n",
    "    --- 결과 ---\n",
    "    ✅ 요약 작업이 완료되었습니다!\n",
    "    요약된 문서 개수는: 61개입니다.\n",
    "    총 소요 시간: 2046.19초 (34.10분)\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b301b498",
   "metadata": {},
   "source": [
    "* 요약된 내용 출력 → 결과 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e42766b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원본 문서의 내용 출력하기\n",
    "print(split_docs[33].page_content, end=\"\\n\\n\")\n",
    "\n",
    "\n",
    "# 요약 출력하기\n",
    "print(\"[요약]\")\n",
    "print(summaries[33])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b4ad9f",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 결과 출력해보기\n",
    "\n",
    "    ```markdown\n",
    "    SPRi AI Brief |  \n",
    "    2023-12월호\n",
    "    10\n",
    "    삼성전자, 자체 개발 생성 AI ‘삼성 가우스’ 공개\n",
    "    n 삼성전자가 온디바이스에서 작동 가능하며 언어, 코드, 이미지의 3개 모델로 구성된 자체 개발 생성 \n",
    "    AI 모델 ‘삼성 가우스’를 공개\n",
    "    n 삼성전자는 삼성 가우스를 다양한 제품에 단계적으로 탑재할 계획으로, 온디바이스 작동이 가능한 \n",
    "    삼성 가우스는 외부로 사용자 정보가 유출될 위험이 없다는 장점을 보유\n",
    "    KEY Contents\n",
    "    £ 언어, 코드, 이미지의 3개 모델로 구성된 삼성 가우스, 온디바이스 작동 지원\n",
    "    n 삼성전자가 2023년 11월 8일 열린 ‘삼성 AI 포럼 2023’ 행사에서 자체 개발한 생성 AI 모델 \n",
    "    ‘삼성 가우스’를 최초 공개\n",
    "    ∙정규분포 이론을 정립한 천재 수학자 가우스(Gauss)의 이름을 본뜬 삼성 가우스는 다양한 상황에 \n",
    "    최적화된 크기의 모델 선택이 가능\n",
    "    ∙삼성 가우스는 라이선스나 개인정보를 침해하지 않는 안전한 데이터를 통해 학습되었으며, \n",
    "    온디바이스에서 작동하도록 설계되어 외부로 사용자의 정보가 유출되지 않는 장점을 보유\n",
    "    ∙삼성전자는 삼성 가우스를 활용한 온디바이스 AI 기술도 소개했으며, 생성 AI 모델을 다양한 제품에\n",
    "\n",
    "    [요약]\n",
    "    - **삼성전자**는 **'삼성 가우스'**라는 자체 개발 생성 AI 모델을 공개, 언어, 코드, 이미지 세 가지 분야를 아우르는 온디바이스 작동형 모델로 구성됨.\n",
    "    - **삼성 가우스**는 2023년 11월 '삼성 AI 포럼 2023'에서 처음 공개되었으며, 가우스의 이름을 따서 다양한 상황에 최적화된 크기의 모델 선택이 가능하도록 설계됨.\n",
    "    - 이 모델은 사용자 정보 유출 위험 없이 안전하게 학습되었으며, 삼성전자는 이를 통해 다양한 제품에 단계적으로 적용할 계획임.\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292227ac",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382dcc19",
   "metadata": {},
   "source": [
    "* **`Chroma`** 벡터 저장소 초기화 → 자식 청크(`child chunks`) 인덱싱 = 이 때 **`임베딩 함수`** 사용하기\n",
    "\n",
    "  * 문서 `ID`를 나타내는 키 = **`doc_id`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13447d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "# 요약 정보를 저장할 벡터 저장소 생성하기\n",
    "summary_vectorstore = Chroma(\n",
    "    collection_name=\"summaries\",\n",
    "    embedding_function=multilingual_embeddings,\n",
    ")\n",
    "\n",
    "# 부모 문서를 저장할 저장소 생성하기\n",
    "store = InMemoryStore()\n",
    "\n",
    "# 문서 ID를 저장할 키 이름 지정하기\n",
    "id_key = \"doc_id\"\n",
    "\n",
    "# 검색기 초기화하기 \n",
    "retriever = MultiVectorRetriever(               # 시작 시 비어 있음\n",
    "    vectorstore=summary_vectorstore,            # 벡터 저장소\n",
    "    byte_store=store,                           # 바이트 저장소\n",
    "    id_key=id_key,                              # 문서 ID 키\n",
    ")\n",
    "\n",
    "# 문서 ID 생성하기\n",
    "doc_ids = [str(uuid.uuid4()) for _ in split_docs]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1434c0",
   "metadata": {},
   "source": [
    "* 요약된 문서, 메타데이터 *(여기에서는 생성한 요약본에 대한 `Document ID`)* 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ea6ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_docs = [\n",
    "    # Document 객체 생성하기\n",
    "    Document(page_content=s, metadata={id_key: doc_ids[i]})         # 요약된 내용=페이지 콘텐츠, 문서 ID=메타데이터\n",
    "    for i, s in enumerate(summaries)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb23a61",
   "metadata": {},
   "source": [
    "* 일치해야 함: **`요약본의 문서의 개수` = `원본 문서의 개수`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 요약본의 문서의 개수\n",
    "len(summary_docs)                                                   # 61"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9778ed9f",
   "metadata": {},
   "source": [
    "* **`retriever.vectorstore.add_documents(summary_docs)`** → **`summary_docs`** = 벡터 저장소에 추가\n",
    "\n",
    "* **`retirever.docstore.mset(list(zip(doc_ids, docs)))`** → **`doc_ids`**, **`docs`** 매핑 → 문서 저장소에 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 요약된 문서를 벡터 저장소에 추가하기\n",
    "retriever.vectorstore.add_documents(\n",
    "    summary_docs\n",
    ")\n",
    "\n",
    "# 문서 ID와 문서를 매핑하여 문서 저장소에 저장하기\n",
    "retriever.docstore.mset(list(zip(doc_ids, split_docs)))             # 3.8s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4772a4d",
   "metadata": {},
   "source": [
    "* **`vectorstor`** 객체의 **`similarity_search`** 메서드 → 유사도 검색 수행하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 유사도 검색 수행하기\n",
    "\n",
    "result_docs = summary_vectorstore.similarity_search(\n",
    "    \"삼성전자가 만든 생성형 AI 의 이름은?\"\n",
    ")                                                                   # 0.1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1개의 결과 문서 출력해보기\n",
    "print(result_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e5b3b1",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 1개의 결과를 문서로 출력해보기\n",
    "\n",
    "    ```markdown\n",
    "    - **삼성전자**는 **'삼성 가우스'**라는 자체 개발 생성 AI 모델을 공개, 언어, 코드, 이미지 세 가지 분야를 아우르는 온디바이스 작동형 모델로 구성됨.\n",
    "    - **삼성 가우스**는 2023년 11월 '삼성 AI 포럼 2023'에서 처음 공개되었으며, 가우스의 이름을 따서 다양한 상황에 최적화된 크기의 모델 선택이 가능하도록 설계됨.\n",
    "    - 이 모델은 사용자 정보 유출 위험 없이 안전하게 학습되었으며, 삼성전자는 이를 통해 다양한 제품에 단계적으로 적용할 계획임.\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da7a016",
   "metadata": {},
   "source": [
    "* **`retriever`** 객체의 **`invoke()`** → 질문과 관련된 문서 검색하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 관련된 문서를 검색하여 가져오기\n",
    "retrieved_docs = retriever.invoke(\"삼성전자가 만든 생성형 AI 의 이름은?\")\n",
    "print(retrieved_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d69925",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 관련된 문서 검색해서 가져오기\n",
    "\n",
    "    ```markdown\n",
    "    SPRi AI Brief |  \n",
    "    2023-12월호\n",
    "    10\n",
    "    삼성전자, 자체 개발 생성 AI ‘삼성 가우스’ 공개\n",
    "    n 삼성전자가 온디바이스에서 작동 가능하며 언어, 코드, 이미지의 3개 모델로 구성된 자체 개발 생성 \n",
    "    AI 모델 ‘삼성 가우스’를 공개\n",
    "    n 삼성전자는 삼성 가우스를 다양한 제품에 단계적으로 탑재할 계획으로, 온디바이스 작동이 가능한 \n",
    "    삼성 가우스는 외부로 사용자 정보가 유출될 위험이 없다는 장점을 보유\n",
    "    KEY Contents\n",
    "    £ 언어, 코드, 이미지의 3개 모델로 구성된 삼성 가우스, 온디바이스 작동 지원\n",
    "    n 삼성전자가 2023년 11월 8일 열린 ‘삼성 AI 포럼 2023’ 행사에서 자체 개발한 생성 AI 모델 \n",
    "    ‘삼성 가우스’를 최초 공개\n",
    "    ∙정규분포 이론을 정립한 천재 수학자 가우스(Gauss)의 이름을 본뜬 삼성 가우스는 다양한 상황에 \n",
    "    최적화된 크기의 모델 선택이 가능\n",
    "    ∙삼성 가우스는 라이선스나 개인정보를 침해하지 않는 안전한 데이터를 통해 학습되었으며, \n",
    "    온디바이스에서 작동하도록 설계되어 외부로 사용자의 정보가 유출되지 않는 장점을 보유\n",
    "    ∙삼성전자는 삼성 가우스를 활용한 온디바이스 AI 기술도 소개했으며, 생성 AI 모델을 다양한 제품에\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ea2056",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240778d8",
   "metadata": {},
   "source": [
    "#### **6) `가설 쿼리 (Hypothetical Queries)를 활용해 문서 내용 탐색`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a544fd",
   "metadata": {},
   "source": [
    "* **`LLM`** = **`특정 문서에 대해 가정할 수 있는 질문 목록 생성하는데 사용 가능`**\n",
    "\n",
    "  * 생성된 가설 질문 = **`embedding`** → 문서의 내용을 더욱 깊이 있게 탐색, 이해 가능\n",
    "    * 문서의 주요 주게와 개념을 파악하는데 도움\n",
    "    * 독자들이 뭇너 내용에 대해 더 많은 궁금증을 갖도록 유도 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f783ae",
   "metadata": {},
   "source": [
    "* 교재 내용\n",
    "\n",
    "  * **`Function Calling`** → 가설 질문 생성하는 예제\n",
    "\n",
    "  * **`ChatPromptTemplate`** → 주어진 문서를 기반으로 **`3개의 가상 질문을 생성하는 프롬프트 템플릿을 정의`**\n",
    "\n",
    "    * **`function`**, **`function_call`** → 가상 질문 생성 함수 호출\n",
    "\n",
    "    * **`JsonKeyOutputFunctionParser`** → 생성된 가상 질문 `파싱` → **`questions`** `key`에 해당하는 값 추출"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3c03ac",
   "metadata": {},
   "source": [
    "* **`OllamaLLM()`** \n",
    "  * **`기본 LLM` (`Legacy LLM`)** 클래스\n",
    "  * 단순한 `text-in`, `text-out` 응답을 처리\n",
    "\n",
    "* **`function`** 인수의 역할 \n",
    "  * **`funcions`**, **`funcion_call`** 인수\n",
    "  * = 원래 **`OpenAI`** 의 `Chat Model`과  같이 함수 호출을 명시적으로 지원하는 모델에 전달되어야 함\n",
    "  * = 즉, **`ChatOpenAI`** 모델에 전달되어야 함\n",
    "\n",
    "* **`문제점`**\n",
    "  * **`OllamaLLM`** = 내부적으로 **`ollama.Client().generate()`** 메서드 호출 **`≠` `functions`, `function_call`**\n",
    "  * 함수 호출과 유사한 `JSON` 출력을 얻기 위해서는 `Ollama` **`X`** → **`ChatOllama`** 사용, **`with_structued_output`** 메서드 사용\n",
    "  * **`Pydantic`** 모델 사용: 원하는 출력 형식을 `명시적으로 정의`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3955c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 필요한 라이브러리 임포트 및 Pydantic 모델 정의\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_ollama import ChatOllama                                 # OllamaLLM 대신 ChatOllama 사용\n",
    "# JsonKeyOutputFunctionsParser는 더 이상 필요하지 않음\n",
    "\n",
    "# 2. 원하는 출력 구조를 정의하는 Pydantic 모델\n",
    "class HypotheticalQuestions(BaseModel):\n",
    "    \"\"\"Generate hypothetical questions based on the document content.\"\"\"\n",
    "    questions: list[str] = Field(\n",
    "        description=\"A list of exactly 3 hypothetical questions that the document could answer, written in Korean.\"\n",
    "    )\n",
    "\n",
    "# 3. ChatOllama 모델 초기화\n",
    "# ChatOllama는 구조화된 출력을 더 잘 지원함\n",
    "llm_chat = ChatOllama(model=\"exaone3.5:7.8b\", temperature=0)            # max_retries는 ChatOllama의 인수 X → 제거\n",
    "\n",
    "# 4. 구조화된 출력을 위한 체인 생성\n",
    "hypothetical_query_chain = (\n",
    "    {\"doc\": lambda x: x.page_content}\n",
    "    \n",
    "    # 아래 문서를 사용하여 답변할 수 있는 가상의 질문을 정확히 3개 생성하도록 요청하는 프롬프트\n",
    "    | ChatPromptTemplate.from_template(\n",
    "        \"Generate a list of exactly 3 hypothetical questions that the below document could be used to answer. \"\n",
    "        \"Potential users are those interested in the AI industry. Create questions that they would be interested in. \"\n",
    "        \"Output should be written in Korean:\\n\\n{doc}\"\n",
    "    )\n",
    "\n",
    "    # 5. with_structured_output을 사용하여 출력 형식을 Pydantic 모델로 강제하기\n",
    "    # 'functions' 및 'JsonKeyOutputFunctionsParser' 대체\n",
    "    | llm_chat.with_structured_output(HypotheticalQuestions)    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1371114",
   "metadata": {},
   "source": [
    "* 문서에 대한 답변 출력하기\n",
    "\n",
    "  * 출력 = 생성한 `3개의 가설 쿼리(Hypothetical Queries)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882b8cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 주어진 문서에 대해 체인 실행하기\n",
    "try:\n",
    "    # split_docs[33]이 Document 객체이므로 .page_content 접근 대신 통째로 invoke에 전달하여\n",
    "    # {\"doc\": ...} 형식으로 매핑되도록 합니다.\n",
    "    result = hypothetical_query_chain.invoke(split_docs[33])\n",
    "    print(\"✅ 가상 질문 생성 성공:\")\n",
    "    print(result.questions)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"❌ 오류 발생: {e}\")\n",
    "    print(\"Ollama 서버가 실행 중인지 확인하고, 모델을 다운로드했는지 확인하세요.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f05d39",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 생성한 3개의 가설 쿼리 출력하기 *(`35.6s`)*\n",
    "\n",
    "    ```markdown\n",
    "    ✅ 가상 질문 생성 성공:\n",
    "    [\"삼성전자의 '삼성 가우스'가 온디바이스 환경에서 어떻게 사용자 데이터 보안을 강화하고 있는지 구체적으로 설명해 주실 수 있나요?\", '삼성 가우스의 세 가지 모델(언어, 코드, 이미지)이 각각 어떤 산업 분야에서 가장 효과적으로 활용될 수 있을까요?', '향후 삼성전자가 삼성 가우스를 기반으로 어떤 혁신적인 제품이나 서비스를 출시할 것으로 예상하시나요?']\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b8307b",
   "metadata": {},
   "source": [
    "* **`chain.batch()`** → **`split_docs`** 데이터에 대해서 동시에 여러 개의 요청 처리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562b9559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문서 목록에 대한 가설 질문에 대한 배치 생성해보기 \n",
    "\n",
    "import time\n",
    "\n",
    "OPTIMIZED_CONCURRENCY = 1 \n",
    "print(f\"Ollama 모델 로드 중: exaone3.5:7.8b (최적 동시성: {OPTIMIZED_CONCURRENCY})\")\n",
    "\n",
    "# 배치 처리 실행 (최적화 적용)\n",
    "start_time = time.time()\n",
    "print(\"\\n▶️ 요약 배치 처리를 시작합니다...\")\n",
    "\n",
    "# max_concurrency=1로 설정하여 M1 Mac의 자원 과부하를 막고 효율적인 순차 처리를 유도하기\n",
    "hypothetical_questions = hypothetical_query_chain.batch(\n",
    "    split_docs, {\"max_concurrency\": 10}\n",
    ")  \n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "# 결과 출력\n",
    "print(\"\\n--- 결과 ---\")\n",
    "print(f\"✅ 요약 작업이 완료되었습니다!\")\n",
    "print(f\"요약된 문서 개수는: {len(hypothetical_questions)}개입니다.\")\n",
    "print(f\"총 소요 시간: {elapsed_time:.2f}초 ({elapsed_time / 60:.2f}분)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed91abbb",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 가설 쿼리 벡터 저장소 저장하기 *(`30m 0.6s`)*\n",
    "\n",
    "    ```markdown\n",
    "    Ollama 모델 로드 중: exaone3.5:7.8b (최적 동시성: 1)\n",
    "\n",
    "    ▶️ 요약 배치 처리를 시작합니다...\n",
    "\n",
    "    --- 결과 ---\n",
    "    ✅ 요약 작업이 완료되었습니다!\n",
    "    요약된 문서 개수는: 61개입니다.\n",
    "    총 소요 시간: 1800.63초 (30.01분)\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0f78ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothetical_questions[33]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92f9705",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 다른 문서의 3개의 가설 쿼리 출력해보기 \n",
    "\n",
    "    ```markdown\n",
    "    HypotheticalQuestions(questions=[\"삼성전자의 '삼성 가우스'가 온디바이스 환경에서 어떻게 사용자 데이터 보안을 강화하고 있는지 구체적으로 설명해 주실 수 있나요?\", '삼성 가우스의 세 가지 모델(언어, 코드, 이미지)이 각각 어떤 산업 분야에서 가장 효과적으로 활용될 수 있을까요?', '향후 삼성전자가 삼성 가우스를 기반으로 어떤 혁신적인 제품이나 서비스를 출시할 것으로 예상하시나요?'])\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39a861c",
   "metadata": {},
   "source": [
    "* 생성한 가설 쿼리 = 벡터 저장소에 저장하는 과정 \n",
    "\n",
    "  * *이전에 진행했던 방식과 동일*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d494207d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 자식 청크를 인덱싱하는 데 사용할 벡터 저장소\n",
    "hypothetical_vectorstore = Chroma(\n",
    "    collection_name=\"hypo-questions\", embedding_function=multilingual_embeddings\n",
    ")\n",
    "\n",
    "# 부모 문서의 저장소 계층\n",
    "store = InMemoryStore()\n",
    "\n",
    "id_key = \"doc_id\"\n",
    "\n",
    "# 검색기 (시작 시 비어 있음)\n",
    "retriever = MultiVectorRetriever(\n",
    "    vectorstore=hypothetical_vectorstore,\n",
    "    byte_store=store,\n",
    "    id_key=id_key,\n",
    ")\n",
    "\n",
    "doc_ids = [str(uuid.uuid4()) for _ in split_docs]                   # 문서 ID 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc215109",
   "metadata": {},
   "source": [
    "* **`question_docs`** 리스트 = `메타데이터 (문서 ID)` 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfd3a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_docs = []\n",
    "\n",
    "# hypothetical_questions 저장\n",
    "for i, question_list in enumerate(hypothetical_questions):\n",
    "    \n",
    "    question_docs.extend(\n",
    "        # 질문 리스트의 각 질문에 대해 Document 객체를 생성하기\n",
    "        [Document(page_content=s, metadata={id_key: doc_ids[i]}) for s in question_list.questions]    \n",
    "        # 메타데이터 = 해당 질문의 문서 ID 포함\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d8dc92",
   "metadata": {},
   "source": [
    "* 가설 쿼리 = 문서에 추가\n",
    "\n",
    "* 원본 문서 = **`docstore`** 에 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a9a5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hypothetical_questions 문서를 벡터 저장소에 추가하기\n",
    "retriever.vectorstore.add_documents(question_docs)\n",
    "\n",
    "# 문서 ID와 문서를 매핑하여 문서 저장소에 저장하기\n",
    "retriever.docstore.mset(list(zip(doc_ids, split_docs)))                     # 4.3s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf58d289",
   "metadata": {},
   "source": [
    "* **`vectorstore`** 객체의 **`similarity_search`** 메서드 → 유사도 검색 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c474219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 유사한 문서를 벡터 저장소에서 검색하기\n",
    "\n",
    "result_docs = hypothetical_vectorstore.similarity_search(\n",
    "    \"삼성전자가 만든 생성형 AI 의 이름은?\"\n",
    ")                                                                           # 0.1s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25455a59",
   "metadata": {},
   "source": [
    "* 유사도 검색 결과 = 생성한 가설 쿼리만 추가해둔 상태 → 생성한 가설 쿼리 중 유사도가 가장 높은 문서를 반환함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4beca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 유사도 검색 결과 출력하기\n",
    "\n",
    "for doc in result_docs:\n",
    "    print(doc.page_content)\n",
    "    print(doc.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e35407e",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 유사도 높은 문서 반환하기\n",
    "\n",
    "    ```markdown\n",
    "    삼성전자가 개최한 '삼성 개발자 콘퍼런스 코리아 2023'에서 공개된 삼성의 생성형 AI 기술, 특히 Samsung Gauss에 대한 주요 업데이트 내용은 무엇인가요?\n",
    "    {'doc_id': 'eeff618f-d0ea-4434-9bce-7512bcb8da7a'}\n",
    "    Samsung Gauss와 같은 삼성의 생성형 AI 기술이 미래의 AI 산업 트렌드에 어떤 영향을 미칠 것으로 예상되나요?\n",
    "    {'doc_id': 'eeff618f-d0ea-4434-9bce-7512bcb8da7a'}\n",
    "    삼성 가우스의 다목적 AI 모델 구성은 어떻게 기존 스마트폰 AI 기능을 혁신적으로 발전시킬 수 있을까요?\n",
    "\n",
    "    삼성 가우스의 온디바이스 AI 기술이 2024년 이후 스마트폰 시장에서 메타의 라마2나 구글 어시스턴트와 비교해 어떤 차별점을 제공할 것으로 예상됩니까?\n",
    "\n",
    "    코드아이(code.i)와 같은 대화형 AI 코딩 어시스턴트 기능이 기업의 소프트웨어 개발 효율성에 어떤 구체적인 영향을 미칠 수 있을까요?\n",
    "    {'doc_id': 'bcc6be37-dd5b-427a-9ba3-f61bc187dc61'}\n",
    "    삼성전자의 개발자 콘퍼런스에서 다룬 AI 기술 발전 동향을 바탕으로, 기업들이 AI 혁신을 위해 어떤 전략을 수립해야 할까요?\n",
    "    {'doc_id': 'eeff618f-d0ea-4434-9bce-7512bcb8da7a'}\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb58106",
   "metadata": {},
   "source": [
    "* **`retriever`** 객체의 **`invoke()`** 메서드 → 뭐리와 관련된 문서 검색하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63ccb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 관련된 문서를 검색하여 가져오기\n",
    "retrieved_docs = retriever.invoke(result_docs[1].page_content)\n",
    "\n",
    "\n",
    "# 검색된 문서 출력하기\n",
    "for doc in retrieved_docs:\n",
    "    print(doc.page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6613cd",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 쿼리와 관련된 문석 검색하기 *(`0.1s`)*\n",
    "\n",
    "    ```markdown\n",
    "    삼성전자, ‘삼성 개발자 콘퍼런스 코리아 2023’ 개최, 2023.11.14.\n",
    "    TechRepublic, Samsung Gauss: Samsung Research Reveals Generative AI, 2023.11.08.\n",
    "    단계적으로 탑재할 계획\n",
    "    n 삼성 가우스는 △텍스트를 생성하는 언어모델 △코드를 생성하는 코드 모델 △이미지를 생성하는 \n",
    "    이미지 모델의 3개 모델로 구성\n",
    "    ∙언어 모델은 클라우드와 온디바이스 대상 다양한 모델로 구성되며, 메일 작성, 문서 요약, 번역 업무의 \n",
    "    처리를 지원\n",
    "    ∙코드 모델 기반의 AI 코딩 어시스턴트 ‘코드아이(code.i)’는 대화형 인터페이스로 서비스를 제공하며 \n",
    "    사내 소프트웨어 개발에 최적화\n",
    "    ∙이미지 모델은 창의적인 이미지를 생성하고 기존 이미지를 원하는 대로 바꿀 수 있도록 지원하며 \n",
    "    저해상도 이미지의 고해상도 전환도 지원\n",
    "    n IT 전문지 테크리퍼블릭(TechRepublic)은 온디바이스 AI가 주요 기술 트렌드로 부상했다며, \n",
    "    2024년부터 가우스를 탑재한 삼성 스마트폰이 메타의 라마(Llama)2를 탑재한 퀄컴 기기 및 구글 \n",
    "    어시스턴트를 적용한 구글 픽셀(Pixel)과 경쟁할 것으로 예상\n",
    "    ☞ 출처 : 삼성전자, ‘삼성 AI 포럼’서 자체 개발 생성형 AI ‘삼성 가우스’ 공개, 2023.11.08.\n",
    "    삼성전자, ‘삼성 개발자 콘퍼런스 코리아 2023’ 개최, 2023.11.14.\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f33d3c7",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6103951",
   "metadata": {},
   "source": [
    "* next: ***`셀프 쿼리 검색기 (SelfQueryRetriever)`***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d893fc2",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lc_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
