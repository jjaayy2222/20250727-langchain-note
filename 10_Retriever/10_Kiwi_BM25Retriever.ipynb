{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70a79bc3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7062113",
   "metadata": {},
   "source": [
    "* ì¶œì²˜: LangChain ê³µì‹ ë¬¸ì„œ ë˜ëŠ” í•´ë‹¹ êµì¬ëª…\n",
    "* ì›ë³¸ URL: https://smith.langchain.com/hub/teddynote/summary-stuff-documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79eccb97",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ab2017",
   "metadata": {},
   "source": [
    "### **10. `í•œê¸€ í˜•íƒœì†Œ ë¶„ì„ê¸°(Kiwi, Kkma, Okt) + BM25 ê²€ìƒ‰ê¸°`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519bf8c2",
   "metadata": {},
   "source": [
    "#### **`1) í•œê¸€ í˜•íƒœì†Œ ë¶„ì„ê¸°ì™€ BM25Retrieverì˜ ê²°í•©`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1701264",
   "metadata": {},
   "source": [
    "* ê¹”ë”í•˜ê²Œ ì¶œë ¥ê²°ê³¼ë¥¼ í™•ì¸í•˜ê¸° ìœ„í•œ í•¨ìˆ˜ë¥¼ ì •ì˜í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87447bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print(docs):\n",
    "    for i, doc in enumerate(docs):\n",
    "        if \"score\" in doc.metadata:\n",
    "            print(f\"[{i+1}] {doc.page_content} ({doc.metadata['score']:.4f})\")\n",
    "        else:\n",
    "            print(f\"[{i+1}] {doc.page_content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b65a190",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a006c3",
   "metadata": {},
   "source": [
    "#### **2) `Kiwi í† í¬ë‚˜ì´ì € ì‚¬ìš© ë° ëª¨ë¸ ë§Œë“¤ì–´ë³´ê¸°`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5cc1ee",
   "metadata": {},
   "source": [
    "* ì‚¬ì „ì— `VS Code` í„°ë¯¸ë„ì— ì„¤ì¹˜í•  ê²ƒ\n",
    "\n",
    "```bash\n",
    "\n",
    "        pip install kiwipiepy                   # Kiwi í† í¬ë‚˜ì´ì € ì„¤ì¹˜\n",
    "\n",
    "        python -m kiwipiepy download            # Kiwi ëª¨ë¸ ë‹¤ìš´ë¡œë“œ\n",
    "\n",
    "```\n",
    "\n",
    "  * ê°€ìƒ í™˜ê²½ì„ ì‚¬ìš©í•˜ê³  ìˆë‹¤ë©´ **`í•´ë‹¹ ê°€ìƒí™˜ê²½ í™œì„±í™”í•œ í›„ ê·¸ê³³ì— ì„¤ì¹˜í•  ê²ƒ`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375d7a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kiwipiepy.Token ê°ì²´ êµ¬ì¡° í™•ì¸í•´ë³´ê¸°\n",
    "\n",
    "from kiwipiepy import Kiwi\n",
    "\n",
    "kiwi = Kiwi()\n",
    "tokens = kiwi.tokenize(\"ì•ˆë…•í•˜ì„¸ìš”, Kiwi í† í¬ë‚˜ì´ì €ë¥¼ ì‚¬ìš©í•´ë³´ê² ìŠµë‹ˆë‹¤.\")\n",
    "for token in tokens:\n",
    "    print(dir(token))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1364e52",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* kiwipiepy.Token ê°ì²´ì˜ ì†ì„± í™•ì¸\n",
    "\n",
    "    ```python\n",
    "    ['__class__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__len__', '__lt__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', 'base_form', 'base_id', 'end', 'form', 'form_tag', 'id', 'lemma', 'len', 'line_number', 'paired_token', 'raw_form', 'regularity', 'score', 'script', 'sense', 'sent_position', 'span', 'start', 'sub_sent_position', 'tag', 'tagged_form', 'typo_cost', 'user_value', 'word_position']\n",
    "    ['__class__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__len__', '__lt__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', 'base_form', 'base_id', 'end', 'form', 'form_tag', 'id', 'lemma', 'len', 'line_number', 'paired_token', 'raw_form', 'regularity', 'score', 'script', 'sense', 'sent_position', 'span', 'start', 'sub_sent_position', 'tag', 'tagged_form', 'typo_cost', 'user_value', 'word_position']\n",
    "    ['__class__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__len__', '__lt__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', 'base_form', 'base_id', 'end', 'form', 'form_tag', 'id', 'lemma', 'len', 'line_number', 'paired_token', 'raw_form', 'regularity', 'score', 'script', 'sense', 'sent_position', 'span', 'start', 'sub_sent_position', 'tag', 'tagged_form', 'typo_cost', 'user_value', 'word_position']\n",
    "    ['__class__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__len__', '__lt__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', 'base_form', 'base_id', 'end', 'form', 'form_tag', 'id', 'lemma', 'len', 'line_number', 'paired_token', 'raw_form', 'regularity', 'score', 'script', 'sense', 'sent_position', 'span', 'start', 'sub_sent_position', 'tag', 'tagged_form', 'typo_cost', 'user_value', 'word_position']\n",
    "    ['__class__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__len__', '__lt__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', 'base_form', 'base_id', 'end', 'form', 'form_tag', 'id', 'lemma', 'len', 'line_number', 'paired_token', 'raw_form', 'regularity', 'score', 'script', 'sense', 'sent_position', 'span', 'start', 'sub_sent_position', 'tag', 'tagged_form', 'typo_cost', 'user_value', 'word_position']\n",
    "    ['__class__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__len__', '__lt__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', 'base_form', 'base_id', 'end', 'form', 'form_tag', 'id', 'lemma', 'len', 'line_number', 'paired_token', 'raw_form', 'regularity', 'score', 'script', 'sense', 'sent_position', 'span', 'start', 'sub_sent_position', 'tag', 'tagged_form', 'typo_cost', 'user_value', 'word_position']\n",
    "    ['__class__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__len__', '__lt__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', 'base_form', 'base_id', 'end', 'form', 'form_tag', 'id', 'lemma', 'len', 'line_number', 'paired_token', 'raw_form', 'regularity', 'score', 'script', 'sense', 'sent_position', 'span', 'start', 'sub_sent_position', 'tag', 'tagged_form', 'typo_cost', 'user_value', 'word_position']\n",
    "    ['__class__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__len__', '__lt__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', 'base_form', 'base_id', 'end', 'form', 'form_tag', 'id', 'lemma', 'len', 'line_number', 'paired_token', 'raw_form', 'regularity', 'score', 'script', 'sense', 'sent_position', 'span', 'start', 'sub_sent_position', 'tag', 'tagged_form', 'typo_cost', 'user_value', 'word_position']\n",
    "    ['__class__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__len__', '__lt__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', 'base_form', 'base_id', 'end', 'form', 'form_tag', 'id', 'lemma', 'len', 'line_number', 'paired_token', 'raw_form', 'regularity', 'score', 'script', 'sense', 'sent_position', 'span', 'start', 'sub_sent_position', 'tag', 'tagged_form', 'typo_cost', 'user_value', 'word_position']\n",
    "    ['__class__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__len__', '__lt__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', 'base_form', 'base_id', 'end', 'form', 'form_tag', 'id', 'lemma', 'len', 'line_number', 'paired_token', 'raw_form', 'regularity', 'score', 'script', 'sense', 'sent_position', 'span', 'start', 'sub_sent_position', 'tag', 'tagged_form', 'typo_cost', 'user_value', 'word_position']\n",
    "    ['__class__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__len__', '__lt__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', 'base_form', 'base_id', 'end', 'form', 'form_tag', 'id', 'lemma', 'len', 'line_number', 'paired_token', 'raw_form', 'regularity', 'score', 'script', 'sense', 'sent_position', 'span', 'start', 'sub_sent_position', 'tag', 'tagged_form', 'typo_cost', 'user_value', 'word_position']\n",
    "    ['__class__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__len__', '__lt__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', 'base_form', 'base_id', 'end', 'form', 'form_tag', 'id', 'lemma', 'len', 'line_number', 'paired_token', 'raw_form', 'regularity', 'score', 'script', 'sense', 'sent_position', 'span', 'start', 'sub_sent_position', 'tag', 'tagged_form', 'typo_cost', 'user_value', 'word_position']\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af26c119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kiwi ê¸°ë³¸ ì‚¬ìš©í•´ë³´ê¸°\n",
    "\n",
    "from kiwipiepy import Kiwi\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"ğŸš€ Kiwi í•œê¸€ í˜•íƒœì†Œ ë¶„ì„ê¸° í…ŒìŠ¤íŠ¸\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Kiwi ì¸ìŠ¤í„´ìŠ¤ ìƒì„±\n",
    "kiwi = Kiwi()\n",
    "\n",
    "# í…ìŠ¤íŠ¸ ì¤€ë¹„\n",
    "text = \"ì•ˆë…•í•˜ì„¸ìš”, Kiwi í† í¬ë‚˜ì´ì €ë¥¼ ì‚¬ìš©í•´ë³´ê² ìŠµë‹ˆë‹¤.\"\n",
    "\n",
    "print(f\"ğŸ“ ì›ë³¸ í…ìŠ¤íŠ¸: {text}\")\n",
    "print()\n",
    "\n",
    "# í˜•íƒœì†Œ ë¶„ì„\n",
    "tokens = kiwi.tokenize(text)\n",
    "\n",
    "#print(\"ğŸ” í˜•íƒœì†Œ ë¶„ì„ ê²°ê³¼:\")\n",
    "#for i, token in enumerate(tokens):\n",
    "#    print(f\"[{i+1:2d}] {token.form:12s} | {token.tag:8s} | {token.prob:.4f}\")   â†’ prob ì†ì„±ì´ ì—†ì–´ ì˜¤ë¥˜ ë°œìƒ\n",
    "\n",
    "print(\"ğŸ” í˜•íƒœì†Œ ë¶„ì„ ê²°ê³¼:\")\n",
    "for i, token in enumerate(tokens):\n",
    "    print(f\"[{i+1:2d}] {token.form:12s} | {token.tag:8s} | {token.score:.4f}\")   # ì†ì„± í™•ì¸ í›„ scoreë¡œ ìˆ˜ì •\n",
    "\n",
    "print()\n",
    "print(\"ğŸ’¡ ì£¼ìš” í˜•íƒœì†Œë§Œ ì¶”ì¶œ:\")\n",
    "keywords = [token.form for token in tokens if token.tag in ['NNG', 'NNP', 'VV', 'VA']]\n",
    "print(f\"í‚¤ì›Œë“œ: {keywords}\")\n",
    "\n",
    "print(\"\\nâœ… Kiwi í…ŒìŠ¤íŠ¸ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f368fa5",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* í˜•íƒœì†Œ ë¶„ì„ í…ŒìŠ¤íŠ¸\n",
    "\n",
    "    ```markdown\n",
    "    ============================================================\n",
    "    ğŸš€ Kiwi í•œê¸€ í˜•íƒœì†Œ ë¶„ì„ê¸° í…ŒìŠ¤íŠ¸\n",
    "    ============================================================\n",
    "    ğŸ“ ì›ë³¸ í…ìŠ¤íŠ¸: ì•ˆë…•í•˜ì„¸ìš”, Kiwi í† í¬ë‚˜ì´ì €ë¥¼ ì‚¬ìš©í•´ë³´ê² ìŠµë‹ˆë‹¤.\n",
    "\n",
    "    ğŸ” í˜•íƒœì†Œ ë¶„ì„ ê²°ê³¼:\n",
    "    [ 1] ì•ˆë…•í•˜ì„¸ìš”        | NNP       | -24.9607\n",
    "    [ 2] ,              | SP        | -3.4208\n",
    "    [ 3] Kiwi           | SL        | -4.6044\n",
    "    [ 4] í† í¬ë‚˜ì´ì €        | NNG       | -34.9031\n",
    "    [ 5] ë¥¼              | JKO       | -2.6550\n",
    "    [ 6] ì‚¬ìš©            | NNG       | -6.3823\n",
    "    [ 7] í•˜             | XSV       | -1.0495\n",
    "    [ 8] ì–´             | EC        | -1.0495\n",
    "    [ 9] ë³´             | VX        | -2.1494\n",
    "    [10] ê²              | EP        | -3.5714\n",
    "    [11] ìŠµë‹ˆë‹¤          | EF        | -0.7610\n",
    "    [12] .             | SF        | -0.2585\n",
    "\n",
    "    ğŸ’¡ ì£¼ìš” í˜•íƒœì†Œë§Œ ì¶”ì¶œ:\n",
    "    í‚¤ì›Œë“œ: ['ì•ˆë…•í•˜ì„¸ìš”', 'í† í¬ë‚˜ì´ì €', 'ì‚¬ìš©']\n",
    "\n",
    "    âœ… Kiwi í…ŒìŠ¤íŠ¸ ì™„ë£Œ!\n",
    "    ```\n",
    "\n",
    "---\n",
    "\n",
    "* **`Kiwi`** ì˜ `Score` = `log probability`\n",
    "\n",
    "  * `Kiwi` = `log-likelihood` ë°©ì‹ ì‚¬ìš©\n",
    "\n",
    "  * í™•ë¥ ì€ `0~1` ì‚¬ì´ì§€ë§Œ, `log`ë¥¼ ì·¨í•˜ë©´ `ìŒìˆ˜`ê°€ ë¨\n",
    "    * ê°’ì´ `0`ì— ê°€ê¹Œìš¸ìˆ˜ë¡ `í™•ë¥ ì´ ë†’ìŒ` **(ì¢‹ìŒ)**\n",
    "    * ê°’ì´ `-ë¬´í•œëŒ€`ë¡œ ê°ˆìˆ˜ë¡ `í™•ë¥ ì´ ë‚®ìŒ` **(ë‚˜ì¨)**\n",
    "\n",
    "    * ì˜ˆì‹œ\n",
    "```python\n",
    "\n",
    "        í™•ë¥  1.0   â†’ log(1.0)   = 0.0      (ìµœìƒ)\n",
    "        í™•ë¥  0.5   â†’ log(0.5)   = -0.69    (ì¤‘ê°„)\n",
    "        í™•ë¥  0.01  â†’ log(0.01)  = -4.61    (ë‚®ìŒ)\n",
    "        í™•ë¥  0.0001 â†’ log(0.0001) = -9.21   (ë§¤ìš° ë‚®ìŒ)\n",
    "\n",
    "```\n",
    "   \n",
    "   * ìœ„ì˜ ê²°ê³¼\n",
    "```python\n",
    "\n",
    "        [ 1] ì•ˆë…•í•˜ì„¸ìš”   | NNP   | -24.9607  (ë‚®ìŒ - ê³ ìœ ëª…ì‚¬ë¡œ ì˜ëª» ë¶„ì„)\n",
    "        [11] ìŠµë‹ˆë‹¤      | EF    | -0.7610   (ë†’ìŒ - í™•ì‹¤í•œ ì–´ë¯¸)\n",
    "        [12] .         | SF     | -0.2585   (ë§¤ìš° ë†’ìŒ - í™•ì‹¤í•œ êµ¬ë‘ì )\n",
    "\n",
    "    # â†’ ì½”ë“œ ìˆ˜ì • í•„ìš”\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ba0254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìˆ˜ì •ëœ ì½”ë“œë¡œ Kiwi ë‹¤ì‹œ ì‚¬ìš©í•´ë³´ê¸° \n",
    "\n",
    "from kiwipiepy import Kiwi\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"ğŸš€ Kiwi í•œê¸€ í˜•íƒœì†Œ ë¶„ì„ê¸° í…ŒìŠ¤íŠ¸\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Kiwi ì¸ìŠ¤í„´ìŠ¤ ìƒì„±\n",
    "kiwi = Kiwi()\n",
    "\n",
    "# í…ìŠ¤íŠ¸ ì¤€ë¹„\n",
    "text = \"ì•ˆë…•í•˜ì„¸ìš”, Kiwi í† í¬ë‚˜ì´ì €ë¥¼ ì‚¬ìš©í•´ë³´ê² ìŠµë‹ˆë‹¤.\"\n",
    "\n",
    "print(f\"ğŸ“ ì›ë³¸ í…ìŠ¤íŠ¸: {text}\")\n",
    "print()\n",
    "\n",
    "# í˜•íƒœì†Œ ë¶„ì„\n",
    "tokens = kiwi.tokenize(text)\n",
    "\n",
    "print(\"ğŸ” í˜•íƒœì†Œ ë¶„ì„ ê²°ê³¼ (ì›ë³¸):\")\n",
    "print(f\"{'ë²ˆí˜¸':<4} {'í˜•íƒœì†Œ':<15} {'í’ˆì‚¬':<8} {'ì ìˆ˜(ë¡œê·¸í™•ë¥ )':<15}\")\n",
    "print(\"-\" * 50)\n",
    "for i, token in enumerate(tokens):\n",
    "    print(f\"[{i+1:2d}] {token.form:<15s} {token.tag:<8s} {token.score:>12.4f}\")\n",
    "\n",
    "print()\n",
    "\n",
    "# í™•ë¥ ë¡œ ë³€í™˜í•´ì„œ ë³´ê¸°\n",
    "print(\"ğŸ” í˜•íƒœì†Œ ë¶„ì„ ê²°ê³¼ (í™•ë¥  ë³€í™˜):\")\n",
    "print(f\"{'ë²ˆí˜¸':<4} {'í˜•íƒœì†Œ':<15} {'í’ˆì‚¬':<8} {'í™•ë¥ ':<15}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "import math\n",
    "for i, token in enumerate(tokens):\n",
    "    # log í™•ë¥  â†’ í™•ë¥  ë³€í™˜\n",
    "    probability = math.exp(token.score)\n",
    "    print(f\"[{i+1:2d}] {token.form:<15s} {token.tag:<8s} {probability:>12.8f}\")\n",
    "\n",
    "print()\n",
    "print(\"ğŸ’¡ ì£¼ìš” í˜•íƒœì†Œë§Œ ì¶”ì¶œ:\")\n",
    "keywords = [token.form for token in tokens if token.tag in ['NNG', 'NNP', 'VV', 'VA']]\n",
    "print(f\"í‚¤ì›Œë“œ: {keywords}\")\n",
    "\n",
    "print()\n",
    "print(\"ğŸ“Š ê°€ì¥ í™•ì‹¤í•œ í† í° TOP 3:\")\n",
    "# score ê¸°ì¤€ ì •ë ¬ (0ì— ê°€ê¹Œìš¸ìˆ˜ë¡ í™•ì‹¤)\n",
    "sorted_tokens = sorted(tokens, key=lambda t: t.score, reverse=True)\n",
    "for i, token in enumerate(sorted_tokens[:3]):\n",
    "    prob = math.exp(token.score)\n",
    "    print(f\"[{i+1}] {token.form:<10s} | {token.tag:<6s} | score: {token.score:>8.4f} | prob: {prob:.6f}\")\n",
    "\n",
    "print(\"\\nâœ… Kiwi í…ŒìŠ¤íŠ¸ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7fe6dc",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* ìˆ˜ì •ëœ ì½”ë“œë¡œ í…ŒìŠ¤íŠ¸í•œ `Kiwi test`\n",
    "\n",
    "    ```markdown\n",
    "    ============================================================\n",
    "    ğŸš€ Kiwi í•œê¸€ í˜•íƒœì†Œ ë¶„ì„ê¸° í…ŒìŠ¤íŠ¸\n",
    "    ============================================================\n",
    "    ğŸ“ ì›ë³¸ í…ìŠ¤íŠ¸: ì•ˆë…•í•˜ì„¸ìš”, Kiwi í† í¬ë‚˜ì´ì €ë¥¼ ì‚¬ìš©í•´ë³´ê² ìŠµë‹ˆë‹¤.\n",
    "\n",
    "    ğŸ” í˜•íƒœì†Œ ë¶„ì„ ê²°ê³¼ (ì›ë³¸):\n",
    "    ë²ˆí˜¸   í˜•íƒœì†Œ             í’ˆì‚¬       ì ìˆ˜(ë¡œê·¸í™•ë¥ )       \n",
    "    --------------------------------------------------\n",
    "    [ 1] ì•ˆë…•í•˜ì„¸ìš”           NNP          -24.9607\n",
    "    [ 2] ,                 SP           -3.4208\n",
    "    [ 3] Kiwi              SL           -4.6044\n",
    "    [ 4] í† í¬ë‚˜ì´ì €           NNG          -34.9031\n",
    "    [ 5] ë¥¼                JKO           -2.6550\n",
    "    [ 6] ì‚¬ìš©               NNG           -6.3823\n",
    "    [ 7] í•˜                XSV           -1.0495\n",
    "    [ 8] ì–´                EC            -1.0495\n",
    "    [ 9] ë³´                VX            -2.1494\n",
    "    [10] ê²                 EP            -3.5714\n",
    "    [11] ìŠµë‹ˆë‹¤             EF            -0.7610\n",
    "    [12] .                SF            -0.2585\n",
    "\n",
    "    ğŸ” í˜•íƒœì†Œ ë¶„ì„ ê²°ê³¼ (í™•ë¥  ë³€í™˜):\n",
    "    ë²ˆí˜¸   í˜•íƒœì†Œ             í’ˆì‚¬          í™•ë¥              \n",
    "    --------------------------------------------------\n",
    "    [ 1] ì•ˆë…•í•˜ì„¸ìš”           NNP         0.00000000\n",
    "    [ 2] ,                 SP          0.03268630\n",
    "    [ 3] Kiwi              SL          0.01000789\n",
    "    [ 4] í† í¬ë‚˜ì´ì €           NNG         0.00000000\n",
    "    [ 5] ë¥¼                JKO         0.07029892\n",
    "    [ 6] ì‚¬ìš©               NNG         0.00169127\n",
    "    [ 7] í•˜                XSV         0.35009691\n",
    "    [ 8] ì–´                EC          0.35009691\n",
    "    [ 9] ë³´                VX          0.11655688\n",
    "    [10] ê²                 EP          0.02811701\n",
    "    [11] ìŠµë‹ˆë‹¤             EF          0.46719469\n",
    "    [12] .                SF          0.77223326\n",
    "\n",
    "    ğŸ’¡ ì£¼ìš” í˜•íƒœì†Œë§Œ ì¶”ì¶œ:\n",
    "    í‚¤ì›Œë“œ: ['ì•ˆë…•í•˜ì„¸ìš”', 'í† í¬ë‚˜ì´ì €', 'ì‚¬ìš©']\n",
    "\n",
    "    ğŸ“Š ê°€ì¥ í™•ì‹¤í•œ í† í° TOP 3:\n",
    "    [1] .           | SF       | score:  -0.2585   | prob: 0.772233\n",
    "    [2] ìŠµë‹ˆë‹¤        | EF      | score:  -0.7610   |  prob: 0.467195\n",
    "    [3] í•˜           | XSV     | score:  -1.0495   |  prob: 0.350097\n",
    "\n",
    "    âœ… Kiwi í…ŒìŠ¤íŠ¸ ì™„ë£Œ!\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c261b4f8",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* `Score` í•´ì„í•´ë³´ê¸°\n",
    "\n",
    "  * `ë¡œê·¸ í™•ë¥  (score)`ì˜ ì˜ë¯¸\n",
    "\n",
    "  | score ë²”ìœ„ | ì˜ë¯¸ | ì˜ˆì‹œ |\n",
    "  |-----------|------|------|\n",
    "  | **0 ~ -1** | ë§¤ìš° í™•ì‹¤ | êµ¬ë‘ì (.), ì¡°ì‚¬(ë¥¼) |\n",
    "  | **-1 ~ -5** | í™•ì‹¤ | ì¼ë°˜ ë™ì‚¬, ëª…ì‚¬ |\n",
    "  | **-5 ~ -10** | ë³´í†µ | ì™¸ë˜ì–´, ë³µí•©ì–´ |\n",
    "  | **-10 ì´í•˜** | ë¶ˆí™•ì‹¤ | ë¯¸ë“±ë¡ì–´, ë“œë¬¸ ë‹¨ì–´ |\n",
    "\n",
    "<br>\n",
    "\n",
    "*  * ìœ„ ê²°ê³¼ í•´ì„ \n",
    "```python\n",
    "\n",
    "        -0.2585  (.)        â†’       99.7% í™•ì‹  (êµ¬ë‘ì ì€ í™•ì‹¤í•¨)\n",
    "        -0.7610  (ìŠµë‹ˆë‹¤)     â†’       46.7% í™•ì‹  (ì–´ë¯¸ëŠ” í™•ì‹¤í•¨)\n",
    "        -24.9607 (ì•ˆë…•í•˜ì„¸ìš”)  â†’       0.0000...% (ê±°ì˜ ë¶ˆê°€ëŠ¥ - NNPë¡œ ë¶„ì„í•œ ê²Œ ì˜ëª»)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4e7812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‹¤ì „: ì‹ ë¢°ë„ ê¸°ë°˜ í•„í„°ë§\n",
    "\n",
    "from kiwipiepy import Kiwi\n",
    "import math\n",
    "\n",
    "def analyze_with_confidence(text, confidence_threshold=-10.0):\n",
    "    \"\"\"\n",
    "    ì‹ ë¢°ë„ ê¸°ë°˜ í˜•íƒœì†Œ ë¶„ì„\n",
    "    confidence_threshold: ì´ ê°’ë³´ë‹¤ ë†’ì€(ëœ ìŒìˆ˜ì¸) í† í°ë§Œ ë°˜í™˜\n",
    "    \"\"\"\n",
    "    kiwi = Kiwi()\n",
    "    tokens = kiwi.tokenize(text)\n",
    "    \n",
    "    # ì‹ ë¢°ë„ ë†’ì€ í† í°ë§Œ í•„í„°ë§\n",
    "    confident_tokens = [\n",
    "        token for token in tokens \n",
    "        if token.score > confidence_threshold                   # -10.0ë³´ë‹¤ í¬ë©´ (ëœ ìŒìˆ˜ë©´)\n",
    "        and token.tag in ['NNG', 'NNP', 'VV', 'VA', 'SL']       # ì˜ë¯¸ìˆëŠ” í’ˆì‚¬\n",
    "    ]\n",
    "    \n",
    "    print(f\"ğŸ“ ì›ë³¸: {text}\")\n",
    "    print(f\"âœ… ì‹ ë¢°ë„ ë†’ì€ í‚¤ì›Œë“œ (threshold={confidence_threshold}):\")\n",
    "    \n",
    "    for token in confident_tokens:\n",
    "        prob = math.exp(token.score)\n",
    "        print(f\"  - {token.form:<12s} | {token.tag:<6s} | score: {token.score:>8.4f} | prob: {prob:.4f}\")\n",
    "    \n",
    "    return [token.form for token in confident_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb75146",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "    \"Pythonì€ AI ê°œë°œì— ì í•©í•œ ì–¸ì–´ì…ë‹ˆë‹¤.\",\n",
    "    \"LangChainê³¼ Kiwië¥¼ í™œìš©í•œ ê²€ìƒ‰ ì‹œìŠ¤í…œ\",\n",
    "    \"í˜•íƒœì†Œ ë¶„ì„ì€ ìì—°ì–´ ì²˜ë¦¬ì˜ ê¸°ì´ˆì…ë‹ˆë‹¤.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aacfad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í…ŒìŠ¤íŠ¸\n",
    "print(\"=\" * 60)\n",
    "print(\"ğŸš€ ì‹ ë¢°ë„ ê¸°ë°˜ í‚¤ì›Œë“œ ì¶”ì¶œ\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for text in texts:\n",
    "    keywords = analyze_with_confidence(text, confidence_threshold=-10.0)\n",
    "    print(f\"  â†’ í‚¤ì›Œë“œ: {keywords}\\n\")\n",
    "\n",
    "# ë‹¤ë¥¸ ì†ì„±ë„ ì¶”ê°€í•´ë³´ê¸°\n",
    "print(\"ğŸ” Token ê°ì²´ì˜ ì¶”ê°€ ì†ì„±:\")\n",
    "for token in tokens:\n",
    "    print(f\"\\ní˜•íƒœì†Œ: {token.form}\")\n",
    "    print(f\"  - tag: {token.tag}\")                      # í’ˆì‚¬ íƒœê·¸\n",
    "    print(f\"  - score: {token.score}\")                  # ë¡œê·¸ í™•ë¥ \n",
    "    print(f\"  - start: {token.start}\")                  # ì‹œì‘ ìœ„ì¹˜\n",
    "    print(f\"  - len: {token.len}\")                      # ê¸¸ì´\n",
    "    print(f\"  - tagged_form: {token.tagged_form}\")      # í˜•íƒœì†Œ/í’ˆì‚¬\n",
    "\n",
    "print(\"\\n\", \"âœ… ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a548b5",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* ì‹ ë¢°ë„ ê¸°ë°˜ í•„í„°ë§ + ì¶”ê°€ ìš”ì†Œ ì¶”ì¶œ\n",
    "\n",
    "    ```markdown\n",
    "    ============================================================\n",
    "    ğŸš€ ì‹ ë¢°ë„ ê¸°ë°˜ í‚¤ì›Œë“œ ì¶”ì¶œ\n",
    "    ============================================================\n",
    "    ğŸ“ ì›ë³¸: Pythonì€ AI ê°œë°œì— ì í•©í•œ ì–¸ì–´ì…ë‹ˆë‹¤.\n",
    "    âœ… ì‹ ë¢°ë„ ë†’ì€ í‚¤ì›Œë“œ (threshold=-10.0):\n",
    "    - Python        | SL     | score:  -5.1598 | prob: 0.0057\n",
    "    - AI            | SL     | score:  -3.4959 | prob: 0.0303\n",
    "    - ê°œë°œ           | NNG    | score:  -9.5165 | prob: 0.0001\n",
    "    - ì í•©           | NNG    | score:  -8.8320 | prob: 0.0001\n",
    "    - ì–¸ì–´           | NNG    | score:  -6.6020 | prob: 0.0014\n",
    "    â†’ í‚¤ì›Œë“œ: ['Python', 'AI', 'ê°œë°œ', 'ì í•©', 'ì–¸ì–´']\n",
    "\n",
    "    ğŸ“ ì›ë³¸: LangChainê³¼ Kiwië¥¼ í™œìš©í•œ ê²€ìƒ‰ ì‹œìŠ¤í…œ\n",
    "    âœ… ì‹ ë¢°ë„ ë†’ì€ í‚¤ì›Œë“œ (threshold=-10.0):\n",
    "    - LangChain      | SL     | score:  -5.1598 | prob: 0.0057\n",
    "    - Kiwi           | SL     | score:  -0.4446 | prob: 0.6411\n",
    "    - í™œìš©            | NNG    | score:  -5.6323 | prob: 0.0036\n",
    "    - ì‹œìŠ¤í…œ           | NNG    | score:  -3.3437 | prob: 0.0353\n",
    "    â†’ í‚¤ì›Œë“œ: ['LangChain', 'Kiwi', 'í™œìš©', 'ì‹œìŠ¤í…œ']\n",
    "\n",
    "    ğŸ“ ì›ë³¸: í˜•íƒœì†Œ ë¶„ì„ì€ ìì—°ì–´ ì²˜ë¦¬ì˜ ê¸°ì´ˆì…ë‹ˆë‹¤.\n",
    "    âœ… ì‹ ë¢°ë„ ë†’ì€ í‚¤ì›Œë“œ (threshold=-10.0):\n",
    "    - ë¶„ì„           | NNG    | score:  -4.0561 | prob: 0.0173\n",
    "    - ê¸°ì´ˆ           | NNG    | score:  -8.7458 | prob: 0.0002\n",
    "    â†’ í‚¤ì›Œë“œ: ['ë¶„ì„', 'ê¸°ì´ˆ']\n",
    "\n",
    "    ğŸ” Token ê°ì²´ì˜ ì¶”ê°€ ì†ì„±:\n",
    "\n",
    "    í˜•íƒœì†Œ: ì•ˆë…•í•˜ì„¸ìš”\n",
    "    - tag: NNP\n",
    "    - score: -24.96066665649414\n",
    "    - start: 0\n",
    "    - len: 5\n",
    "    - tagged_form: ì•ˆë…•í•˜ì„¸ìš”/NNP\n",
    "\n",
    "    í˜•íƒœì†Œ: ,\n",
    "    - tag: SP\n",
    "    - score: -3.4207992553710938\n",
    "    - start: 5\n",
    "    - len: 1\n",
    "    - tagged_form: ,/SP\n",
    "\n",
    "    í˜•íƒœì†Œ: Kiwi\n",
    "    - tag: SL\n",
    "    - score: -4.604381561279297\n",
    "    - start: 7\n",
    "    - len: 4\n",
    "    - tagged_form: Kiwi/SL\n",
    "\n",
    "    í˜•íƒœì†Œ: í† í¬ë‚˜ì´ì €\n",
    "    - tag: NNG\n",
    "    - score: -34.90306091308594\n",
    "    - start: 12\n",
    "    - len: 5\n",
    "    - tagged_form: í† í¬ë‚˜ì´ì €/NNG\n",
    "\n",
    "    í˜•íƒœì†Œ: ë¥¼\n",
    "    - tag: JKO\n",
    "    - score: -2.654998779296875\n",
    "    - start: 17\n",
    "    - len: 1\n",
    "    - tagged_form: ë¥¼/JKO\n",
    "\n",
    "    í˜•íƒœì†Œ: ì‚¬ìš©\n",
    "    - tag: NNG\n",
    "    - score: -6.3822784423828125\n",
    "    - start: 19\n",
    "    - len: 2\n",
    "    - tagged_form: ì‚¬ìš©/NNG\n",
    "\n",
    "    í˜•íƒœì†Œ: í•˜\n",
    "    - tag: XSV\n",
    "    - score: -1.0495452880859375\n",
    "    - start: 21\n",
    "    - len: 1\n",
    "    - tagged_form: í•˜/XSV\n",
    "\n",
    "    í˜•íƒœì†Œ: ì–´\n",
    "    - tag: EC\n",
    "    - score: -1.0495452880859375\n",
    "    - start: 21\n",
    "    - len: 1\n",
    "    - tagged_form: ì–´/EC\n",
    "\n",
    "    í˜•íƒœì†Œ: ë³´\n",
    "    - tag: VX\n",
    "    - score: -2.1493759155273438\n",
    "    - start: 22\n",
    "    - len: 1\n",
    "    - tagged_form: ë³´/VX\n",
    "\n",
    "    í˜•íƒœì†Œ: ê² \n",
    "    - tag: EP\n",
    "    - score: -3.571380615234375\n",
    "    - start: 23\n",
    "    - len: 1\n",
    "    - tagged_form: ê² /EP\n",
    "\n",
    "    í˜•íƒœì†Œ: ìŠµë‹ˆë‹¤\n",
    "    - tag: EF\n",
    "    - score: -0.7610092163085938\n",
    "    - start: 24\n",
    "    - len: 3\n",
    "    - tagged_form: ìŠµë‹ˆë‹¤/EF\n",
    "\n",
    "    í˜•íƒœì†Œ: .\n",
    "    - tag: SF\n",
    "    - score: -0.2584686279296875\n",
    "    - start: 27\n",
    "    - len: 1\n",
    "    - tagged_form: ./SF\n",
    "    \n",
    "    âœ… ì™„ë£Œ!\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a38d2b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53cd74e4",
   "metadata": {},
   "source": [
    "* [ì¬ì‚¬ìš© ê°€ëŠ¥í•œ í´ë˜ìŠ¤ ëª¨ë¸ë¡œ ë§Œë“¤ê¸°](../10_Retriever/utils/korean_analyzer.py)\n",
    "\n",
    "  * **`í´ë˜ìŠ¤ ëª¨ë¸`** - í•µì‹¬ ê¸°ëŠ¥\n",
    "\n",
    "  | ë©”ì„œë“œ | ì„¤ëª… | ì‚¬ìš© ì˜ˆì‹œ |\n",
    "  |--------|------|----------|\n",
    "  | **analyze()** | ê¸°ë³¸ í˜•íƒœì†Œ ë¶„ì„ | `analyzer.analyze(text)` |\n",
    "  | **extract_keywords()** | ì‹ ë¢°ë„ ê¸°ë°˜ í‚¤ì›Œë“œ ì¶”ì¶œ | `analyzer.extract_keywords(text, -10.0)` |\n",
    "  | **extract_nouns()** | ëª…ì‚¬ë§Œ ì¶”ì¶œ | `analyzer.extract_nouns(text)` |\n",
    "  | **extract_verbs()** | ë™ì‚¬ë§Œ ì¶”ì¶œ | `analyzer.extract_verbs(text)` |\n",
    "  | **extract_adjectives()** | í˜•ìš©ì‚¬ë§Œ ì¶”ì¶œ | `analyzer.extract_adjectives(text)` |\n",
    "  | **get_detailed_info()** | ìƒì„¸ ì •ë³´ ì¡°íšŒ | `analyzer.get_detailed_info(text)` |\n",
    "  | **analyze_with_confidence()** | í†µí•© ë¶„ì„ | `analyzer.analyze_with_confidence(text)` |\n",
    "  | **print_analysis()** | ì˜ˆìœ ì¶œë ¥ | `analyzer.print_analysis(text, detailed=True)` |\n",
    "\n",
    "<br>\n",
    "\n",
    "*  * ì‚¬ìš© ì˜ˆì œ \n",
    "*  *  * a. ê°„ë‹¨í•œ í‚¤ì›Œë“œ ì¶”ì¶œ\n",
    "```python\n",
    "\n",
    "        from korean_analyzer import KoreanMorphologicalAnalyzer\n",
    "\n",
    "        analyzer = KoreanMorphologicalAnalyzer()\n",
    "\n",
    "        text = \"Pythonê³¼ LangChainì„ í™œìš©í•œ AI ê°œë°œ\"\n",
    "        keywords = analyzer.extract_keywords(text)\n",
    "\n",
    "        print(keywords)\n",
    "        # ['Python', 'LangChain', 'í™œìš©', 'AI', 'ê°œë°œ']\n",
    "\n",
    "```\n",
    "\n",
    "*  *  * b. ë¬¸ì„œ ë°°ì¹˜ ì²˜ë¦¬  \n",
    "```python\n",
    "\n",
    "        analyzer = KoreanMorphologicalAnalyzer()\n",
    "\n",
    "        documents = [\n",
    "            \"RAG ì‹œìŠ¤í…œ êµ¬ì¶• ë°©ë²•\",\n",
    "            \"í˜•íƒœì†Œ ë¶„ì„ì˜ ì¤‘ìš”ì„±\",\n",
    "            \"í•œêµ­ì–´ ìì—°ì–´ ì²˜ë¦¬ ê¸°ìˆ \"\n",
    "        ]\n",
    "\n",
    "        all_keywords = []\n",
    "        for doc in documents:\n",
    "            keywords = analyzer.extract_keywords(doc, confidence_threshold=-8.0)\n",
    "            all_keywords.extend(keywords)\n",
    "\n",
    "        print(f\"ì „ì²´ í‚¤ì›Œë“œ: {set(all_keywords)}\")\n",
    "\n",
    "```\n",
    "*  *  * c. í’ˆì‚¬ë³„ ë¶„ë¦¬ ì²˜ë¦¬\n",
    "```python\n",
    "\n",
    "        analyzer = KoreanMorphologicalAnalyzer()\n",
    "\n",
    "        text = \"Pythonì€ ê°•ë ¥í•˜ê³  ìœ ìš©í•œ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ì…ë‹ˆë‹¤.\"\n",
    "\n",
    "        print(f\"ëª…ì‚¬: {analyzer.extract_nouns(text)}\")\n",
    "        print(f\"ë™ì‚¬: {analyzer.extract_verbs(text)}\")\n",
    "        print(f\"í˜•ìš©ì‚¬: {analyzer.extract_adjectives(text)}\")\n",
    "\n",
    "```\n",
    "*  *  * d. íŒŒì¼ë¡œ ì €ì¥ í›„ ì‚¬ìš©í•˜ê¸° \n",
    "```python\n",
    "\n",
    "        # 10_Retriever/utils/korean_analyzer.pyë¡œ ì €ì¥\n",
    "\n",
    "        from utils.korean_analyzer import KoreanMorphologicalAnalyzer\n",
    "\n",
    "        analyzer = KoreanMorphologicalAnalyzer()\n",
    "        result = analyzer.extract_keywords(\"ì•ˆë…•í•˜ì„¸ìš”\")\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a3eefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10_Retriever/utils/Korean_analyzer.py ì‚¬ìš©í•´ë³´ê¸°\n",
    "\n",
    "from utils.korean_analyzer import KoreanMorphologicalAnalyzer\n",
    "\n",
    "analyzer = KoreanMorphologicalAnalyzer()\n",
    "\n",
    "text = \"AI ê¸°ìˆ ì´ ë¹ ë¥´ê²Œ ë°œì „í•˜ê³  ìˆìŠµë‹ˆë‹¤.\"\n",
    "\n",
    "print(f\"ëª…ì‚¬: {analyzer.extract_nouns(text)}\")\n",
    "print(f\"ë™ì‚¬: {analyzer.extract_verbs(text)}\")\n",
    "print(f\"í˜•ìš©ì‚¬: {analyzer.extract_adjectives(text)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2dc1d1",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* ëª…ì‚¬: ['ê¸°ìˆ ', 'ë°œì „']\n",
    "* ë™ì‚¬: []\n",
    "* í˜•ìš©ì‚¬: ['ë¹ ë¥´']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f72ea1",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* test_2 (`8.1s`)\n",
    "\n",
    "    ```markdown\n",
    "    ============================================================\n",
    "    ğŸ“ ì›ë³¸: Pythonì€ ê°•ë ¥í•œ ì–¸ì–´ì…ë‹ˆë‹¤\n",
    "    ============================================================\n",
    "\n",
    "    ë²ˆí˜¸   í˜•íƒœì†Œ             í’ˆì‚¬     í’ˆì‚¬ì„¤ëª…            ì ìˆ˜         í™•ë¥         \n",
    "    ----------------------------------------------------------------------\n",
    "    [ 1] Python            SL      ì™¸êµ­ì–´             -5.1598    0.005743\n",
    "    [ 2] ì€                JX       ê¸°íƒ€              -1.5430    0.213736\n",
    "    [ 3] ê°•ë ¥               XR      ì–´ê·¼              -8.0364    0.000323\n",
    "    [ 4] í•˜                XSA     í˜•ìš©ì‚¬ íŒŒìƒ ì ‘ë¯¸ì‚¬    -0.2585    0.772234\n",
    "    [ 5] á†«                ETM      ê¸°íƒ€             -0.2585     0.772234\n",
    "    [ 6] ì–¸ì–´              NNG     ì¼ë°˜ ëª…ì‚¬          -6.6236     0.001329\n",
    "    [ 7] ì´               VCP       ê¸°íƒ€             -2.7300    0.065219\n",
    "    [ 8] á†¸ë‹ˆë‹¤             EF      ì¢…ê²° ì–´ë¯¸          -4.1887    0.015165\n",
    "\n",
    "    ğŸ’¡ ìš”ì•½:\n",
    "    - ì´ í† í°: 8ê°œ\n",
    "    - ëª…ì‚¬: ['ì–¸ì–´']\n",
    "    - ë™ì‚¬: []\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14287acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10_Retriever/utils/Korean_analyzer.py ì‚¬ìš©í•´ë³´ê¸°\n",
    "\n",
    "from utils.korean_analyzer import KoreanMorphologicalAnalyzer\n",
    "analyzer = KoreanMorphologicalAnalyzer()\n",
    "analyzer.print_analysis(\"Pythonì€ ê°•ë ¥í•œ ì–¸ì–´ì…ë‹ˆë‹¤\", detailed=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b73d1d5",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c74365",
   "metadata": {},
   "source": [
    "#### **3) `Kiwi Analyzer + BM25 Retriever`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d10d26",
   "metadata": {},
   "source": [
    "* `Kiwi Analyzer` + `BM25 Retriever` ê²°í•© â†’ [`korean_bm25_retriever`](../10_Retriever/utils/korean_bm25_retriever.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e03562a",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* `/10_Retriever/utils/korean_bm25_retriever.py` ì‹¤í–‰ ê²°ê³¼\n",
    "\n",
    "    ```markdown\n",
    "    /10_Retriever/utils/korean_bm25_retriever.py\n",
    "    ============================================================\n",
    "    ğŸš€ ì˜ˆì œ 1: ê¸°ë³¸ BM25 ê²€ìƒ‰\n",
    "    ============================================================\n",
    "\n",
    "    ğŸ” ê²€ìƒ‰ì–´: 'ê¸ˆìœµë³´í—˜'\n",
    "\n",
    "    ğŸ“Š ê²€ìƒ‰ ê²°ê³¼:\n",
    "    [1] ê¸ˆìœµë³´í—˜ì€ ì¥ê¸°ì ì¸ ìì‚° ê´€ë¦¬ì™€ ìœ„í—˜ ëŒ€ë¹„ë¥¼ ëª©ì ìœ¼ë¡œ ê³ ì•ˆëœ ê¸ˆìœµ ìƒí’ˆì…ë‹ˆë‹¤.\n",
    "    [2] ê¸ˆìœµì €ì¶•ì‚°ë¬¼ë³´í—˜ì€ ì¥ê¸°ì ì¸ ì €ì¶• ëª©ì ê³¼ ë”ë¶ˆì–´, ì¶•ì‚°ë¬¼ ì œê³µ ê¸°ëŠ¥ì„ ê°–ì¶”ê³  ìˆëŠ” íŠ¹ë³„ ê¸ˆìœµ ìƒí’ˆì…ë‹ˆë‹¤.\n",
    "    [3] ê¸ˆìœµë‹¨í­ê²©ë³´í—˜ì€ ì €ì¶•ì€ ì»¤ë…• ìœ„í—˜ ëŒ€ë¹„ì— ì´ˆì ì„ ë§ì¶˜ ìƒí’ˆì…ë‹ˆë‹¤. ë†’ì€ ìœ„í—˜ì„ ê°ìˆ˜í•˜ê³ ì í•˜ëŠ” ê³ ê°ì—ê²Œ ì í•©í•©ë‹ˆë‹¤.\n",
    "    [4] ê¸ˆìœµë³´ì”¨ í—˜í•œë§ ì¢€ í•˜ì§€ë§ˆì‹œê³ , ì €ì¶•ì´ë‚˜ ì¢€ í•˜ì‹œë˜ê°€ìš”. ë­ê°€ ê·¸ë¦¬ ê¸‰í•˜ì‹ ì§€ ëª¨ë¥´ê² ë„¤ìš”.\n",
    "\n",
    "    ============================================================\n",
    "    ğŸš€ ì˜ˆì œ 2: ì ìˆ˜ í¬í•¨ ê²€ìƒ‰\n",
    "    ============================================================\n",
    "\n",
    "    ğŸ” ê²€ìƒ‰ì–´: 'ê¸ˆìœµë³´í—˜'\n",
    "\n",
    "    ğŸ“Š ì ìˆ˜ í¬í•¨ ê²°ê³¼:\n",
    "    [1] ê¸ˆìœµë³´í—˜ì€ ì¥ê¸°ì ì¸ ìì‚° ê´€ë¦¬ì™€ ìœ„í—˜ ëŒ€ë¹„ë¥¼ ëª©ì ìœ¼ë¡œ ê³ ì•ˆëœ ê¸ˆìœµ ìƒí’ˆì…ë‹ˆë‹¤. (1.0000)\n",
    "    [2] ê¸ˆìœµì €ì¶•ì‚°ë¬¼ë³´í—˜ì€ ì¥ê¸°ì ì¸ ì €ì¶• ëª©ì ê³¼ ë”ë¶ˆì–´, ì¶•ì‚°ë¬¼ ì œê³µ ê¸°ëŠ¥ì„ ê°–ì¶”ê³  ìˆëŠ” íŠ¹ë³„ ê¸ˆìœµ ìƒí’ˆì…ë‹ˆë‹¤. (1.0000)\n",
    "    [3] ê¸ˆìœµë‹¨í­ê²©ë³´í—˜ì€ ì €ì¶•ì€ ì»¤ë…• ìœ„í—˜ ëŒ€ë¹„ì— ì´ˆì ì„ ë§ì¶˜ ìƒí’ˆì…ë‹ˆë‹¤. ë†’ì€ ìœ„í—˜ì„ ê°ìˆ˜í•˜ê³ ì í•˜ëŠ” ê³ ê°ì—ê²Œ ì í•©í•©ë‹ˆë‹¤. (1.0000)\n",
    "    [4] ê¸ˆìœµë³´ì”¨ í—˜í•œë§ ì¢€ í•˜ì§€ë§ˆì‹œê³ , ì €ì¶•ì´ë‚˜ ì¢€ í•˜ì‹œë˜ê°€ìš”. ë­ê°€ ê·¸ë¦¬ ê¸‰í•˜ì‹ ì§€ ëª¨ë¥´ê² ë„¤ìš”. (0.5000)\n",
    "\n",
    "    ============================================================\n",
    "    ğŸš€ ì˜ˆì œ 3: k ê°’ ì„¤ì • (ìƒìœ„ 2ê°œë§Œ)\n",
    "    ============================================================\n",
    "\n",
    "    ğŸ” ê²€ìƒ‰ì–´: 'ê¸ˆìœµë³´í—˜'\n",
    "\n",
    "    ğŸ“Š ìƒìœ„ 2ê°œ ê²°ê³¼:\n",
    "    [1] ê¸ˆìœµë³´í—˜ì€ ì¥ê¸°ì ì¸ ìì‚° ê´€ë¦¬ì™€ ìœ„í—˜ ëŒ€ë¹„ë¥¼ ëª©ì ìœ¼ë¡œ ê³ ì•ˆëœ ê¸ˆìœµ ìƒí’ˆì…ë‹ˆë‹¤. (1.0000)\n",
    "    [2] ê¸ˆìœµì €ì¶•ì‚°ë¬¼ë³´í—˜ì€ ì¥ê¸°ì ì¸ ì €ì¶• ëª©ì ê³¼ ë”ë¶ˆì–´, ì¶•ì‚°ë¬¼ ì œê³µ ê¸°ëŠ¥ì„ ê°–ì¶”ê³  ìˆëŠ” íŠ¹ë³„ ê¸ˆìœµ ìƒí’ˆì…ë‹ˆë‹¤. (1.0000)\n",
    "\n",
    "    ============================================================\n",
    "    ğŸš€ ì˜ˆì œ 4: ê¸°ë³¸ BM25 vs Kiwi BM25 ë¹„êµ\n",
    "    ============================================================\n",
    "\n",
    "    ğŸ” ê²€ìƒ‰ì–´: 'ê¸ˆìœµë³´í—˜'\n",
    "\n",
    "    ğŸ“Š Kiwi BM25 1ìœ„:\n",
    "    ê¸ˆìœµë³´í—˜ì€ ì¥ê¸°ì ì¸ ìì‚° ê´€ë¦¬ì™€ ìœ„í—˜ ëŒ€ë¹„ë¥¼ ëª©ì ìœ¼ë¡œ ê³ ì•ˆëœ ê¸ˆìœµ ìƒí’ˆì…ë‹ˆë‹¤.\n",
    "\n",
    "    ğŸ“Š ê¸°ë³¸ BM25 1ìœ„:\n",
    "    ê¸ˆìœµë‹¨í­ê²©ë³´í—˜ì€ ì €ì¶•ì€ ì»¤ë…• ìœ„í—˜ ëŒ€ë¹„ì— ì´ˆì ì„ ë§ì¶˜ ìƒí’ˆì…ë‹ˆë‹¤. ë†’ì€ ìœ„í—˜ì„ ê°ìˆ˜í•˜ê³ ì í•˜ëŠ” ê³ ê°ì—ê²Œ ì í•©í•©ë‹ˆë‹¤.\n",
    "\n",
    "    ğŸ’¡ ì°¨ì´ì :\n",
    "    âœ… Kiwiê°€ í˜•íƒœì†Œ ë¶„ì„ìœ¼ë¡œ ë” ì •í™•í•œ ê²°ê³¼ ë°˜í™˜!\n",
    "\n",
    "    ============================================================\n",
    "    âœ… ëª¨ë“  ì˜ˆì œ ì™„ë£Œ!\n",
    "    ============================================================\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b7628f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.korean_bm25_retriever import KoreanBM25Retriever, pretty_print\n",
    "\n",
    "# ë¬¸ì„œ ìƒì„±\n",
    "documents = [\n",
    "    \"Pythonì€ AI ê°œë°œì— ì í•©í•œ ì–¸ì–´ì…ë‹ˆë‹¤.\",\n",
    "    \"LangChainì€ RAG ì‹œìŠ¤í…œ êµ¬ì¶• í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.\",]\n",
    "\n",
    "# ê²€ìƒ‰ê¸° ìƒì„±í•˜ê¸°\n",
    "retriever = KoreanBM25Retriever.from_texts(\n",
    "    documents,\n",
    "    k=1                     # ìƒìœ„ 1ê°œë§Œ ë°˜í™˜\n",
    ")\n",
    "\n",
    "# ê²€ìƒ‰\n",
    "query = \"AI ê°œë°œ ë„êµ¬\"\n",
    "results = retriever.search_with_score(query)\n",
    "\n",
    "print(f\"ğŸ” ê²€ìƒ‰ì–´: {query}\")\n",
    "print(f\"ğŸ“Š ê²°ê³¼: {len(results)}ê°œ\\n\")\n",
    "\n",
    "for i, doc in enumerate(results):\n",
    "    score = doc.metadata.get('score', 0)\n",
    "    print(f\"[{i+1}] ì ìˆ˜: {score:.4f}\")\n",
    "    print(f\"    {doc.page_content}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780cbe06",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* ë¬¸ì„œë¡œ ê²€ìƒ‰í•´ë³´ê¸° (`0.9s`)\n",
    "\n",
    "    ```markdown\n",
    "    ğŸ” ê²€ìƒ‰ì–´: AI ê°œë°œ ë„êµ¬\n",
    "    ğŸ“Š ê²°ê³¼: 1ê°œ\n",
    "\n",
    "    [1] ì ìˆ˜: 0.0000\n",
    "        LangChainì€ RAG ì‹œìŠ¤í…œ êµ¬ì¶• í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f79ab39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.korean_bm25_retriever import KoreanBM25Retriever, pretty_print\n",
    "\n",
    "# êµì¬ ì˜ˆì‹œë¡œ í•´ë³´ê¸° \n",
    "\n",
    "documents = [\n",
    "    \"ê¸ˆìœµë³´í—˜ì€ ì¥ê¸°ì ì¸ ìì‚° ê´€ë¦¬ì™€ ìœ„í—˜ ëŒ€ë¹„ë¥¼ ëª©ì ìœ¼ë¡œ ê³ ì•ˆëœ ê¸ˆìœµ ìƒí’ˆì…ë‹ˆë‹¤.\",\n",
    "    \"ê¸ˆìœµì €ì¶•ì‚°ë¬¼ë³´í—˜ì€ ì¥ê¸°ì ì¸ ì €ì¶• ëª©ì ê³¼ ë”ë¶ˆì–´, ì¶•ì‚°ë¬¼ ì œê³µ ê¸°ëŠ¥ì„ ê°–ì¶”ê³  ìˆëŠ” íŠ¹ë³„ ê¸ˆìœµ ìƒí’ˆì…ë‹ˆë‹¤.\",\n",
    "    \"ê¸ˆìœµë³´ì”¨ í—˜í•œë§ ì¢€ í•˜ì§€ë§ˆì‹œê³ , ì €ì¶•ì´ë‚˜ ì¢€ í•˜ì‹œë˜ê°€ìš”. ë­ê°€ ê·¸ë¦¬ ê¸‰í•˜ì‹ ì§€ ëª¨ë¥´ê² ë„¤ìš”.\",\n",
    "    \"ê¸ˆìœµë‹¨í­ê²©ë³´í—˜ì€ ì €ì¶•ì€ ì»¤ë…• ìœ„í—˜ ëŒ€ë¹„ì— ì´ˆì ì„ ë§ì¶˜ ìƒí’ˆì…ë‹ˆë‹¤. ë†’ì€ ìœ„í—˜ì„ ê°ìˆ˜í•˜ê³ ì í•˜ëŠ” ê³ ê°ì—ê²Œ ì í•©í•©ë‹ˆë‹¤.\",\n",
    "]\n",
    "\n",
    "# ê²€ìƒ‰ê¸° ìƒì„±í•˜ê¸°\n",
    "retriever = KoreanBM25Retriever.from_texts(\n",
    "    documents,\n",
    "    k=2                         # ìƒìœ„ 2ê°œë§Œ ë°˜í™˜\n",
    ")\n",
    "\n",
    "# ê²€ìƒ‰\n",
    "query = \"ê¸ˆìœµë³´í—˜\"\n",
    "results = retriever.search_with_score(query)\n",
    "\n",
    "print(f\"ğŸ” ê²€ìƒ‰ì–´: {query}\")\n",
    "print(f\"ğŸ“Š ê²°ê³¼: {len(results)}ê°œ\\n\")\n",
    "\n",
    "for i, doc in enumerate(results):\n",
    "    score = doc.metadata.get('score', 0)\n",
    "    print(f\"[{i+1}] ì ìˆ˜: {score:.4f}\")\n",
    "    print(f\"    {doc.page_content}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e86abe9",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* êµì¬ ì† í…ìŠ¤íŠ¸ë¡œ test (`0.1s`)\n",
    "\n",
    "    ```markdown\n",
    "    ğŸ” ê²€ìƒ‰ì–´: ê¸ˆìœµë³´í—˜\n",
    "    ğŸ“Š ê²°ê³¼: 2ê°œ\n",
    "\n",
    "    [1] ì ìˆ˜: 1.0000\n",
    "        ê¸ˆìœµë³´í—˜ì€ ì¥ê¸°ì ì¸ ìì‚° ê´€ë¦¬ì™€ ìœ„í—˜ ëŒ€ë¹„ë¥¼ ëª©ì ìœ¼ë¡œ ê³ ì•ˆëœ ê¸ˆìœµ ìƒí’ˆì…ë‹ˆë‹¤.\n",
    "\n",
    "    [2] ì ìˆ˜: 1.0000\n",
    "        ê¸ˆìœµì €ì¶•ì‚°ë¬¼ë³´í—˜ì€ ì¥ê¸°ì ì¸ ì €ì¶• ëª©ì ê³¼ ë”ë¶ˆì–´, ì¶•ì‚°ë¬¼ ì œê³µ ê¸°ëŠ¥ì„ ê°–ì¶”ê³  ìˆëŠ” íŠ¹ë³„ ê¸ˆìœµ ìƒí’ˆì…ë‹ˆë‹¤.\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9813507d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a7d923",
   "metadata": {},
   "source": [
    "#### **4) `KonlPy` (`Kkma`, `Okt`) ì‚¬ìš©í•œ `BM25Retriever`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a10a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Kkma, Okt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# ë¬¸ì„œ ì¤€ë¹„\n",
    "documents = [\n",
    "    \"ì•ˆë…•í•˜ì„¸ìš”, í•œêµ­ì–´ ë¬¸ì„œ ê²€ìƒ‰ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.\",\n",
    "    \"ì´ ë¬¸ì„œëŠ” í•œêµ­ì–´ ë¬¸ì„œ ê²€ìƒ‰ì„ ìœ„í•œ ì˜ˆì œì…ë‹ˆë‹¤.\",\n",
    "    \"í•œêµ­ì–´ ë¬¸ì„œ ê²€ìƒ‰ì€ BM25 ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\"\n",
    "]\n",
    "\n",
    "# Kkma í˜•íƒœì†Œ ë¶„ì„ê¸° ì‚¬ìš©\n",
    "kkma = Kkma()\n",
    "kkma_tokens = [kkma.morphs(doc) for doc in documents]\n",
    "\n",
    "# Okt í˜•íƒœì†Œ ë¶„ì„ê¸° ì‚¬ìš©\n",
    "okt = Okt()\n",
    "okt_tokens = [okt.morphs(doc) for doc in documents]\n",
    "\n",
    "# TF-IDF ë²¡í„°í™”\n",
    "kkma_vectorizer = TfidfVectorizer()\n",
    "kkma_tfidf = kkma_vectorizer.fit_transform([' '.join(tokens) for tokens in kkma_tokens])\n",
    "\n",
    "okt_vectorizer = TfidfVectorizer()\n",
    "okt_tfidf = okt_vectorizer.fit_transform([' '.join(tokens) for tokens in okt_tokens])\n",
    "\n",
    "# ì¿¼ë¦¬ ì¤€ë¹„\n",
    "query = \"í•œêµ­ì–´ ë¬¸ì„œ ê²€ìƒ‰\"\n",
    "\n",
    "# Kkma í˜•íƒœì†Œ ë¶„ì„ê¸° ì‚¬ìš©\n",
    "kkma_query_tokens = kkma.morphs(query)\n",
    "kkma_query_tfidf = kkma_vectorizer.transform([' '.join(kkma_query_tokens)])\n",
    "\n",
    "# Okt í˜•íƒœì†Œ ë¶„ì„ê¸° ì‚¬ìš©\n",
    "okt_query_tokens = okt.morphs(query)\n",
    "okt_query_tfidf = okt_vectorizer.transform([' '.join(okt_query_tokens)])\n",
    "\n",
    "# ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°\n",
    "kkma_similarities = cosine_similarity(kkma_query_tfidf, kkma_tfidf)\n",
    "okt_similarities = cosine_similarity(okt_query_tfidf, okt_tfidf)\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(\"KkmaBM25Retriever ê²°ê³¼:\", [documents[i] for i in kkma_similarities.argsort()[0][::-1]])\n",
    "print(\"OktBM25Retriever ê²°ê³¼:\", [documents[i] for i in okt_similarities.argsort()[0][::-1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c46a565",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* `Kkma`, `Okt` (`14.1s`)\n",
    "\n",
    "    ```markdown\n",
    "    \n",
    "    KkmaBM25Retriever ê²°ê³¼: ['ì´ ë¬¸ì„œëŠ” í•œêµ­ì–´ ë¬¸ì„œ ê²€ìƒ‰ì„ ìœ„í•œ ì˜ˆì œì…ë‹ˆë‹¤.', 'ì•ˆë…•í•˜ì„¸ìš”, í•œêµ­ì–´ ë¬¸ì„œ ê²€ìƒ‰ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.', 'í•œêµ­ì–´ ë¬¸ì„œ ê²€ìƒ‰ì€ BM25 ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.']\n",
    "\n",
    "    OktBM25Retriever ê²°ê³¼: ['ì´ ë¬¸ì„œëŠ” í•œêµ­ì–´ ë¬¸ì„œ ê²€ìƒ‰ì„ ìœ„í•œ ì˜ˆì œì…ë‹ˆë‹¤.', 'ì•ˆë…•í•˜ì„¸ìš”, í•œêµ­ì–´ ë¬¸ì„œ ê²€ìƒ‰ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.', 'í•œêµ­ì–´ ë¬¸ì„œ ê²€ìƒ‰ì€ BM25 ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.']\n",
    "    \n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a500ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Kkma, Okt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# ë¬¸ì„œ ì¤€ë¹„\n",
    "sample_texts = [\n",
    "    \"ê¸ˆìœµë³´í—˜ì€ ì¥ê¸°ì ì¸ ìì‚° ê´€ë¦¬ì™€ ìœ„í—˜ ëŒ€ë¹„ë¥¼ ëª©ì ìœ¼ë¡œ ê³ ì•ˆëœ ê¸ˆìœµ ìƒí’ˆì…ë‹ˆë‹¤.\",\n",
    "    \"ê¸ˆìœµì €ì¶•ì‚°ë¬¼ë³´í—˜ì€ ì¥ê¸°ì ì¸ ì €ì¶• ëª©ì ê³¼ ë”ë¶ˆì–´, ì¶•ì‚°ë¬¼ ì œê³µ ê¸°ëŠ¥ì„ ê°–ì¶”ê³  ìˆëŠ” íŠ¹ë³„ ê¸ˆìœµ ìƒí’ˆì…ë‹ˆë‹¤.\",\n",
    "    \"ê¸ˆìœµë³´ì”¨ í—˜í•œë§ ì¢€ í•˜ì§€ë§ˆì‹œê³ , ì €ì¶•ì´ë‚˜ ì¢€ í•˜ì‹œë˜ê°€ìš”. ë­ê°€ ê·¸ë¦¬ ê¸‰í•˜ì‹ ì§€ ëª¨ë¥´ê² ë„¤ìš”.\",\n",
    "    \"ê¸ˆìœµë‹¨í­ê²©ë³´í—˜ì€ ì €ì¶•ì€ ì»¤ë…• ìœ„í—˜ ëŒ€ë¹„ì— ì´ˆì ì„ ë§ì¶˜ ìƒí’ˆì…ë‹ˆë‹¤. ë†’ì€ ìœ„í—˜ì„ ê°ìˆ˜í•˜ê³ ì í•˜ëŠ” ê³ ê°ì—ê²Œ ì í•©í•©ë‹ˆë‹¤.\",\n",
    "]\n",
    "\n",
    "# Kkma í˜•íƒœì†Œ ë¶„ì„ê¸° ì‚¬ìš©\n",
    "kkma = Kkma()\n",
    "kkma_tokens = [kkma.morphs(doc) for doc in documents]\n",
    "\n",
    "# Okt í˜•íƒœì†Œ ë¶„ì„ê¸° ì‚¬ìš©\n",
    "okt = Okt()\n",
    "okt_tokens = [okt.morphs(doc) for doc in documents]\n",
    "\n",
    "# TF-IDF ë²¡í„°í™”\n",
    "kkma_vectorizer = TfidfVectorizer()\n",
    "kkma_tfidf = kkma_vectorizer.fit_transform([' '.join(tokens) for tokens in kkma_tokens])\n",
    "\n",
    "okt_vectorizer = TfidfVectorizer()\n",
    "okt_tfidf = okt_vectorizer.fit_transform([' '.join(tokens) for tokens in okt_tokens])\n",
    "\n",
    "# ì¿¼ë¦¬ ì¤€ë¹„\n",
    "query = \"ê¸ˆìœµë³´í—˜\"\n",
    "\n",
    "# Kkma í˜•íƒœì†Œ ë¶„ì„ê¸° ì‚¬ìš©\n",
    "kkma_query_tokens = kkma.morphs(query)\n",
    "kkma_query_tfidf = kkma_vectorizer.transform([' '.join(kkma_query_tokens)])\n",
    "\n",
    "# Okt í˜•íƒœì†Œ ë¶„ì„ê¸° ì‚¬ìš©\n",
    "okt_query_tokens = okt.morphs(query)\n",
    "okt_query_tfidf = okt_vectorizer.transform([' '.join(okt_query_tokens)])\n",
    "\n",
    "# ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°\n",
    "kkma_similarities = cosine_similarity(kkma_query_tfidf, kkma_tfidf)\n",
    "okt_similarities = cosine_similarity(okt_query_tfidf, okt_tfidf)\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(\"KkmaBM25Retriever ê²°ê³¼:\", [documents[i] for i in kkma_similarities.argsort()[0][::-1]])\n",
    "print(\"OktBM25Retriever ê²°ê³¼:\", [documents[i] for i in okt_similarities.argsort()[0][::-1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7e7000",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* êµì¬ ì† í…ìŠ¤íŠ¸ë¡œ í…ŒìŠ¤íŠ¸í•´ë³´ê¸° (`1.5s`)\n",
    "\n",
    "    ```markdown\n",
    "\n",
    "    KkmaBM25Retriever ê²°ê³¼: ['ê¸ˆìœµë³´í—˜ì€ ì¥ê¸°ì ì¸ ìì‚° ê´€ë¦¬ì™€ ìœ„í—˜ ëŒ€ë¹„ë¥¼ ëª©ì ìœ¼ë¡œ ê³ ì•ˆëœ ê¸ˆìœµ ìƒí’ˆì…ë‹ˆë‹¤.', 'ê¸ˆìœµì €ì¶•ì‚°ë¬¼ë³´í—˜ì€ ì¥ê¸°ì ì¸ ì €ì¶• ëª©ì ê³¼ ë”ë¶ˆì–´, ì¶•ì‚°ë¬¼ ì œê³µ ê¸°ëŠ¥ì„ ê°–ì¶”ê³  ìˆëŠ” íŠ¹ë³„ ê¸ˆìœµ ìƒí’ˆì…ë‹ˆë‹¤.', 'ê¸ˆìœµë³´ì”¨ í—˜í•œë§ ì¢€ í•˜ì§€ë§ˆì‹œê³ , ì €ì¶•ì´ë‚˜ ì¢€ í•˜ì‹œë˜ê°€ìš”. ë­ê°€ ê·¸ë¦¬ ê¸‰í•˜ì‹ ì§€ ëª¨ë¥´ê² ë„¤ìš”.', 'ê¸ˆìœµë‹¨í­ê²©ë³´í—˜ì€ ì €ì¶•ì€ ì»¤ë…• ìœ„í—˜ ëŒ€ë¹„ì— ì´ˆì ì„ ë§ì¶˜ ìƒí’ˆì…ë‹ˆë‹¤. ë†’ì€ ìœ„í—˜ì„ ê°ìˆ˜í•˜ê³ ì í•˜ëŠ” ê³ ê°ì—ê²Œ ì í•©í•©ë‹ˆë‹¤.']\n",
    "    \n",
    "    OktBM25Retriever ê²°ê³¼: ['ê¸ˆìœµë³´í—˜ì€ ì¥ê¸°ì ì¸ ìì‚° ê´€ë¦¬ì™€ ìœ„í—˜ ëŒ€ë¹„ë¥¼ ëª©ì ìœ¼ë¡œ ê³ ì•ˆëœ ê¸ˆìœµ ìƒí’ˆì…ë‹ˆë‹¤.', 'ê¸ˆìœµì €ì¶•ì‚°ë¬¼ë³´í—˜ì€ ì¥ê¸°ì ì¸ ì €ì¶• ëª©ì ê³¼ ë”ë¶ˆì–´, ì¶•ì‚°ë¬¼ ì œê³µ ê¸°ëŠ¥ì„ ê°–ì¶”ê³  ìˆëŠ” íŠ¹ë³„ ê¸ˆìœµ ìƒí’ˆì…ë‹ˆë‹¤.', 'ê¸ˆìœµë‹¨í­ê²©ë³´í—˜ì€ ì €ì¶•ì€ ì»¤ë…• ìœ„í—˜ ëŒ€ë¹„ì— ì´ˆì ì„ ë§ì¶˜ ìƒí’ˆì…ë‹ˆë‹¤. ë†’ì€ ìœ„í—˜ì„ ê°ìˆ˜í•˜ê³ ì í•˜ëŠ” ê³ ê°ì—ê²Œ ì í•©í•©ë‹ˆë‹¤.', 'ê¸ˆìœµë³´ì”¨ í—˜í•œë§ ì¢€ í•˜ì§€ë§ˆì‹œê³ , ì €ì¶•ì´ë‚˜ ì¢€ í•˜ì‹œë˜ê°€ìš”. ë­ê°€ ê·¸ë¦¬ ê¸‰í•˜ì‹ ì§€ ëª¨ë¥´ê² ë„¤ìš”.']\n",
    "\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be820c94",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452e4cd7",
   "metadata": {},
   "source": [
    "* `BM25 Retriever` vs `kkma`, `okt` \n",
    "\n",
    "| êµ¬ë¶„                     | í˜•íƒœì†Œ ë¶„ì„ê¸° / ê²€ìƒ‰ ë„êµ¬                  | ì—­í•  (ì¤‘í•™ìƒ ëˆˆë†’ì´ ì„¤ëª…)                                              | ì¥ì  (Pros) ğŸ‘                                                  | ë‹¨ì  (Cons) ğŸ‘                                                                    |\n",
    "|------------------------|----------------------------------|--------------------------------------------------------------|---------------------------------------------------------------|---------------------------------------------------------------------------------|\n",
    "| **`BM25 Retriever`**         | ê²€ìƒ‰ ì•Œê³ ë¦¬ì¦˜ (Retrieval Algorithm)    | ì§ˆë¬¸(Query)ì— ëŒ€í•´ ê°€ì¥ ê´€ë ¨ì„±ì´ ë†’ì€ ë¬¸ì„œë¥¼ ì°¾ì•„ì£¼ëŠ” 'ë˜‘ë˜‘í•œ ë„ì„œê´€ ì‚¬ì„œ' ì—­í•       | ì„±ëŠ¥ì´ ì•ˆì •ì ì´ê³  ì „í†µì ì¸ ê²€ìƒ‰ ë°©ë²• ì¤‘ì—ì„œ ë§¤ìš° ë›°ì–´ë‚¨ / í‚¤ì›Œë“œê°€ ì§ˆë¬¸ê³¼ ë§ì´ ê²¹ì¹ ìˆ˜ë¡ ì ìˆ˜ë¥¼ ì˜ ì¤Œ | ë‹¨ì–´ì˜ **'ì˜ë¯¸'** ë¥¼ ì´í•´í•˜ì§€ ëª»í•˜ê³ , í‚¤ì›Œë“œê°€ ë¬¸ì„œì— ì •í™•íˆ ìˆì–´ì•¼ ì˜ ì°¾ëŠ” í¸ / ìµœì‹  ì¸ê³µì§€ëŠ¥ ë°©ì‹(ë²¡í„° ê²€ìƒ‰)ê³¼ í•¨ê»˜ ì¨ì•¼ ë” ì¢‹ìŒ |\n",
    "| **`kkma`** (ê¼¬ê¼¬ë§ˆ)             | í˜•íƒœì†Œ ë¶„ì„ê¸° (Morphological Analyzer) | í•œêµ­ì–´ ë¬¸ì¥ì„ ì•„ì£¼ ê¼¼ê¼¼í•˜ê³  ê·œì¹™ì— ë§ê²Œ ë‹¨ì–´(í˜•íƒœì†Œ) ë‹¨ìœ„ë¡œ ìë¥´ëŠ” 'ì •êµí•œ ì¹¼' ì—­í•       | ì •í™•ë„ê°€ ë†’ê³ , ë¬¸ë²•ì ì¸ ë¶„ì„ì„ ì„¸ë°€í•˜ê²Œ ì˜í•´ì„œ í•™ìˆ ì ì¸ ì—°êµ¬ë‚˜ ì—„ê²©í•œ ë¶„ì„ì— ì í•©             | ì²˜ë¦¬ ì†ë„ê°€ ëŠë¦¬ê³ , ë¶„ì„ ê·œì¹™ì´ ë³µì¡í•´ì„œ ë¹„í‘œì¤€ì–´(ì¤„ì„ë§, ì¸í„°ë„· ìš©ì–´)ì—ëŠ” ì•½í•¨                                |\n",
    "| **`okt`** (Open Korean Text) | í˜•íƒœì†Œ ë¶„ì„ê¸° (Morphological Analyzer) | í•œêµ­ì–´ ë¬¸ì¥ì„ ë¹ ë¥´ê³  ìœ ì—°í•˜ê²Œ ë‹¨ì–´(ì–´ì ˆ) ë‹¨ìœ„ë¡œ ìë¥´ëŠ” 'ë¹ ë¥¸ ì¹¼' ì—­í•  / ì¹´ì¹´ì˜¤ì—ì„œ ë§Œë“¦ | ì²˜ë¦¬ ì†ë„ê°€ ë§¤ìš° ë¹ ë¥´ê³ , ì¸í„°ë„· ìš©ì–´ë‚˜ ì˜¤íƒ€ ê°™ì€ ë¹„í‘œì¤€ì–´ë¥¼ ë¹„êµì  ì˜ ì²˜ë¦¬ / ì‚¬ìš©í•˜ê¸° ê°„í¸    | kkmaë³´ë‹¤ ë¶„ì„ ë‹¨ìœ„ê°€ ì»¤ì„œ ì„¸ë°€í•œ ë¬¸ë²• ë¶„ì„ì—ëŠ” ì•½ê°„ ë¶ˆë¦¬í•  ìˆ˜ ìˆìŒ                                      |\n",
    "\n",
    "  * ì‰¬ìš´ ì„¤ëª…\n",
    "\n",
    "    * `BM25 Retriever` (â‰’ ì‚¬ì„œ)\n",
    "      * êµ¬ê¸€, ë„¤ì´ë²„ì— ê²€ìƒ‰í–ˆì„ ë•Œ ê´€ë ¨ì„± ë†’ì€ ê²°ê³¼ë¥¼ ë³´ì—¬ì£¼ëŠ” ë°©ì‹ê³¼ ë¹„ìŠ·\n",
    "      * **`ì§ˆë¬¸ê³¼ ê²¹ì¹˜ëŠ” ë‹¨ì–´ê°€ ë§ì„ìˆ˜ë¡`**, **`ê·¸ ë‹¨ì–´ê°€ ë‹¤ë¥¸ ë¬¸ì„œì—ëŠ” í”í•˜ì§€ ì•Šì„ìˆ˜ë¡`** ê·¸ ë¬¸ì„œë¥¼ ê°€ì¥ ì¤‘ìš”í•œ ê²ƒìœ¼ë¡œ ë½‘ì•„ì¤Œ\n",
    "      * **`ì•™ìƒë¸” ê²€ìƒ‰`** = ìµœê·¼ì—ëŠ” `BM25 Retreiver` + `Vector Search` í•¨ê»˜ ì‚¬ìš© â†’ ê²€ìƒ‰ ì„±ëŠ¥ â†‘\n",
    "\n",
    "\n",
    "    * `kkma`, `okt` (â‰’ `ì¹¼`ì˜ ì¢…ë¥˜)\n",
    "      * **`í˜•íƒœì†Œ ë¶„ì„ê¸°`** = ë‘˜ ë‹¤ ì»´í“¨í„°ê°€ í•œêµ­ì–´ ë¬¸ì¥ì˜ ëœ»ì„ ì´í•´í•˜ë„ë¡ **`ë‹¨ì–´ ë‹¨ìœ„ë¡œ ìª¼ê°œì£¼ëŠ” ë„êµ¬`**\n",
    "      * `kkma` â‰’ ë¬¸ë²• ê·œì¹™ì„ ì² ì €íˆ ë”°ë¥´ëŠ” **`í•™ì`** â†’ ëŠë¦¬ì§€ë§Œ ì •í™• / ë…¼ë¬¸ ë¶„ì„ì— ìœ ìš©\n",
    "      * `okt` â‰’ ì‹¤ìš©ì , ë¹ ë¥¸ **`í˜„ì¥ ì „ë¬¸ê°€`** â†’ ì¸í„°ë„· ìš©ì–´ ë¹ ë¥´ê²Œ ì²˜ë¦¬ ê°€ëŠ¥ / ìˆ˜ë§ì€ ëŒ“ê¸€, SNS ë°ì´í„° ë¶„ì„ì— ìœ ìš©"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1497f6fc",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884391ad",
   "metadata": {},
   "source": [
    "* next: **`Convex Combination(CC) ì ìš©ëœ ì•™ìƒë¸” ê²€ìƒ‰ê¸° (EnsembleRetriever)`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403ac8ee",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lc_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
