{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70a79bc3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7062113",
   "metadata": {},
   "source": [
    "* 출처: LangChain 공식 문서 또는 해당 교재명\n",
    "* 원본 URL: https://smith.langchain.com/hub/teddynote/summary-stuff-documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79eccb97",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ab2017",
   "metadata": {},
   "source": [
    "### **10. `한글 형태소 분석기(Kiwi, Kkma, Okt) + BM25 검색기`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519bf8c2",
   "metadata": {},
   "source": [
    "#### **`1) 한글 형태소 분석기와 BM25Retriever의 결합`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1701264",
   "metadata": {},
   "source": [
    "* 깔끔하게 출력결과를 확인하기 위한 함수를 정의하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87447bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print(docs):\n",
    "    for i, doc in enumerate(docs):\n",
    "        if \"score\" in doc.metadata:\n",
    "            print(f\"[{i+1}] {doc.page_content} ({doc.metadata['score']:.4f})\")\n",
    "        else:\n",
    "            print(f\"[{i+1}] {doc.page_content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b65a190",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a006c3",
   "metadata": {},
   "source": [
    "#### **2) `Kiwi 토크나이저 사용 및 모델 만들어보기`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5cc1ee",
   "metadata": {},
   "source": [
    "* 사전에 `VS Code` 터미널에 설치할 것\n",
    "\n",
    "```bash\n",
    "\n",
    "        pip install kiwipiepy                   # Kiwi 토크나이저 설치\n",
    "\n",
    "        python -m kiwipiepy download            # Kiwi 모델 다운로드\n",
    "\n",
    "```\n",
    "\n",
    "  * 가상 환경을 사용하고 있다면 **`해당 가상환경 활성화한 후 그곳에 설치할 것`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375d7a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kiwipiepy.Token 객체 구조 확인해보기\n",
    "\n",
    "from kiwipiepy import Kiwi\n",
    "\n",
    "kiwi = Kiwi()\n",
    "tokens = kiwi.tokenize(\"안녕하세요, Kiwi 토크나이저를 사용해보겠습니다.\")\n",
    "for token in tokens:\n",
    "    print(dir(token))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1364e52",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* kiwipiepy.Token 객체의 속성 확인\n",
    "\n",
    "    ```python\n",
    "    ['__class__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__len__', '__lt__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', 'base_form', 'base_id', 'end', 'form', 'form_tag', 'id', 'lemma', 'len', 'line_number', 'paired_token', 'raw_form', 'regularity', 'score', 'script', 'sense', 'sent_position', 'span', 'start', 'sub_sent_position', 'tag', 'tagged_form', 'typo_cost', 'user_value', 'word_position']\n",
    "    ['__class__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__len__', '__lt__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', 'base_form', 'base_id', 'end', 'form', 'form_tag', 'id', 'lemma', 'len', 'line_number', 'paired_token', 'raw_form', 'regularity', 'score', 'script', 'sense', 'sent_position', 'span', 'start', 'sub_sent_position', 'tag', 'tagged_form', 'typo_cost', 'user_value', 'word_position']\n",
    "    ['__class__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__len__', '__lt__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', 'base_form', 'base_id', 'end', 'form', 'form_tag', 'id', 'lemma', 'len', 'line_number', 'paired_token', 'raw_form', 'regularity', 'score', 'script', 'sense', 'sent_position', 'span', 'start', 'sub_sent_position', 'tag', 'tagged_form', 'typo_cost', 'user_value', 'word_position']\n",
    "    ['__class__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__len__', '__lt__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', 'base_form', 'base_id', 'end', 'form', 'form_tag', 'id', 'lemma', 'len', 'line_number', 'paired_token', 'raw_form', 'regularity', 'score', 'script', 'sense', 'sent_position', 'span', 'start', 'sub_sent_position', 'tag', 'tagged_form', 'typo_cost', 'user_value', 'word_position']\n",
    "    ['__class__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__len__', '__lt__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', 'base_form', 'base_id', 'end', 'form', 'form_tag', 'id', 'lemma', 'len', 'line_number', 'paired_token', 'raw_form', 'regularity', 'score', 'script', 'sense', 'sent_position', 'span', 'start', 'sub_sent_position', 'tag', 'tagged_form', 'typo_cost', 'user_value', 'word_position']\n",
    "    ['__class__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__len__', '__lt__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', 'base_form', 'base_id', 'end', 'form', 'form_tag', 'id', 'lemma', 'len', 'line_number', 'paired_token', 'raw_form', 'regularity', 'score', 'script', 'sense', 'sent_position', 'span', 'start', 'sub_sent_position', 'tag', 'tagged_form', 'typo_cost', 'user_value', 'word_position']\n",
    "    ['__class__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__len__', '__lt__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', 'base_form', 'base_id', 'end', 'form', 'form_tag', 'id', 'lemma', 'len', 'line_number', 'paired_token', 'raw_form', 'regularity', 'score', 'script', 'sense', 'sent_position', 'span', 'start', 'sub_sent_position', 'tag', 'tagged_form', 'typo_cost', 'user_value', 'word_position']\n",
    "    ['__class__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__len__', '__lt__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', 'base_form', 'base_id', 'end', 'form', 'form_tag', 'id', 'lemma', 'len', 'line_number', 'paired_token', 'raw_form', 'regularity', 'score', 'script', 'sense', 'sent_position', 'span', 'start', 'sub_sent_position', 'tag', 'tagged_form', 'typo_cost', 'user_value', 'word_position']\n",
    "    ['__class__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__len__', '__lt__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', 'base_form', 'base_id', 'end', 'form', 'form_tag', 'id', 'lemma', 'len', 'line_number', 'paired_token', 'raw_form', 'regularity', 'score', 'script', 'sense', 'sent_position', 'span', 'start', 'sub_sent_position', 'tag', 'tagged_form', 'typo_cost', 'user_value', 'word_position']\n",
    "    ['__class__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__len__', '__lt__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', 'base_form', 'base_id', 'end', 'form', 'form_tag', 'id', 'lemma', 'len', 'line_number', 'paired_token', 'raw_form', 'regularity', 'score', 'script', 'sense', 'sent_position', 'span', 'start', 'sub_sent_position', 'tag', 'tagged_form', 'typo_cost', 'user_value', 'word_position']\n",
    "    ['__class__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__len__', '__lt__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', 'base_form', 'base_id', 'end', 'form', 'form_tag', 'id', 'lemma', 'len', 'line_number', 'paired_token', 'raw_form', 'regularity', 'score', 'script', 'sense', 'sent_position', 'span', 'start', 'sub_sent_position', 'tag', 'tagged_form', 'typo_cost', 'user_value', 'word_position']\n",
    "    ['__class__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__len__', '__lt__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', 'base_form', 'base_id', 'end', 'form', 'form_tag', 'id', 'lemma', 'len', 'line_number', 'paired_token', 'raw_form', 'regularity', 'score', 'script', 'sense', 'sent_position', 'span', 'start', 'sub_sent_position', 'tag', 'tagged_form', 'typo_cost', 'user_value', 'word_position']\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af26c119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kiwi 기본 사용해보기\n",
    "\n",
    "from kiwipiepy import Kiwi\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"🚀 Kiwi 한글 형태소 분석기 테스트\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Kiwi 인스턴스 생성\n",
    "kiwi = Kiwi()\n",
    "\n",
    "# 텍스트 준비\n",
    "text = \"안녕하세요, Kiwi 토크나이저를 사용해보겠습니다.\"\n",
    "\n",
    "print(f\"📝 원본 텍스트: {text}\")\n",
    "print()\n",
    "\n",
    "# 형태소 분석\n",
    "tokens = kiwi.tokenize(text)\n",
    "\n",
    "#print(\"🔍 형태소 분석 결과:\")\n",
    "#for i, token in enumerate(tokens):\n",
    "#    print(f\"[{i+1:2d}] {token.form:12s} | {token.tag:8s} | {token.prob:.4f}\")   → prob 속성이 없어 오류 발생\n",
    "\n",
    "print(\"🔍 형태소 분석 결과:\")\n",
    "for i, token in enumerate(tokens):\n",
    "    print(f\"[{i+1:2d}] {token.form:12s} | {token.tag:8s} | {token.score:.4f}\")   # 속성 확인 후 score로 수정\n",
    "\n",
    "print()\n",
    "print(\"💡 주요 형태소만 추출:\")\n",
    "keywords = [token.form for token in tokens if token.tag in ['NNG', 'NNP', 'VV', 'VA']]\n",
    "print(f\"키워드: {keywords}\")\n",
    "\n",
    "print(\"\\n✅ Kiwi 테스트 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f368fa5",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 형태소 분석 테스트\n",
    "\n",
    "    ```markdown\n",
    "    ============================================================\n",
    "    🚀 Kiwi 한글 형태소 분석기 테스트\n",
    "    ============================================================\n",
    "    📝 원본 텍스트: 안녕하세요, Kiwi 토크나이저를 사용해보겠습니다.\n",
    "\n",
    "    🔍 형태소 분석 결과:\n",
    "    [ 1] 안녕하세요        | NNP       | -24.9607\n",
    "    [ 2] ,              | SP        | -3.4208\n",
    "    [ 3] Kiwi           | SL        | -4.6044\n",
    "    [ 4] 토크나이저        | NNG       | -34.9031\n",
    "    [ 5] 를              | JKO       | -2.6550\n",
    "    [ 6] 사용            | NNG       | -6.3823\n",
    "    [ 7] 하             | XSV       | -1.0495\n",
    "    [ 8] 어             | EC        | -1.0495\n",
    "    [ 9] 보             | VX        | -2.1494\n",
    "    [10] 겠             | EP        | -3.5714\n",
    "    [11] 습니다          | EF        | -0.7610\n",
    "    [12] .             | SF        | -0.2585\n",
    "\n",
    "    💡 주요 형태소만 추출:\n",
    "    키워드: ['안녕하세요', '토크나이저', '사용']\n",
    "\n",
    "    ✅ Kiwi 테스트 완료!\n",
    "    ```\n",
    "\n",
    "---\n",
    "\n",
    "* **`Kiwi`** 의 `Score` = `log probability`\n",
    "\n",
    "  * `Kiwi` = `log-likelihood` 방식 사용\n",
    "\n",
    "  * 확률은 `0~1` 사이지만, `log`를 취하면 `음수`가 됨\n",
    "    * 값이 `0`에 가까울수록 `확률이 높음` **(좋음)**\n",
    "    * 값이 `-무한대`로 갈수록 `확률이 낮음` **(나쁨)**\n",
    "\n",
    "    * 예시\n",
    "```python\n",
    "\n",
    "        확률 1.0   → log(1.0)   = 0.0      (최상)\n",
    "        확률 0.5   → log(0.5)   = -0.69    (중간)\n",
    "        확률 0.01  → log(0.01)  = -4.61    (낮음)\n",
    "        확률 0.0001 → log(0.0001) = -9.21   (매우 낮음)\n",
    "\n",
    "```\n",
    "   \n",
    "   * 위의 결과\n",
    "```python\n",
    "\n",
    "        [ 1] 안녕하세요   | NNP   | -24.9607  (낮음 - 고유명사로 잘못 분석)\n",
    "        [11] 습니다      | EF    | -0.7610   (높음 - 확실한 어미)\n",
    "        [12] .         | SF     | -0.2585   (매우 높음 - 확실한 구두점)\n",
    "\n",
    "    # → 코드 수정 필요\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ba0254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 수정된 코드로 Kiwi 다시 사용해보기 \n",
    "\n",
    "from kiwipiepy import Kiwi\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"🚀 Kiwi 한글 형태소 분석기 테스트\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Kiwi 인스턴스 생성\n",
    "kiwi = Kiwi()\n",
    "\n",
    "# 텍스트 준비\n",
    "text = \"안녕하세요, Kiwi 토크나이저를 사용해보겠습니다.\"\n",
    "\n",
    "print(f\"📝 원본 텍스트: {text}\")\n",
    "print()\n",
    "\n",
    "# 형태소 분석\n",
    "tokens = kiwi.tokenize(text)\n",
    "\n",
    "print(\"🔍 형태소 분석 결과 (원본):\")\n",
    "print(f\"{'번호':<4} {'형태소':<15} {'품사':<8} {'점수(로그확률)':<15}\")\n",
    "print(\"-\" * 50)\n",
    "for i, token in enumerate(tokens):\n",
    "    print(f\"[{i+1:2d}] {token.form:<15s} {token.tag:<8s} {token.score:>12.4f}\")\n",
    "\n",
    "print()\n",
    "\n",
    "# 확률로 변환해서 보기\n",
    "print(\"🔍 형태소 분석 결과 (확률 변환):\")\n",
    "print(f\"{'번호':<4} {'형태소':<15} {'품사':<8} {'확률':<15}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "import math\n",
    "for i, token in enumerate(tokens):\n",
    "    # log 확률 → 확률 변환\n",
    "    probability = math.exp(token.score)\n",
    "    print(f\"[{i+1:2d}] {token.form:<15s} {token.tag:<8s} {probability:>12.8f}\")\n",
    "\n",
    "print()\n",
    "print(\"💡 주요 형태소만 추출:\")\n",
    "keywords = [token.form for token in tokens if token.tag in ['NNG', 'NNP', 'VV', 'VA']]\n",
    "print(f\"키워드: {keywords}\")\n",
    "\n",
    "print()\n",
    "print(\"📊 가장 확실한 토큰 TOP 3:\")\n",
    "# score 기준 정렬 (0에 가까울수록 확실)\n",
    "sorted_tokens = sorted(tokens, key=lambda t: t.score, reverse=True)\n",
    "for i, token in enumerate(sorted_tokens[:3]):\n",
    "    prob = math.exp(token.score)\n",
    "    print(f\"[{i+1}] {token.form:<10s} | {token.tag:<6s} | score: {token.score:>8.4f} | prob: {prob:.6f}\")\n",
    "\n",
    "print(\"\\n✅ Kiwi 테스트 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7fe6dc",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 수정된 코드로 테스트한 `Kiwi test`\n",
    "\n",
    "    ```markdown\n",
    "    ============================================================\n",
    "    🚀 Kiwi 한글 형태소 분석기 테스트\n",
    "    ============================================================\n",
    "    📝 원본 텍스트: 안녕하세요, Kiwi 토크나이저를 사용해보겠습니다.\n",
    "\n",
    "    🔍 형태소 분석 결과 (원본):\n",
    "    번호   형태소             품사       점수(로그확률)       \n",
    "    --------------------------------------------------\n",
    "    [ 1] 안녕하세요           NNP          -24.9607\n",
    "    [ 2] ,                 SP           -3.4208\n",
    "    [ 3] Kiwi              SL           -4.6044\n",
    "    [ 4] 토크나이저           NNG          -34.9031\n",
    "    [ 5] 를                JKO           -2.6550\n",
    "    [ 6] 사용               NNG           -6.3823\n",
    "    [ 7] 하                XSV           -1.0495\n",
    "    [ 8] 어                EC            -1.0495\n",
    "    [ 9] 보                VX            -2.1494\n",
    "    [10] 겠                EP            -3.5714\n",
    "    [11] 습니다             EF            -0.7610\n",
    "    [12] .                SF            -0.2585\n",
    "\n",
    "    🔍 형태소 분석 결과 (확률 변환):\n",
    "    번호   형태소             품사          확률             \n",
    "    --------------------------------------------------\n",
    "    [ 1] 안녕하세요           NNP         0.00000000\n",
    "    [ 2] ,                 SP          0.03268630\n",
    "    [ 3] Kiwi              SL          0.01000789\n",
    "    [ 4] 토크나이저           NNG         0.00000000\n",
    "    [ 5] 를                JKO         0.07029892\n",
    "    [ 6] 사용               NNG         0.00169127\n",
    "    [ 7] 하                XSV         0.35009691\n",
    "    [ 8] 어                EC          0.35009691\n",
    "    [ 9] 보                VX          0.11655688\n",
    "    [10] 겠                EP          0.02811701\n",
    "    [11] 습니다             EF          0.46719469\n",
    "    [12] .                SF          0.77223326\n",
    "\n",
    "    💡 주요 형태소만 추출:\n",
    "    키워드: ['안녕하세요', '토크나이저', '사용']\n",
    "\n",
    "    📊 가장 확실한 토큰 TOP 3:\n",
    "    [1] .           | SF       | score:  -0.2585   | prob: 0.772233\n",
    "    [2] 습니다        | EF      | score:  -0.7610   |  prob: 0.467195\n",
    "    [3] 하           | XSV     | score:  -1.0495   |  prob: 0.350097\n",
    "\n",
    "    ✅ Kiwi 테스트 완료!\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c261b4f8",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* `Score` 해석해보기\n",
    "\n",
    "  * `로그 확률 (score)`의 의미\n",
    "\n",
    "  | score 범위 | 의미 | 예시 |\n",
    "  |-----------|------|------|\n",
    "  | **0 ~ -1** | 매우 확실 | 구두점(.), 조사(를) |\n",
    "  | **-1 ~ -5** | 확실 | 일반 동사, 명사 |\n",
    "  | **-5 ~ -10** | 보통 | 외래어, 복합어 |\n",
    "  | **-10 이하** | 불확실 | 미등록어, 드문 단어 |\n",
    "\n",
    "<br>\n",
    "\n",
    "*  * 위 결과 해석 \n",
    "```python\n",
    "\n",
    "        -0.2585  (.)        →       99.7% 확신 (구두점은 확실함)\n",
    "        -0.7610  (습니다)     →       46.7% 확신 (어미는 확실함)\n",
    "        -24.9607 (안녕하세요)  →       0.0000...% (거의 불가능 - NNP로 분석한 게 잘못)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4e7812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실전: 신뢰도 기반 필터링\n",
    "\n",
    "from kiwipiepy import Kiwi\n",
    "import math\n",
    "\n",
    "def analyze_with_confidence(text, confidence_threshold=-10.0):\n",
    "    \"\"\"\n",
    "    신뢰도 기반 형태소 분석\n",
    "    confidence_threshold: 이 값보다 높은(덜 음수인) 토큰만 반환\n",
    "    \"\"\"\n",
    "    kiwi = Kiwi()\n",
    "    tokens = kiwi.tokenize(text)\n",
    "    \n",
    "    # 신뢰도 높은 토큰만 필터링\n",
    "    confident_tokens = [\n",
    "        token for token in tokens \n",
    "        if token.score > confidence_threshold                   # -10.0보다 크면 (덜 음수면)\n",
    "        and token.tag in ['NNG', 'NNP', 'VV', 'VA', 'SL']       # 의미있는 품사\n",
    "    ]\n",
    "    \n",
    "    print(f\"📝 원본: {text}\")\n",
    "    print(f\"✅ 신뢰도 높은 키워드 (threshold={confidence_threshold}):\")\n",
    "    \n",
    "    for token in confident_tokens:\n",
    "        prob = math.exp(token.score)\n",
    "        print(f\"  - {token.form:<12s} | {token.tag:<6s} | score: {token.score:>8.4f} | prob: {prob:.4f}\")\n",
    "    \n",
    "    return [token.form for token in confident_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb75146",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "    \"Python은 AI 개발에 적합한 언어입니다.\",\n",
    "    \"LangChain과 Kiwi를 활용한 검색 시스템\",\n",
    "    \"형태소 분석은 자연어 처리의 기초입니다.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aacfad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트\n",
    "print(\"=\" * 60)\n",
    "print(\"🚀 신뢰도 기반 키워드 추출\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for text in texts:\n",
    "    keywords = analyze_with_confidence(text, confidence_threshold=-10.0)\n",
    "    print(f\"  → 키워드: {keywords}\\n\")\n",
    "\n",
    "# 다른 속성도 추가해보기\n",
    "print(\"🔍 Token 객체의 추가 속성:\")\n",
    "for token in tokens:\n",
    "    print(f\"\\n형태소: {token.form}\")\n",
    "    print(f\"  - tag: {token.tag}\")                      # 품사 태그\n",
    "    print(f\"  - score: {token.score}\")                  # 로그 확률\n",
    "    print(f\"  - start: {token.start}\")                  # 시작 위치\n",
    "    print(f\"  - len: {token.len}\")                      # 길이\n",
    "    print(f\"  - tagged_form: {token.tagged_form}\")      # 형태소/품사\n",
    "\n",
    "print(\"\\n\", \"✅ 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a548b5",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 신뢰도 기반 필터링 + 추가 요소 추출\n",
    "\n",
    "    ```markdown\n",
    "    ============================================================\n",
    "    🚀 신뢰도 기반 키워드 추출\n",
    "    ============================================================\n",
    "    📝 원본: Python은 AI 개발에 적합한 언어입니다.\n",
    "    ✅ 신뢰도 높은 키워드 (threshold=-10.0):\n",
    "    - Python        | SL     | score:  -5.1598 | prob: 0.0057\n",
    "    - AI            | SL     | score:  -3.4959 | prob: 0.0303\n",
    "    - 개발           | NNG    | score:  -9.5165 | prob: 0.0001\n",
    "    - 적합           | NNG    | score:  -8.8320 | prob: 0.0001\n",
    "    - 언어           | NNG    | score:  -6.6020 | prob: 0.0014\n",
    "    → 키워드: ['Python', 'AI', '개발', '적합', '언어']\n",
    "\n",
    "    📝 원본: LangChain과 Kiwi를 활용한 검색 시스템\n",
    "    ✅ 신뢰도 높은 키워드 (threshold=-10.0):\n",
    "    - LangChain      | SL     | score:  -5.1598 | prob: 0.0057\n",
    "    - Kiwi           | SL     | score:  -0.4446 | prob: 0.6411\n",
    "    - 활용            | NNG    | score:  -5.6323 | prob: 0.0036\n",
    "    - 시스템           | NNG    | score:  -3.3437 | prob: 0.0353\n",
    "    → 키워드: ['LangChain', 'Kiwi', '활용', '시스템']\n",
    "\n",
    "    📝 원본: 형태소 분석은 자연어 처리의 기초입니다.\n",
    "    ✅ 신뢰도 높은 키워드 (threshold=-10.0):\n",
    "    - 분석           | NNG    | score:  -4.0561 | prob: 0.0173\n",
    "    - 기초           | NNG    | score:  -8.7458 | prob: 0.0002\n",
    "    → 키워드: ['분석', '기초']\n",
    "\n",
    "    🔍 Token 객체의 추가 속성:\n",
    "\n",
    "    형태소: 안녕하세요\n",
    "    - tag: NNP\n",
    "    - score: -24.96066665649414\n",
    "    - start: 0\n",
    "    - len: 5\n",
    "    - tagged_form: 안녕하세요/NNP\n",
    "\n",
    "    형태소: ,\n",
    "    - tag: SP\n",
    "    - score: -3.4207992553710938\n",
    "    - start: 5\n",
    "    - len: 1\n",
    "    - tagged_form: ,/SP\n",
    "\n",
    "    형태소: Kiwi\n",
    "    - tag: SL\n",
    "    - score: -4.604381561279297\n",
    "    - start: 7\n",
    "    - len: 4\n",
    "    - tagged_form: Kiwi/SL\n",
    "\n",
    "    형태소: 토크나이저\n",
    "    - tag: NNG\n",
    "    - score: -34.90306091308594\n",
    "    - start: 12\n",
    "    - len: 5\n",
    "    - tagged_form: 토크나이저/NNG\n",
    "\n",
    "    형태소: 를\n",
    "    - tag: JKO\n",
    "    - score: -2.654998779296875\n",
    "    - start: 17\n",
    "    - len: 1\n",
    "    - tagged_form: 를/JKO\n",
    "\n",
    "    형태소: 사용\n",
    "    - tag: NNG\n",
    "    - score: -6.3822784423828125\n",
    "    - start: 19\n",
    "    - len: 2\n",
    "    - tagged_form: 사용/NNG\n",
    "\n",
    "    형태소: 하\n",
    "    - tag: XSV\n",
    "    - score: -1.0495452880859375\n",
    "    - start: 21\n",
    "    - len: 1\n",
    "    - tagged_form: 하/XSV\n",
    "\n",
    "    형태소: 어\n",
    "    - tag: EC\n",
    "    - score: -1.0495452880859375\n",
    "    - start: 21\n",
    "    - len: 1\n",
    "    - tagged_form: 어/EC\n",
    "\n",
    "    형태소: 보\n",
    "    - tag: VX\n",
    "    - score: -2.1493759155273438\n",
    "    - start: 22\n",
    "    - len: 1\n",
    "    - tagged_form: 보/VX\n",
    "\n",
    "    형태소: 겠\n",
    "    - tag: EP\n",
    "    - score: -3.571380615234375\n",
    "    - start: 23\n",
    "    - len: 1\n",
    "    - tagged_form: 겠/EP\n",
    "\n",
    "    형태소: 습니다\n",
    "    - tag: EF\n",
    "    - score: -0.7610092163085938\n",
    "    - start: 24\n",
    "    - len: 3\n",
    "    - tagged_form: 습니다/EF\n",
    "\n",
    "    형태소: .\n",
    "    - tag: SF\n",
    "    - score: -0.2584686279296875\n",
    "    - start: 27\n",
    "    - len: 1\n",
    "    - tagged_form: ./SF\n",
    "    \n",
    "    ✅ 완료!\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a38d2b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53cd74e4",
   "metadata": {},
   "source": [
    "* [재사용 가능한 클래스 모델로 만들기](../10_Retriever/utils/korean_analyzer.py)\n",
    "\n",
    "  * **`클래스 모델`** - 핵심 기능\n",
    "\n",
    "  | 메서드 | 설명 | 사용 예시 |\n",
    "  |--------|------|----------|\n",
    "  | **analyze()** | 기본 형태소 분석 | `analyzer.analyze(text)` |\n",
    "  | **extract_keywords()** | 신뢰도 기반 키워드 추출 | `analyzer.extract_keywords(text, -10.0)` |\n",
    "  | **extract_nouns()** | 명사만 추출 | `analyzer.extract_nouns(text)` |\n",
    "  | **extract_verbs()** | 동사만 추출 | `analyzer.extract_verbs(text)` |\n",
    "  | **extract_adjectives()** | 형용사만 추출 | `analyzer.extract_adjectives(text)` |\n",
    "  | **get_detailed_info()** | 상세 정보 조회 | `analyzer.get_detailed_info(text)` |\n",
    "  | **analyze_with_confidence()** | 통합 분석 | `analyzer.analyze_with_confidence(text)` |\n",
    "  | **print_analysis()** | 예쁜 출력 | `analyzer.print_analysis(text, detailed=True)` |\n",
    "\n",
    "<br>\n",
    "\n",
    "*  * 사용 예제 \n",
    "*  *  * a. 간단한 키워드 추출\n",
    "```python\n",
    "\n",
    "        from korean_analyzer import KoreanMorphologicalAnalyzer\n",
    "\n",
    "        analyzer = KoreanMorphologicalAnalyzer()\n",
    "\n",
    "        text = \"Python과 LangChain을 활용한 AI 개발\"\n",
    "        keywords = analyzer.extract_keywords(text)\n",
    "\n",
    "        print(keywords)\n",
    "        # ['Python', 'LangChain', '활용', 'AI', '개발']\n",
    "\n",
    "```\n",
    "\n",
    "*  *  * b. 문서 배치 처리  \n",
    "```python\n",
    "\n",
    "        analyzer = KoreanMorphologicalAnalyzer()\n",
    "\n",
    "        documents = [\n",
    "            \"RAG 시스템 구축 방법\",\n",
    "            \"형태소 분석의 중요성\",\n",
    "            \"한국어 자연어 처리 기술\"\n",
    "        ]\n",
    "\n",
    "        all_keywords = []\n",
    "        for doc in documents:\n",
    "            keywords = analyzer.extract_keywords(doc, confidence_threshold=-8.0)\n",
    "            all_keywords.extend(keywords)\n",
    "\n",
    "        print(f\"전체 키워드: {set(all_keywords)}\")\n",
    "\n",
    "```\n",
    "*  *  * c. 품사별 분리 처리\n",
    "```python\n",
    "\n",
    "        analyzer = KoreanMorphologicalAnalyzer()\n",
    "\n",
    "        text = \"Python은 강력하고 유용한 프로그래밍 언어입니다.\"\n",
    "\n",
    "        print(f\"명사: {analyzer.extract_nouns(text)}\")\n",
    "        print(f\"동사: {analyzer.extract_verbs(text)}\")\n",
    "        print(f\"형용사: {analyzer.extract_adjectives(text)}\")\n",
    "\n",
    "```\n",
    "*  *  * d. 파일로 저장 후 사용하기 \n",
    "```python\n",
    "\n",
    "        # 10_Retriever/utils/korean_analyzer.py로 저장\n",
    "\n",
    "        from utils.korean_analyzer import KoreanMorphologicalAnalyzer\n",
    "\n",
    "        analyzer = KoreanMorphologicalAnalyzer()\n",
    "        result = analyzer.extract_keywords(\"안녕하세요\")\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a3eefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10_Retriever/utils/Korean_analyzer.py 사용해보기\n",
    "\n",
    "from utils.korean_analyzer import KoreanMorphologicalAnalyzer\n",
    "\n",
    "analyzer = KoreanMorphologicalAnalyzer()\n",
    "\n",
    "text = \"AI 기술이 빠르게 발전하고 있습니다.\"\n",
    "\n",
    "print(f\"명사: {analyzer.extract_nouns(text)}\")\n",
    "print(f\"동사: {analyzer.extract_verbs(text)}\")\n",
    "print(f\"형용사: {analyzer.extract_adjectives(text)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2dc1d1",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 명사: ['기술', '발전']\n",
    "* 동사: []\n",
    "* 형용사: ['빠르']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f72ea1",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* test_2 (`8.1s`)\n",
    "\n",
    "    ```markdown\n",
    "    ============================================================\n",
    "    📝 원본: Python은 강력한 언어입니다\n",
    "    ============================================================\n",
    "\n",
    "    번호   형태소             품사     품사설명            점수         확률        \n",
    "    ----------------------------------------------------------------------\n",
    "    [ 1] Python            SL      외국어             -5.1598    0.005743\n",
    "    [ 2] 은                JX       기타              -1.5430    0.213736\n",
    "    [ 3] 강력               XR      어근              -8.0364    0.000323\n",
    "    [ 4] 하                XSA     형용사 파생 접미사    -0.2585    0.772234\n",
    "    [ 5] ᆫ                ETM      기타             -0.2585     0.772234\n",
    "    [ 6] 언어              NNG     일반 명사          -6.6236     0.001329\n",
    "    [ 7] 이               VCP       기타             -2.7300    0.065219\n",
    "    [ 8] ᆸ니다             EF      종결 어미          -4.1887    0.015165\n",
    "\n",
    "    💡 요약:\n",
    "    - 총 토큰: 8개\n",
    "    - 명사: ['언어']\n",
    "    - 동사: []\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14287acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10_Retriever/utils/Korean_analyzer.py 사용해보기\n",
    "\n",
    "from utils.korean_analyzer import KoreanMorphologicalAnalyzer\n",
    "analyzer = KoreanMorphologicalAnalyzer()\n",
    "analyzer.print_analysis(\"Python은 강력한 언어입니다\", detailed=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b73d1d5",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c74365",
   "metadata": {},
   "source": [
    "#### **3) `Kiwi Analyzer + BM25 Retriever`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d10d26",
   "metadata": {},
   "source": [
    "* `Kiwi Analyzer` + `BM25 Retriever` 결합 → [`korean_bm25_retriever`](../10_Retriever/utils/korean_bm25_retriever.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e03562a",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* `/10_Retriever/utils/korean_bm25_retriever.py` 실행 결과\n",
    "\n",
    "    ```markdown\n",
    "    /10_Retriever/utils/korean_bm25_retriever.py\n",
    "    ============================================================\n",
    "    🚀 예제 1: 기본 BM25 검색\n",
    "    ============================================================\n",
    "\n",
    "    🔍 검색어: '금융보험'\n",
    "\n",
    "    📊 검색 결과:\n",
    "    [1] 금융보험은 장기적인 자산 관리와 위험 대비를 목적으로 고안된 금융 상품입니다.\n",
    "    [2] 금융저축산물보험은 장기적인 저축 목적과 더불어, 축산물 제공 기능을 갖추고 있는 특별 금융 상품입니다.\n",
    "    [3] 금융단폭격보험은 저축은 커녕 위험 대비에 초점을 맞춘 상품입니다. 높은 위험을 감수하고자 하는 고객에게 적합합니다.\n",
    "    [4] 금융보씨 험한말 좀 하지마시고, 저축이나 좀 하시던가요. 뭐가 그리 급하신지 모르겠네요.\n",
    "\n",
    "    ============================================================\n",
    "    🚀 예제 2: 점수 포함 검색\n",
    "    ============================================================\n",
    "\n",
    "    🔍 검색어: '금융보험'\n",
    "\n",
    "    📊 점수 포함 결과:\n",
    "    [1] 금융보험은 장기적인 자산 관리와 위험 대비를 목적으로 고안된 금융 상품입니다. (1.0000)\n",
    "    [2] 금융저축산물보험은 장기적인 저축 목적과 더불어, 축산물 제공 기능을 갖추고 있는 특별 금융 상품입니다. (1.0000)\n",
    "    [3] 금융단폭격보험은 저축은 커녕 위험 대비에 초점을 맞춘 상품입니다. 높은 위험을 감수하고자 하는 고객에게 적합합니다. (1.0000)\n",
    "    [4] 금융보씨 험한말 좀 하지마시고, 저축이나 좀 하시던가요. 뭐가 그리 급하신지 모르겠네요. (0.5000)\n",
    "\n",
    "    ============================================================\n",
    "    🚀 예제 3: k 값 설정 (상위 2개만)\n",
    "    ============================================================\n",
    "\n",
    "    🔍 검색어: '금융보험'\n",
    "\n",
    "    📊 상위 2개 결과:\n",
    "    [1] 금융보험은 장기적인 자산 관리와 위험 대비를 목적으로 고안된 금융 상품입니다. (1.0000)\n",
    "    [2] 금융저축산물보험은 장기적인 저축 목적과 더불어, 축산물 제공 기능을 갖추고 있는 특별 금융 상품입니다. (1.0000)\n",
    "\n",
    "    ============================================================\n",
    "    🚀 예제 4: 기본 BM25 vs Kiwi BM25 비교\n",
    "    ============================================================\n",
    "\n",
    "    🔍 검색어: '금융보험'\n",
    "\n",
    "    📊 Kiwi BM25 1위:\n",
    "    금융보험은 장기적인 자산 관리와 위험 대비를 목적으로 고안된 금융 상품입니다.\n",
    "\n",
    "    📊 기본 BM25 1위:\n",
    "    금융단폭격보험은 저축은 커녕 위험 대비에 초점을 맞춘 상품입니다. 높은 위험을 감수하고자 하는 고객에게 적합합니다.\n",
    "\n",
    "    💡 차이점:\n",
    "    ✅ Kiwi가 형태소 분석으로 더 정확한 결과 반환!\n",
    "\n",
    "    ============================================================\n",
    "    ✅ 모든 예제 완료!\n",
    "    ============================================================\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b7628f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.korean_bm25_retriever import KoreanBM25Retriever, pretty_print\n",
    "\n",
    "# 문서 생성\n",
    "documents = [\n",
    "    \"Python은 AI 개발에 적합한 언어입니다.\",\n",
    "    \"LangChain은 RAG 시스템 구축 프레임워크입니다.\",]\n",
    "\n",
    "# 검색기 생성하기\n",
    "retriever = KoreanBM25Retriever.from_texts(\n",
    "    documents,\n",
    "    k=1                     # 상위 1개만 반환\n",
    ")\n",
    "\n",
    "# 검색\n",
    "query = \"AI 개발 도구\"\n",
    "results = retriever.search_with_score(query)\n",
    "\n",
    "print(f\"🔍 검색어: {query}\")\n",
    "print(f\"📊 결과: {len(results)}개\\n\")\n",
    "\n",
    "for i, doc in enumerate(results):\n",
    "    score = doc.metadata.get('score', 0)\n",
    "    print(f\"[{i+1}] 점수: {score:.4f}\")\n",
    "    print(f\"    {doc.page_content}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780cbe06",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 문서로 검색해보기 (`0.9s`)\n",
    "\n",
    "    ```markdown\n",
    "    🔍 검색어: AI 개발 도구\n",
    "    📊 결과: 1개\n",
    "\n",
    "    [1] 점수: 0.0000\n",
    "        LangChain은 RAG 시스템 구축 프레임워크입니다.\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f79ab39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.korean_bm25_retriever import KoreanBM25Retriever, pretty_print\n",
    "\n",
    "# 교재 예시로 해보기 \n",
    "\n",
    "documents = [\n",
    "    \"금융보험은 장기적인 자산 관리와 위험 대비를 목적으로 고안된 금융 상품입니다.\",\n",
    "    \"금융저축산물보험은 장기적인 저축 목적과 더불어, 축산물 제공 기능을 갖추고 있는 특별 금융 상품입니다.\",\n",
    "    \"금융보씨 험한말 좀 하지마시고, 저축이나 좀 하시던가요. 뭐가 그리 급하신지 모르겠네요.\",\n",
    "    \"금융단폭격보험은 저축은 커녕 위험 대비에 초점을 맞춘 상품입니다. 높은 위험을 감수하고자 하는 고객에게 적합합니다.\",\n",
    "]\n",
    "\n",
    "# 검색기 생성하기\n",
    "retriever = KoreanBM25Retriever.from_texts(\n",
    "    documents,\n",
    "    k=2                         # 상위 2개만 반환\n",
    ")\n",
    "\n",
    "# 검색\n",
    "query = \"금융보험\"\n",
    "results = retriever.search_with_score(query)\n",
    "\n",
    "print(f\"🔍 검색어: {query}\")\n",
    "print(f\"📊 결과: {len(results)}개\\n\")\n",
    "\n",
    "for i, doc in enumerate(results):\n",
    "    score = doc.metadata.get('score', 0)\n",
    "    print(f\"[{i+1}] 점수: {score:.4f}\")\n",
    "    print(f\"    {doc.page_content}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e86abe9",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 교재 속 텍스트로 test (`0.1s`)\n",
    "\n",
    "    ```markdown\n",
    "    🔍 검색어: 금융보험\n",
    "    📊 결과: 2개\n",
    "\n",
    "    [1] 점수: 1.0000\n",
    "        금융보험은 장기적인 자산 관리와 위험 대비를 목적으로 고안된 금융 상품입니다.\n",
    "\n",
    "    [2] 점수: 1.0000\n",
    "        금융저축산물보험은 장기적인 저축 목적과 더불어, 축산물 제공 기능을 갖추고 있는 특별 금융 상품입니다.\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9813507d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a7d923",
   "metadata": {},
   "source": [
    "#### **4) `KonlPy` (`Kkma`, `Okt`) 사용한 `BM25Retriever`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a10a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Kkma, Okt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# 문서 준비\n",
    "documents = [\n",
    "    \"안녕하세요, 한국어 문서 검색을 테스트합니다.\",\n",
    "    \"이 문서는 한국어 문서 검색을 위한 예제입니다.\",\n",
    "    \"한국어 문서 검색은 BM25 알고리즘을 사용합니다.\"\n",
    "]\n",
    "\n",
    "# Kkma 형태소 분석기 사용\n",
    "kkma = Kkma()\n",
    "kkma_tokens = [kkma.morphs(doc) for doc in documents]\n",
    "\n",
    "# Okt 형태소 분석기 사용\n",
    "okt = Okt()\n",
    "okt_tokens = [okt.morphs(doc) for doc in documents]\n",
    "\n",
    "# TF-IDF 벡터화\n",
    "kkma_vectorizer = TfidfVectorizer()\n",
    "kkma_tfidf = kkma_vectorizer.fit_transform([' '.join(tokens) for tokens in kkma_tokens])\n",
    "\n",
    "okt_vectorizer = TfidfVectorizer()\n",
    "okt_tfidf = okt_vectorizer.fit_transform([' '.join(tokens) for tokens in okt_tokens])\n",
    "\n",
    "# 쿼리 준비\n",
    "query = \"한국어 문서 검색\"\n",
    "\n",
    "# Kkma 형태소 분석기 사용\n",
    "kkma_query_tokens = kkma.morphs(query)\n",
    "kkma_query_tfidf = kkma_vectorizer.transform([' '.join(kkma_query_tokens)])\n",
    "\n",
    "# Okt 형태소 분석기 사용\n",
    "okt_query_tokens = okt.morphs(query)\n",
    "okt_query_tfidf = okt_vectorizer.transform([' '.join(okt_query_tokens)])\n",
    "\n",
    "# 코사인 유사도 계산\n",
    "kkma_similarities = cosine_similarity(kkma_query_tfidf, kkma_tfidf)\n",
    "okt_similarities = cosine_similarity(okt_query_tfidf, okt_tfidf)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"KkmaBM25Retriever 결과:\", [documents[i] for i in kkma_similarities.argsort()[0][::-1]])\n",
    "print(\"OktBM25Retriever 결과:\", [documents[i] for i in okt_similarities.argsort()[0][::-1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c46a565",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* `Kkma`, `Okt` (`14.1s`)\n",
    "\n",
    "    ```markdown\n",
    "    \n",
    "    KkmaBM25Retriever 결과: ['이 문서는 한국어 문서 검색을 위한 예제입니다.', '안녕하세요, 한국어 문서 검색을 테스트합니다.', '한국어 문서 검색은 BM25 알고리즘을 사용합니다.']\n",
    "\n",
    "    OktBM25Retriever 결과: ['이 문서는 한국어 문서 검색을 위한 예제입니다.', '안녕하세요, 한국어 문서 검색을 테스트합니다.', '한국어 문서 검색은 BM25 알고리즘을 사용합니다.']\n",
    "    \n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a500ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Kkma, Okt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# 문서 준비\n",
    "sample_texts = [\n",
    "    \"금융보험은 장기적인 자산 관리와 위험 대비를 목적으로 고안된 금융 상품입니다.\",\n",
    "    \"금융저축산물보험은 장기적인 저축 목적과 더불어, 축산물 제공 기능을 갖추고 있는 특별 금융 상품입니다.\",\n",
    "    \"금융보씨 험한말 좀 하지마시고, 저축이나 좀 하시던가요. 뭐가 그리 급하신지 모르겠네요.\",\n",
    "    \"금융단폭격보험은 저축은 커녕 위험 대비에 초점을 맞춘 상품입니다. 높은 위험을 감수하고자 하는 고객에게 적합합니다.\",\n",
    "]\n",
    "\n",
    "# Kkma 형태소 분석기 사용\n",
    "kkma = Kkma()\n",
    "kkma_tokens = [kkma.morphs(doc) for doc in documents]\n",
    "\n",
    "# Okt 형태소 분석기 사용\n",
    "okt = Okt()\n",
    "okt_tokens = [okt.morphs(doc) for doc in documents]\n",
    "\n",
    "# TF-IDF 벡터화\n",
    "kkma_vectorizer = TfidfVectorizer()\n",
    "kkma_tfidf = kkma_vectorizer.fit_transform([' '.join(tokens) for tokens in kkma_tokens])\n",
    "\n",
    "okt_vectorizer = TfidfVectorizer()\n",
    "okt_tfidf = okt_vectorizer.fit_transform([' '.join(tokens) for tokens in okt_tokens])\n",
    "\n",
    "# 쿼리 준비\n",
    "query = \"금융보험\"\n",
    "\n",
    "# Kkma 형태소 분석기 사용\n",
    "kkma_query_tokens = kkma.morphs(query)\n",
    "kkma_query_tfidf = kkma_vectorizer.transform([' '.join(kkma_query_tokens)])\n",
    "\n",
    "# Okt 형태소 분석기 사용\n",
    "okt_query_tokens = okt.morphs(query)\n",
    "okt_query_tfidf = okt_vectorizer.transform([' '.join(okt_query_tokens)])\n",
    "\n",
    "# 코사인 유사도 계산\n",
    "kkma_similarities = cosine_similarity(kkma_query_tfidf, kkma_tfidf)\n",
    "okt_similarities = cosine_similarity(okt_query_tfidf, okt_tfidf)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"KkmaBM25Retriever 결과:\", [documents[i] for i in kkma_similarities.argsort()[0][::-1]])\n",
    "print(\"OktBM25Retriever 결과:\", [documents[i] for i in okt_similarities.argsort()[0][::-1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7e7000",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 교재 속 텍스트로 테스트해보기 (`1.5s`)\n",
    "\n",
    "    ```markdown\n",
    "\n",
    "    KkmaBM25Retriever 결과: ['금융보험은 장기적인 자산 관리와 위험 대비를 목적으로 고안된 금융 상품입니다.', '금융저축산물보험은 장기적인 저축 목적과 더불어, 축산물 제공 기능을 갖추고 있는 특별 금융 상품입니다.', '금융보씨 험한말 좀 하지마시고, 저축이나 좀 하시던가요. 뭐가 그리 급하신지 모르겠네요.', '금융단폭격보험은 저축은 커녕 위험 대비에 초점을 맞춘 상품입니다. 높은 위험을 감수하고자 하는 고객에게 적합합니다.']\n",
    "    \n",
    "    OktBM25Retriever 결과: ['금융보험은 장기적인 자산 관리와 위험 대비를 목적으로 고안된 금융 상품입니다.', '금융저축산물보험은 장기적인 저축 목적과 더불어, 축산물 제공 기능을 갖추고 있는 특별 금융 상품입니다.', '금융단폭격보험은 저축은 커녕 위험 대비에 초점을 맞춘 상품입니다. 높은 위험을 감수하고자 하는 고객에게 적합합니다.', '금융보씨 험한말 좀 하지마시고, 저축이나 좀 하시던가요. 뭐가 그리 급하신지 모르겠네요.']\n",
    "\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be820c94",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452e4cd7",
   "metadata": {},
   "source": [
    "* `BM25 Retriever` vs `kkma`, `okt` \n",
    "\n",
    "| 구분                     | 형태소 분석기 / 검색 도구                  | 역할 (중학생 눈높이 설명)                                              | 장점 (Pros) 👍                                                  | 단점 (Cons) 👎                                                                    |\n",
    "|------------------------|----------------------------------|--------------------------------------------------------------|---------------------------------------------------------------|---------------------------------------------------------------------------------|\n",
    "| **`BM25 Retriever`**         | 검색 알고리즘 (Retrieval Algorithm)    | 질문(Query)에 대해 가장 관련성이 높은 문서를 찾아주는 '똑똑한 도서관 사서' 역할      | 성능이 안정적이고 전통적인 검색 방법 중에서 매우 뛰어남 / 키워드가 질문과 많이 겹칠수록 점수를 잘 줌 | 단어의 **'의미'** 를 이해하지 못하고, 키워드가 문서에 정확히 있어야 잘 찾는 편 / 최신 인공지능 방식(벡터 검색)과 함께 써야 더 좋음 |\n",
    "| **`kkma`** (꼬꼬마)             | 형태소 분석기 (Morphological Analyzer) | 한국어 문장을 아주 꼼꼼하고 규칙에 맞게 단어(형태소) 단위로 자르는 '정교한 칼' 역할      | 정확도가 높고, 문법적인 분석을 세밀하게 잘해서 학술적인 연구나 엄격한 분석에 적합             | 처리 속도가 느리고, 분석 규칙이 복잡해서 비표준어(줄임말, 인터넷 용어)에는 약함                                |\n",
    "| **`okt`** (Open Korean Text) | 형태소 분석기 (Morphological Analyzer) | 한국어 문장을 빠르고 유연하게 단어(어절) 단위로 자르는 '빠른 칼' 역할 / 카카오에서 만듦 | 처리 속도가 매우 빠르고, 인터넷 용어나 오타 같은 비표준어를 비교적 잘 처리 / 사용하기 간편    | kkma보다 분석 단위가 커서 세밀한 문법 분석에는 약간 불리할 수 있음                                      |\n",
    "\n",
    "  * 쉬운 설명\n",
    "\n",
    "    * `BM25 Retriever` (≒ 사서)\n",
    "      * 구글, 네이버에 검색했을 때 관련성 높은 결과를 보여주는 방식과 비슷\n",
    "      * **`질문과 겹치는 단어가 많을수록`**, **`그 단어가 다른 문서에는 흔하지 않을수록`** 그 문서를 가장 중요한 것으로 뽑아줌\n",
    "      * **`앙상블 검색`** = 최근에는 `BM25 Retreiver` + `Vector Search` 함께 사용 → 검색 성능 ↑\n",
    "\n",
    "\n",
    "    * `kkma`, `okt` (≒ `칼`의 종류)\n",
    "      * **`형태소 분석기`** = 둘 다 컴퓨터가 한국어 문장의 뜻을 이해하도록 **`단어 단위로 쪼개주는 도구`**\n",
    "      * `kkma` ≒ 문법 규칙을 철저히 따르는 **`학자`** → 느리지만 정확 / 논문 분석에 유용\n",
    "      * `okt` ≒ 실용적, 빠른 **`현장 전문가`** → 인터넷 용어 빠르게 처리 가능 / 수많은 댓글, SNS 데이터 분석에 유용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1497f6fc",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884391ad",
   "metadata": {},
   "source": [
    "* next: **`Convex Combination(CC) 적용된 앙상블 검색기 (EnsembleRetriever)`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403ac8ee",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lc_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
