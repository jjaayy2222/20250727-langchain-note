# ========================================
# ğŸ† KoreanBM25Retriever (ì™„ì „ ìˆ˜ì • ë²„ì „)
# ========================================

from kiwipiepy import Kiwi
from langchain_community.retrievers import BM25Retriever
from langchain_core.documents import Document
from langchain_core.retrievers import BaseRetriever
from typing import List, Optional, Any
import math

class KoreanBM25Retriever(BaseRetriever):
    """
    Kiwi í˜•íƒœì†Œ ë¶„ì„ê¸°ë¥¼ ì‚¬ìš©í•œ í•œêµ­ì–´ BM25 ê²€ìƒ‰ê¸°
    
    BaseRetriever ìƒì†ìœ¼ë¡œ LangChain Runnable ì¸í„°í˜ì´ìŠ¤ í˜¸í™˜
    
    Features:
    - Kiwi í˜•íƒœì†Œ ë¶„ì„ ê¸°ë°˜ í† í°í™”
    - BM25 ì•Œê³ ë¦¬ì¦˜ ê²€ìƒ‰
    - ìœ ì‚¬ë„ ì ìˆ˜ ê³„ì‚°
    - ê²€ìƒ‰ ê²°ê³¼ ê°œìˆ˜ ì¡°ì • (k)
    - EnsembleRetriever í˜¸í™˜ ê°€ëŠ¥
    
    Examples:
        >>> retriever = KoreanBM25Retriever.from_texts(texts)
        >>> results = retriever.invoke("ê²€ìƒ‰ì–´")
        >>> results_with_score = retriever.search_with_score("ê²€ìƒ‰ì–´")
    """
    
    # ========================================
    # Pydantic ì„¤ì • â† ì¶”ê°€!
    # ========================================
    class Config:
        """Pydantic ì„¤ì •"""
        arbitrary_types_allowed = True  # ì„ì˜ íƒ€ì… í—ˆìš©
    
    # ========================================
    # ì¸ìŠ¤í„´ìŠ¤ ë³€ìˆ˜ (í´ë˜ìŠ¤ ë³€ìˆ˜ ì œê±°!)
    # ========================================
    _retriever: BM25Retriever = None    # â† private ë³€ìˆ˜ë¡œ!
    _kiwi: Kiwi = None                  # â† private ë³€ìˆ˜ë¡œ!
    _k: int = 4                         # â† private ë³€ìˆ˜ë¡œ!
    
    def __init__(
        self,
        retriever: BM25Retriever,
        kiwi: Kiwi,
        k: int = 4,
        **kwargs
    ):
        """
        ì´ˆê¸°í™”
        
        Args:
            retriever: BM25Retriever ì¸ìŠ¤í„´ìŠ¤
            kiwi: Kiwi ì¸ìŠ¤í„´ìŠ¤
            k: ë°˜í™˜í•  ë¬¸ì„œ ê°œìˆ˜
        """
        # BaseRetriever ì´ˆê¸°í™” (ë¨¼ì €!)
        super().__init__(**kwargs)
        
        # ì¸ìŠ¤í„´ìŠ¤ ë³€ìˆ˜ í• ë‹¹ (ë‚˜ì¤‘ì—!)
        self._retriever = retriever
        self._kiwi = kiwi
        self._k = k
        self._retriever.k = k
    
    # ========================================
    # Propertyë¡œ ì ‘ê·¼ (ì„ íƒì‚¬í•­)
    # ========================================
    
    @property
    def retriever(self) -> BM25Retriever:
        """BM25Retriever ì ‘ê·¼"""
        return self._retriever
    
    @property
    def kiwi(self) -> Kiwi:
        """Kiwi ì ‘ê·¼"""
        return self._kiwi
    
    @property
    def k(self) -> int:
        """k ê°’ ì ‘ê·¼"""
        return self._k
    
    @k.setter
    def k(self, value: int):
        """k ê°’ ì„¤ì •"""
        self._k = value
        self._retriever.k = value
    
    @classmethod
    def from_texts(
        cls,
        texts: List[str],
        metadatas: Optional[List[dict]] = None,
        k: int = 4,
        **kwargs
    ) -> "KoreanBM25Retriever":
        """
        í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸ë¡œë¶€í„° ê²€ìƒ‰ê¸° ìƒì„±
        
        Args:
            texts: ë¬¸ì„œ í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸
            metadatas: ë©”íƒ€ë°ì´í„° ë¦¬ìŠ¤íŠ¸ (ì„ íƒ)
            k: ë°˜í™˜í•  ë¬¸ì„œ ê°œìˆ˜
            
        Returns:
            KoreanBM25Retriever ì¸ìŠ¤í„´ìŠ¤
        """
        # Kiwi ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
        kiwi = Kiwi()
        
        # í† í¬ë‚˜ì´ì € í•¨ìˆ˜ ì •ì˜
        def korean_tokenizer(text: str) -> List[str]:
            """Kiwi ê¸°ë°˜ í•œêµ­ì–´ í† í¬ë‚˜ì´ì €"""
            tokens = kiwi.tokenize(text)
            meaningful_tags = ['NNG', 'NNP', 'VV', 'VA', 'SL', 'SH']
            return [
                token.form for token in tokens 
                if token.tag in meaningful_tags and len(token.form) > 1
            ]
        
        # Document ê°ì²´ ìƒì„±
        if metadatas:
            docs = [
                Document(page_content=text, metadata=metadata)
                for text, metadata in zip(texts, metadatas)
            ]
        else:
            docs = [Document(page_content=text) for text in texts]
        
        # BM25Retriever ìƒì„±
        bm25_retriever = BM25Retriever.from_documents(
            docs,
            preprocess_func=korean_tokenizer
        )
        bm25_retriever.k = k
        
        return cls(bm25_retriever, kiwi, k, **kwargs)
    
    @classmethod
    def from_documents(
        cls,
        documents: List[Document],
        k: int = 4,
        **kwargs
    ) -> "KoreanBM25Retriever":
        """
        Document ê°ì²´ ë¦¬ìŠ¤íŠ¸ë¡œë¶€í„° ê²€ìƒ‰ê¸° ìƒì„±
        
        Args:
            documents: Document ê°ì²´ ë¦¬ìŠ¤íŠ¸
            k: ë°˜í™˜í•  ë¬¸ì„œ ê°œìˆ˜
            
        Returns:
            KoreanBM25Retriever ì¸ìŠ¤í„´ìŠ¤
        """
        # Kiwi ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
        kiwi = Kiwi()
        
        # í† í¬ë‚˜ì´ì € í•¨ìˆ˜ ì •ì˜
        def korean_tokenizer(text: str) -> List[str]:
            """Kiwi ê¸°ë°˜ í•œêµ­ì–´ í† í¬ë‚˜ì´ì €"""
            tokens = kiwi.tokenize(text)
            meaningful_tags = ['NNG', 'NNP', 'VV', 'VA', 'SL', 'SH']
            return [
                token.form for token in tokens 
                if token.tag in meaningful_tags and len(token.form) > 1
            ]
        
        # BM25Retriever ìƒì„±
        bm25_retriever = BM25Retriever.from_documents(
            documents,
            preprocess_func=korean_tokenizer
        )
        bm25_retriever.k = k
        
        return cls(bm25_retriever, kiwi, k, **kwargs)
    
    # ========================================
    # BaseRetriever í•„ìˆ˜ ë©”ì„œë“œ
    # ========================================
    
    def _get_relevant_documents(
        self, 
        query: str,
        *,
        run_manager=None
    ) -> List[Document]:
        """
        BaseRetriever ì¸í„°í˜ì´ìŠ¤ êµ¬í˜„
        
        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            run_manager: ì‹¤í–‰ ê´€ë¦¬ì (ì„ íƒ)
            
        Returns:
            ê²€ìƒ‰ëœ Document ë¦¬ìŠ¤íŠ¸
        """
        return self._retriever.invoke(query)
    
    # ========================================
    # ì¶”ê°€ ë©”ì„œë“œë“¤
    # ========================================
    
    def search_with_score(self, query: str) -> List[Document]:
        """
        ìœ ì‚¬ë„ ì ìˆ˜ë¥¼ í¬í•¨í•œ ê²€ìƒ‰
        
        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            
        Returns:
            ì ìˆ˜ê°€ ë©”íƒ€ë°ì´í„°ì— í¬í•¨ëœ Document ë¦¬ìŠ¤íŠ¸
        """
        # ê¸°ë³¸ ê²€ìƒ‰ ìˆ˜í–‰
        docs = self._get_relevant_documents(query)
        
        # ì¿¼ë¦¬ í† í°í™”
        query_tokens = self._tokenize(query)
        
        # ê° ë¬¸ì„œì˜ ì ìˆ˜ ê³„ì‚°
        scored_docs = []
        for doc in docs:
            doc_tokens = self._tokenize(doc.page_content)
            
            # ë‹¨ìˆœ overlap ê¸°ë°˜ ì ìˆ˜ (0~1 ì •ê·œí™”)
            common_tokens = set(query_tokens) & set(doc_tokens)
            score = len(common_tokens) / max(len(query_tokens), 1)
            
            # ë©”íƒ€ë°ì´í„°ì— ì ìˆ˜ ì¶”ê°€
            new_metadata = doc.metadata.copy()
            new_metadata['score'] = score
            
            scored_doc = Document(
                page_content=doc.page_content,
                metadata=new_metadata
            )
            scored_docs.append(scored_doc)
        
        # ì ìˆ˜ ê¸°ì¤€ ì •ë ¬
        scored_docs.sort(key=lambda x: x.metadata['score'], reverse=True)
        
        return scored_docs
    
    def _tokenize(self, text: str) -> List[str]:
        """ë‚´ë¶€ í† í°í™” í•¨ìˆ˜"""
        tokens = self._kiwi.tokenize(text)
        meaningful_tags = ['NNG', 'NNP', 'VV', 'VA', 'SL', 'SH']
        return [
            token.form for token in tokens 
            if token.tag in meaningful_tags and len(token.form) > 1
        ]


# ========================================
# ğŸ¯ ì˜ˆìœ ì¶œë ¥ í•¨ìˆ˜
# ========================================

def pretty_print(docs: List[Document]):
    """
    ê²€ìƒ‰ ê²°ê³¼ ì˜ˆì˜ê²Œ ì¶œë ¥
    
    Args:
        docs: Document ë¦¬ìŠ¤íŠ¸
    """
    for i, doc in enumerate(docs):
        if "score" in doc.metadata:
            print(f"[{i+1}] {doc.page_content} ({doc.metadata['score']:.4f})")
        else:
            print(f"[{i+1}] {doc.page_content}")
