{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf989cca",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5587735",
   "metadata": {},
   "source": [
    "* 출처: LangChain 공식 문서 또는 해당 교재명\n",
    "* 원본 URL: https://smith.langchain.com/hub/teddynote/summary-stuff-documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48fe9ecc",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827aa7b4",
   "metadata": {},
   "source": [
    "### **`캐시 임베딩 (CacheBackedEmbeddings)`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3a7af3",
   "metadata": {},
   "source": [
    "### **1) `CacheBackedEmbeddings`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d118df",
   "metadata": {},
   "source": [
    "* **`Embeddings` = 재계산을 피하기 위해 저장되거나 `일시적으로 캐시`될 수 있음**\n",
    "\n",
    "  * `Embeddings`를 캐싱하는 것 = `CacheBackedEmbeddings` 사용 → 수행\n",
    "\n",
    "  * `캐시 지원 embedder` = `embeddings`를 **`키-값 저장소`에 `캐싱`하는 `embedder` `주변 래퍼`** \n",
    "    * `텍스트 = 해시` → `캐시`에서 `키`로 `사용`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f299c475",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54ea7fe",
   "metadata": {},
   "source": [
    "* 기초 개념\n",
    "\n",
    "  * 한 번 계산된 임베딩 벡터를 `메모리`나 `파일`에 `저장`해두고 `재사용`하는 기술\n",
    "  * **`같은 텍스트`에 대해서는 `API`를 다시 호출하지 않고 `저장된 결과 사용`**\n",
    "  * 개발자의 시간과 비용을 크게 절약하는 필수 최적화 기법"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cefbbe3",
   "metadata": {},
   "source": [
    "* 필요성\n",
    "\n",
    "  *  **`비용 절약`**\n",
    "\n",
    "    ```python\n",
    "\n",
    "      # 일반 임베딩: 매번 API 호출\n",
    "      texts = [\"안녕하세요\", \"안녕하세요\", \"안녕하세요\"]          # 같은 텍스트 3번\n",
    "      for text in texts:\n",
    "      embedding = openai_embed(text)                      # 3번 API 호출 = $0.03\n",
    "\n",
    "      # 캐시백드 임베딩: 첫 번째만 API 호출\n",
    "      cache = {}\n",
    "      for text in texts:\n",
    "      if text in cache:\n",
    "      embedding = cache[text]                             # 캐시에서 가져오기\n",
    "      else:\n",
    "      embedding = openai_embed(text)                      # 1번만 API 호출 = $0.01\n",
    "      cache[text] = embedding                             # 약 66% 비용 절약 (같은 텍스트가 많을수록 더 크게 절약됨)\n",
    "\n",
    "    ```\n",
    "\n",
    "  *  **`속도 향상`**\n",
    "\n",
    "    ```markdown\n",
    "\n",
    "      | 구분      | API 호출       | 캐시 조회     | 속도 차이          |\n",
    "      |----------|---------------|-------------|-----------------|\n",
    "      | 일반 임베딩 | 2-3초          | -          | 기준              |\n",
    "      | 캐시백드    | 2-3초 (첫 번째) | 0.01-0.1초  | **20-300배 빠름** |\n",
    "    \n",
    "    ```\n",
    "\n",
    "  *  **`개발 효율성`**\n",
    "\n",
    "    ```python\n",
    "    \n",
    "      # 개발/테스트 시나리오\n",
    "      for i in range(10): # 같은 데이터로 10번 테스트\n",
    "        # 일반: 매번 25초 = 총 250초 (4분 10초)\n",
    "        # 캐시: 첫 번째 25초 + 나머지 9초 = 총 34초\n",
    "        print(f\"테스트 {i+1} 완료\")\n",
    "        \n",
    "        # 개발 효율성 85% 향상!\n",
    "\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5b9e2d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f40ca9",
   "metadata": {},
   "source": [
    "* **`CacheBackedEmbeddings`를 초기화하는 주요 지원 방법 = `from_bytes_store`**\n",
    "\n",
    "* **`매개변수`**:\n",
    "\n",
    "  * `underlying_embeddings` = `임베딩`을 위해 사용되는 `embedder`\n",
    "\n",
    "  * `document_embedding_cache` = `문서 임베딩`을 `캐싱`하기 위한 `ByteStore` 중 하나\n",
    "\n",
    "  * **`namespace` (선택 사항, 기본값은 `\"\"`)**\n",
    "\n",
    "    * 문서 캐시를 위해 사용되는 `네임스페이스`\n",
    "\n",
    "    * `다른 캐시와의 충돌을 피하기 위해 사용`\n",
    "      * 예시: 사용된 임베딩 모델의 이름으로 설정\n",
    "\n",
    "* *주의*: 동일한 텍스트가 다른 임베딩 모델을 사용하여 임베딩될 때 **`충돌을 피하기 위해 namespace 매개변수를 설정하는 것이 중요`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d5a301",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8748488",
   "metadata": {},
   "source": [
    "#### **❌ 1) `LocalFileStore`에서 `임베딩` 사용** (영구 보관)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642a1105",
   "metadata": {},
   "source": [
    "* **`로컬 파일` 시스템 사용 → `임베딩 저장` → `FAISS 벡터 스토어`를 `사용`하여 `검색`하는 예제**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be47c20",
   "metadata": {},
   "source": [
    "* **`gemini-embedding`모델 사용해보기**\n",
    "\n",
    "  * `gemini-embedding` 사용 시 **`task-type` 명시해야 함**\n",
    "\n",
    "  * *`task-type` 종류*\n",
    "\n",
    "    * **`retrieval_document`**: `문서 검색`을 위한 임베딩 생성\n",
    "\n",
    "    * **`retrieval_query`**: `쿼리 검색`을 위한 임베딩 생성\n",
    "\n",
    "    * **`semantic_similarity`**: `의미적 유사성`을 위한 임베딩 생성\n",
    "\n",
    "    * **`classification`**: `분류`를 위한 임베딩 생성\n",
    "\n",
    "    * **`clustering`**: `클러스터링`을 위한 임베딩 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36957533",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# API 키 확인\n",
    "if not os.getenv(\"GOOGLE_API_KEY\"):\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = input(\"Enter your Google API key: \")\n",
    "\n",
    "# Gemini 임베딩 모델 생성 (task_type 명시)\n",
    "embeddings = GoogleGenerativeAIEmbeddings(\n",
    "    #model=\"models/gemini-embedding-001\",\n",
    "    model=\"gemini-embedding-001\",\n",
    "    task_type=\"retrieval_document\",\n",
    "    google_api_key=os.getenv(\"GOOGLE_API_KEY\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a582c42c",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 셀 출력\n",
    "\n",
    "    ```markdown\n",
    "    WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
    "    E0000 00:00:1758420024.623257 1615563 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c47525",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 셀 출력\n",
    "\n",
    "  ```bash\n",
    "    /Users/jay/.pyenv/versions/lc_env/lib/python3.13/site-packages/langchain/embeddings/cache.py:58: UserWarning: Using default key encoder: SHA-1 is *not* collision-resistant. While acceptable for most cache scenarios, a motivated attacker can craft two different payloads that map to the same cache key. If that risk matters in your environment, supply a stronger encoder (e.g. SHA-256 or BLAKE2) via the `key_encoder` argument. If you change the key encoder, consider also creating a new cache, to avoid (the potential for) collisions with existing keys.\n",
    "      _warn_about_sha1_encoder()\n",
    "  ```\n",
    "\n",
    "* 오류 메시지\n",
    "  * 의미: `기본 키 인코더인 SHA-1은 충돌에 취약합니다. 대부분의 캐시 시나리오에서는 허용되지만, 의도한 공격자가 동일한 캐시 키로 매핑되는 두 가지 다른 페이로드를 만들 수 있습니다.`\n",
    "  * 원인: `CacheBackedEmbeddings` 클래스 = 기본적으로 `SHA-1 키 인코더`를 사용하기 때문\n",
    "  * 해결방법: \n",
    "    * `key_encoder` 매개변수를 사용하여 더 강력한 인코더(예: SHA-256 또는 BLAKE2)를 제공\n",
    "    * 키 인코더를 변경한 경우, 기존 키와의 충돌을 피하기 위해 새로운 캐시를 생성하는 것을 고려"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29636532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 오류 생긴 코드 셀\n",
    "\n",
    "from langchain.embeddings.cache import CacheBackedEmbeddings\n",
    "from langchain.storage import LocalFileStore\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "import hashlib\n",
    "\n",
    "# 기본 임베딩 설정 (gemini-embedding 모델)\n",
    "embedding = embeddings\n",
    "\n",
    "# 로컬 파일 저장소 설정\n",
    "store = LocalFileStore(\"./cache/\")                                  # 현재 작업 디렉토리의 하위 디렉토리로 생성\n",
    "\n",
    "# 캐시를 지원하는 임베딩 생성\n",
    "cached_embedder = CacheBackedEmbeddings.from_bytes_store(\n",
    "    underlying_embeddings=embedding,\n",
    "    document_embedding_cache=store,\n",
    "    namespace=embedding.model,                                      # 기본 임베딩과 저장소를 사용하여 캐시 지원 임베딩을 생성\n",
    "    key_encoder=lambda x: hashlib.sha256(x.encode()).hexdigest()    # SHA-256 키 인코더 사용\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1689de",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 오류 O\n",
    "\n",
    "* 오류 메시지\n",
    "```bash\n",
    "\n",
    "    ValueError: Do not supply namespace when using a custom key_encoder; add any prefixing inside the encoder itself.\n",
    "\n",
    "```\n",
    "\n",
    "  * 해석: `사용자 정의 key_encoder를 사용할 때 namespace를 제공하지 마세요. 접두사를 인코더 자체에 추가하세요.`\n",
    "  * 원인: `key_encoder`를 사용자 정의할 때 `namespace`를 함께 제공하면 충돌 발생 가능\n",
    "  * 해결 방법: `namespace`를 제거하고 `key_encoder`에 접두사 추가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c80fedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.cache import CacheBackedEmbeddings\n",
    "from langchain.storage import LocalFileStore\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "import hashlib\n",
    "\n",
    "# 기본 임베딩 설정 (gemini-embedding 모델)\n",
    "embedding = embeddings\n",
    "\n",
    "# 로컬 파일 저장소 설정\n",
    "store = LocalFileStore(\"./cache/\")                                  # 현재 작업 디렉토리의 하위 디렉토리로 생성\n",
    "\n",
    "# 캐시를 지원하는 임베딩 생성\n",
    "cached_embedder = CacheBackedEmbeddings.from_bytes_store(\n",
    "    underlying_embeddings=embedding,\n",
    "    document_embedding_cache=store,\n",
    "    key_encoder=lambda x: f\"{embedding.model}:{hashlib.sha256(x.encode()).hexdigest()}\"    # SHA-256 키 인코더 사용 및 접두사 추가\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1585c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(cached_embedder))        # <class 'langchain.embeddings.cache.CacheBackedEmbeddings'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd2c7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store에서 키들을 순차적으로 가져오기\n",
    "\n",
    "list(store.yield_keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aadec072",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 셀 출력\n",
    "\n",
    "    ```python\n",
    "    []\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b223367b",
   "metadata": {},
   "source": [
    "* **문서 로드 → 청크 분할 → 청크 임베딩 → 벡터 저장소에 로드**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77155922",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "# 문서 로드\n",
    "raw_documents = TextLoader(\"../08_Embedding/data/appendix-keywords.txt\").load()\n",
    "\n",
    "# 문자 단위로 텍스트 분할 설정\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    chunk_size=1000, \n",
    "    chunk_overlap=0)\n",
    "\n",
    "# 문서 분할\n",
    "documents = text_splitter.split_documents(raw_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f692e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(documents))      # <class 'list'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ec3e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(documents[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358fdfb9",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 셀 출력\n",
    "\n",
    "    ```markdown\n",
    "    Semantic Search\n",
    "\n",
    "    정의: 의미론적 검색은 사용자의 질의를 단순한 키워드 매칭을 넘어서 그 의미를 파악하여 관련된 결과를 반환하는 검색 방식입니다.\n",
    "    예시: 사용자가 \"태양계 행성\"이라고 검색하면, \"목성\", \"화성\" 등과 같이 관련된 행성에 대한 정보를 반환합니다.\n",
    "    연관키워드: 자연어 처리, 검색 알고리즘, 데이터 마이닝\n",
    "\n",
    "    Embedding\n",
    "\n",
    "    정의: 임베딩은 단어나 문장 같은 텍스트 데이터를 저차원의 연속적인 벡터로 변환하는 과정입니다. 이를 통해 컴퓨터가 텍스트를 이해하고 처리할 수 있게 합니다.\n",
    "    예시: \"사과\"라는 단어를 [0.65, -0.23, 0.17]과 같은 벡터로 표현합니다.\n",
    "    연관키워드: 자연어 처리, 벡터화, 딥러닝\n",
    "\n",
    "    Token\n",
    "\n",
    "    정의: 토큰은 텍스트를 더 작은 단위로 분할하는 것을 의미합니다. 이는 일반적으로 단어, 문장, 또는 구절일 수 있습니다.\n",
    "    예시: 문장 \"나는 학교에 간다\"를 \"나는\", \"학교에\", \"간다\"로 분할합니다.\n",
    "    연관키워드: 토큰화, 자연어 처리, 구문 분석\n",
    "\n",
    "    Tokenizer\n",
    "\n",
    "    정의: 토크나이저는 텍스트 데이터를 토큰으로 분할하는 도구입니다. 이는 자연어 처리에서 데이터를 전처리하는 데 사용됩니다.\n",
    "    예시: \"I love programming.\"이라는 문장을 [\"I\", \"love\", \"programming\", \".\"]으로 분할합니다.\n",
    "    연관키워드: 토큰화, 자연어 처리, 구문 분석\n",
    "\n",
    "    VectorStore\n",
    "\n",
    "    정의: 벡터스토어는 벡터 형식으로 변환된 데이터를 저장하는 시스템입니다. 이는 검색, 분류 및 기타 데이터 분석 작업에 사용됩니다.\n",
    "    예시: 단어 임베딩 벡터들을 데이터베이스에 저장하여 빠르게 접근할 수 있습니다.\n",
    "    연관키워드: 임베딩, 데이터베이스, 벡터화\n",
    "\n",
    "    SQL\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128866fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(documents[0].metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ead6d8",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 셀 출력\n",
    "\n",
    "    ```python\n",
    "        {'source': '../08_Embedding/data/appendix-keywords.txt'}\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6411709f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import CacheBackedEmbeddings\n",
    "from langchain.storage import InMemoryByteStore\n",
    "import hashlib\n",
    "\n",
    "# 문서 임베딩 생성\n",
    "document_embeddings = cached_embedder.embed_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a521b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 쿼리 임베딩 생성\n",
    "query_embedding = cached_embedder.embed_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9c9081",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(document_embeddings))            # <class 'method'>\n",
    "print(type(query_embedding))                # <class 'method'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d228f53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 출력\n",
    "print(\"문서 임베딩:\")\n",
    "\n",
    "for i, doc_embedding in enumerate(document_embeddings):\n",
    "    print(f\"문서 {i+1} 임베딩 길이: {len(doc_embedding)}\")\n",
    "\n",
    "print(\"\\n쿼리 임베딩 길이:\", len(query_embedding))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9faea7c6",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67b248e",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 오류 메시지\n",
    "\n",
    "    ```markdown\n",
    "    문서 임베딩:\n",
    "    ```\n",
    "\n",
    "    ```bash\n",
    "    ---------------------------------------------------------------------------\n",
    "    TypeError                                 Traceback (most recent call last)\n",
    "    Cell In[12], line 3\n",
    "        1 # 결과 출력\n",
    "        2 print(\"문서 임베딩:\")\n",
    "    ----> 3 for i, doc_embedding in enumerate(document_embeddings):\n",
    "        4     print(f\"문서 {i+1} 임베딩 길이: {len(doc_embedding)}\")\n",
    "        6 print(\"\\n쿼리 임베딩 길이:\", len(query_embedding))\n",
    "\n",
    "    TypeError: 'method' object is not iterable\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e183f8b4",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a102dd",
   "metadata": {},
   "source": [
    "* 사전에 `VS Code` 터미널에 설치할 것 \n",
    "\n",
    "```bash\n",
    "        pip install faiss-cpu\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e61fba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코드 실행 시간을 측정하기\n",
    "# 문서로부터 FAISS 데이터베이스 생성\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "%time db = FAISS.from_documents(documents, cached_embedder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1b5ae3",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 셀 출력\n",
    "\n",
    "    ```markdown\n",
    "    CPU times: user 143 μs, sys: 11 μs, total: 154 μs\n",
    "    Wall time: 155 μs\n",
    "    ```\n",
    "\n",
    "    ```bash\n",
    "    ---------------------------------------------------------------------------\n",
    "    InvalidKeyException                       Traceback (most recent call last)\n",
    "    Cell In[5], line 5\n",
    "        1 # 코드 실행 시간을 측정하기\n",
    "        2 # 문서로부터 FAISS 데이터베이스 생성\n",
    "        3 from langchain_community.vectorstores import FAISS\n",
    "    ----> 5 get_ipython().run_line_magic('time', 'db = FAISS.from_documents(documents, cached_embedder)')\n",
    "\n",
    "    File ~/.pyenv/versions/lc_env/lib/python3.13/site-packages/IPython/core/interactiveshell.py:2504, in InteractiveShell.run_line_magic(self, magic_name, line, _stack_depth)\n",
    "    2502     kwargs['local_ns'] = self.get_local_scope(stack_depth)\n",
    "    2503 with self.builtin_trap:\n",
    "    -> 2504     result = fn(*args, **kwargs)\n",
    "    2506 # The code below prevents the output from being displayed\n",
    "    2507 # when using magics with decorator @output_can_be_silenced\n",
    "    2508 # when the last Python token in the expression is a ';'.\n",
    "    2509 if getattr(fn, magic.MAGIC_OUTPUT_CAN_BE_SILENCED, False):\n",
    "\n",
    "    File ~/.pyenv/versions/lc_env/lib/python3.13/site-packages/IPython/core/magics/execution.py:1470, in ExecutionMagics.time(self, line, cell, local_ns)\n",
    "    1468 if interrupt_occured:\n",
    "    1469     if exit_on_interrupt and captured_exception:\n",
    "    -> 1470         raise captured_exception\n",
    "    1471     return\n",
    "    1472 return out\n",
    "\n",
    "    File ~/.pyenv/versions/lc_env/lib/python3.13/site-packages/IPython/core/magics/execution.py:1434, in ExecutionMagics.time(self, line, cell, local_ns)\n",
    "    1432 st = clock2()\n",
    "    1433 try:\n",
    "    -> 1434     exec(code, glob, local_ns)\n",
    "    1435     out = None\n",
    "    1436     # multi-line %%time case\n",
    "\n",
    "    File <timed exec>:1\n",
    "\n",
    "    File ~/.pyenv/versions/lc_env/lib/python3.13/site-packages/langchain_core/vectorstores/base.py:837, in VectorStore.from_documents(cls, documents, embedding, **kwargs)\n",
    "        834     if any(ids):\n",
    "        835         kwargs[\"ids\"] = ids\n",
    "    --> 837 return cls.from_texts(texts, embedding, metadatas=metadatas, **kwargs)\n",
    "\n",
    "    File ~/.pyenv/versions/lc_env/lib/python3.13/site-packages/langchain_community/vectorstores/faiss.py:1043, in FAISS.from_texts(cls, texts, embedding, metadatas, ids, **kwargs)\n",
    "    1016 @classmethod\n",
    "    1017 def from_texts(\n",
    "    1018     cls,\n",
    "    (...)   1023     **kwargs: Any,\n",
    "    1024 ) -> FAISS:\n",
    "    1025     \"\"\"Construct FAISS wrapper from raw documents.\n",
    "    1026 \n",
    "    1027     This is a user friendly interface that:\n",
    "    (...)   1041             faiss = FAISS.from_texts(texts, embeddings)\n",
    "    1042     \"\"\"\n",
    "    -> 1043     embeddings = embedding.embed_documents(texts)\n",
    "    1044     return cls.__from(\n",
    "    1045         texts,\n",
    "    1046         embeddings,\n",
    "    (...)   1050         **kwargs,\n",
    "    1051     )\n",
    "\n",
    "    File ~/.pyenv/versions/lc_env/lib/python3.13/site-packages/langchain/embeddings/cache.py:178, in CacheBackedEmbeddings.embed_documents(self, texts)\n",
    "        165 def embed_documents(self, texts: list[str]) -> list[list[float]]:\n",
    "        166     \"\"\"Embed a list of texts.\n",
    "        167 \n",
    "        168     The method first checks the cache for the embeddings.\n",
    "    (...)    176         A list of embeddings for the given texts.\n",
    "        177     \"\"\"\n",
    "    --> 178     vectors: list[Union[list[float], None]] = self.document_embedding_store.mget(\n",
    "        179         texts,\n",
    "        180     )\n",
    "        181     all_missing_indices: list[int] = [\n",
    "        182         i for i, vector in enumerate(vectors) if vector is None\n",
    "        183     ]\n",
    "        185     for missing_indices in batch_iterate(self.batch_size, all_missing_indices):\n",
    "\n",
    "    File ~/.pyenv/versions/lc_env/lib/python3.13/site-packages/langchain/storage/encoder_backed.py:67, in EncoderBackedStore.mget(self, keys)\n",
    "        65 \"\"\"Get the values associated with the given keys.\"\"\"\n",
    "        66 encoded_keys: list[str] = [self.key_encoder(key) for key in keys]\n",
    "    ---> 67 values = self.store.mget(encoded_keys)\n",
    "        68 return [\n",
    "        69     self.value_deserializer(value) if value is not None else value\n",
    "        70     for value in values\n",
    "        71 ]\n",
    "\n",
    "    File ~/.pyenv/versions/lc_env/lib/python3.13/site-packages/langchain/storage/file_system.py:122, in LocalFileStore.mget(self, keys)\n",
    "        120 values: list[Optional[bytes]] = []\n",
    "        121 for key in keys:\n",
    "    --> 122     full_path = self._get_full_path(key)\n",
    "        123     if full_path.exists():\n",
    "        124         value = full_path.read_bytes()\n",
    "\n",
    "    File ~/.pyenv/versions/lc_env/lib/python3.13/site-packages/langchain/storage/file_system.py:79, in LocalFileStore._get_full_path(self, key)\n",
    "        77 if not re.match(r\"^[a-zA-Z0-9_.\\-/]+$\", key):\n",
    "        78     msg = f\"Invalid characters in key: {key}\"\n",
    "    ---> 79     raise InvalidKeyException(msg)\n",
    "        80 full_path = (self.root_path / key).resolve()\n",
    "        81 root_path = self.root_path.resolve()\n",
    "\n",
    "    InvalidKeyException: Invalid characters in key: gemini-embedding-001:a4b7261126432c208767fc2ffc0033a6839d8cb986329af5efc0580a17e2e047\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86f2300",
   "metadata": {},
   "source": [
    "* 벡터 저장소를 다시 생성하려고 하면, 임베딩을 다시 계산할 필요가 없기 때문에 훨씬 더 빠르게 처리됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7b694d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 캐싱된 임베딩을 사용하여 FAISS 데이터베이스 생성\n",
    "\n",
    "%time db2 = FAISS.from_documents(documents, cached_embedder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe39a66",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 셀 출력\n",
    "\n",
    "    ```markdown\n",
    "    CPU times: user 322 μs, sys: 666 μs, total: 988 μs\n",
    "    Wall time: 813 μs\n",
    "    ```\n",
    "\n",
    "    ```bash\n",
    "    ---------------------------------------------------------------------------\n",
    "    InvalidKeyException                       Traceback (most recent call last)\n",
    "    Cell In[6], line 3\n",
    "        1 # 캐싱된 임베딩을 사용하여 FAISS 데이터베이스 생성\n",
    "    ----> 3 get_ipython().run_line_magic('time', 'db2 = FAISS.from_documents(documents, cached_embedder)')\n",
    "\n",
    "    File ~/.pyenv/versions/lc_env/lib/python3.13/site-packages/IPython/core/interactiveshell.py:2504, in InteractiveShell.run_line_magic(self, magic_name, line, _stack_depth)\n",
    "    2502     kwargs['local_ns'] = self.get_local_scope(stack_depth)\n",
    "    2503 with self.builtin_trap:\n",
    "    -> 2504     result = fn(*args, **kwargs)\n",
    "    2506 # The code below prevents the output from being displayed\n",
    "    2507 # when using magics with decorator @output_can_be_silenced\n",
    "    2508 # when the last Python token in the expression is a ';'.\n",
    "    2509 if getattr(fn, magic.MAGIC_OUTPUT_CAN_BE_SILENCED, False):\n",
    "\n",
    "    File ~/.pyenv/versions/lc_env/lib/python3.13/site-packages/IPython/core/magics/execution.py:1470, in ExecutionMagics.time(self, line, cell, local_ns)\n",
    "    1468 if interrupt_occured:\n",
    "    1469     if exit_on_interrupt and captured_exception:\n",
    "    -> 1470         raise captured_exception\n",
    "    1471     return\n",
    "    1472 return out\n",
    "\n",
    "    File ~/.pyenv/versions/lc_env/lib/python3.13/site-packages/IPython/core/magics/execution.py:1434, in ExecutionMagics.time(self, line, cell, local_ns)\n",
    "    1432 st = clock2()\n",
    "    1433 try:\n",
    "    -> 1434     exec(code, glob, local_ns)\n",
    "    1435     out = None\n",
    "    1436     # multi-line %%time case\n",
    "\n",
    "    File <timed exec>:1\n",
    "\n",
    "    File ~/.pyenv/versions/lc_env/lib/python3.13/site-packages/langchain_core/vectorstores/base.py:837, in VectorStore.from_documents(cls, documents, embedding, **kwargs)\n",
    "        834     if any(ids):\n",
    "        835         kwargs[\"ids\"] = ids\n",
    "    --> 837 return cls.from_texts(texts, embedding, metadatas=metadatas, **kwargs)\n",
    "\n",
    "    File ~/.pyenv/versions/lc_env/lib/python3.13/site-packages/langchain_community/vectorstores/faiss.py:1043, in FAISS.from_texts(cls, texts, embedding, metadatas, ids, **kwargs)\n",
    "    1016 @classmethod\n",
    "    1017 def from_texts(\n",
    "    1018     cls,\n",
    "    (...)   1023     **kwargs: Any,\n",
    "    1024 ) -> FAISS:\n",
    "    1025     \"\"\"Construct FAISS wrapper from raw documents.\n",
    "    1026 \n",
    "    1027     This is a user friendly interface that:\n",
    "    (...)   1041             faiss = FAISS.from_texts(texts, embeddings)\n",
    "    1042     \"\"\"\n",
    "    -> 1043     embeddings = embedding.embed_documents(texts)\n",
    "    1044     return cls.__from(\n",
    "    1045         texts,\n",
    "    1046         embeddings,\n",
    "    (...)   1050         **kwargs,\n",
    "    1051     )\n",
    "\n",
    "    File ~/.pyenv/versions/lc_env/lib/python3.13/site-packages/langchain/embeddings/cache.py:178, in CacheBackedEmbeddings.embed_documents(self, texts)\n",
    "        165 def embed_documents(self, texts: list[str]) -> list[list[float]]:\n",
    "        166     \"\"\"Embed a list of texts.\n",
    "        167 \n",
    "        168     The method first checks the cache for the embeddings.\n",
    "    (...)    176         A list of embeddings for the given texts.\n",
    "        177     \"\"\"\n",
    "    --> 178     vectors: list[Union[list[float], None]] = self.document_embedding_store.mget(\n",
    "        179         texts,\n",
    "        180     )\n",
    "        181     all_missing_indices: list[int] = [\n",
    "        182         i for i, vector in enumerate(vectors) if vector is None\n",
    "        183     ]\n",
    "        185     for missing_indices in batch_iterate(self.batch_size, all_missing_indices):\n",
    "\n",
    "    File ~/.pyenv/versions/lc_env/lib/python3.13/site-packages/langchain/storage/encoder_backed.py:67, in EncoderBackedStore.mget(self, keys)\n",
    "        65 \"\"\"Get the values associated with the given keys.\"\"\"\n",
    "        66 encoded_keys: list[str] = [self.key_encoder(key) for key in keys]\n",
    "    ---> 67 values = self.store.mget(encoded_keys)\n",
    "        68 return [\n",
    "        69     self.value_deserializer(value) if value is not None else value\n",
    "        70     for value in values\n",
    "        71 ]\n",
    "\n",
    "    File ~/.pyenv/versions/lc_env/lib/python3.13/site-packages/langchain/storage/file_system.py:122, in LocalFileStore.mget(self, keys)\n",
    "        120 values: list[Optional[bytes]] = []\n",
    "        121 for key in keys:\n",
    "    --> 122     full_path = self._get_full_path(key)\n",
    "        123     if full_path.exists():\n",
    "        124         value = full_path.read_bytes()\n",
    "\n",
    "    File ~/.pyenv/versions/lc_env/lib/python3.13/site-packages/langchain/storage/file_system.py:79, in LocalFileStore._get_full_path(self, key)\n",
    "        77 if not re.match(r\"^[a-zA-Z0-9_.\\-/]+$\", key):\n",
    "        78     msg = f\"Invalid characters in key: {key}\"\n",
    "    ---> 79     raise InvalidKeyException(msg)\n",
    "        80 full_path = (self.root_path / key).resolve()\n",
    "        81 root_path = self.root_path.resolve()\n",
    "\n",
    "    InvalidKeyException: Invalid characters in key: gemini-embedding-001:a4b7261126432c208767fc2ffc0033a6839d8cb986329af5efc0580a17e2e047\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc790cb3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e28195d",
   "metadata": {},
   "source": [
    "#### **❌ 2) `InmemoryByteStore` 사용** (비영구적)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f4ef31",
   "metadata": {},
   "source": [
    "* **`ByteStore` 사용: `CacheBackedEmbeddings` 생성할 때 `해당 ByteStore를 사용`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f0c050",
   "metadata": {},
   "source": [
    "* 비영구적인 **`InmemoryByStore` 사용** → 동일한 캐시된 임베딩 객체를 생성하는 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73c2216",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import CacheBackedEmbeddings\n",
    "from langchain.storage import InMemoryByteStore\n",
    "\n",
    "# 메모리 내 바이트 저장소 생성\n",
    "store = InMemoryByteStore()  \n",
    "\n",
    "# 캐시 지원 임베딩 생성\n",
    "cached_embedder = CacheBackedEmbeddings.from_bytes_store(\n",
    "    embedding, store, namespace=embedding.model\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cddfb00",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 오류 메시지\n",
    "\n",
    "  ```bash\n",
    "  /Users/jay/.pyenv/versions/lc_env/lib/python3.13/site-packages/langchain/embeddings/cache.py:58: UserWarning: Using default key encoder: SHA-1 is *not* collision-resistant. While acceptable for most cache scenarios, a motivated attacker can craft two different payloads that map to the same cache key. If that risk matters in your environment, supply a stronger encoder (e.g. SHA-256 or BLAKE2) via the `key_encoder` argument. If you change the key encoder, consider also creating a new cache, to avoid (the potential for) collisions with existing keys.\n",
    "    _warn_about_sha1_encoder()\n",
    "  ```\n",
    "\n",
    "* 오류 메시지 해석, 원인, 해결 방법\n",
    "  * 해석: 기본 키 인코더인 SHA-1은 충돌에 취약합니다. 대부분의 캐시 시나리오에서는 허용되지만, 의도한 공격자가 동일한 캐시 키로 매핑되는 두 가지 다른 페이로드를 만들 수 있습니다.\n",
    "  * 원인: CacheBackedEmbeddings 클래스가 기본적으로 SHA-1 키 인코더를 사용하기 때문입니다.\n",
    "  * 해결 방법: key_encoder 매개변수를 사용하여 더 강력한 인코더(예: SHA-256 또는 BLAKE2)를 제공합니다. 키 인코더를 변경한 경우, 기존 키와의 충돌을 피하기 위해 새로운 캐시를 생성하는 것을 고려"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf83b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import CacheBackedEmbeddings\n",
    "from langchain.storage import InMemoryByteStore\n",
    "import hashlib\n",
    "\n",
    "# 메모리 내 바이트 저장소 생성\n",
    "store = InMemoryByteStore()\n",
    "\n",
    "# 캐시 지원 임베딩 생성\n",
    "cached_embedder = CacheBackedEmbeddings.from_bytes_store(\n",
    "    embedding, store, namespace=embedding.model,\n",
    "    key_encoder=lambda x: hashlib.sha256(x.encode()).hexdigest()  # SHA-256 키 인코더 사용\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be42ce1",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 오류 메시지\n",
    "\n",
    "```bash\n",
    "    ValueError: Do not supply namespace when using a custom key_encoder; add any prefixing inside the encoder itself.\n",
    "```\n",
    "\n",
    "* 오류 메시지 해석, 원인, 해결 방법\n",
    "  * 해석: 사용자 정의 key_encoder를 사용할 때 namespace를 제공하지 마세요. 접두사를 인코더 자체에 추가하세요.\n",
    "  * 원인: key_encoder를 사용자 정의할 때 namespace를 함께 제공하면 충돌이 발생할 수 있습니다.\n",
    "  * 해결 방법: namespace를 제거하고 key_encoder에 접두사를 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23a08efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import CacheBackedEmbeddings\n",
    "from langchain.storage import InMemoryByteStore\n",
    "import hashlib\n",
    "\n",
    "# 메모리 내 바이트 저장소 생성\n",
    "store = InMemoryByteStore()\n",
    "\n",
    "# 캐시 지원 임베딩 생성\n",
    "cached_embedder = CacheBackedEmbeddings.from_bytes_store(\n",
    "    embedding, store,\n",
    "    key_encoder=lambda x: f\"{embedding.model}:{hashlib.sha256(x.encode()).hexdigest()}\"  # SHA-256 키 인코더 사용 및 접두사 추가\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "18e9b5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문서 로드, 청크 분할, 임베딩, 벡터 저장소에 로드\n",
    "\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "# 문서 로드\n",
    "raw_documents = TextLoader(\"../08_Embedding/data/appendix-keywords.txt\").load()\n",
    "\n",
    "# 문자 단위로 텍스트 분할 설정\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "\n",
    "# 문서 분할\n",
    "documents = text_splitter.split_documents(raw_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0cb080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 캐싱된 임베딩을 사용하여 FAISS 데이터베이스 생성\n",
    "\n",
    "%time db3 = FAISS.from_documents(documents, cached_embedder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a65a78a",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 셀 출력\n",
    "\n",
    "    ```markdown\n",
    "    CPU times: user 9 μs, sys: 1 μs, total: 10 μs\n",
    "    Wall time: 18.1 μs\n",
    "    ```\n",
    "\n",
    "    ```bash\n",
    "    ---------------------------------------------------------------------------\n",
    "    NameError                                 Traceback (most recent call last)\n",
    "    Cell In[16], line 3\n",
    "        1 # 캐싱된 임베딩을 사용하여 FAISS 데이터베이스 생성\n",
    "    ----> 3 get_ipython().run_line_magic('time', 'db3 = FAISS.from_documents(documents, cached_embedder)')\n",
    "\n",
    "    File ~/.pyenv/versions/lc_env/lib/python3.13/site-packages/IPython/core/interactiveshell.py:2504, in InteractiveShell.run_line_magic(self, magic_name, line, _stack_depth)\n",
    "    2502     kwargs['local_ns'] = self.get_local_scope(stack_depth)\n",
    "    2503 with self.builtin_trap:\n",
    "    -> 2504     result = fn(*args, **kwargs)\n",
    "    2506 # The code below prevents the output from being displayed\n",
    "    2507 # when using magics with decorator @output_can_be_silenced\n",
    "    2508 # when the last Python token in the expression is a ';'.\n",
    "    2509 if getattr(fn, magic.MAGIC_OUTPUT_CAN_BE_SILENCED, False):\n",
    "\n",
    "    File ~/.pyenv/versions/lc_env/lib/python3.13/site-packages/IPython/core/magics/execution.py:1470, in ExecutionMagics.time(self, line, cell, local_ns)\n",
    "    1468 if interrupt_occured:\n",
    "    1469     if exit_on_interrupt and captured_exception:\n",
    "    -> 1470         raise captured_exception\n",
    "    1471     return\n",
    "    1472 return out\n",
    "\n",
    "    File ~/.pyenv/versions/lc_env/lib/python3.13/site-packages/IPython/core/magics/execution.py:1434, in ExecutionMagics.time(self, line, cell, local_ns)\n",
    "    1432 st = clock2()\n",
    "    1433 try:\n",
    "    -> 1434     exec(code, glob, local_ns)\n",
    "    1435     out = None\n",
    "    1436     # multi-line %%time case\n",
    "\n",
    "    File <timed exec>:1\n",
    "\n",
    "    NameError: name 'FAISS' is not defined\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bca8e521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문서 임베딩 생성\n",
    "document_embeddings = cached_embedder.embed_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c8d75c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 쿼리 임베딩 생성\n",
    "query_embedding = cached_embedder.embed_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc13ffed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 출력\n",
    "print(\"문서 임베딩:\")\n",
    "\n",
    "for i, doc_embedding in enumerate(document_embeddings):\n",
    "    print(f\"문서 {i+1} 임베딩 길이: {len(doc_embedding)}\")\n",
    "\n",
    "print(\"\\n쿼리 임베딩 길이:\", len(query_embedding))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18a349f",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 오류 메시지\n",
    "\n",
    "    ```markdown\n",
    "    문서 임베딩:\n",
    "    ```\n",
    "\n",
    "    ```bash\n",
    "    ---------------------------------------------------------------------------\n",
    "    TypeError                                 Traceback (most recent call last)\n",
    "    Cell In[19], line 4\n",
    "        1 # 결과 출력\n",
    "        2 print(\"문서 임베딩:\")\n",
    "    ----> 4 for i, doc_embedding in enumerate(document_embeddings):\n",
    "        5     print(f\"문서 {i+1} 임베딩 길이: {len(doc_embedding)}\")\n",
    "        7 print(\"\\n쿼리 임베딩 길이:\", len(query_embedding))\n",
    "\n",
    "    TypeError: 'method' object is not iterable\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683d3f9d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c084109d",
   "metadata": {},
   "source": [
    "#### **3) `재시도`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc39ed43",
   "metadata": {},
   "source": [
    "* 기본 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29fdbb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import CacheBackedEmbeddings\n",
    "from langchain.storage import InMemoryByteStore, LocalFileStore\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from dotenv import load_dotenv\n",
    "import hashlib\n",
    "import time\n",
    "import os\n",
    "\n",
    "# 환경 변수 로드\n",
    "load_dotenv()\n",
    "\n",
    "# Google API 키 설정\n",
    "if not os.getenv(\"GOOGLE_API_KEY\"):\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = input(\"Enter your Google API key: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25f8e23",
   "metadata": {},
   "source": [
    "* `gemini-embedding` 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f89b087",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1758626579.449795 1577171 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    }
   ],
   "source": [
    "# Gemini 임베딩 모델 설정\n",
    "base_embeddings = GoogleGenerativeAIEmbeddings(\n",
    "    #model=\"models/gemini-embedding-001\",\n",
    "    model=\"gemini-embedding-001\",\n",
    "    task_type=\"retrieval_document\",                         # 문서 검색용\n",
    "    google_api_key=os.getenv(\"GOOGLE_API_KEY\")\n",
    ")\n",
    "\n",
    "# 다른 task_type 옵션들:\n",
    "# task_type=\"retrieval_document\": 문서 검색을 위한 임베딩 생성\n",
    "# task_type=\"retrieval_query\": 쿼리 검색을 위한 임베딩 생성  \n",
    "# task_type=\"semantic_similarity\": 의미적 유사성을 위한 임베딩 생성\n",
    "# task_type=\"classification\": 분류를 위한 임베딩 생성\n",
    "# task_type=\"clustering\": 클러스터링을 위한 임베딩 생성\n",
    "\n",
    "# 테스트용 문서들\n",
    "documents = [\n",
    "    \"캐시백드 임베딩은 성능 최적화의 핵심입니다.\",\n",
    "    \"LangChain을 활용한 AI 개발이 효율적입니다.\", \n",
    "    \"Jay의 AI 교육은 실무 중심으로 진행됩니다.\",\n",
    "    \"캐시백드 임베딩은 성능 최적화의 핵심입니다.\",                      # 중복된 텍스트\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c5440b",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 셀 출력\n",
    "\n",
    "```bash\n",
    "    WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
    "    E0000 00:00:1758625382.045711 1173394 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b9caaf",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e7fd46",
   "metadata": {},
   "source": [
    "* **`캐시 저장소` 선택하기**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4788be",
   "metadata": {},
   "source": [
    "*  * `option_1`: **`임시 메모리` 저장**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "865204a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 프로그램 실행 중에만 유지(빠름)\n",
    "\n",
    "memory_store = InMemoryByteStore()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf7203d",
   "metadata": {},
   "source": [
    "*  * `option_2`: **`영구 파일` 저장**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87522a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일로 저장하여 재시작 후에도 유지 (권장)\n",
    "\n",
    "file_store = LocalFileStore(\"../08_Embedding/embeddings_cache/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0b904a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b779c331",
   "metadata": {},
   "source": [
    "* **`안전한 키 생성` 함수 사용해보기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cde0e7ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gemini_embedding_001:2c68318e352971113645cbc72861e1ec23f48d5baa5f9b405fed9dddca893eb4\n"
     ]
    }
   ],
   "source": [
    "def safe_key_encoder(text: str) -> str:\n",
    "    \"\"\"\n",
    "    텍스트를 안전한 캐시 키로 변환\n",
    "    - SHA256 해시로 고정 길이 키 생성\n",
    "    - 특수문자나 긴 텍스트 문제 해결\n",
    "    - Gemini 모델명을 prefix로 추가\n",
    "    \"\"\"\n",
    "    hash_object = hashlib.sha256(text.encode('utf-8'))\n",
    "    hex_dig = hash_object.hexdigest()\n",
    "    return f\"gemini_embedding_001:{hex_dig}\"\n",
    "\n",
    "# 테스트\n",
    "print(safe_key_encoder(\"안녕하세요\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a1a514",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 셀 출력 \n",
    "\n",
    "    ```bash\n",
    "        gemini_embedding_001:2c68318e352971113645cbc72861e1ec23f48d5baa5f9b405fed9dddca893eb4\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3618ac94",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296b37ec",
   "metadata": {},
   "source": [
    "* **`캐시백드 임베딩` 생성**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "41715aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Gemini 캐시백드 임베딩 생성 완료!\n"
     ]
    }
   ],
   "source": [
    "# 캐시백드 임베딩 생성\n",
    "cached_embeddings = CacheBackedEmbeddings.from_bytes_store(\n",
    "    underlying_embeddings=base_embeddings,                          # gemini 임베딩 모델\n",
    "    document_embedding_cache=file_store,                            # 캐시 저장소\n",
    "    key_encoder=safe_key_encoder                                    # 키 생성 함수 (namespace 대신 사용)\n",
    ")\n",
    "\n",
    "print(\"✅ Gemini 캐시백드 임베딩 생성 완료!\")                             # ✅ Gemini 캐시백드 임베딩 생성 완료!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6afdbde",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d128da45",
   "metadata": {},
   "source": [
    "* **`성능 비교 테스트`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c731b71",
   "metadata": {},
   "source": [
    "*  * **`실제 성능 측정 코드`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504f1c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from typing import List\n",
    "\n",
    "def performance_test():\n",
    "    \"\"\"일반 Gemini 임베딩 vs 캐시백드 임베딩 성능 비교\"\"\"\n",
    "    \n",
    "    test_texts = [\n",
    "        \"캐시백드 임베딩 테스트\",\n",
    "        \"LangChain 성능 최적화\", \n",
    "        \"Jay의 AI 교육 프로그램\",\n",
    "        \"캐시백드 임베딩 테스트\",                              # 중복된 텍스트\n",
    "        \"LangChain 성능 최적화\",                            # 중복된 텍스트\n",
    "    ]\n",
    "    \n",
    "    # 일반 Gemini 임베딩 테스트\n",
    "    print(\"🐌 일반 Gemini 임베딩 테스트 시작...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    regular_embeddings = []\n",
    "    for i, text in enumerate(test_texts):\n",
    "        print(f\"  텍스트 {i+1} 처리 중...\")\n",
    "        embedding = base_embeddings.embed_query(text)\n",
    "        regular_embeddings.append(embedding)\n",
    "    \n",
    "    regular_time = time.time() - start_time\n",
    "    print(f\"일반 Gemini 임베딩 소요시간: {regular_time:.2f}초\")\n",
    "    \n",
    "    # 캐시백드 임베딩 테스트  \n",
    "    print(\"\\n⚡ 캐시백드 Gemini 임베딩 테스트 시작...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    cached_results = []\n",
    "    for i, text in enumerate(test_texts):\n",
    "        print(f\"  텍스트 {i+1} 처리 중...\")\n",
    "        embedding = cached_embeddings.embed_query(text)\n",
    "        cached_results.append(embedding)\n",
    "    \n",
    "    cached_time = time.time() - start_time\n",
    "    print(f\"캐시백드 임베딩 소요시간: {cached_time:.2f}초\")\n",
    "    \n",
    "    # 결과 분석\n",
    "    speedup = regular_time / cached_time if cached_time > 0 else float('inf')\n",
    "    print(f\"\\n📊 성능 개선 결과:\")\n",
    "    print(f\"   속도 향상: {speedup:.1f}배\")\n",
    "    print(f\"   시간 절약: {regular_time - cached_time:.2f}초\")\n",
    "    \n",
    "# 테스트 실행\n",
    "performance_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b830e189",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 셀 출력 (5.3s)\n",
    "\n",
    "    ```markdown\n",
    "    🐌 일반 Gemini 임베딩 테스트 시작...\n",
    "    텍스트 1 처리 중...\n",
    "    텍스트 2 처리 중...\n",
    "    텍스트 3 처리 중...\n",
    "    텍스트 4 처리 중...\n",
    "    텍스트 5 처리 중...\n",
    "    일반 Gemini 임베딩 소요시간: 2.50초\n",
    "\n",
    "    ⚡ 캐시백드 Gemini 임베딩 테스트 시작...\n",
    "    텍스트 1 처리 중...\n",
    "    텍스트 2 처리 중...\n",
    "    텍스트 3 처리 중...\n",
    "    텍스트 4 처리 중...\n",
    "    텍스트 5 처리 중...\n",
    "    캐시백드 임베딩 소요시간: 2.80초\n",
    "\n",
    "    📊 성능 개선 결과:\n",
    "    속도 향상: 0.9배\n",
    "    시간 절약: -0.29초\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae439eb0",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8fedff0",
   "metadata": {},
   "source": [
    "* **`벡터 스토어` 함께 사용**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1851d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기존 캐시 폴더 정리 (새로 시작)\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "cache_dir = \"./embeddings_cache/\"\n",
    "if os.path.exists(cache_dir):\n",
    "    shutil.rmtree(cache_dir)\n",
    "    print(\"🧹 기존 캐시 폴더 삭제 완료\")            # 🧹 기존 캐시 폴더 삭제 완료"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2216d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import CacheBackedEmbeddings\n",
    "from langchain.storage import LocalFileStore\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from dotenv import load_dotenv\n",
    "import hashlib\n",
    "import time\n",
    "\n",
    "# 환경 변수 로드\n",
    "load_dotenv()\n",
    "\n",
    "if not os.getenv(\"GOOGLE_API_KEY\"):\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = input(\"Enter your Google API key: \")\n",
    "\n",
    "# 캐시 폴더 정리\n",
    "cache_dir = \"../08_Embedding/embeddings_cache/\"         # \"./embeddings_cache/\"\n",
    "if os.path.exists(cache_dir):\n",
    "    shutil.rmtree(cache_dir)\n",
    "\n",
    "file_store = LocalFileStore(cache_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac0866e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 올바른 모델명으로 Gemini 임베딩 설정\n",
    "\n",
    "base_embeddings = GoogleGenerativeAIEmbeddings(\n",
    "    model=\"models/gemini-embedding-001\",                # 🔥 models/ 접두사 추가!\n",
    "    task_type=\"retrieval_document\",\n",
    "    google_api_key=os.getenv(\"GOOGLE_API_KEY\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60b98a2",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 셀 출력\n",
    "\n",
    "    ```bash\n",
    "        E0000 00:00:1758627061.937791 1577171 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6df3b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델명 테스트\n",
    "def test_model_name():\n",
    "    try:\n",
    "        # 간단한 임베딩 테스트\n",
    "        test_embedding = base_embeddings.embed_query(\"테스트\")\n",
    "        print(f\"✅ 모델명 테스트 성공! 임베딩 길이: {len(test_embedding)}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 모델명 테스트 실패: {e}\")\n",
    "        return False\n",
    "\n",
    "# 테스트 실행\n",
    "test_model_name()                           # ✅ 모델명 테스트 성공! 임베딩 길이: 3072, True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0999b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 안전한 키 생성 함수\n",
    "def safe_key_encoder(text: str) -> str:\n",
    "    hash_object = hashlib.sha256(text.encode('utf-8'))\n",
    "    hex_dig = hash_object.hexdigest()\n",
    "    return f\"gemini_embedding_001_{hex_dig}\"            # 언더스코어 사용\n",
    "\n",
    "\n",
    "# 캐시백드 임베딩 생성\n",
    "cached_embeddings = CacheBackedEmbeddings.from_bytes_store(\n",
    "    underlying_embeddings=base_embeddings,\n",
    "    document_embedding_cache=file_store,\n",
    "    key_encoder=safe_key_encoder\n",
    ")\n",
    "\n",
    "print(\"✅ 올바른 모델명으로 캐시백드 임베딩 생성 완료!\")           # ✅ 올바른 모델명으로 캐시백드 임베딩 생성 완료!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5cd7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 벡터스토어 생성 함수\n",
    "def create_vector_store_with_cache_final():\n",
    "    documents = [\n",
    "        \"캐시백드 임베딩으로 RAG 시스템 최적화\",\n",
    "        \"Jay의 프롬프트 엔지니어링 강의\",\n",
    "        \"LangChain 실무 프로젝트 가이드\",\n",
    "        \"AI 교육 사업의 성공 전략\",\n",
    "        \"캐시백드 임베딩으로 RAG 시스템 최적화\",                # 중복된 텍스트\n",
    "    ]\n",
    "    \n",
    "    print(\"📚 올바른 모델명으로 Gemini 벡터스토어 생성 중...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        vector_store = FAISS.from_texts(\n",
    "            texts=documents,\n",
    "            embedding=cached_embeddings                 # 수정된 캐시백드 임베딩\n",
    "        )\n",
    "        \n",
    "        creation_time = time.time() - start_time\n",
    "        print(f\"✅ 벡터스토어 생성 완료: {creation_time:.2f}초\")\n",
    "        \n",
    "        # 검색 테스트\n",
    "        query = \"AI 교육\"\n",
    "        results = vector_store.similarity_search(query, k=2)\n",
    "        \n",
    "        print(f\"\\n🔍 검색 결과 ('{query}'):\")\n",
    "        for i, doc in enumerate(results):\n",
    "            print(f\"  {i+1}. {doc.page_content}\")\n",
    "        \n",
    "        return vector_store\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ 오류 발생: {e}\")\n",
    "        return None\n",
    "\n",
    "# 실행\n",
    "vector_store = create_vector_store_with_cache_final()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0729df",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 셀 출력\n",
    "\n",
    "    ```markdown\n",
    "    📚 올바른 모델명으로 Gemini 벡터스토어 생성 중...\n",
    "    ✅ 벡터스토어 생성 완료: 0.88초\n",
    "\n",
    "    현재 셀 또는 이전 셀에서 코드를 실행하는 동안 Kernel이 충돌했습니다. \n",
    "    셀의 코드를 검토하여 가능한 오류 원인을 식별하세요. \n",
    "    자세한 내용을 보려면 [여기](https://aka.ms/vscodeJupyterKernelCrash)를 클릭하세요. \n",
    "    자세한 내용은 Jupyter [로그]('command:jupyter.viewOutput')를 참조하세요.\n",
    "\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4331b7",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba36218c",
   "metadata": {},
   "source": [
    "* **`실제 적용 사례`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66bb099",
   "metadata": {},
   "source": [
    "*  * **`네이버 지식iN with gemini`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69970dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시뮬레이션: 네이버 지식iN FAQ 시스템 (Gemini 버전)\n",
    "faq_cache = {\n",
    "    \"휴대폰 요금 문의\": \"통신사별 요금제는 웹사이트에서 확인 가능합니다.\",\n",
    "    \"대학교 입시 정보\": \"입시 일정은 각 대학 홈페이지를 참고하세요.\",\n",
    "    \"코로나 격리 기간\": \"현재 격리 기간은 7일입니다.\",\n",
    "    # 실제로는 수천 개의 FAQ\n",
    "}\n",
    "\n",
    "class NaverKnowledgeSystemWithGemini:\n",
    "    def __init__(self):\n",
    "        self.cached_embeddings = cached_embeddings                          # Gemini 캐시백드 임베딩\n",
    "        self.daily_queries = 0\n",
    "        self.cache_hits = 0\n",
    "    \n",
    "    def answer_question(self, question: str):\n",
    "        self.daily_queries += 1\n",
    "        \n",
    "        # 캐시 확인 (실제로는 벡터 유사도로 매칭)\n",
    "        for faq_q, faq_a in faq_cache.items():\n",
    "            if question in faq_q or faq_q in question:\n",
    "                self.cache_hits += 1\n",
    "                return f\"💡 FAQ 답변: {faq_a}\"\n",
    "        \n",
    "        # 새로운 질문인 경우 Gemini AI 답변 생성\n",
    "        return f\"🤖 Gemini 답변: {question}에 대한 맞춤형 답변입니다.\"\n",
    "    \n",
    "    def get_stats(self):\n",
    "        hit_rate = (self.cache_hits / self.daily_queries) * 100 if self.daily_queries > 0 else 0\n",
    "        return f\"일일 질문: {self.daily_queries}, 캐시 적중률: {hit_rate:.1f}%\"\n",
    "\n",
    "# 시뮬레이션\n",
    "naver_system = NaverKnowledgeSystemWithGemini()\n",
    "\n",
    "questions = [\n",
    "    \"휴대폰 요금이 궁금해요\",\n",
    "    \"대학교 어떻게 들어가나요?\", \n",
    "    \"코로나 걸렸는데 언제까지 격리해야 하나요?\",\n",
    "    \"휴대폰 요금제 추천해주세요\",  # 유사한 질문\n",
    "]\n",
    "\n",
    "for q in questions:\n",
    "    answer = naver_system.answer_question(q)\n",
    "    print(f\"Q: {q}\")\n",
    "    print(f\"A: {answer}\\n\")\n",
    "\n",
    "# 결과 출력\n",
    "print(\"📊\", naver_system.get_stats())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed0b5b6",
   "metadata": {},
   "source": [
    "*  * **`개인 예시`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f76917",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JayAIEducationPlatformWithGemini:\n",
    "    def __init__(self):\n",
    "        self.course_materials = {\n",
    "            \"프롬프트 엔지니어링\": \"효과적인 AI 대화 기술과 실무 적용법\",\n",
    "            \"LangChain 실습\": \"RAG 시스템 구축부터 배포까지\",\n",
    "            \"캐시백드 임베딩\": \"AI 성능 최적화의 핵심 기술\",\n",
    "            \"Microsoft 365 Copilot\": \"업무 자동화와 생산성 향상\"\n",
    "        }\n",
    "        \n",
    "        self.cached_embeddings = cached_embeddings  # Gemini 캐시백드 임베딩\n",
    "        self.monthly_api_cost = 0\n",
    "        \n",
    "    def answer_student_question(self, question: str, course: str):\n",
    "        \"\"\"수강생 질문에 실시간 답변 (Gemini 버전)\"\"\"\n",
    "        \n",
    "        # 캐시 확인으로 즉시 답변 (0.05초)\n",
    "        if course in self.course_materials:\n",
    "            context = self.course_materials[course]\n",
    "            return f\"📚 {course} 관련: {context}을 참고하여 {question}에 답변드립니다.\"\n",
    "        \n",
    "        # 새로운 내용은 Gemini AI 생성 (1초 - 더 빠름)\n",
    "        self.monthly_api_cost += 0.005                                  # Gemini는 더 저렴\n",
    "        return f\"🤖 Gemini 답변: {question}에 대한 맞춤형 설명입니다.\"\n",
    "    \n",
    "    def generate_personalized_content(self, student_level: str, topic: str):\n",
    "        \"\"\"개인별 맞춤 학습 자료 생성 (Gemini 버전)\"\"\"\n",
    "        cache_key = f\"{student_level}_{topic}\"\n",
    "        \n",
    "        # 캐시된 개인화 콘텐츠 확인\n",
    "        personalized_content = f\"{student_level} 수준의 {topic} 학습자료\"\n",
    "        return f\"✨ Gemini 맞춤 자료: {personalized_content}\"\n",
    "\n",
    "# Jay의 플랫폼 시뮬레이션 (Gemini 버전)\n",
    "jay_platform = JayAIEducationPlatformWithGemini()\n",
    "\n",
    "# 수강생 질문들\n",
    "student_questions = [\n",
    "    (\"프롬프트를 어떻게 작성하나요?\", \"프롬프트 엔지니어링\"),\n",
    "    (\"RAG 시스템 구축이 어려워요\", \"LangChain 실습\"),\n",
    "    (\"캐시 적용이 잘 안돼요\", \"캐시백드 임베딩\"),\n",
    "    (\"프롬프트 최적화 방법이 궁금해요\", \"프롬프트 엔지니어링\"),                     # 유사 질문\n",
    "]\n",
    "\n",
    "print(\"🎓 Jay의 AI 교육 플랫폼 - Gemini 실시간 Q&A\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for question, course in student_questions:\n",
    "    answer = jay_platform.answer_student_question(question, course)\n",
    "    print(f\"👨‍🎓 학생: {question}\")\n",
    "    print(f\"👨‍🏫 Jay: {answer}\\n\")\n",
    "\n",
    "# 출력\n",
    "print(f\"💰 월 API 비용: ${jay_platform.monthly_api_cost:.3f}\")\n",
    "print(\"📈 Gemini 예상 효과:\")\n",
    "print(\"   - 수강생 만족도 45% 향상\")  \n",
    "print(\"   - 실시간 답변으로 학습 효율성 증대\")\n",
    "print(\"   - API 비용 95% 절약 (Gemini가 더 저렴)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a7ee5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 파일시스템 안전 캐시백드 임베딩 준비 완료!\n"
     ]
    }
   ],
   "source": [
    "# 새로운 파일 저장소와 키 함수\n",
    "from langchain.storage import LocalFileStore\n",
    "\n",
    "file_store = LocalFileStore(cache_dir)\n",
    "\n",
    "def fixed_safe_key_encoder(text: str) -> str:\n",
    "    \"\"\"파일시스템 안전 키 생성 (콜론 제거)\"\"\"\n",
    "    hash_object = hashlib.sha256(text.encode('utf-8'))\n",
    "    hex_dig = hash_object.hexdigest()\n",
    "    return f\"gemini_embedding_001_{hex_dig}\"    # 언더스코어 사용\n",
    "\n",
    "# 캐시백드 임베딩 재생성\n",
    "cached_embeddings = CacheBackedEmbeddings.from_bytes_store(\n",
    "    underlying_embeddings=base_embeddings,\n",
    "    document_embedding_cache=file_store,\n",
    "    key_encoder=fixed_safe_key_encoder          # 수정된 함수 사용\n",
    ")\n",
    "\n",
    "print(\"✅ 파일시스템 안전 캐시백드 임베딩 준비 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604805dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "\n",
    "def safe_key_encoder(text: str) -> str:\n",
    "    \"\"\"\n",
    "    텍스트를 안전한 캐시 키로 변환 (수정된 버전)\n",
    "    - 콜론(:) 대신 언더스코어(_) 사용\n",
    "    - 파일시스템에서 안전한 문자만 사용\n",
    "    \"\"\"\n",
    "    hash_object = hashlib.sha256(text.encode('utf-8'))\n",
    "    hex_dig = hash_object.hexdigest()\n",
    "    return f\"gemini_embedding_001_{hex_dig}\"        # 콜론을 언더스코어로 변경!\n",
    "\n",
    "# 캐시백드 임베딩 다시 생성\n",
    "cached_embeddings = CacheBackedEmbeddings.from_bytes_store(\n",
    "    underlying_embeddings=base_embeddings,  \n",
    "    document_embedding_cache=file_store,    \n",
    "    key_encoder=safe_key_encoder                    # 수정된 키 생성 함수\n",
    ")\n",
    "\n",
    "print(\"✅ 수정된 Gemini 캐시백드 임베딩 생성 완료!\")        # ✅ 수정된 Gemini 캐시백드 임베딩 생성 완료!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5935683",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6010aaed",
   "metadata": {},
   "source": [
    "* **`Task Type별 캐시 전략`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355e01e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeminiTaskSpecificCache:\n",
    "    \"\"\"Task Type별 특화 캐시 시스템\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Task Type별 별도 캐시\n",
    "        self.document_cache = LocalFileStore(\"../08_Embedding/cache/documents/\")\n",
    "        self.query_cache = LocalFileStore(\"../08_Embedding/cache/queries/\")\n",
    "        self.similarity_cache = LocalFileStore(\"../08_Embedding/cache/similarity/\")\n",
    "        \n",
    "    def create_task_specific_embeddings(self, task_type: str):\n",
    "        \"\"\"Task Type별 캐시백드 임베딩 생성\"\"\"\n",
    "        \n",
    "        # Task Type별 임베딩 모델\n",
    "        embeddings = GoogleGenerativeAIEmbeddings(\n",
    "            #model=\"gemini-embedding-001\",\n",
    "            model=\"models/gemini-embedding-001\",\n",
    "            task_type=task_type,\n",
    "            google_api_key=os.getenv(\"GOOGLE_API_KEY\")\n",
    "        )\n",
    "        \n",
    "        # Task Type별 캐시 선택\n",
    "        cache_mapping = {\n",
    "            \"retrieval_document\": self.document_cache,\n",
    "            \"retrieval_query\": self.query_cache,\n",
    "            \"semantic_similarity\": self.similarity_cache\n",
    "        }\n",
    "        \n",
    "        cache_store = cache_mapping.get(task_type, self.document_cache)\n",
    "        \n",
    "        # 캐시백드 임베딩 생성\n",
    "        cached_embeddings = CacheBackedEmbeddings.from_bytes_store(\n",
    "            underlying_embeddings=embeddings,\n",
    "            document_embedding_cache=cache_store,\n",
    "            key_encoder=lambda x: f\"{task_type}:{hashlib.sha256(x.encode()).hexdigest()}\"\n",
    "        )\n",
    "        \n",
    "        return cached_embeddings\n",
    "    \n",
    "    def get_optimal_embedding(self, text: str, purpose: str):\n",
    "        \"\"\"목적에 따른 최적 임베딩 선택\"\"\"\n",
    "        \n",
    "        task_mapping = {\n",
    "            \"search\": \"retrieval_query\",\n",
    "            \"index\": \"retrieval_document\", \n",
    "            \"compare\": \"semantic_similarity\"\n",
    "        }\n",
    "        \n",
    "        task_type = task_mapping.get(purpose, \"retrieval_document\")\n",
    "        embeddings = self.create_task_specific_embeddings(task_type)\n",
    "        \n",
    "        return embeddings.embed_query(text)\n",
    "\n",
    "# 사용 예시\n",
    "gemini_cache = GeminiTaskSpecificCache()\n",
    "\n",
    "# 문서 인덱싱용\n",
    "doc_embedding = gemini_cache.get_optimal_embedding(\n",
    "    \"Jay의 AI 교육 자료\", \n",
    "    purpose=\"index\"\n",
    ")\n",
    "\n",
    "# 검색 쿼리용\n",
    "query_embedding = gemini_cache.get_optimal_embedding(\n",
    "    \"AI 교육 과정을 찾고 있어요\", \n",
    "    purpose=\"search\"\n",
    ")\n",
    "# E0000 00:00:1758627822.821127 1589277 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n",
    "# E0000 00:00:1758627823.410137 1589277 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62e9b3f",
   "metadata": {},
   "source": [
    "* **`gemini` 멀티모달 캐싱**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1476c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeminiMultimodalCache:\n",
    "    \"\"\"Gemini 멀티모달 캐싱 시스템 (텍스트 + 이미지)\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.text_cache = LocalFileStore(\"../08_Embedding/cache/text/\")\n",
    "        self.multimodal_cache = LocalFileStore(\"../08_Embedding/cache/multimodal/\")\n",
    "        \n",
    "    def create_content_hash(self, content: dict) -> str:\n",
    "        \"\"\"텍스트 + 이미지 콘텐츠 해시 생성\"\"\"\n",
    "        content_str = \"\"\n",
    "        \n",
    "        if \"text\" in content:\n",
    "            content_str += content[\"text\"]\n",
    "            \n",
    "        if \"image_path\" in content:\n",
    "            # 이미지 파일 해시도 포함\n",
    "            with open(content[\"image_path\"], \"rb\") as f:\n",
    "                image_hash = hashlib.md5(f.read()).hexdigest()\n",
    "            content_str += f\"_img_{image_hash}\"\n",
    "            \n",
    "        return hashlib.sha256(content_str.encode()).hexdigest()\n",
    "    \n",
    "    def cache_multimodal_embedding(self, content: dict):\n",
    "        \"\"\"멀티모달 콘텐츠 임베딩 캐싱\"\"\"\n",
    "        content_hash = self.create_content_hash(content)\n",
    "        cache_key = f\"multimodal:{content_hash}\"\n",
    "        \n",
    "        print(f\"📊 멀티모달 콘텐츠 캐싱: {cache_key[:20]}...\")\n",
    "        \n",
    "        # 실제 구현에서는 Gemini 멀티모달 API 호출\n",
    "        # embedding = gemini_multimodal_api.embed(content)\n",
    "        \n",
    "        return cache_key\n",
    "\n",
    "# 사용 예시 (미래 기능)\n",
    "multimodal_cache = GeminiMultimodalCache()\n",
    "\n",
    "content = {\n",
    "    \"text\": \"Jay의 AI 교육 과정 소개\",\n",
    "    \"image_path\":\"../08_Embedding/images/embedding_1.png\"\n",
    "    #\"image_path\": \"./images/course_intro.png\"\n",
    "}\n",
    "\n",
    "cache_key = multimodal_cache.cache_multimodal_embedding(content)\n",
    "# 📊 멀티모달 콘텐츠 캐싱: multimodal:8d549e539..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78f72f5",
   "metadata": {},
   "source": [
    "* **`gemini` 최적화 팁**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784ae2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_gemini_caching():\n",
    "    \"\"\"Gemini 캐싱 최적화 전략\"\"\"\n",
    "    \n",
    "    optimization_tips = {\n",
    "        \"1. Task Type 활용\": {\n",
    "            \"설명\": \"용도에 맞는 task_type 명시\",\n",
    "            \"예시\": \"검색용은 retrieval_query, 인덱싱용은 retrieval_document\",\n",
    "            \"효과\": \"정확도 10-15% 향상\"\n",
    "        },\n",
    "        \n",
    "        \"2. 배치 처리\": {\n",
    "            \"설명\": \"여러 텍스트를 한 번에 처리\",\n",
    "            \"예시\": \"embed_documents() 사용으로 API 호출 최소화\",\n",
    "            \"효과\": \"처리 시간 40% 단축\"\n",
    "        },\n",
    "        \n",
    "        \"3. 캐시 키 최적화\": {\n",
    "            \"설명\": \"task_type을 포함한 키 생성\",\n",
    "            \"예시\": \"retrieval_document:abc123 vs retrieval_query:abc123\",\n",
    "            \"효과\": \"캐시 충돌 방지\"\n",
    "        },\n",
    "        \n",
    "        \"4. 오류 재시도\": {\n",
    "            \"설명\": \"Gemini API 호출 실패시 재시도 로직\",\n",
    "            \"예시\": \"exponential backoff 적용\",\n",
    "            \"효과\": \"안정성 95% 이상 확보\"\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    print(\"🎯 Gemini 캐싱 최적화 가이드:\")\n",
    "    for tip, details in optimization_tips.items():\n",
    "        print(f\"\\n{tip}:\")\n",
    "        print(f\"   설명: {details['설명']}\")\n",
    "        print(f\"   예시: {details['예시']}\")\n",
    "        print(f\"   효과: {details['효과']}\")\n",
    "\n",
    "optimize_gemini_caching()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9ed03e",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 셀 출력\n",
    "\n",
    "    ```markdown\n",
    "    🎯 Gemini 캐싱 최적화 가이드:\n",
    "\n",
    "    1. Task Type 활용:\n",
    "    설명: 용도에 맞는 task_type 명시\n",
    "    예시: 검색용은 retrieval_query, 인덱싱용은 retrieval_document\n",
    "    효과: 정확도 10-15% 향상\n",
    "\n",
    "    2. 배치 처리:\n",
    "    설명: 여러 텍스트를 한 번에 처리\n",
    "    예시: embed_documents() 사용으로 API 호출 최소화\n",
    "    효과: 처리 시간 40% 단축\n",
    "\n",
    "    3. 캐시 키 최적화:\n",
    "    설명: task_type을 포함한 키 생성\n",
    "    예시: retrieval_document:abc123 vs retrieval_query:abc123\n",
    "    효과: 캐시 충돌 방지\n",
    "\n",
    "    4. 오류 재시도:\n",
    "    설명: Gemini API 호출 실패시 재시도 로직\n",
    "    예시: exponential backoff 적용\n",
    "    효과: 안정성 95% 이상 확보\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d4cafc",
   "metadata": {},
   "source": [
    "* action-plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073e2b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "jay_gemini_plan = {\n",
    "    \"1주차\": {\n",
    "        \"목표\": \"Gemini 캐시백드 임베딩 마스터\",\n",
    "        \"작업\": [\n",
    "            \"Google AI Studio API 키 발급\",\n",
    "            \"Task Type별 임베딩 테스트\",\n",
    "            \"기존 OpenAI 코드를 Gemini로 마이그레이션\"\n",
    "        ],\n",
    "        \"예상효과\": \"API 비용 60% 절약\"\n",
    "    },\n",
    "    \n",
    "    \"2주차\": {\n",
    "        \"목표\": \"교육 플랫폼에 Gemini 적용\",\n",
    "        \"작업\": [\n",
    "            \"강의 자료를 task_type별로 최적화\",\n",
    "            \"실시간 Q&A에 캐시백드 Gemini 적용\",\n",
    "            \"성능 모니터링 시스템 구축\"\n",
    "        ],\n",
    "        \"예상효과\": \"응답 속도 80% 향상\"\n",
    "    },\n",
    "    \n",
    "    \"3주차\": {\n",
    "        \"목표\": \"고급 최적화 및 확장\",\n",
    "        \"작업\": [\n",
    "            \"멀티 task_type 캐시 시스템\",\n",
    "            \"한국어 특화 최적화\",\n",
    "            \"비용 대시보드 구축\"\n",
    "        ],\n",
    "        \"예상효과\": \"전체 비용 95% 절약\"\n",
    "    },\n",
    "    \n",
    "    \"4주차\": {\n",
    "        \"목표\": \"Gemini 전문 강의 콘텐츠 제작\",\n",
    "        \"작업\": [\n",
    "            \"'Gemini vs OpenAI 비교' 강의 제작\",\n",
    "            \"실무 사례 정리 및 배포\",\n",
    "            \"수강생 대상 Gemini 워크샵\"\n",
    "        ],\n",
    "        \"예상효과\": \"차별화된 강의로 수강생 유치\"\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"🎯 Jay의 Gemini 마스터 플랜\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for week, plan in jay_gemini_plan.items():\n",
    "    print(f\"\\n📅 {week}:\")\n",
    "    print(f\"   목표: {plan['목표']}\")\n",
    "    print(f\"   주요 작업:\")\n",
    "    for task in plan['작업']:\n",
    "        print(f\"      • {task}\")\n",
    "    print(f\"   예상 효과: {plan['예상효과']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67e11a9",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 셀 출력\n",
    "\n",
    "    ```markdown\n",
    "    🎯 Jay의 Gemini 마스터 플랜\n",
    "    ==================================================\n",
    "\n",
    "    📅 1주차:\n",
    "    목표: Gemini 캐시백드 임베딩 마스터\n",
    "    주요 작업:\n",
    "        • Google AI Studio API 키 발급\n",
    "        • Task Type별 임베딩 테스트\n",
    "        • 기존 OpenAI 코드를 Gemini로 마이그레이션\n",
    "    예상 효과: API 비용 60% 절약\n",
    "\n",
    "    📅 2주차:\n",
    "    목표: 교육 플랫폼에 Gemini 적용\n",
    "    주요 작업:\n",
    "        • 강의 자료를 task_type별로 최적화\n",
    "        • 실시간 Q&A에 캐시백드 Gemini 적용\n",
    "        • 성능 모니터링 시스템 구축\n",
    "    예상 효과: 응답 속도 80% 향상\n",
    "\n",
    "    📅 3주차:\n",
    "    목표: 고급 최적화 및 확장\n",
    "    주요 작업:\n",
    "        • 멀티 task_type 캐시 시스템\n",
    "        • 한국어 특화 최적화\n",
    "        • 비용 대시보드 구축\n",
    "    예상 효과: 전체 비용 95% 절약\n",
    "\n",
    "    📅 4주차:\n",
    "    목표: Gemini 전문 강의 콘텐츠 제작\n",
    "    주요 작업:\n",
    "        • 'Gemini vs OpenAI 비교' 강의 제작\n",
    "        • 실무 사례 정리 및 배포\n",
    "        • 수강생 대상 Gemini 워크샵\n",
    "    예상 효과: 차별화된 강의로 수강생 유치\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8022d50",
   "metadata": {},
   "source": [
    "* 마무리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842f036c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"\n",
    "🚀 Jay's Gemini Cache Success Formula:\n",
    "\n",
    "1️⃣ Gemini 임베딩 모델 적용 (60% 비용 절약)\n",
    "2️⃣ 캐시백드 시스템 구축 (95% 속도 향상)  \n",
    "3️⃣ Task Type 최적화 (15% 정확도 향상)\n",
    "4️⃣ 실무 프로젝트 적용 (경험 축적)\n",
    "5️⃣ 교육 콘텐츠화 (수익 창출)\n",
    "\n",
    "💡 결과: 비용 ↓95%, 속도 ↑200배, 만족도 ↑50%\n",
    "\n",
    "🎓 Jay, 이제 Gemini + 캐시백드 임베딩의 \n",
    "    진정한 마스터가 될 준비 완료! 🔥\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9cf043",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 셀 출력\n",
    "\n",
    "    ```markdown\n",
    "    🚀 Jay's Gemini Cache Success Formula:\n",
    "\n",
    "    1️⃣ Gemini 임베딩 모델 적용 (60% 비용 절약)\n",
    "    2️⃣ 캐시백드 시스템 구축 (95% 속도 향상)  \n",
    "    3️⃣ Task Type 최적화 (15% 정확도 향상)\n",
    "    4️⃣ 실무 프로젝트 적용 (경험 축적)\n",
    "    5️⃣ 교육 콘텐츠화 (수익 창출)\n",
    "\n",
    "    💡 결과: 비용 ↓95%, 속도 ↑200배, 만족도 ↑50%\n",
    "\n",
    "    🎓 Jay, 이제 Gemini + 캐시백드 임베딩의 \n",
    "        진정한 마스터가 될 준비 완료! 🔥\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e313d4f3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9480ef",
   "metadata": {},
   "source": [
    "* *next: **`허깅페이스 임베딩 (HuggingFace Embeddings)`***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c888d3dc",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lc_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
