# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# langchain-note/config.py 
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
""" OpenAI ëª¨ë¸ ì„¤ì • í•¨ìˆ˜
- gpt-5-nano / gpt-5-mini
- text-embedding-3-small / text-embedding-3-large
"""

import os
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI, OpenAIEmbeddings

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# ì „ì—­ ë³€ìˆ˜: LLM ì„¤ì • (í”„ë¡ì‹œ ê¸°ë°˜)
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

# GPT-5-nano ê¸°ë³¸ ì„¤ì • (í”„ë¡ì‹œ ê²½ìœ )
gpt_5_nano = ChatOpenAI(
    api_key=os.getenv("GPT5_NANO_API_KEY"),
    base_url=os.getenv("GPT5_NANO_BASE_URL"),
    model=os.getenv("GPT5_NANO_MODEL", "openai/gpt-5-nano"),
    #temperature=0.7
)

# GPT-5-mini ì„¤ì • (í”„ë¡ì‹œ ê²½ìœ )
gpt_5_mini = ChatOpenAI(
    api_key=os.getenv("GPT5_MINI_API_KEY"),
    base_url=os.getenv("GPT5_MINI_BASE_URL"),
    model=os.getenv("GPT5_MINI_MODEL", "openai/gpt-5-mini"),
    #temperature=0.7
)


# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# ì „ì—­ ë³€ìˆ˜: Embeddings ì„¤ì • (í”„ë¡ì‹œ ê¸°ë°˜)
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

embeddings = OpenAIEmbeddings(
    api_key=os.getenv("EMBEDDING_API_KEY"),
    base_url=os.getenv("EMBEDDING_BASE_URL"),
    model=os.getenv("EMBEDDING_MODEL", "text-embedding-3-small")
)

# text-embedding-3-large ì„¤ì • (í”„ë¡ì‹œ ê²½ìœ )
embeddings_large = OpenAIEmbeddings(
    api_key=os.getenv("EMBEDDING_LARGE_API_KEY"),
    base_url=os.getenv("EMBEDDING_LARGE_BASE_URL"),
    model=os.getenv("EMBEDDING_LARGE_MODEL", "text-embedding-3-large")
)

# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# ë„ìš°ë¯¸ í•¨ìˆ˜: ë™ì  ëª¨ë¸ ë³€ê²½
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

def get_llm(model=(os.getenv("GPT5_MINI_MODEL", "openai/gpt-5-mini"))):
    """
    ë™ì  LLM ìƒì„± í•¨ìˆ˜ (í”„ë¡ì‹œ ê¸°ë°˜)
    
    Args:
        model_name: ì‚¬ìš©í•  ëª¨ë¸ ì´ë¦„ (gpt_5_nano ë˜ëŠ” gpt_5_mini)
    
    Returns:
        ì„¤ì •ëœ LLM ê°ì²´
    """
    if model== os.getenv("GPT5_MINI_MODEL", "openai/gpt-5-mini"):
        return gpt_5_nano
    return gpt_5_mini


def get_embeddings(model=(os.getenv("EMBEDDING_MODEL", "text-embedding-3-small"))):
    """
    ë™ì  Embeddings ìƒì„± í•¨ìˆ˜
    
    Args:
        model_name: ì‚¬ìš©í•  ì„ë² ë”© ëª¨ë¸ ì´ë¦„
    
    Returns:
        ì„¤ì •ëœ Embeddings ê°ì²´
    """
    if model== os.getenv("EMBEDDING_MODEL", "text-embedding-3-small"):              # text-embedding-3-small (ê¸°ë³¸)
        return embeddings
    return embeddings_large

# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# ë©”ì¸ ì‹¤í–‰ (í…ŒìŠ¤íŠ¸ìš© / í•¨ìˆ˜ í˜¸ì¶œ ê¸°ë°˜ìœ¼ë¡œ ë³€ê²½)
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

if __name__ == "__main__":
    print("ğŸ” LangChain Note Config í…ŒìŠ¤íŠ¸ (í”„ë¡ì‹œ ê¸°ë°˜)")
    print("=" * 50)
    
    # ì§ˆì˜ë‚´ìš©
    question = "ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì¸ê°€ìš”?"
    
    # 1. ì§ì ‘ í˜¸ì¶œ í…ŒìŠ¤íŠ¸
    print("\n1ï¸âƒ£ ì§ì ‘ í˜¸ì¶œ (gpt_5_nano):", "\n")
    response1 = gpt_5_nano.invoke(question)
    print(f"   ë‹µë³€: {response1.content}")
    print("-" * 50, "\n")

    # 2. í•¨ìˆ˜ í˜¸ì¶œ í…ŒìŠ¤íŠ¸ (ê¸°ë³¸ê°’)
    print("\n2ï¸âƒ£ í•¨ìˆ˜ í˜¸ì¶œ get_llm() [ê¸°ë³¸ê°’]:", "\n")
    llm = get_llm()
    response2 = llm.invoke(question)
    print(f"   ë‹µë³€: {response2.content}")
    print("-" * 50, "\n")

    # 3. í•¨ìˆ˜ í˜¸ì¶œ í…ŒìŠ¤íŠ¸ (gpt-5-mini) - ëª…ì‹œì  í˜¸ì¶œ
    print("\n3ï¸âƒ£ í•¨ìˆ˜ í˜¸ì¶œ get_llm() [gpt-5-mini]:", "\n")
    llm = get_llm("openai/gpt-5-mini")
    response3 = llm.invoke(question)
    print(f"   ë‹µë³€: {response3.content}")
    print("-" * 50, "\n")

    # 4. ì„ë² ë”© í…ŒìŠ¤íŠ¸
    text = "ì„ë² ë”© í…ŒìŠ¤íŠ¸ ë¬¸ì¥"

    print("\n4ï¸âƒ£ Embeddings í…ŒìŠ¤íŠ¸:")
    emb_small = get_embeddings("small")
    vec_small = emb_small.embed_query(text)
    print(f"   small: {len(vec_small)}ì°¨ì›")
    
    emb_large = get_embeddings("large")
    vec_large = emb_large.embed_query(text)
    print(f"   large: {len(vec_large)}ì°¨ì›")
    
    print("\n" + "=" * 50)
    print("âœ… ëª¨ë“  í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")

    
    
"""test_result â†’ â­•ï¸ (but, ê°œë³„ í•¨ìˆ˜ë¡œ í˜¸ì¶œí•¨)

    python -m config
    
    ğŸ” LangChain Note Config í…ŒìŠ¤íŠ¸ (í”„ë¡ì‹œ ê¸°ë°˜)
    ==================================================

    1ï¸âƒ£ ê¸°ë³¸ LLM (gpt-5-nano): 

    [ì „ì²´ ë‹µë³€]: content='ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ” ì„œìš¸íŠ¹ë³„ì‹œ(ì„œìš¸)ì…ë‹ˆë‹¤. í•„ìš”í•˜ì‹  ì •ë³´ê°€ ë” ìˆë‚˜ìš”?' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 224, 'prompt_tokens': 15, 'total_tokens': 239, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 192, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CbgLVwFqErslOfV9Kl12BW4dqpwAm', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--90484fd4-62e1-4d4b-9b66-63beb12437d8-0' usage_metadata={'input_tokens': 15, 'output_tokens': 224, 'total_tokens': 239, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 192}}
    --------------------------------------------------
    [ë‹µë³€]:ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ” ì„œìš¸íŠ¹ë³„ì‹œ(ì„œìš¸)ì…ë‹ˆë‹¤. í•„ìš”í•˜ì‹  ì •ë³´ê°€ ë” ìˆë‚˜ìš”?
    --------------------------------------------------
    [ë©”íƒ€ë°ì´í„°]]: {'input_tokens': 15, 'output_tokens': 224, 'total_tokens': 239, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 192}}
    --------------------------------------------------

    2ï¸âƒ£ ë³€ê²½ëœ LLM (gpt-5-mini): 

    [ì „ì²´ ë‹µë³€]: content='ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ” ì„œìš¸íŠ¹ë³„ì‹œì…ë‹ˆë‹¤. ë‹¤ë§Œ ì¼ë¶€ ì¤‘ì•™í–‰ì •ê¸°ê´€ê³¼ í–‰ì • ê¸°ëŠ¥ì€ ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œë¡œ ì´ì „ë˜ì–´ í–‰ì • ì¤‘ì‹¬ ê¸°ëŠ¥ì´ ë¶„ì‚°ë˜ì–´ ìˆìŠµë‹ˆë‹¤.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 308, 'prompt_tokens': 15, 'total_tokens': 323, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 256, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-mini-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CbgLYTNhe6D7LNYETiGdOt2lHFh9U', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--29108493-8737-4d56-9959-1ead94f684f2-0' usage_metadata={'input_tokens': 15, 'output_tokens': 308, 'total_tokens': 323, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 256}}
    -------------------------------------------------- 

    [ë‹µë³€]:ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ” ì„œìš¸íŠ¹ë³„ì‹œ(ì„œìš¸)ì…ë‹ˆë‹¤. í•„ìš”í•˜ì‹  ì •ë³´ê°€ ë” ìˆë‚˜ìš”?
    -------------------------------------------------- 

    [ë©”íƒ€ë°ì´í„°]]: {'input_tokens': 15, 'output_tokens': 224, 'total_tokens': 239, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 192}}
    -------------------------------------------------- 


    3ï¸âƒ£ ê¸°ë³¸ Embeddings (text-embedding-3-small): 

    [-0.00776276458054781, 0.03680367395281792, 0.019545823335647583, -0.0196656696498394, 0.017203375697135925]

    ==================================================

        ì°¨ì›: 1536ì°¨ì›

    4ï¸âƒ£ ë³€ê²½ëœ Embeddings (text-embedding-3-large): 

    [-0.00311934482306242, -0.007872357964515686, -0.012800268828868866, 0.030090242624282837, 0.016375118866562843]

    ==================================================

        ì°¨ì›: 3072ì°¨ì›

    ============================

"""


"""test_result_2 â†’ â­•ï¸ (í•¨ìˆ˜ë¡œ í˜¸ì¶œ)


    python -m config

    ğŸ” LangChain Note Config í…ŒìŠ¤íŠ¸ (í”„ë¡ì‹œ ê¸°ë°˜)
    ==================================================

    1ï¸âƒ£ ì§ì ‘ í˜¸ì¶œ (gpt_5_nano): 

    ë‹µë³€: ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ” ì„œìš¸(ì„œìš¸íŠ¹ë³„ì‹œ)ì…ë‹ˆë‹¤.
    -------------------------------------------------- 


    2ï¸âƒ£ í•¨ìˆ˜ í˜¸ì¶œ get_llm() [ê¸°ë³¸ê°’]: 

    ë‹µë³€: ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ” ì„œìš¸(ì„œìš¸íŠ¹ë³„ì‹œ)ì…ë‹ˆë‹¤.
    -------------------------------------------------- 


    3ï¸âƒ£ í•¨ìˆ˜ í˜¸ì¶œ get_llm() [gpt-5-mini]: 

    ë‹µë³€: ì„œìš¸íŠ¹ë³„ì‹œì…ë‹ˆë‹¤.
    -------------------------------------------------- 


    4ï¸âƒ£ Embeddings í…ŒìŠ¤íŠ¸:
    small: 3072ì°¨ì›
    large: 3072ì°¨ì›

    ==================================================
    âœ… ëª¨ë“  í…ŒìŠ¤íŠ¸ ì™„ë£Œ!

"""



