{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f730d88e",
   "metadata": {},
   "source": [
    "#### **`LangChain Hub`**\n",
    "* ê°œë…\n",
    "  * `LangChain`ì˜ í•µì‹¬ ê¸°ëŠ¥ ì¤‘ í•˜ë‚˜\n",
    "  * í”„ë¡¬í”„íŠ¸ë“¤ì„ **ì¤‘ì•™ì—ì„œ ê´€ë¦¬í•˜ê³  ê³µìœ í•˜ëŠ” ì €ì¥ì†Œ** \n",
    "  * **â‰’** `Git`: ë‹¤ë¥¸ ì‚¬ëŒì´ ë§Œë“  í”„ë¡¬í”„íŠ¸ë¥¼ ê°€ì ¸ì™€ ì‚¬ìš©í•  ìˆ˜ë„ ìˆê³ , ë‚´ê°€ ë§Œë“  í”„ë¡¬í”„íŠ¸ë¥¼ ì˜¬ë ¤ì„œ ê´€ë¦¬í•˜ê±°ë‚˜ ê³µìœ í•  ìˆ˜ë„ ìˆìŒ\n",
    "\n",
    "* ê¸°ëŠ¥\n",
    "  * `hub.pull()`\n",
    "    * í—ˆë¸Œì— ì €ì¥ëœ í”„ë¡¬í”„íŠ¸ë¥¼ ê°€ì ¸ì˜¤ëŠ” ëª…ë ¹ì–´\n",
    "    * **â‰’** `git clone`ê³¼ ë¹„ìŠ·\n",
    "    * `ìµœì‹  ë²„ì „`ì´ë‚˜ `íŠ¹ì • ì»¤ë°‹ ë²„ì „ì˜ í”„ë¡¬í”„íŠ¸`ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ìˆìŒ  \n",
    "\n",
    "  * `hub.push()`\n",
    "    * `ë¡œì»¬ì—ì„œ ë§Œë“  í”„ë¡¬í”„íŠ¸`ë¥¼ `í—ˆë¸Œì— ë“±ë¡`í•˜ëŠ” ëª…ë ¹ì–´\n",
    "    * ë“±ë¡ í›„ `ë‹¤ë¥¸ ì‚¬ëŒë„ ë‚´ í”„ë¡¬í”„íŠ¸` ì‚¬ìš© ê°€ëŠ¥\n",
    "\n",
    "  * `ChatPromptTemplate`\n",
    "    * `LLM`ì—ê²Œ ë³´ë‚¼ **ë©”ì‹œì§€(í”„ë¡¬í”„íŠ¸)ì˜ í˜•ì‹** ì„ ì •ì˜í•˜ëŠ” í…œí”Œë¦¿\n",
    "    * ë³€ìˆ˜ë¥¼ `{ }ë¡œ ì§€ì •`í•´ ë‘ë©´ ë‚˜ì¤‘ì— ì‹¤ì œ ê°’ìœ¼ë¡œ ì±„ì›Œì„œ ì‚¬ìš© ê°€ëŠ¥"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5c00f9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796ab5ea",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "# ğŸ“š LangChain Hub í”„ë¡¬í”„íŠ¸ ì£¼ì†Œ & ì‚¬ìš©ë²•\n",
    "\n",
    "## ğŸš€ LangChain Hubì— í”„ë¡¬í”„íŠ¸ ë“±ë¡í•˜ê¸°\n",
    "\n",
    "* `LangSmith` ì ‘ì†\n",
    "  * `LangSmith` ì ‘ì†\n",
    "  * ë¡œê·¸ì¸ (`Personal ê³„ì •` ì‚¬ìš© ê°€ëŠ¥)\n",
    "\n",
    "* ìƒˆ í”„ë¡¬í”„íŠ¸ ìƒì„±\n",
    "  * ì¢Œì¸¡ ë©”ë‰´ì—ì„œ `Prompts` í´ë¦­\n",
    "  * ìš°ì¸¡ ìƒë‹¨ **`+ Prompt`** ë²„íŠ¼ í´ë¦­\n",
    "  * ì›í•˜ëŠ” ìœ í˜• ì„ íƒ\n",
    "    * `Chat-style prompt` â†’ `ëŒ€í™”í˜•` í”„ë¡¬í”„íŠ¸\n",
    "    * `Instruct-style prompt` â†’ `ì§€ì‹œë¬¸í˜•` í”„ë¡¬í”„íŠ¸\n",
    "\n",
    "## í”„ë¡¬í”„íŠ¸ ì‘ì„±\n",
    "\n",
    "* ì˜ˆì‹œ (`Chat-style`):\n",
    "\n",
    "  * `SYSTEM`\n",
    "  \n",
    "    ```python\n",
    "    You are an assistant for question-answering tasks.\n",
    "    Use the provided context to answer concisely in Korean.\n",
    "    If you donâ€™t know, say \"ì˜ ëª¨ë¥´ê² ìŠµë‹ˆë‹¤.\"\n",
    "    ```\n",
    "\n",
    "  * `HUMAN`\n",
    "\n",
    "    ```python\n",
    "    ì§ˆë¬¸: {question}\n",
    "    ë¬¸ë§¥: {context}\n",
    "    ë‹µë³€:\n",
    "    ```\n",
    "\n",
    "## ì €ì¥ ë° ì´ë¦„ ì„¤ì •\n",
    "  * í™”ë©´ ìƒë‹¨ `Save` í´ë¦­\n",
    "  * ì €ì¥ì†Œ ì´ë¦„ ì…ë ¥ (ì˜ˆ: jay-test-prompt)\n",
    "  * `Private/Public` ì„ íƒ\n",
    "\t* `Private` â†’ ë‚˜ë§Œ ì‚¬ìš© ê°€ëŠ¥\n",
    "\t* `Public` â†’ ì „ì²´ ê³µê°œ\n",
    "\n",
    "\n",
    "## ì €ì¥ì†Œ í™•ì¸\n",
    "* ì €ì¥ í›„ `ì¢Œì¸¡ ë©”ë‰´ Prompts`ì—ì„œ í•´ë‹¹ ì €ì¥ì†Œ í´ë¦­\n",
    "* `Commit` ëª©ë¡ê³¼ `SYSTEM`/`HUMAN` ë©”ì‹œì§€ í™•ì¸ ê°€ëŠ¥\n",
    "\n",
    "## ì£¼ì†Œ êµ¬ì¡°\n",
    "\n",
    "### ìµœì‹  ë²„ì „\n",
    "* `username/repo-name`\n",
    "  * ì˜ˆ: `jay/jay-test-prompt`\n",
    "  * `URL`: `https://smith.langchain.com/hub/jay/jay-test-prompt`\n",
    "  \n",
    "* `íŠ¹ì • ì»¤ë°‹ ë²„ì „` : `username/repo-name:commit-id`\n",
    "  * ì˜ˆ: `jay/jay-test-prompt:ea749f49`\n",
    "  * `URL`:`https://smith.langchain.com/hub/jay/jay-test-prompt/ea749f49`\n",
    "\n",
    "\n",
    "\n",
    "## `LangChain` ì½”ë“œì—ì„œ ì‚¬ìš©\n",
    "\n",
    "  ```python\n",
    "  from langchain import hub\n",
    "\n",
    "  # ìµœì‹  ë²„ì „ ê°€ì ¸ì˜¤ê¸°\n",
    "  prompt = hub.pull(\"jay/jay-test-prompt\")\n",
    "\n",
    "  # íŠ¹ì • ì»¤ë°‹ ë²„ì „ ê°€ì ¸ì˜¤ê¸°\n",
    "  prompt = hub.pull(\"jay/jay-test-prompt:ea749f49\")\n",
    "  ```\n",
    "\n",
    "---\n",
    "\n",
    "## ì •ë¦¬!\n",
    "  * `hub.pull(\"username/repo-name\")` â†’ í•­ìƒ ìµœì‹  ë²„ì „ ì‚¬ìš©\n",
    "  * `hub.pull(\"username/repo-name:commit-id\")` â†’ íŠ¹ì • ì‹œì  ë²„ì „ ê³ ì •\n",
    "  * ì›¹ì—ì„œ ì§ì ‘ í™•ì¸ ê°€ëŠ¥: `https://smith.langchain.com/hub/username/repo-name`\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed357b6f",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* ê¸°ë³¸ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24d1fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê¸°ë³¸ ëª¨ë“ˆ ì„í¬íŠ¸\n",
    "import os\n",
    "import asyncio\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API KEYë¥¼ í™˜ê²½ë³€ìˆ˜ë¡œ ê´€ë¦¬í•˜ê¸° ìœ„í•œ ì„¤ì • íŒŒì¼\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API KEY ì •ë³´ ë¡œë“œ\n",
    "load_dotenv()                   # true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b9ab98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í™˜ê²½ ë³€ìˆ˜ í™•ì¸í•˜ê¸°\n",
    "\n",
    "# ë§ˆìŠ¤í‚¹ ì²˜ë¦¬ í•¨ìˆ˜ ì •ì˜\n",
    "def mask_key(key: str, visible_count: int = 2) -> str:\n",
    "    if not key or len(key) <= visible_count:\n",
    "        return '*' * len(key)\n",
    "    return key[:visible_count] + '*' * (len(key) - visible_count)\n",
    "\n",
    "# í™˜ê²½ë³€ìˆ˜ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "if not api_key:\n",
    "    raise ValueError(\"GOOGLE_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "# ë§ˆìŠ¤í‚¹ëœ í˜•íƒœë¡œ ì¶œë ¥\n",
    "print(f\"GOOGLE_API_KEY: {mask_key(api_key)}\")           # GOOGLE_API_KEY: AI*************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092157ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangSmith ì¶”ì  ì„¤ì • (https://smith.langchain.com)\n",
    "\n",
    "\"\"\"\n",
    "- !pip install -qU langsmith\n",
    "- !pip install -qU langchain-teddynote\n",
    "    -> ì œë¯¸ë‚˜ì´ì™€ poetryì™€ì˜ ì˜ì¡´ì„± ì¶©ëŒë¡œ langchain_teddy ì„¤ì¹˜ X \n",
    "    -> langsmithë¡œ ì§„í–‰\n",
    "\"\"\"\n",
    "# LangSmith ì¶”ì ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
    "from langsmith import traceable                                                             # @traceable ë°ì½”ë ˆì´í„° ì‚¬ìš© ì‹œ\n",
    "\n",
    "# LangSmith í™˜ê²½ ë³€ìˆ˜ í™•ì¸\n",
    "\n",
    "print(\"\\n--- LangSmith í™˜ê²½ ë³€ìˆ˜ í™•ì¸ ---\")\n",
    "langchain_tracing_v2 = os.getenv('LANGCHAIN_TRACING_V2')\n",
    "langchain_project = os.getenv('LANGCHAIN_PROJECT')\n",
    "langchain_api_key_status = \"ì„¤ì •ë¨\" if os.getenv('LANGCHAIN_API_KEY') else \"ì„¤ì •ë˜ì§€ ì•ŠìŒ\"      # API í‚¤ ê°’ì€ ì§ì ‘ ì¶œë ¥í•˜ì§€ ì•ŠìŒ\n",
    "org = \"ì„¤ì •ë¨\" if os.getenv('LANGCHAIN_ORGANIZATION') else \"ì„¤ì •ë˜ì§€ ì•ŠìŒ\"                     # ì§ì ‘ ì¶œë ¥í•˜ì§€ ì•ŠìŒ\n",
    "\n",
    "if langchain_tracing_v2 == \"true\" and os.getenv('LANGCHAIN_API_KEY') and langchain_project:\n",
    "    print(f\"âœ… LangSmith ì¶”ì  í™œì„±í™”ë¨ (LANGCHAIN_TRACING_V2='{langchain_tracing_v2}')\")\n",
    "    print(f\"âœ… LangSmith í”„ë¡œì íŠ¸: '{langchain_project}'\")\n",
    "    print(f\"âœ… LangSmith API Key: {langchain_api_key_status}\")\n",
    "    print(f\"âœ… username_or_org: {org}\")\n",
    "    print(\"  -> ì´ì œ LangSmith ëŒ€ì‹œë³´ë“œì—ì„œ ì´ í”„ë¡œì íŠ¸ë¥¼ í™•ì¸í•´ ë³´ì„¸ìš”.\")\n",
    "else:\n",
    "    print(\"âŒ LangSmith ì¶”ì ì´ ì™„ì „íˆ í™œì„±í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë‹¤ìŒì„ í™•ì¸í•˜ì„¸ìš”:\")\n",
    "    if langchain_tracing_v2 != \"true\":\n",
    "        print(f\"  - LANGCHAIN_TRACING_V2ê°€ 'true'ë¡œ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤ (í˜„ì¬: '{langchain_tracing_v2}').\")\n",
    "    if not os.getenv('LANGCHAIN_API_KEY'):\n",
    "        print(\"  - LANGCHAIN_API_KEYê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.\")\n",
    "    if not langchain_project:\n",
    "        print(\"  - LANGCHAIN_PROJECTê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c549dc42",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* ì…€ ì¶œë ¥\n",
    "\n",
    "    ```\n",
    "        --- LangSmith í™˜ê²½ ë³€ìˆ˜ í™•ì¸ ---\n",
    "        âœ… LangSmith ì¶”ì  í™œì„±í™”ë¨ (LANGCHAIN_TRACING_V2='true')\n",
    "        âœ… LangSmith í”„ë¡œì íŠ¸: 'LangChain-prantice'\n",
    "        âœ… LangSmith API Key: ì„¤ì •ë¨\n",
    "        âœ… username_or_org: ì„¤ì •ë¨\n",
    "        -> ì´ì œ LangSmith ëŒ€ì‹œë³´ë“œì—ì„œ ì´ í”„ë¡œì íŠ¸ë¥¼ í™•ì¸í•´ ë³´ì„¸ìš”.\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8ea38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "# model2 = gemini-2.5-falsh-lite\n",
    "\n",
    "try:\n",
    "    model2 = ChatGoogleGenerativeAI(                                      # ëª¨ë¸ í˜¸ì¶œ\n",
    "        model=\"gemini-2.5-flash-lite\",\n",
    "    )\n",
    "    print(\"âœ… gemini-2.5-flash-lite í˜¸ì¶œ ì„±ê³µ.\")\n",
    "except Exception as e:                                                   # ë””ë²„ê¹… ë©”ì‹œì§€\n",
    "    print(f\"âŒ Google GenAI ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}\")\n",
    "    print(\"  -> GEMINI_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì˜¬ë°”ë¥´ê²Œ ì„¤ì •ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.\")      # âœ… gemini-2.5-flash-lite í˜¸ì¶œ ì„±ê³µ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0a1238",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe159c8",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* `LangSmith Client` ì‚¬ìš©ë°©ë²• ë³€ê²½\n",
    "  * ê¸°ì¡´ `langchain.hub.push()` / `hub.pull()` **âŒ**\n",
    "  * **`langsmith.Client ê°ì²´`** ë¥¼ ë§Œë“¤ì–´ì„œ **`client.push_prompt()`** , **`client.pull_prompt()`** ê¸°\n",
    "  * **`API í‚¤`** ë§Œ ìˆìœ¼ë©´ `ìë™`ìœ¼ë¡œ ì¡°ì§ ê¶Œí•œë„ ë§ê²Œ ì²˜ë¦¬ë©ë‹ˆë‹¤.\n",
    "  * ë„¤ì„ìŠ¤í˜ì´ìŠ¤(ì¡°ì§ëª…) ì§€ì •ì€ Clientê°€ ë‚´ë¶€ì—ì„œ ì²˜ë¦¬í•˜ë¯€ë¡œ `push_prompt()` í˜¸ì¶œ ì‹œ `ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ì—†ì´` í”„ë¡¬í”„íŠ¸ëª…ë§Œ ë„˜ê¸°ë©´ ë¨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd936d6",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74bac5a3",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "### a. LangChain Hubì—ì„œ í”„ë¡¬í”„íŠ¸ ê°€ì ¸ì˜¤ê¸°"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc418b9",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* `LangChain` `Client.push_prompt()` ê³µì‹ ê°€ì´ë“œ\n",
    "\n",
    "    ```python\n",
    "\n",
    "    def push_prompt(\n",
    "        self,\n",
    "        prompt_identifier: str,\n",
    "        *,\n",
    "        object: Optional[Any] = None,\n",
    "        parent_commit_hash: Optional[str] = None,\n",
    "        is_public: Optional[bool] = None,\n",
    "        description: Optional[str] = None,\n",
    "        readme: Optional[str] = None,\n",
    "        tags: Optional[List[str]] = None,\n",
    "    ) -> str:\n",
    "        ...\n",
    "\n",
    "    ```\n",
    "  * `prompt_identifier` = **(í•„ìˆ˜)** **ì²« ë²ˆì§¸ ìœ„ì¹˜ ì¸ì**\n",
    "  * ë‚˜ë¨¸ì§€ = `í‚¤ì›Œë“œ ì¸ì`\n",
    "    * ì¦‰, ë°”ë¡œ ë„˜ê¸¸ ìˆ˜ ì—†ê³  ë°˜ë“œì‹œ `object =  ...`ì˜ í˜•íƒœë¡œ ì „ë‹¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab58ca9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain import hub\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langsmith import Client\n",
    "\n",
    "# .env í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ\n",
    "load_dotenv()\n",
    "\n",
    "# í™˜ê²½ ë³€ìˆ˜ ì½ê¸°\n",
    "api_key = os.getenv('LANGCHAIN_API_KEY')\n",
    "if not api_key:\n",
    "    raise ValueError(\"API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "\n",
    "# ë³€ê²½ëœ ì§€ì  = ë­ì²´ì¸ í—ˆë¸Œ í´ë¼ì´ì–¸íŠ¸ ê°ì²´ ìƒì„±í•˜ê¸°\n",
    "client = Client(api_key=api_key)\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ push (ë“±ë¡) ì˜ˆì‹œ\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "my_prompt = ChatPromptTemplate.from_template(\n",
    "    \"ë‹¹ì‹ ì€ Jayì˜ AI ë¹„ì„œì…ë‹ˆë‹¤.\\n\\nì •ë³´: {context}\\nì§ˆë¬¸: {question}\"\n",
    ")\n",
    "\n",
    "result = client.push_prompt(\"jay-test-prompt\", my_prompt)\n",
    "print(\"ì—…ë¡œë“œ ì„±ê³µ:\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e820a519",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* ì…€ ì¶œë ¥\n",
    "  \n",
    "  ```<markdown>\n",
    "    ì—…ë¡œë“œ ì„±ê³µ: https://smith.langchain.com/prompts/jay-test-prompt/4******\n",
    "  ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7c193d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangSmith Clientë¡œ ìµœê·¼ ì»¤ë°‹ í•´ì‹œ ì¡°íšŒí•˜ê¸°\n",
    "\n",
    "from langsmith import Client\n",
    "import os\n",
    "import json\n",
    "\n",
    "api_key = os.getenv(\"LANGSMITH_API_KEY\")\n",
    "client = Client(api_key=api_key)\n",
    "\n",
    "prompt_id = \"jay-test-prompt\"\n",
    "\n",
    "# 1) í”„ë¡¬í”„íŠ¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸°\n",
    "prompt_info = client.get_prompt(prompt_id)\n",
    "\n",
    "print(\"í”„ë¡¬í”„íŠ¸ ì •ë³´:\", prompt_info)\n",
    "\n",
    "prompt_info = client.get_prompt(prompt_id)\n",
    "print(\"í”„ë¡¬í”„íŠ¸ ì •ë³´:\")\n",
    "for key, value in prompt_info.__dict__.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "# ì¤„ ë°”ê¿ˆ\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "\n",
    "# 2) í”„ë¡¬í”„íŠ¸ ê°€ì ¸ì˜¤ê¸°\n",
    "prompt_obj = client.pull_prompt(prompt_id)\n",
    "print(\"í”„ë¡¬í”„íŠ¸ ê°ì²´ íƒ€ì…:\", type(prompt_obj))\n",
    "\n",
    "# ì¤„ ë°”ê¿ˆ\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# 3) í”„ë¡¬í”„íŠ¸ ë©”íƒ€ë°ì´í„° ê°€ì ¸ì˜¤ê¸° - ë§Œì•½ metadata ì†ì„±ì´ ìˆìœ¼ë©´ ì¶œë ¥\n",
    "if hasattr(prompt_obj, \"metadata\"):\n",
    "    metadata = prompt_obj.metadata\n",
    "    print(\"ë©”íƒ€ë°ì´í„°:\")\n",
    "    for key, value in metadata.items():\n",
    "        print(f\" {key}: {value}\")\n",
    "    print(\"\\nJSON í¬ë§·ìœ¼ë¡œ ë³´ê¸°:\")\n",
    "    import json\n",
    "    print(json.dumps(metadata, indent=2, ensure_ascii=False))\n",
    "else:\n",
    "    print(\"ë©”íƒ€ë°ì´í„° ì†ì„±ì´ ì—†ìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5259f66b",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* ì…€ ì¶œë ¥\n",
    "\n",
    "    ```<plaintext>\n",
    "    í”„ë¡¬í”„íŠ¸ ì •ë³´: repo_handle='jay-test-prompt' description='' readme='' id='a0ce4f9f-ef1d-4186-aab4-3154c40e72de' tenant_id='2c3342d3-1170-4ffa-86fd-f621199e0b9c' created_at=datetime.datetime(2025, 8, 12, 9, 36, 6, 760941) updated_at=datetime.datetime(2025, 8, 12, 9, 36, 7, 668335) is_public=False is_archived=False tags=['ChatPromptTemplate'] original_repo_id=None upstream_repo_id=None owner=None full_name='jay-test-prompt' num_likes=0 num_downloads=2 num_views=0 liked_by_auth_user=False last_commit_hash='4e4d02c6bb4c15e9fb2eada3665923489bdb979d37bd6baf7a389b9f7734dd5c' num_commits=1 original_repo_full_name=None upstream_repo_full_name=None\n",
    "    í”„ë¡¬í”„íŠ¸ ì •ë³´:\n",
    "    repo_handle: jay-test-prompt\n",
    "    description: \n",
    "    readme: \n",
    "    id: a0ce4f9f-ef1d-4186-aab4-3154c40e72de\n",
    "    tenant_id: 2c3342d3-1170-4ffa-86fd-f621199e0b9c\n",
    "    created_at: 2025-08-12 09:36:06.760941\n",
    "    updated_at: 2025-08-12 09:36:07.668335\n",
    "    is_public: False\n",
    "    is_archived: False\n",
    "    tags: ['ChatPromptTemplate']\n",
    "    original_repo_id: None\n",
    "    upstream_repo_id: None\n",
    "    owner: None\n",
    "    full_name: jay-test-prompt\n",
    "    num_likes: 0\n",
    "    num_downloads: 2\n",
    "    num_views: 0\n",
    "    liked_by_auth_user: False\n",
    "    last_commit_hash: 4e4d02c6bb4c15e9fb2eada3665923489bdb979d37bd6baf7a389b9f7734dd5c\n",
    "    num_commits: 1\n",
    "    original_repo_full_name: None\n",
    "    upstream_repo_full_name: None\n",
    "\n",
    "    ==================================================\n",
    "\n",
    "    í”„ë¡¬í”„íŠ¸ ê°ì²´ íƒ€ì…: <class 'langchain_core.prompts.chat.ChatPromptTemplate'>\n",
    "\n",
    "    ==================================================\n",
    "\n",
    "    ë©”íƒ€ë°ì´í„°:\n",
    "    lc_hub_owner: -\n",
    "    lc_hub_repo: jay-test-prompt\n",
    "    lc_hub_commit_hash: 4e4d02c6bb4c15e9fb2eada3665923489bdb979d37bd6baf7a389b9f7734dd5c\n",
    "    ë©”íƒ€ë°ì´í„° ì†ì„±ì´ ì—†ìŠµë‹ˆë‹¤.\n",
    "\n",
    "    JSON í¬ë§·ìœ¼ë¡œ ë³´ê¸°:\n",
    "    {\n",
    "    \"lc_hub_owner\": \"-\",\n",
    "    \"lc_hub_repo\": \"jay-test-prompt\",\n",
    "    \"lc_hub_commit_hash\": \"4e4d02c6bb4c15e9fb2eada3665923489bdb979d37bd6baf7a389b9f7734dd5c\"\n",
    "    }\n",
    "\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74bfd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìµœê·¼ ì»¤ë°‹ = `4e4d02c6bb4c15e9fb2eada3665923489bdb979d37bd6baf7a389b9f7734dd5c`\n",
    "# íŠ¹ì • ì»¤ë°‹ í•´ì‹œë¡œ í”„ë¡¬í”„íŠ¸ ê°€ì ¸ì˜¤ê¸°\n",
    "\n",
    "import json\n",
    "\n",
    "commit_hash = \"4e4d02c6bb4c15e9fb2eada3665923489bdb979d37bd6baf7a389b9f7734dd5c\"\n",
    "prompt_id = \"jay-test-prompt\"\n",
    "\n",
    "# íŠ¹ì • ì»¤ë°‹ ë²„ì „ í”„ë¡¬í”„íŠ¸ ê°€ì ¸ì˜¤ê¸° (ì• 8ìë¦¬ë§Œìœ¼ë¡œë„ ì¶©ë¶„)\n",
    "prompt_version = client.pull_prompt(f\"{prompt_id}:{commit_hash[:8]}\")\n",
    "\n",
    "print(\"í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ë‚´ìš©:\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# ChatPromptTemplateì˜ ê²½ìš°, template ì†ì„±ë“¤ì´ list í˜•íƒœë¡œ ì €ì¥ë˜ì–´ ìˆì„ ìˆ˜ ìˆìŒ\n",
    "if hasattr(prompt_version, \"prompt\"):\n",
    "    # ë‚´ë¶€ prompt ê°ì²´ í™•ì¸\n",
    "    inner_prompt = prompt_version.prompt\n",
    "    # ë³´í†µ human_message_prompt_templates ë¦¬ìŠ¤íŠ¸ê°€ ìˆìŒ\n",
    "    if hasattr(inner_prompt, \"human_message_prompt_templates\"):\n",
    "        for idx, hmp in enumerate(inner_prompt.human_message_prompt_templates):\n",
    "            print(f\"[í…œí”Œë¦¿ #{idx + 1}]\")\n",
    "            print(hmp.prompt.template)\n",
    "            print()\n",
    "    else:\n",
    "        print(inner_prompt)\n",
    "else:\n",
    "    print(prompt_version)\n",
    "\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# repr() = ë¬¸ìì—´ë¡œ ë³€í™˜í•´ ì¶œë ¥í•´ë³´ê¸°\n",
    "print(repr(prompt_version))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6495ef9d",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* ì…€ ì¶œë ¥\n",
    "\n",
    "    ```<plaintext>\n",
    "    í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ë‚´ìš©:\n",
    "    ------------------------------\n",
    "    input_variables=['context', 'question'] input_types={} partial_variables={} metadata={'lc_hub_owner': '-', 'lc_hub_repo': 'jay-test-prompt', 'lc_hub_commit_hash': '4e4d02c6bb4c15e9fb2eada3665923489bdb979d37bd6baf7a389b9f7734dd5c'} messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template='ë‹¹ì‹ ì€ Jayì˜ AI ë¹„ì„œì…ë‹ˆë‹¤.\\n\\nì •ë³´: {context}\\nì§ˆë¬¸: {question}'), additional_kwargs={})]\n",
    "    ------------------------------\n",
    "    ```\n",
    "\n",
    "---\n",
    "\n",
    "```python\n",
    "\n",
    "# repr() = ë¬¸ìì—´ë¡œ ë³€í™˜í•´ ì¶œë ¥í•´ë³´ê¸°\n",
    "print(repr(prompt_version))\n",
    "\n",
    "```\n",
    "\n",
    "* ì…€ ì¶œë ¥\n",
    "\n",
    "  ```<plaintext>\n",
    "  ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, metadata={'lc_hub_owner': '-', 'lc_hub_repo': 'jay-test-prompt', 'lc_hub_commit_hash': '4e4d02c6bb4c15e9fb2eada3665923489bdb979d37bd6baf7a389b9f7734dd5c'}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template='ë‹¹ì‹ ì€ Jayì˜ AI ë¹„ì„œì…ë‹ˆë‹¤.\\n\\nì •ë³´: {context}\\nì§ˆë¬¸: {question}'), additional_kwargs={})])\n",
    "  ```\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "* êµ¬ì¡° í•´ì„\n",
    "  * `ChatPromptTemplate` ê°ì²´ëŠ”\n",
    "  * `input_variables`: í”„ë¡¬í”„íŠ¸ì— ë“¤ì–´ê°€ëŠ” ë³€ìˆ˜ ë¦¬ìŠ¤íŠ¸ ([`context`, `question`])\n",
    "  * `messages`: ì‹¤ì œ ë©”ì‹œì§€ í…œí”Œë¦¿ë“¤ì´ ë‹´ê¸´ ë¦¬ìŠ¤íŠ¸\n",
    "    * ì—¬ê¸°ì„œ `HumanMessagePromptTemplate` ë‚´ë¶€ì— `PromptTemplat`eê°€ ìˆê³ ,\n",
    "    * `PromptTemplate`ì˜ `template` ì†ì„±ì— **`ì‹¤ì œ í…ìŠ¤íŠ¸`** ê°€ ë“¤ì–´ìˆìŒ\n",
    "  \n",
    "* ì¶œë ¥í•  ë§Œí•œ ì£¼ìš” ì •ë³´\n",
    "  * **ê°€ì¥ ì¤‘ìš”í•œ ê²ƒ** : `template ë¬¸ìì—´` â†’ ì´ê²Œ **ì‹¤ì œ í”„ë¡¬í”„íŠ¸ ë¬¸ì¥(ì§ˆë¬¸/ì‘ë‹µ í…œí”Œë¦¿)** ì´ë¯€ë¡œ ê¼­ ì¶œë ¥í•˜ê¸°\n",
    "\n",
    "  * `ì°¸ê³ ` \n",
    "    * `input_variables` : í”„ë¡¬í”„íŠ¸ ì‹¤í–‰ ì‹œ ì–´ë–¤ ë³€ìˆ˜ë¥¼ ë„£ì–´ì•¼ í•˜ëŠ”ì§€ ì•Œë ¤ì¤Œ\n",
    "    * ì˜ˆì‹œ: `context`, `question` ë³€ìˆ˜ í•„ìš”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8330fa01",
   "metadata": {},
   "source": [
    "![ChatPromptTemplateê°ì²´](./img/ChatPromptTemplate_structure.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf4407e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Input Variables:\", prompt_version.input_variables)\n",
    "\n",
    "# messages ë¦¬ìŠ¤íŠ¸ì—ì„œ ê° ë©”ì‹œì§€ í…œí”Œë¦¿ì˜ ì‹¤ì œ ë¬¸ì¥ ì¶œë ¥\n",
    "for i, message_template in enumerate(prompt_version.messages):\n",
    "    prompt_template = message_template.prompt  # PromptTemplate ê°ì²´\n",
    "    print(f\"\\n[í…œí”Œë¦¿ #{i + 1}]\")\n",
    "    print(prompt_template.template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552d5f07",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* ì…€ ì¶œë ¥\n",
    "\n",
    "    ```<plaintext>\n",
    "\n",
    "    Input Variables: ['context', 'question']\n",
    "\n",
    "    [í…œí”Œë¦¿ #1]\n",
    "    ë‹¹ì‹ ì€ Jayì˜ AI ë¹„ì„œì…ë‹ˆë‹¤.\n",
    "\n",
    "    ì •ë³´: {context}\n",
    "    ì§ˆë¬¸: {question}\n",
    "\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e29390d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gemini-2.5-flash-liteë¡œ chain ìƒì„±í•˜ê¸°\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Gemini ëª¨ë¸ ì´ˆê¸°í™”\n",
    "gemini_lc = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash-lite\",\n",
    "    temperature=0,  \n",
    ")\n",
    "\n",
    "# hubì—ì„œ ê°€ì ¸ì˜¨ prompt_latestë¥¼ ì´ë¯¸ ê°–ê³  ìˆë‹¤ê³  ê°€ì •\n",
    "# í”„ë¡¬í”„íŠ¸, ëª¨ë¸, ì¶œë ¥ íŒŒì„œ ì—°ê²°í•˜ì—¬ ì²´ì¸ ìƒì„±\n",
    "chain = prompt_obj | gemini_lc | StrOutputParser()\n",
    "\n",
    "# ì²´ì¸ ì‹¤í–‰ ì…ë ¥ê°’\n",
    "context_for_chain = \"ì˜¤ëŠ˜ ì˜¤ì „ì—ëŠ” ìƒˆë¡œìš´ ì¸ê³µì§€ëŠ¥ ëª¨ë¸ì˜ ë²¤ì¹˜ë§ˆí‚¹ì„ ì§„í–‰í–ˆìŠµë‹ˆë‹¤. ê²°ê³¼ê°€ ë§¤ìš° ì¸ìƒì ì´ì—ˆìŠµë‹ˆë‹¤.\"\n",
    "question_for_chain = \"ì˜¤ëŠ˜ ì˜¤ì „ì— í•œ ì¼ì€ ë¬´ì—‡ì¸ê°€ìš”?\"\n",
    "\n",
    "# ì²´ì¸ ì‹¤í–‰ ë° ì¶œë ¥\n",
    "print('\\n', \"-\" * 50, '\\n')\n",
    "print(\"gemini-2.5-flash-lite ìƒì„± ë‹µë³€:\", '\\n')\n",
    "summary_result = chain.invoke({\"context\": context_for_chain, \"question\": question_for_chain})\n",
    "print(summary_result)\n",
    "print('\\n', \"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40867380",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* ì…€ ì¶œë ¥\n",
    "\n",
    "    ```<plaintext>\n",
    "\n",
    "    -------------------------------------------------- \n",
    "\n",
    "    gemini-2.5-flash-lite ìƒì„± ë‹µë³€: \n",
    "\n",
    "    ì˜¤ëŠ˜ ì˜¤ì „ì—ëŠ” ìƒˆë¡œìš´ ì¸ê³µì§€ëŠ¥ ëª¨ë¸ì˜ ë²¤ì¹˜ë§ˆí‚¹ì„ ì§„í–‰í–ˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "    --------------------------------------------------\n",
    "\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19523d03",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ea57e6",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "### b. ìƒˆ í”„ë¡¬í”„íŠ¸ ë§Œë“¤ì–´ LangChain Hubì— ì˜¬ë¦¬ê³  ê°€ì ¸ì˜¤ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aae8ea9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1_ìƒˆ í”„ë¡¬í”„íŠ¸ ìƒì„±í•˜ê¸° (ì§€ë‚œë²ˆ íŒŒì¼ í”„ë¡¬í”„íŠ¸ í™œìš©)\n",
    "\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "my_prompt_2 = ChatPromptTemplate.from_template(\n",
    "    \"ë‹¹ì‹ ì€ IT ì „ë¬¸ ë¸”ë¡œê±° 'Jay'ì…ë‹ˆë‹¤. ë‹¤ìŒ CONTEXTë¥¼ ì½ê³ , ê¸°ìˆ  ìš©ì–´ëŠ” ì‰½ê²Œ í’€ì–´ ë…ìì—ê²Œ ì¹œì ˆí•˜ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”. ë‹µë³€ì€ ë°˜ë“œì‹œ í•œê¸€ë¡œ ì‘ì„±í•˜ì„¸ìš”\\n\\nCONTEXT: {context}\\n\\nSUMMARY:\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505fad49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2_LangSmith Client ìƒì„± ë° í”„ë¡¬í”„íŠ¸ ë“±ë¡í•˜ê¸°\n",
    "\n",
    "from langsmith import Client\n",
    "import os\n",
    "\n",
    "api_key = os.environ.get('LANGSMITH_API_KEY') or os.environ.get('LANGCHAIN_API_KEY')\n",
    "client = Client(api_key=api_key)\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ ì—…ë¡œë“œ (push_prompt ì‚¬ìš©)\n",
    "result2 = client.push_prompt(\"jay-it-blogger-prompt\", object=my_prompt_2)\n",
    "print('\\n', \"-\" * 50, '\\n')\n",
    "print(\"âœ… í”„ë¡¬í”„íŠ¸ ì—…ë¡œë“œ ê²°ê³¼:\", result2)\n",
    "print('\\n', \"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11472d9",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* ì…€ ì¶œë ¥\n",
    "\n",
    "    ```<plaintext>\n",
    "    -------------------------------------------------- \n",
    "\n",
    "    âœ… í”„ë¡¬í”„íŠ¸ ì—…ë¡œë“œ ê²°ê³¼: https://smith.langchain.com/prompts/jay-it-blogger-prompt/70f49b3d?organizationId=2c3342d3-1170-4ffa-86fd-f621199e0b9c\n",
    "\n",
    "    --------------------------------------------------\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0b900109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -------------------------------------------------- \n",
      "\n",
      "í—ˆë¸Œì—ì„œ í”„ë¡¬í”„íŠ¸ë¥¼ ì„±ê³µì ìœ¼ë¡œ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤.\n",
      "\n",
      " --------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 3_ì—…ë¡œë“œí•œ í—ˆë¸Œì—ì„œ ê°€ì ¸ì™€ë³´ê¸°\n",
    "\n",
    "prompt_from_hub = client.pull_prompt(\"jay-it-blogger-prompt\")\n",
    "print('\\n', \"-\" * 50, '\\n')\n",
    "print(\"í—ˆë¸Œì—ì„œ í”„ë¡¬í”„íŠ¸ë¥¼ ì„±ê³µì ìœ¼ë¡œ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤.\")\n",
    "print('\\n', \"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8706c70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4_LangSmith Clientë¡œ ìµœê·¼ ì»¤ë°‹ í•´ì‹œ ì¡°íšŒí•˜ê¸°\n",
    "\n",
    "from langsmith import Client\n",
    "import os\n",
    "import json\n",
    "\n",
    "api_key = os.getenv(\"LANGSMITH_API_KEY\")\n",
    "client = Client(api_key=api_key)\n",
    "\n",
    "prompt_id = \"jay-it-blogger-prompt\"\n",
    "\n",
    "# 1) í”„ë¡¬í”„íŠ¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸°\n",
    "prompt_info2 = client.get_prompt(prompt_id)\n",
    "\n",
    "print(\"í”„ë¡¬í”„íŠ¸ ì •ë³´:\", prompt_info2)\n",
    "\n",
    "prompt_info2 = client.get_prompt(prompt_id)\n",
    "print(\"í”„ë¡¬í”„íŠ¸ ì •ë³´:\")\n",
    "for key, value in prompt_info.__dict__.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "# ì¤„ ë°”ê¿ˆ\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "\n",
    "# 2) í”„ë¡¬í”„íŠ¸ ê°€ì ¸ì˜¤ê¸°\n",
    "prompt_obj2 = client.pull_prompt(prompt_id)\n",
    "print(\"í”„ë¡¬í”„íŠ¸ ê°ì²´ íƒ€ì…:\", type(prompt_obj2))\n",
    "\n",
    "# ì¤„ ë°”ê¿ˆ\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# 3) í”„ë¡¬í”„íŠ¸ ë©”íƒ€ë°ì´í„° ê°€ì ¸ì˜¤ê¸° - ë§Œì•½ metadata ì†ì„±ì´ ìˆìœ¼ë©´ ì¶œë ¥\n",
    "if hasattr(prompt_obj2, \"metadata\"):\n",
    "    metadata = prompt_obj2.metadata\n",
    "    print(\"ë©”íƒ€ë°ì´í„°:\")\n",
    "    for key, value in metadata.items():\n",
    "        print(f\" {key}: {value}\")\n",
    "    print(\"\\nJSON í¬ë§·ìœ¼ë¡œ ë³´ê¸°:\")\n",
    "    import json\n",
    "    print(json.dumps(metadata, indent=2, ensure_ascii=False))\n",
    "else:\n",
    "    print(\"ë©”íƒ€ë°ì´í„° ì†ì„±ì´ ì—†ìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dea7d14",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* ì…€ ì¶œë ¥\n",
    "\n",
    "    ```<plaintext>\n",
    "    í”„ë¡¬í”„íŠ¸ ì •ë³´: repo_handle='jay-it-blogger-prompt' description='' readme='' id='20cbbac0-f223-4065-9213-7594de3f4326' tenant_id='2c3342d3-1170-4ffa-86fd-f621199e0b9c' created_at=datetime.datetime(2025, 8, 12, 10, 32, 13, 144166) updated_at=datetime.datetime(2025, 8, 12, 10, 32, 14, 381062) is_public=False is_archived=False tags=['ChatPromptTemplate'] original_repo_id=None upstream_repo_id=None owner=None full_name='jay-it-blogger-prompt' num_likes=0 num_downloads=1 num_views=0 liked_by_auth_user=False last_commit_hash='70f49b3d05aff97e884e7df7a68e09cd3483ef25c5d1609b53501ac809a25efc' num_commits=1 original_repo_full_name=None upstream_repo_full_name=None\n",
    "    í”„ë¡¬í”„íŠ¸ ì •ë³´:\n",
    "    repo_handle: jay-test-prompt\n",
    "    description: \n",
    "    readme: \n",
    "    id: a0ce4f9f-ef1d-4186-aab4-3154c40e72de\n",
    "    tenant_id: 2c3342d3-1170-4ffa-86fd-f621199e0b9c\n",
    "    created_at: 2025-08-12 09:36:06.760941\n",
    "    updated_at: 2025-08-12 09:36:07.668335\n",
    "    is_public: False\n",
    "    is_archived: False\n",
    "    tags: ['ChatPromptTemplate']\n",
    "    original_repo_id: None\n",
    "    upstream_repo_id: None\n",
    "    owner: None\n",
    "    full_name: jay-test-prompt\n",
    "    num_likes: 0\n",
    "    num_downloads: 4\n",
    "    num_views: 0\n",
    "    liked_by_auth_user: False\n",
    "    last_commit_hash: 4e4d02c6bb4c15e9fb2eada3665923489bdb979d37bd6baf7a389b9f7734dd5c\n",
    "    num_commits: 1\n",
    "    original_repo_full_name: None\n",
    "    upstream_repo_full_name: None\n",
    "\n",
    "    ==================================================\n",
    "\n",
    "    í”„ë¡¬í”„íŠ¸ ê°ì²´ íƒ€ì…: <class 'langchain_core.prompts.chat.ChatPromptTemplate'>\n",
    "\n",
    "    ==================================================\n",
    "\n",
    "    ë©”íƒ€ë°ì´í„°:\n",
    "    lc_hub_owner: -\n",
    "    lc_hub_repo: jay-it-blogger-prompt\n",
    "    lc_hub_commit_hash: 70f49b3d05aff97e884e7df7a68e09cd3483ef25c5d1609b53501ac809a25efc\n",
    "\n",
    "    JSON í¬ë§·ìœ¼ë¡œ ë³´ê¸°:\n",
    "    {\n",
    "    \"lc_hub_owner\": \"-\",\n",
    "    \"lc_hub_repo\": \"jay-it-blogger-prompt\",\n",
    "    \"lc_hub_commit_hash\": \"70f49b3d05aff97e884e7df7a68e09cd3483ef25c5d1609b53501ac809a25efc\"\n",
    "    }\n",
    "    ```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466dc93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Input Variables:\", prompt_obj2.input_variables)\n",
    "\n",
    "# messages ë¦¬ìŠ¤íŠ¸ì—ì„œ ê° ë©”ì‹œì§€ í…œí”Œë¦¿ì˜ ì‹¤ì œ ë¬¸ì¥ ì¶œë ¥\n",
    "for i, message_template in enumerate(prompt_obj2.messages):\n",
    "    prompt_template = message_template.prompt  # PromptTemplate ê°ì²´\n",
    "    print(f\"\\n[í…œí”Œë¦¿ #{i + 1}]\")\n",
    "    print(prompt_template.template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f801976",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* ì…€ ì¶œë ¥\n",
    "\n",
    "    ```<pliantext>\n",
    "\n",
    "    Input Variables: ['context']\n",
    "\n",
    "    [í…œí”Œë¦¿ #1]\n",
    "    ë‹¹ì‹ ì€ IT ì „ë¬¸ ë¸”ë¡œê±° 'Jay'ì…ë‹ˆë‹¤. ë‹¤ìŒ CONTEXTë¥¼ ì½ê³ , ê¸°ìˆ  ìš©ì–´ëŠ” ì‰½ê²Œ í’€ì–´ ë…ìì—ê²Œ ì¹œì ˆí•˜ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”. ë‹µë³€ì€ ë°˜ë“œì‹œ í•œê¸€ë¡œ ì‘ì„±í•˜ì„¸ìš”\n",
    "\n",
    "    CONTEXT: {context}\n",
    "\n",
    "    SUMMARY:\n",
    "\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "18a33136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5_geminië¡œ LLM ì´ˆê¸°í™” ë° Chain ìƒì„±í•˜ê¸°\n",
    "# 6_Chain ì‹¤í–‰ í•¨ìˆ˜ì— @traceble ë°ì½”ë ˆì´í„° ë¶™ì´ê¸° (ì˜µì…˜)\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langsmith import traceable\n",
    "\n",
    "@traceable\n",
    "\n",
    "def run_summary_chain(context: str, question: str) -> str:\n",
    "    gemini_lc = ChatGoogleGenerativeAI(\n",
    "        model=\"gemini-2.5-flash-lite\",\n",
    "        temperature=0.7,\n",
    "        max_output_tokens=4096,\n",
    "    )\n",
    "    \n",
    "    chain = my_prompt | gemini_lc | StrOutputParser()\n",
    "        \n",
    "    return chain.invoke({\"context\": context, \"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e0adc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7_í•¨ìˆ˜ ì‹¤í–‰ ë° ê²°ê³¼ í™•ì¸\n",
    "\n",
    "context_for_summary = \"\"\"\n",
    "ë°ì´í„° ê³¼í•™ì€ ë‹¤ì–‘í•œ í•™ë¬¸ ë¶„ì•¼ì˜ ë°©ë²•ë¡ ê³¼ í”„ë¡œì„¸ìŠ¤ë¥¼ í†µí•©í•˜ì—¬ ë°ì´í„°ë¡œë¶€í„° ê°€ì¹˜ë¥¼ ì¶”ì¶œí•˜ê³  ì§€ì‹ì„ ì–»ëŠ” í•™ì œê°„ ë¶„ì•¼ì´ë‹¤.\n",
    "ì´ëŠ” í†µê³„í•™, ì»´í“¨í„° ê³¼í•™, ê·¸ë¦¬ê³  íŠ¹ì • ë¶„ì•¼ì˜ ì „ë¬¸ ì§€ì‹ì„ ê²°í•©í•œë‹¤.\n",
    "ë°ì´í„° ê³¼í•™ì˜ ê¶ê·¹ì ì¸ ëª©í‘œëŠ” ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ë³µì¡í•œ ë¬¸ì œë¥¼ í•´ê²°í•˜ê³  ë¯¸ë˜ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ë° ìˆë‹¤.\n",
    "\"\"\"\n",
    "\n",
    "#result = run_summary_chain(context=context_for_summary)\n",
    "result = run_summary_chain(context=context_for_summary, question=\"ìš”ì•½í•´ì¤˜\")\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "print(\"ìƒì„±ëœ ìš”ì•½:\")\n",
    "print(result)\n",
    "print(\"\\n\" + \"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a2398a",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* ì…€ ì¶œë ¥ (temperature=0.7, max_tokens=4,096)(1.8s)\n",
    "    \n",
    "    ```<plaintext>\n",
    "\n",
    "   ==================================================\n",
    "\n",
    "    ìƒì„±ëœ ìš”ì•½:\n",
    "    Jayë‹˜, ì•ˆë…•í•˜ì„¸ìš”! ë°ì´í„° ê³¼í•™ì— ëŒ€í•œ ì •ë³´ë¥¼ ìš”ì•½í•´ ë“œë¦¬ê² ìŠµë‹ˆë‹¤.\n",
    "\n",
    "    **ë°ì´í„° ê³¼í•™ì€ ì—¬ëŸ¬ í•™ë¬¸ ë¶„ì•¼ì˜ ë°©ë²•ê³¼ í”„ë¡œì„¸ìŠ¤ë¥¼ í•©ì³ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³  ìƒˆë¡œìš´ ì§€ì‹ì„ ì–»ëŠ” ë¶„ì•¼ì…ë‹ˆë‹¤.**\n",
    "\n",
    "    ì£¼ë¡œ **í†µê³„í•™, ì»´í“¨í„° ê³¼í•™, ê·¸ë¦¬ê³  íŠ¹ì • ë¶„ì•¼ì˜ ì „ë¬¸ ì§€ì‹**ì„ í™œìš©í•©ë‹ˆë‹¤.\n",
    "\n",
    "    ê¶ê·¹ì ì¸ ëª©í‘œëŠ” **ë°ì´í„°ë¥¼ í†µí•´ ë³µì¡í•œ ë¬¸ì œë¥¼ í•´ê²°í•˜ê³  ë¯¸ë˜ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ê²ƒ**ì…ë‹ˆë‹¤.\n",
    "\n",
    "    ==================================================\n",
    "\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5843804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì˜¨ë„ ë‚®ì¶°ë³´ê¸° (temperature=0.2)\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langsmith import traceable\n",
    "\n",
    "@traceable\n",
    "\n",
    "def run_summary_chain2(context: str, question: str) -> str:\n",
    "    gemini_lc2 = ChatGoogleGenerativeAI(\n",
    "        model=\"gemini-2.5-flash-lite\",\n",
    "        temperature=0.2,\n",
    "        max_output_tokens=4096,\n",
    "    )\n",
    "    \n",
    "    chain = my_prompt | gemini_lc2 | StrOutputParser()\n",
    "        \n",
    "    return chain.invoke({\"context\": context, \"question\": question})\n",
    "\n",
    "context_for_summary = \"\"\"\n",
    "ë°ì´í„° ê³¼í•™ì€ ë‹¤ì–‘í•œ í•™ë¬¸ ë¶„ì•¼ì˜ ë°©ë²•ë¡ ê³¼ í”„ë¡œì„¸ìŠ¤ë¥¼ í†µí•©í•˜ì—¬ ë°ì´í„°ë¡œë¶€í„° ê°€ì¹˜ë¥¼ ì¶”ì¶œí•˜ê³  ì§€ì‹ì„ ì–»ëŠ” í•™ì œê°„ ë¶„ì•¼ì´ë‹¤.\n",
    "ì´ëŠ” í†µê³„í•™, ì»´í“¨í„° ê³¼í•™, ê·¸ë¦¬ê³  íŠ¹ì • ë¶„ì•¼ì˜ ì „ë¬¸ ì§€ì‹ì„ ê²°í•©í•œë‹¤.\n",
    "ë°ì´í„° ê³¼í•™ì˜ ê¶ê·¹ì ì¸ ëª©í‘œëŠ” ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ë³µì¡í•œ ë¬¸ì œë¥¼ í•´ê²°í•˜ê³  ë¯¸ë˜ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ë° ìˆë‹¤.\n",
    "\"\"\"\n",
    "\n",
    "#result = run_summary_chain(context=context_for_summary)\n",
    "result = run_summary_chain(context=context_for_summary, question=\"ìš”ì•½í•´ì¤˜\")\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "print(\"ìƒì„±ëœ ìš”ì•½:\")\n",
    "print(result)\n",
    "print(\"\\n\" + \"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b306fa2",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* ì…€ ì¶œë ¥ (temperature=0.2, max_tokens=4,096)(1.1s)\n",
    "\n",
    "    ```<plaintext>\n",
    "    ==================================================\n",
    "\n",
    "    ìƒì„±ëœ ìš”ì•½:\n",
    "    Jayì˜ AI ë¹„ì„œì…ë‹ˆë‹¤. ë°ì´í„° ê³¼í•™ì— ëŒ€í•œ ì •ë³´ë¥¼ ìš”ì•½í•´ ë“œë¦¬ê² ìŠµë‹ˆë‹¤.\n",
    "\n",
    "    **ë°ì´í„° ê³¼í•™ì€ í†µê³„í•™, ì»´í“¨í„° ê³¼í•™, ê·¸ë¦¬ê³  íŠ¹ì • ë¶„ì•¼ì˜ ì „ë¬¸ ì§€ì‹ì„ ê²°í•©í•˜ì—¬ ë°ì´í„°ì—ì„œ ê°€ì¹˜ë¥¼ ì¶”ì¶œí•˜ê³  ì§€ì‹ì„ ì–»ëŠ” í•™ì œê°„ ë¶„ì•¼ì…ë‹ˆë‹¤. ê¶ê·¹ì ì¸ ëª©í‘œëŠ” ë°ì´í„°ë¥¼ í™œìš©í•˜ì—¬ ë³µì¡í•œ ë¬¸ì œë¥¼ í•´ê²°í•˜ê³  ë¯¸ë˜ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.**\n",
    "\n",
    "    ==================================================\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c16214",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa56ea32",
   "metadata": {},
   "source": [
    "### `update`ëœ `LangChain Hub` ì—°ë™ ë°©ì‹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53df2e0f",
   "metadata": {},
   "source": [
    "#### 1) í”„ë¡¬í”„íŠ¸ ì •ì˜ ë° ì—…ë¡œë“œ\n",
    "\n",
    "* client ê°ì²´ ìƒì„±\n",
    "\n",
    "    ```python\n",
    "    from langchain.prompts import PromptTemplate, ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "    from langsmith import Client\n",
    "\n",
    "    # 1) LangSmith API í‚¤ ì„¸íŒ… (í™˜ê²½ë³€ìˆ˜ ë˜ëŠ” ì§ì ‘)\n",
    "    import os\n",
    "    LANGSMITH_API_KEY = os.getenv(\"LANGSMITH_API_KEY\")\n",
    "    client = Client(api_key=LANGSMITH_API_KEY)\n",
    "\n",
    "    # 2) í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì •ì˜ (ì˜ˆ: rag-prompt-korean)\n",
    "    system_template = \"\"\"ë‹¹ì‹ ì€ ì§ˆë¬¸-ë‹µë³€(Question-Answering)ì„ ìˆ˜í–‰í•˜ëŠ” ì¹œì ˆí•œ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. \n",
    "    ... (ìƒëµ, Jayë‹˜ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ê·¸ëŒ€ë¡œ) ...\n",
    "    \"\"\"\n",
    "    human_template = \"\"\"#Question: \n",
    "    {question} \n",
    "\n",
    "    #Context: \n",
    "    {context} \n",
    "\n",
    "    #Answer:\"\"\"\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", system_template),\n",
    "        (\"human\", human_template),\n",
    "    ])\n",
    "\n",
    "    # 3) í—ˆë¸Œì— ì—…ë¡œë“œ\n",
    "    prompt_id = \"rag-prompt-korean\"\n",
    "    owner = \"teddynote\"  # Jayë‹˜ ìƒí™©ì— ë§ê²Œ ë°”ê¾¸ê¸°\n",
    "\n",
    "    response = client.create_or_update_prompt(\n",
    "        repo_handle=f\"{owner}/{prompt_id}\",\n",
    "        object=prompt,\n",
    "        is_public=False,\n",
    "        description=\"RAG ì§ˆë¬¸-ë‹µë³€ìš© í•œêµ­ì–´ í”„ë¡¬í”„íŠ¸\"\n",
    "    )\n",
    "\n",
    "    print(\"ì—…ë¡œë“œ ì„±ê³µ! URL:\", f\"https://smith.langchain.com/hub/{owner}/{prompt_id}/latest\")\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8d361a",
   "metadata": {},
   "source": [
    "#### 2) í—ˆë¸Œì— ì—°ê²° \n",
    "\n",
    "* í—ˆë¸Œì—ì„œ íŠ¹ì • í”„ë¡¬í”„íŠ¸ ë¶ˆëŸ¬ì˜¤ê±°ë‚˜ ì—°ê²°í•´ì„œ ì‹¤í–‰í•˜ê¸°\n",
    "  \n",
    "    ```python\n",
    "\n",
    "    from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "    from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "    # 1) í”„ë¡¬í”„íŠ¸ ë¡œë“œ (ìµœì‹  ê¶Œì¥ ë°©ë²•)\n",
    "    prompt_loaded = client.pull_prompt(f\"{owner}/{prompt_id}:latest\")\n",
    "\n",
    "    # 2) LLM ì´ˆê¸°í™”\n",
    "    llm = ChatGoogleGenerativeAI(\n",
    "        model=\"gemini-2.5-flash-lite\",\n",
    "        temperature=0.7,\n",
    "        max_output_tokens=1024,\n",
    "    )\n",
    "\n",
    "    # 3) ì²´ì¸ êµ¬ì„±\n",
    "    chain = prompt_loaded | llm | StrOutputParser()\n",
    "\n",
    "    # 4) ì²´ì¸ ì‹¤í–‰ìš© ì…ë ¥ ì˜ˆì‹œ\n",
    "    inputs = {\n",
    "        \"context\": \"ì—¬ê¸°ì— ë¬¸ì„œ ë‚´ìš©ì´ë‚˜ ì°¸ê³  í…ìŠ¤íŠ¸ ì…ë ¥\",\n",
    "        \"question\": \"ì§ˆë¬¸ ë‚´ìš© ì…ë ¥\"\n",
    "    }\n",
    "\n",
    "    # 5) ì‹¤í–‰ ë° ì¶œë ¥\n",
    "    result = chain.invoke(inputs)\n",
    "    print(\"ê²°ê³¼:\", result)\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2217816c",
   "metadata": {},
   "source": [
    "![LangChain Workflow](./img/langchain_workflow.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lc_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
