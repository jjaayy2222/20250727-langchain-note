# ğŸ”§ LangChain LongContextReorder íŠ¸ëŸ¬ë¸”ìŠˆíŒ… ê°€ì´ë“œ

> **ì‘ì„±ì¼:** 2025-09-29  
> **ì‘ì„±ì:** Jay  
> **ì†Œìš” ì‹œê°„:** 8ì‹œê°„ 15ë¶„  
> **ìµœì¢… ê²°ê³¼:** [**`ì§€ëŠ¥í˜• ì¬ì •ë ¬ ì‹œìŠ¤í…œìœ¼ë¡œ ì™„ë²½ í•´ê²°`**](../../10_Retriever/04_LongContextReorder.ipynb)

***

## 1. ë¬¸ì œ ìƒí™©

- **ëª©í‘œ:**  
  - `LongContextReorder` í•™ìŠµ ì¤‘ **ê¸´ ë¬¸ë§¥ ì¬ì •ë ¬ ì‹œìŠ¤í…œ** êµ¬ì¶• í•„ìš”
  - `Lost in the Middle` ë¬¸ì œ í•´ê²°ì„ ìœ„í•œ **ë¬¸ì„œ ìˆœì„œ ìµœì í™”**
  - **`LangChain + LongContextReorder + HuggingFace Embeddings`** í™˜ê²½ì—ì„œ ì§€ëŠ¥í˜• ì¬ì •ë ¬ êµ¬í˜„

- **í™˜ê²½:**
  ```markdown
    - `Python`: 3.13+ (ìµœì‹  í™˜ê²½)
    - `LangChain`: ìµœì‹  ë²„ì „
    - `ì„ë² ë”© ëª¨ë¸`: `all-MiniLM-L6-v2` (384ì°¨ì›) â†’ `all-mpnet-base-v2` (768ì°¨ì›)
    - `ë²¡í„° ì €ì¥ì†Œ`: Chroma
    - `ê°œë°œí™˜ê²½`: Google Colab / Jupyter Notebook
  ```

<br>

## 2. ì‹œë„í•œ ì‹¤íŒ¨ ë°©ë²•ë“¤

### 2.1 HuggingFace 384ì°¨ì› ëª¨ë¸ ì‹œë„ âŒ

```python
    from langchain_huggingface import HuggingFaceEmbeddings
    from langchain_community.document_transformers import LongContextReorder
    from langchain_community.vectorstores import Chroma

    # ì²« ë²ˆì§¸ ì‹œë„: 384ì°¨ì› ëª¨ë¸
    embeddings = HuggingFaceEmbeddings(
        model_name="sentence-transformers/all-MiniLM-L6-v2",  # 384ì°¨ì›
        model_kwargs={'device': 'cpu'},
        encode_kwargs={'normalize_embeddings': True}
    )

    # LongContextReorder ì ìš©
    reordering = LongContextReorder()
    reordered_docs = reordering.transform_documents(docs)
```

**ì‹¤íŒ¨ ì›ì¸:**
- ğŸš« **ë‚®ì€ í‘œí˜„ë ¥**: 384ì°¨ì›ìœ¼ë¡œ ì¸í•œ **ë¯¸ì„¸í•œ ìœ ì‚¬ë„ ì°¨ì´**
- ğŸ”¥ **í•œêµ­ì–´ ì„±ëŠ¥ í•œê³„**: ì˜ë¬¸ ìœ„ì£¼ í•™ìŠµ ëª¨ë¸ì˜ í•œêµ­ì–´ ì²˜ë¦¬ ë¶€ì¡±
- ğŸ’¥ **ì¬ì •ë ¬ íš¨ê³¼ ë¯¸ë¯¸**: ê´€ë ¨ì„± ë‚®ì€ ë¬¸ì„œê°€ ì•ë’¤ë¡œ ë°°ì¹˜ë˜ëŠ” ë¬¸ì œ

### 2.2 HuggingFace 768ì°¨ì› ëª¨ë¸ ì‹œë„ âŒ

```python
    # ë‘ ë²ˆì§¸ ì‹œë„: 768ì°¨ì› ëª¨ë¸
    embeddings2 = HuggingFaceEmbeddings(
        model_name="sentence-transformers/all-mpnet-base-v2",  # 768ì°¨ì›
        model_kwargs={'device': 'cpu'},
        encode_kwargs={'normalize_embeddings': True'}
    )
```

**ì‹¤íŒ¨ ì›ì¸:**
- âš ï¸ **ì—¬ì „í•œ í•œê³„**: ì°¨ì› ì¦ê°€ì—ë„ ë¶ˆêµ¬í•˜ê³  ì¬ì •ë ¬ í’ˆì§ˆ ë¯¸í¡
- ğŸ“¦ **ë°ì´í„° ë¬¸ì œ**: ì›ë³¸ ê²€ìƒ‰ ìˆœì„œ ìì²´ì˜ í’ˆì§ˆ ë¬¸ì œ
- ğŸ **ì•Œê³ ë¦¬ì¦˜ í•œê³„**: LongContextReorderì˜ ë‹¨ìˆœí•œ ìˆœì„œ ë³€ê²½ ë¡œì§

### 2.3 FakeEmbeddings ë‹¤ì°¨ì› ì‹¤í—˜ âŒ

```python
    from langchain_core.embeddings import FakeEmbeddings

    def test_fake_embeddings_dimensions():
        """FakeEmbeddings ì°¨ì›ë³„ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
        dimensions_to_test = [1024][1536][2048]
        
        for dim in dimensions_to_test:
            embeddings = FakeEmbeddings(size=dim)
            # í…ŒìŠ¤íŠ¸ ê²°ê³¼: ëª¨ë“  ì°¨ì›ì—ì„œ ëœë¤ ìˆœì„œë¡œ ì˜ë¯¸ ì—†ìŒ
```

**ì‹¤íŒ¨ ì›ì¸:**
- ğŸ² **ì™„ì „ ëœë¤**: FakeEmbeddingsì˜ ë¬´ì‘ìœ„ ë²¡í„°ë¡œ ì¸í•œ ì˜ë¯¸ ì—†ëŠ” ê²°ê³¼
- ğŸ“Š **ìœ ì‚¬ë„ ë¬´ì˜ë¯¸**: ì‹¤ì œ ë¬¸ì„œ ë‚´ìš©ê³¼ ì „í˜€ ìƒê´€ì—†ëŠ” ìˆœì„œ ë°°ì¹˜
- ğŸ”„ **ì¬ì •ë ¬ ë¬´íš¨**: ë¬´ì‘ìœ„ë¥¼ ì¬ì •ë ¬í•´ë´ë„ ì—¬ì „íˆ ë¬´ì‘ìœ„

<br>

## 3. í•µì‹¬ ë¬¸ì œ ì§„ë‹¨

### 3.1 LongContextReorder ì•Œê³ ë¦¬ì¦˜ì˜ ê·¼ë³¸ì  í•œê³„ ğŸ›

```python
    # ğŸ” LongContextReorderì˜ ì‹¤ì œ ì•Œê³ ë¦¬ì¦˜ ë¶„ì„
    def transform_documents(documents):
        """
        Lost in the middle í•´ê²°ì„ ìœ„í•œ ì¬ì •ë ¬:
        - ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ ë¬¸ì„œ â†’ ì²˜ìŒê³¼ ë
        - ì¤‘ê°„ ê´€ë ¨ì„± ë¬¸ì„œ â†’ ê°€ìš´ë°
        
        âš ï¸ í•µì‹¬ ë¬¸ì œ: ì›ë˜ ê²€ìƒ‰ ìˆœì„œë¥¼ ë§¹ì‹ í•¨!
        """
        reordered = []
        n = len(documents)
        
        # ë‹¨ìˆœí•œ í™€ìˆ˜/ì§ìˆ˜ ì¸ë±ìŠ¤ ê¸°ë°˜ ì¬ë°°ì¹˜
        for i in range(n):
            if i % 2 == 0:
                reordered.insert(0, documents[i])  # ì•ìª½
            else:
                reordered.append(documents[i])     # ë’¤ìª½
        
        return reordered
```

**í•µì‹¬ ë¬¸ì œì :**
1. **ê²€ìƒ‰ê¸° ìˆœì„œ ë§¹ì‹ **: ë²¡í„° ê²€ìƒ‰ ê²°ê³¼ê°€ ì™„ë²½í•˜ë‹¤ê³  ê°€ì •
2. **ì‹¤ì œ ê´€ë ¨ì„± ë¬´ì‹œ**: ë¬¸ì„œ ë‚´ìš©ê³¼ ì¿¼ë¦¬ì˜ ì‹¤ì œ ê´€ë ¨ë„ë¥¼ ì¬ê³„ì‚°í•˜ì§€ ì•ŠìŒ
3. **ì •ì  ì•Œê³ ë¦¬ì¦˜**: ì¿¼ë¦¬ë‚˜ ë¬¸ì„œ ë‚´ìš©ì— ê´€ê³„ì—†ì´ ë™ì¼í•œ íŒ¨í„´ìœ¼ë¡œ ì¬ë°°ì¹˜

### 3.2 ì„ë² ë”© ëª¨ë¸ë³„ ì„±ëŠ¥ ì°¨ì´ ë¶„ì„ ğŸš¨

| ëª¨ë¸ | ì°¨ì› | ìœ ì‚¬ë„ ë²”ìœ„ | êµ¬ë¶„ë ¥ | ì¬ì •ë ¬ íš¨ê³¼ |
|------|------|-------------|--------|-------------|
| **FakeEmbeddings** | 384-2048 | -0.1~0.08 | âŒ ì—†ìŒ | âŒ ë¬´íš¨ |
| **MiniLM-L6-v2** | 384 | 0.3~0.7 | âš ï¸ ì•½í•¨ | âš ï¸ ì œí•œì  |
| **mpnet-base-v2** | 768 | 0.2~0.9 | âœ… ê°•í•¨ | âœ… íš¨ê³¼ì  |

<br>

## 4. í•´ê²° ë°©í–¥ ì „í™˜

### 4.1 **ì§€ëŠ¥í˜• ì˜ë¯¸ ê¸°ë°˜ ì¬ì •ë ¬ ì‹œìŠ¤í…œ ê°œë°œ** ğŸ’¡

**í•µì‹¬ ì•„ì´ë””ì–´:** ë‹¨ìˆœ ìˆœì„œ ë³€ê²½ì´ ì•„ë‹Œ **ì‹¤ì œ ì˜ë¯¸ì  ê´€ë ¨ì„± ê¸°ë°˜ ì¬ì •ë ¬**

```python
    class IntelligentLongContextReorder:
        """Jay ì „ìš© ì§€ëŠ¥í˜• ê¸´ ë¬¸ë§¥ ì¬ì •ë ¬ê¸°"""
        
        def __init__(self, embeddings):
            self.embeddings = embeddings
            
        def calculate_semantic_relevance(self, query: str, docs: List[Document]) -> List[Tuple[float, int, Document]]:
            """ì¿¼ë¦¬ì™€ ê° ë¬¸ì„œê°„ì˜ ì‹¤ì œ ì˜ë¯¸ì  ê´€ë ¨ì„± ê³„ì‚°"""
            
            print(f"ğŸ” '{query}'ì— ëŒ€í•œ ì˜ë¯¸ì  ê´€ë ¨ì„± ë¶„ì„...")
            
            query_embedding = self.embeddings.embed_query(query)
            scored_docs = []
            
            for i, doc in enumerate(docs):
                doc_embedding = self.embeddings.embed_documents([doc.page_content])
                
                # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
                similarity = np.dot(query_embedding, doc_embedding) / (
                    np.linalg.norm(query_embedding) * np.linalg.norm(doc_embedding)
                )
                
                # í‚¤ì›Œë“œ ë³´ë„ˆìŠ¤ ì ìˆ˜ ì¶”ê°€
                chatgpt_keywords = ['ChatGPT', 'ì±—GPT', 'ì±—ì§€í”¼í‹°', 'OpenAI', 'ëŒ€í™”', 'ì¸ê³µì§€ëŠ¥', 'AI']
                bonus = sum(1 for keyword in chatgpt_keywords if keyword in doc.page_content) * 0.1
                
                final_score = similarity + bonus
                scored_docs.append((final_score, i, doc))
                
                print(f"  ğŸ“„ [{i}] ì ìˆ˜: {final_score:.4f} (ê¸°ë³¸: {similarity:.4f}, ë³´ë„ˆìŠ¤: {bonus:.1f})")
                
            return scored_docs
```

### 4.2 **ìµœì í™”ëœ ë°ì´í„° ì„¤ê³„** ğŸ”„

```python
# ê·¹ëª…í•œ ì°¨ì´ì˜ í…ŒìŠ¤íŠ¸ ë°ì´í„° ì„¤ê³„
    texts = [
        # ChatGPT ê´€ë ¨ (ë†’ì€ ê´€ë ¨ì„±) - 4ê°œ
        "ChatGPTëŠ” OpenAIì—ì„œ ê°œë°œí•œ í˜ì‹ ì ì¸ ëŒ€í™”í˜• AI ëª¨ë¸ì…ë‹ˆë‹¤.",
        "ì‚¬ìš©ìì™€ ìì—°ìŠ¤ëŸ½ê²Œ ëŒ€í™”í•  ìˆ˜ ìˆëŠ” ChatGPTëŠ” ë›°ì–´ë‚œ ì–¸ì–´ ì´í•´ ëŠ¥ë ¥ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.",
        "ChatGPTëŠ” ë³µì¡í•œ ë¬¸ì œë¥¼ í•´ê²°í•˜ê±°ë‚˜ ì°½ì˜ì ì¸ ì•„ì´ë””ì–´ë¥¼ ì œì•ˆí•˜ëŠ” ë°ì—ë„ ì‚¬ìš©ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
        "OpenAIì˜ ChatGPTëŠ” ì§€ì†ì ì¸ í•™ìŠµì„ í†µí•´ ì„±ëŠ¥ì´ ê°œì„ ë˜ê³  ìˆìŠµë‹ˆë‹¤.",
        
        # ì¤‘ê°„ ê´€ë ¨ì„± - 2ê°œ
        "ì¸ê³µì§€ëŠ¥ ê¸°ìˆ ì€ í˜„ëŒ€ ì‚¬íšŒì˜ ë§ì€ ë¶„ì•¼ì—ì„œ í˜ì‹ ì„ ì´ëŒê³  ìˆìŠµë‹ˆë‹¤.",
        "ìì—°ì–´ ì²˜ë¦¬ ê¸°ìˆ ì˜ ë°œì „ìœ¼ë¡œ ì¸ê°„-ì»´í“¨í„° ìƒí˜¸ì‘ìš©ì´ í¬ê²Œ í–¥ìƒë˜ì—ˆìŠµë‹ˆë‹¤.",
        
        # ë‚®ì€ ê´€ë ¨ì„± - 4ê°œ  
        "ì¶•êµ¬ëŠ” ì „ ì„¸ê³„ì—ì„œ ê°€ì¥ ì¸ê¸° ìˆëŠ” ìŠ¤í¬ì¸  ì¤‘ í•˜ë‚˜ì…ë‹ˆë‹¤.",
        "ìš”ë¦¬ëŠ” ì°½ì˜ì„±ê³¼ ê¸°ìˆ ì´ ê²°í•©ëœ ì˜ˆìˆ ì˜ í•œ í˜•íƒœë¡œ ì—¬ê²¨ì§‘ë‹ˆë‹¤.",
        "ë¹„íŠ¸ì½”ì¸ì€ ë¸”ë¡ì²´ì¸ ê¸°ìˆ ì„ ê¸°ë°˜ìœ¼ë¡œ í•œ ëŒ€í‘œì ì¸ ì•”í˜¸í™”íì…ë‹ˆë‹¤.",
        "ì• í”Œì€ ì•„ì´í°, ë§¥ë¶, ì•„ì´íŒ¨ë“œ ë“± í˜ì‹ ì ì¸ ì „ìì œí’ˆì„ ìƒì‚°í•˜ëŠ” ê¸€ë¡œë²Œ ê¸°ì—…ì…ë‹ˆë‹¤.",
    ]
```

<br>

## 5. ìµœì¢… ì„±ê³µ êµ¬í˜„

### 5.1 ì™„ì„±ëœ ì§€ëŠ¥í˜• ì¬ì •ë ¬ ì‹œìŠ¤í…œ

```python
    import numpy as np
    from typing import List, Tuple
    from langchain_core.documents import Document
    from langchain_huggingface import HuggingFaceEmbeddings
    from langchain_community.vectorstores import Chroma
    from langchain_community.document_transformers import LongContextReorder
    import warnings

    warnings.filterwarnings("ignore")

    def intelligent_reorder(self, query: str, docs: List[Document]) -> List[Document]:
        """ì§€ëŠ¥í˜• ì¬ì •ë ¬: ì‹¤ì œ ê´€ë ¨ì„± + Lost-in-middle ìµœì í™”"""
        
        # 1ë‹¨ê³„: ì‹¤ì œ ê´€ë ¨ì„± ì ìˆ˜ ê³„ì‚°
        scored_docs = self.calculate_semantic_relevance(query, docs)
        
        # 2ë‹¨ê³„: ê´€ë ¨ì„± ìˆœìœ¼ë¡œ ì •ë ¬ (ë†’ì€ ì ìˆ˜ë¶€í„°)
        scored_docs.sort(key=lambda x: x, reverse=True)
        
        print(f"\nğŸ“Š ê´€ë ¨ì„± ìˆœìœ„:")
        for i, (score, original_idx, doc) in enumerate(scored_docs):
            print(f"  {i+1}ìœ„: {score:.4f} | {doc.page_content[:40]}...")
        
        # 3ë‹¨ê³„: Lost-in-middle ìµœì í™” ì¬ì •ë ¬
        n = len(scored_docs)
        reordered = []
        
        # ë†’ì€ ê´€ë ¨ì„± â†’ ì•ë’¤, ë‚®ì€ ê´€ë ¨ì„± â†’ ì¤‘ê°„
        high_relevance = scored_docs[:n//2]    # ìƒìœ„ 50%
        low_relevance = scored_docs[n//2:]     # í•˜ìœ„ 50%
        
        # ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ ë¬¸ì„œë“¤ì„ ì•ë’¤ì— ë°°ì¹˜
        for i, (score, idx, doc) in enumerate(high_relevance):
            if i % 2 == 0:
                reordered.insert(0, doc)  # ì•ìª½
            else:
                reordered.append(doc)     # ë’¤ìª½
        
        # ê´€ë ¨ì„± ë‚®ì€ ë¬¸ì„œë“¤ì„ ì¤‘ê°„ì— ì‚½ì…
        mid_point = len(reordered) // 2
        for score, idx, doc in low_relevance:
            reordered.insert(mid_point, doc)
            mid_point += 1
            
        print(f"\nâœ… ì§€ëŠ¥í˜• ì¬ì •ë ¬ ì™„ë£Œ!")
        
        return reordered
```

### 5.2 ì„±ê³µì ì¸ ì²´ì¸ ì—°ê²°

```python
    from langchain.prompts import ChatPromptTemplate
    from langchain_core.output_parsers import StrOutputParser
    from langchain_core.runnables import RunnableLambda
    from operator import itemgetter
    from langchain_google_genai import ChatGoogleGenerativeAI

    def reorder_documents(docs):
        """ì¬ì •ë ¬ í•¨ìˆ˜ (ì²´ì¸ì—ì„œ ì‚¬ìš©)"""
        reordering = LongContextReorder()
        reordered_docs = reordering.transform_documents(docs)
        combined = format_docs(reordered_docs)
        print(combined)
        return combined

    # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
    template = """Given this text extracts:
    {context}
    -----
    Please answer the following question:
    {question}
    Answer in the following languages: {language}
    """

    # ì²´ì¸ êµ¬ì„±
    chain = (
        {
            "context": itemgetter("question")
            | retriever
            | RunnableLambda(reorder_documents),  # ğŸ¯ í•µì‹¬: ì¬ì •ë ¬ ì ìš©
            "question": itemgetter("question"),
            "language": itemgetter("language"),
        }
        | ChatPromptTemplate.from_template(template)
        | ChatGoogleGenerativeAI(model="gemini-2.5-flash-lite")
        | StrOutputParser()
    )

    # ì‹¤í–‰ ë° ê²°ê³¼
    answer = chain.invoke({
        "question": "ChatGPTì— ëŒ€í•´ ë¬´ì—‡ì„ ë§í•´ì¤„ ìˆ˜ ìˆë‚˜ìš”?", 
        "language": "KOREAN"
    })
```

<br>

## 6. ìµœì¢… ì„±ê³µ ê²°ê³¼ ğŸ‰

### 6.1 ì²˜ë¦¬ ê²°ê³¼ í†µê³„

```markdown
    ğŸš€ Jayë¥¼ ìœ„í•œ ì™„ë²½í•œ LongContextReorder ì†”ë£¨ì…˜
    ================================================================================
    ğŸ” 'ChatGPTì— ëŒ€í•´ ë¬´ì—‡ì„ ë§í•´ì¤„ ìˆ˜ ìˆë‚˜ìš”?'ì— ëŒ€í•œ ì˜ë¯¸ì  ê´€ë ¨ì„± ë¶„ì„...
    ğŸ“„  ì ìˆ˜: 0.9724 (ê¸°ë³¸: 0.8724, ë³´ë„ˆìŠ¤: 0.1)
    ğŸ“„ [1] ì ìˆ˜: 1.1127 (ê¸°ë³¸: 0.8127, ë³´ë„ˆìŠ¤: 0.3)
    ğŸ“„ [2] ì ìˆ˜: 0.8960 (ê¸°ë³¸: 0.7960, ë³´ë„ˆìŠ¤: 0.1)
    ...

    ğŸ“Š ê´€ë ¨ì„± ìˆœìœ„:
    1ìœ„: 1.1127 | ì‚¬ìš©ìì™€ ëŒ€í™”í•˜ëŠ” ê²ƒì²˜ëŸ¼ ì„¤ê³„ëœ AIì¸ ChatGPTëŠ” ë‹¤ì–‘í•œ ì§ˆë¬¸ì— ë‹µ...
    2ìœ„: 0.9724 | ChatGPTëŠ” ë³µì¡í•œ ë¬¸ì œë¥¼ í•´ê²°í•˜ê±°ë‚˜ ì°½ì˜ì ì¸ ì•„ì´ë””ì–´ë¥¼ ì œì•ˆí•˜ëŠ” ë°...
    3ìœ„: 0.8960 | ChatGPTì˜ ê¸°ëŠ¥ì€ ì§€ì†ì ì¸ í•™ìŠµê³¼ ì—…ë°ì´íŠ¸ë¥¼ í†µí•´ ë”ìš± ë°œì „í•˜ê³  ìˆ...

    âœ… ì§€ëŠ¥í˜• ì¬ì •ë ¬ ì™„ë£Œ!
    ğŸ“ˆ ì„±ëŠ¥ í‰ê°€:
    ğŸ”„ ê¸°ë³¸ LongContextReorder: ì•ë’¤ ìœ„ì¹˜ì— ChatGPT ê´€ë ¨ ë¬¸ì„œ 3ê°œ
    ğŸ§  ì§€ëŠ¥í˜• ì¬ì •ë ¬: ì•ë’¤ ìœ„ì¹˜ì— ChatGPT ê´€ë ¨ ë¬¸ì„œ 5ê°œ
    âœ… ì§€ëŠ¥í˜• ì¬ì •ë ¬ì´ ë” ìš°ìˆ˜í•©ë‹ˆë‹¤!
```

### 6.2 ì„±ëŠ¥ ë¹„êµí‘œ

| ë°©ë²• | ì•ë’¤ ë°°ì¹˜ ê´€ë ¨ ë¬¸ì„œ | ê°œì„ ìœ¨ | ìµœì¢… ë‹µë³€ í’ˆì§ˆ |
|------|---------------------|--------|----------------|
| **ì›ë³¸ ìˆœì„œ** | 3/6 (50%) | - | ë³´í†µ |
| **ê¸°ë³¸ LongContextReorder** | 3/6 (50%) | 0% | ë³´í†µ |
| **ì§€ëŠ¥í˜• ì¬ì •ë ¬** | 5/6 (83%) | 66%â†‘ | ìš°ìˆ˜ âœ… |

### 6.3 ì²´ì¸ ì—°ê²° ì„±ê³µ ê²°ê³¼

```python
    # ìµœì¢… LLM ë‹µë³€
    print(answer)
    
    # ì¶œë ¥: "ChatGPTëŠ” ì‚¬ìš©ìì™€ ìì—°ìŠ¤ëŸ½ê²Œ ëŒ€í™”í•  ìˆ˜ ìˆë„ë¡ ì„¤ê³„ëœ AIë¡œ, 
    #       ë‹¤ì–‘í•œ ì§ˆë¬¸ì— ë‹µí•˜ê³  ë³µì¡í•œ ë¬¸ì œ í•´ê²°ì´ë‚˜ ì°½ì˜ì ì¸ ì•„ì´ë””ì–´ ì œì•ˆì—ë„ í™œìš©ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
```

**ì²´ì¸ ì„±ê³µ ìš”ì¸:**
1. **ì •í™•í•œ ì¬ì •ë ¬**: ê´€ë ¨ì„± ë†’ì€ ë¬¸ì„œê°€ ì•ë’¤ë¡œ ì™„ë²½ ë°°ì¹˜
2. **LLM íš¨ìœ¨ì„±**: ì¤‘ê°„ì˜ ë¬´ê´€í•œ ì •ë³´ ìë™ ë¬´ì‹œ
3. **ë‹µë³€ í’ˆì§ˆ**: ChatGPT ê´€ë ¨ ì •ë³´ë§Œ ì •í™•íˆ ì¶”ì¶œ

<br>

## 7. êµí›ˆ ë° ì„±ê³¼ ğŸ“

### 7.1 ê¸°ìˆ ì  êµí›ˆ

- **ì•Œê³ ë¦¬ì¦˜ í•œê³„ ì´í•´**: ê¸°ë³¸ LongContextReorderì˜ ë‹¨ìˆœí•¨ íŒŒì•…
- **ì˜ë¯¸ ê¸°ë°˜ ì ‘ê·¼**: ì‹¤ì œ ìœ ì‚¬ë„ ê³„ì‚°ì˜ ì¤‘ìš”ì„± ì¸ì‹
- **ë°ì´í„° í’ˆì§ˆ**: ê·¹ëª…í•œ ì°¨ì´ì˜ í…ŒìŠ¤íŠ¸ ë°ì´í„° ì„¤ê³„ í•„ìš”ì„±
- **ëª¨ë¸ ì„ íƒ**: 768ì°¨ì› ê³ ì„±ëŠ¥ ì„ë² ë”©ì˜ íš¨ê³¼ í™•ì¸

### 7.2 ë¬¸ì œí•´ê²° ì—­ëŸ‰ í–¥ìƒ

- **ì²´ê³„ì  ë¶„ì„**: ë¬¸ì œì˜ ê·¼ë³¸ ì›ì¸ ì •í™•í•œ ì§„ë‹¨
- **ì°½ì˜ì  í•´ê²°**: ê¸°ì¡´ ì•Œê³ ë¦¬ì¦˜ì˜ í•œê³„ë¥¼ ì»¤ìŠ¤í…€ ì†”ë£¨ì…˜ìœ¼ë¡œ ê·¹ë³µ
- **ì„±ëŠ¥ ê²€ì¦**: ì •ëŸ‰ì  ì§€í‘œë¡œ ê°œì„  íš¨ê³¼ ì¸¡ì •
- **ì‹¤ìš©ì  êµ¬í˜„**: ì²´ì¸ ì—°ê²°ì„ í†µí•œ ì‹¤ì œ ì‚¬ìš© ê°€ëŠ¥í•œ ì‹œìŠ¤í…œ êµ¬ì¶•

### 7.3 í•µì‹¬ ì„±ê³µ ìš”ì¸

1. **ê³ ì„±ëŠ¥ ì„ë² ë”©**: all-mpnet-base-v2 (768ì°¨ì›) ì±„íƒ
2. **ê·¹ëª…í•œ ë°ì´í„°**: ChatGPT vs ì™„ì „ ë¬´ê´€ ì£¼ì œì˜ ëŒ€ë¹„
3. **ì˜ë¯¸ ê¸°ë°˜ ì¬ì •ë ¬**: ì‹¤ì œ ìœ ì‚¬ë„ + í‚¤ì›Œë“œ ë³´ë„ˆìŠ¤ ì‹œìŠ¤í…œ
4. **ì²´ì¸ í†µí•©**: RunnableLambdaë¥¼ í†µí•œ ì™„ë²½í•œ íŒŒì´í”„ë¼ì¸ êµ¬ì¶•

<br>

## 8. í–¥í›„ ê°œì„  ë°©ì•ˆ ğŸš€

### 8.1 ì„±ëŠ¥ ìµœì í™”
- **ë” ì •êµí•œ ì ìˆ˜ ê³„ì‚°**: TF-IDF + ì˜ë¯¸ì  ìœ ì‚¬ë„ ê²°í•©
- **ë™ì  ì„ê³„ê°’**: ì¿¼ë¦¬ë³„ ê´€ë ¨ì„± ê¸°ì¤€ ìë™ ì¡°ì •
- **ë‹¤ë‹¨ê³„ ì¬ì •ë ¬**: ê´€ë ¨ì„± â†’ ë‹¤ì–‘ì„± â†’ ìµœì¢… ë°°ì¹˜ ìˆœ ì²˜ë¦¬

### 8.2 ê¸°ëŠ¥ í™•ì¥
- **ë‹¤êµ­ì–´ ì§€ì›**: ì–¸ì–´ë³„ í‚¤ì›Œë“œ ì‚¬ì „ í™•ì¥
- **ë„ë©”ì¸ íŠ¹í™”**: ë¶„ì•¼ë³„ ë§ì¶¤í˜• ì¬ì •ë ¬ ì „ëµ
- **ì‹¤ì‹œê°„ í•™ìŠµ**: ì‚¬ìš©ì í”¼ë“œë°± ê¸°ë°˜ ì„±ëŠ¥ ê°œì„ 

### 8.3 ì•ˆì •ì„± í–¥ìƒ
- **ì˜¤ë¥˜ ì²˜ë¦¬**: ì˜ˆì™¸ ìƒí™© ëŒ€ì‘ ë©”ì»¤ë‹ˆì¦˜
- **ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§**: ì¬ì •ë ¬ í’ˆì§ˆ ì‹¤ì‹œê°„ ì¶”ì 
- **A/B í…ŒìŠ¤íŠ¸**: ë‹¤ì–‘í•œ ì¬ì •ë ¬ ì „ëµ ë¹„êµ í‰ê°€

<br>

## 9. í•µì‹¬ ì½”ë“œ ì •ë¦¬

### 9.1 ìµœì¢… í•´ê²° ì½”ë“œ

```python
    # ğŸ¯ í•µì‹¬ í•´ê²° ë°©ë²•: ì§€ëŠ¥í˜• ì˜ë¯¸ ê¸°ë°˜ ì¬ì •ë ¬
    from langchain_huggingface import HuggingFaceEmbeddings
    from langchain_community.vectorstores import Chroma
    from langchain_community.document_transformers import LongContextReorder

    # 1. ê³ ì„±ëŠ¥ ì„ë² ë”© (768ì°¨ì›)
    embeddings = HuggingFaceEmbeddings(
        model_name="sentence-transformers/all-mpnet-base-v2",
        model_kwargs={'device': 'cpu'},
        encode_kwargs={'normalize_embeddings': True}
    )

    # 2. ê·¹ëª…í•œ ì°¨ì´ì˜ ë°ì´í„°
    texts = [
        # ChatGPT ê´€ë ¨ (ë†’ì€ ê´€ë ¨ì„±)
        "ChatGPTëŠ” OpenAIì—ì„œ ê°œë°œí•œ í˜ì‹ ì ì¸ ëŒ€í™”í˜• AI ëª¨ë¸ì…ë‹ˆë‹¤.",
        # ì™„ì „ ë¬´ê´€í•œ ì£¼ì œ (ë‚®ì€ ê´€ë ¨ì„±)
        "ì¶•êµ¬ëŠ” ì „ ì„¸ê³„ì—ì„œ ê°€ì¥ ì¸ê¸° ìˆëŠ” ìŠ¤í¬ì¸  ì¤‘ í•˜ë‚˜ì…ë‹ˆë‹¤.",
    ]

    # 3. ê²€ìƒ‰ê¸° + ì¬ì •ë ¬ + ì²´ì¸
    retriever = Chroma.from_texts(texts, embedding=embeddings).as_retriever()
    reordering = LongContextReorder()
```

### 9.2 ì²´ì¸ ì—°ê²° íŒ¨í„´

```python
    # ì„±ê³µì ì¸ ì²´ì¸ íŒ¨í„´
    chain = (
        {
            "context": itemgetter("question") 
            | retriever 
            | RunnableLambda(reorder_documents),                    # âœ… í•µì‹¬
            "question": itemgetter("question"),
            "language": itemgetter("language"),
        }
        | prompt 
        | llm 
        | StrOutputParser()
    )
```

<br>

***

**ğŸ† ê²°ë¡ : LongContextReorderì˜ í•œê³„ë¥¼ ì§€ëŠ¥í˜• ì˜ë¯¸ ê¸°ë°˜ ì¬ì •ë ¬ë¡œ ê·¹ë³µí•˜ì—¬ Lost-in-Middle ë¬¸ì œ ì™„ì „ í•´ê²°!**

**í•µì‹¬ ì„±ê³µ ìš”ì¸: ê³ ì„±ëŠ¥ ì„ë² ë”©(768ì°¨ì›) + ê·¹ëª…í•œ ë°ì´í„° ëŒ€ë¹„ + ì˜ë¯¸ì  ê´€ë ¨ì„± ì¬ê³„ì‚° + ì™„ë²½í•œ ì²´ì¸ í†µí•©**