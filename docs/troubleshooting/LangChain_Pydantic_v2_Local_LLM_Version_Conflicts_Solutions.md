# Local LLM Evaluation with LangSmith: Dependency Conflicts & Solutions

  - `LangSmith`ë¥¼ í™œìš©í•œ `ë¡œì»¬ LLM` í‰ê°€ - ì˜ì¡´ì„± ì¶©ëŒê³¼ í•´ê²°ì±…

<br>

> ë‚ ì§œ: 2025.10.18.
> 
> í™˜ê²½: `M1 MacBook Air`, `Python 3.12`, `pyenv virtualenv`
> 
> í”„ë¡œì íŠ¸: `LangChain RAG Evaluation` with Local LLM (Qwen2.5-Coder-7B)

---

## 1. ğŸ¯ ëª©í‘œ

### 1) Local-Only RAG í‰ê°€ íŒŒì´í”„ë¼ì¸ êµ¬í˜„:
  - ë¡œì»¬ LLM: `Qwen2.5-Coder-7B` (Ollama ê¸°ë°˜)
  - `LangSmith`: í‰ê°€ í”„ë ˆì„ì›Œí¬
  - `LangChain 0.3.x`: `ì•ˆì • ë²„ì „`
  - `Pydantic` v2: ìµœì‹  ê²€ì¦ ë¼ì´ë¸ŒëŸ¬ë¦¬

### 2) ëª©í‘œ:
- `Gemini`, `GPT-4` ë“± ìƒìš© LLM ìˆ˜ì¤€ì˜ í‰ê°€ í’ˆì§ˆì„ ìœ ì§€í•˜ë©´ì„œ API ë¹„ìš© ì¤„ì´ê¸°

---

## 2. ğŸ› ì£¼ìš” ë¬¸ì œì 

### ì´ìŠˆ 1: `Pydantic v1` â†” `v2` `ì¶©ëŒ` (íŠœí† ë¦¬ì–¼ ìš”êµ¬ì‚¬í•­ ë¶ˆì¼ì¹˜)

- ë¬¸ì œ

```bash

    ModuleNotFoundError: No module named 'langchain.evaluation'

```

- ì›ì¸ ë¶„ì„:
  - *ê¸°ì¡´ íŠœí† ë¦¬ì–¼* = `Pydantic v1.10.18` ìš”êµ¬ (*êµ¬ë²„ì „*)
  - `ìµœì‹  LangChain 1.0.0+` = `Pydantic v2`ë§Œ ì§€ì›
  - `langchain.evaluation` `ëª¨ë“ˆ`ì€ `LangChain 1.0.0`ì—ì„œ `ì œê±°`ë¨
  - `langsmith` í‰ê°€ìëŠ” `LangChain í‰ê°€ ìŠ¤í‚¤ë§ˆ`ì— `ì˜ì¡´`í•¨

- í™˜ê²½ í˜¼ë€:

  - `lc_eval_env` (Pydantic v1) â†’ íŠœí† ë¦¬ì–¼ìš© í™˜ê²½
  - `lc_local_env` (Pydantic v2) â†’ ë¡œì»¬ LLMìš© í™˜ê²½

- í•´ê²°ì±…: `LangChain`ì„ `0.3.x` ì‹œë¦¬ì¦ˆë¡œ **`ë‹¤ìš´ê·¸ë ˆì´ë“œ`**

```bash

        pip install langchain==0.3.7
        pip install angchain-core==0.3.15
        pip install langchain-community==0.3.5

```

- **`ì™œ 0.3.7 ë²„ì „ì¸ê°€?`**
  - `langchain.evaluation ëª¨ë“ˆ`ì´ ì•„ì§ í¬í•¨ë¨
  - `Pydantic v2`ì™€ `í˜¸í™˜`
  - `LangSmith í‰ê°€ì`ì™€ `í˜¸í™˜`
  - í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œë„ ì•ˆì •ì 

---

### ì´ìŠˆ 2: `langchain-huggingface` ë²„ì „ **`ì¶©ëŒ`**

- ë¬¸ì œ

```bash

    ImportError: cannot import name 'convert_to_json_schema' from 'langchain_core.utils.function_calling'

```

- ì›ì¸:
```bash

    langchain-huggingface 1.0.0         â†’ langchain-core 1.0.0+ í•„ìš”
    langchain-core 0.3.15               â†’ convert_to_json_schema ì—†ìŒ

```

- í•´ê²°ì±…

```bash

        pip install langchain-huggingface==0.1.2

```

- ê²°ê³¼:
  - `langchain-core==0.3.15`ì™€ ì™„ë²½íˆ `í˜¸í™˜`
  - `ì„ë² ë”© ëª¨ë¸ ì •ìƒ ì‘ë™`
  - `í•¨ìˆ˜ í˜¸ì¶œ ì¶©ëŒ ì—†ìŒ`

---

### ì´ìŠˆ 3: `langchain-ollama` ë²„ì „ **`ì¶©ëŒ`**

- ë¬¸ì œ

```bash

    ImportError: cannot import name 'is_data_content_block' from 'langchain_core.messages'

```

- ì›ì¸:

```bash

    langchain-ollama 1.0.0              â†’ langchain-core 1.0.0+ í•„ìš”
    langchain-core 0.3.15               â†’ is_data_content_block ì—†ìŒ

```

- í•´ê²°ì±…

```bash

        pip install langchain-ollama==0.2.0

```

- ê²°ê³¼:
  - `LangChain 0.3.x`ì™€ ì™„ì „ `í˜¸í™˜`
  - `Qwen2.5-Coder-7B` ì™„ë²½ `êµ¬ë™`
  - `Streaming`, `Async` ê¸°ëŠ¥ ëª¨ë‘ `ìœ ì§€`

---

### ì´ìŠˆ 4: `langchain-classic` **`ê°„ì„­`** ë¬¸ì œ

- ë¬¸ì œ: ìë™ ì„¤ì¹˜ëœ **`langchain-classic==1.0.0`** ì´ **`ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ì¶©ëŒ`ì„ ìœ ë°œ**

- í•´ê²°ì±…

```bash

        pip uninstall -y langchain-classic

```

- ì´ìœ :
  - `langchain-classic` = *`êµ¬ë²„ì „ í˜¸í™˜ìš© íŒ¨í‚¤ì§€`*
  - LangChain 0.3.xì—ëŠ” **`ë¶ˆí•„ìš”`**
  - `import ê²½ë¡œ í˜¼ë€`ì„ ì¼ìœ¼í‚´

---

## 3. âœ… ìµœì¢… ì•ˆì • êµ¬ì„±

### 1) ìµœì  íŒ¨í‚¤ì§€ ë²„ì „

```bash

    # Core LangChain (0.3.x series)
    langchain==0.3.7
    langchain-core==0.3.15
    langchain-community==0.3.5
    langchain-text-splitters==0.3.2

    # LLM Providers (downgraded)
    langchain-ollama==0.2.0        # Local LLM
    langchain-huggingface==0.1.2   # Embeddings
    langchain-openai==1.0.0        # Optional

    # Evaluation & Tracking
    langsmith==0.1.147
    pydantic==2.12.3
    pydantic-core==2.41.4

    # Additional Dependencies
    python-dotenv==1.0.1
    faiss-cpu==1.9.0.post1
    pypdf==5.1.0

```

### 2) í™˜ê²½ ì„¤ì • ëª…ë ¹ì–´

```bash

        # ìƒˆ ê°€ìƒí™˜ê²½ ìƒì„±
        pyenv virtualenv 3.12 lc_eval_env

        # í™œì„±í™”
        pyenv activate lc_eval_env

        # pip ìµœì‹ í™”
        pip install --upgrade pip

        # 1. Core LangChain
        pip install langchain==0.3.7
        pip install langchain-core==0.3.15
        pip install langchain-community==0.3.5
        pip install langchain-text-splitters==0.3.2

        # 2. LLM Providers
        pip install langchain-ollama==0.2.0
        pip install langchain-huggingface==0.1.2
        pip install langchain-openai==1.0.0

        # 3. Evaluation
        pip install langsmith==0.1.147
        pip install pydantic==2.12.3
        pip install python-dotenv==1.0.1
        pip install faiss-cpu==1.9.0.post1
        pip install pypdf==5.1.0

        # 4. ê²€ì¦ (ì¤‘ìš”!)
        pip list | grep -E "langchain|pydantic"

```

---

## 4. ğŸ§ª í‰ê°€ ê²°ê³¼

### 1) ì„±ëŠ¥ ë¹„êµ

| í•­ëª©     | API LLM (Gemini) | Local LLM (Qwen2.5-Coder) |
|--------|------------------|---------------------------|
| ì •í™•ë„    | 3/5 (60%)        | 5/5 (100%)                |
| í‰ê°€ ì‹œê°„  | ì•½ 5ë¶„             | ì•½ 24ë¶„                     |
| API ë¹„ìš© | $0.02            | $0.00                     |
| ë™ì‹œì„±    | 4 threads        | 1 thread                  |


### 2) í•µì‹¬ ì¸ì‚¬ì´íŠ¸
- Local LLMì´ ìƒìš© LLMê³¼ ë™ë“±í•˜ê±°ë‚˜ ë” ë†’ì€ í‰ê°€ í’ˆì§ˆ ë‹¬ì„±
- Qwen2.5-Coder-7BëŠ” í‰ê°€ìš©ìœ¼ë¡œ ë§¤ìš° ìš°ìˆ˜
- ë¬´ë£Œì´ì§€ë§Œ `ëŠë¦¼` â†’ ì¶©ë¶„íˆ ìˆ˜ìš© ê°€ëŠ¥
- `ê²°ê³¼ ì¬í˜„ì„± ë³´ì¥` (`ëœë¤ ì‹œë“œ ê³ ì •`)

---

### 3) ğŸ”§ ì¶”ê°€ ìˆ˜ì • ì‚¬í•­

- **`TOKENIZERS_PARALLELISM` ê²½ê³ **

```python

    # ì½”ë“œ ìƒë‹¨ì— ì¶”ê°€
    os.environ["TOKENIZERS_PARALLELISM"] = "false"

```

- **`Jupyter Kernel` ì¶©ëŒ**

  - ë¬¸ì œ: `evaluate()` í˜¸ì¶œ ì‹œ `Jupyter ì»¤ë„` ë‹¤ìš´ë¨
  - í•´ê²°: `Python ìŠ¤í¬ë¦½íŠ¸`ë¡œ ì‹¤í–‰

```bash

    python myrag.py
    #  ...
    python myrag5.py

    python eval_context.py
    python eval_labeled_criteria.py
    python eval_labeled_score.py
    

```

- íŒŒì¼ ê²½ë¡œ ë¬¸ì œ

```python

    # ì ˆëŒ€ê²½ë¡œ ì‚¬ìš©
    script_dir = os.path.dirname(os.path.abspath(__file__))
    pdf_path = os.path.join(script_dir, "data", "SPRI_AI_Brief_2023ë…„12ì›”í˜¸_F.pdf")

```

---

## 5. í‰ê°€ êµ¬ì¡° 

### 1) ğŸ“Š êµ¬ì¡°: **`myrag5.py`**

```python

    class PDFRAG:
        def create_chain_with_context(self, retriever):
            """
            í‰ê°€ ì‹œ Contextì™€ Answerë¥¼ í•¨ê»˜ ë°˜í™˜.
            - Context ê¸°ë°˜ í‰ê°€ (context_qa, cot_qa)
            - Labeled Criteria (ê¸°ì¤€ ë¹„êµí˜•)
            - Labeled Score (ì •ëŸ‰ ì ìˆ˜í˜•)
            """
            prompt = ChatPromptTemplate.from_template(
                "Based ONLY on the following context, answer the question.\n"
                "Context:\n{context}\n\n"
                "Question: {question}\n"
                "Answer:"
            )
            
            chain = (
                {
                    "context": retriever | self._format_docs,
                    "question": RunnablePassthrough()
                }
                | RunnablePassthrough.assign(
                    answer=prompt | self.llm | StrOutputParser()
                )
            )
            return chain

```

  - ì´ ì„¤ê³„ì˜ ì´ìœ 
    - `context` = `í‰ê°€ ì°¸ì¡°`ë¡œ í™œìš© ê°€ëŠ¥
	- `answer` = `LLM`ì´ `ìƒì„±`
	- `question` = `ì¶”ì ìš©`ìœ¼ë¡œ ìœ ì§€
	- `ë°ì´í„° êµ¬ì¡°`ê°€ `ì¼ê´€`ë˜ì–´ `í‰ê°€`ì— `ì í•©`

--- 

### 2) ğŸ¯ í‰ê°€ ìŠ¤í¬ë¦½íŠ¸ ì˜ˆì‹œ

- 1. Context-Based Evaluators

```python
    # eval_context.py

    context_qa_evaluator = LangChainStringEvaluator(
        "context_qa",
        config={"llm": eval_llm},
        prepare_data=lambda run, example: {
            "prediction": run.outputs["answer"],
            "reference": run.outputs["context"],
            "input": example.inputs["question"],
        },
    )
```

- 2. Labeled Criteria

```python
    # eval_labeled_criteria.py

    helpfulness_evaluator = LangChainStringEvaluator(
        "labeled_criteria",
        config={
            "criteria": {
                "helpfulness": "Is this helpful compared to the reference?"
            },
            "llm": eval_llm,
        },
        prepare_data=lambda run, example: {
            "prediction": run.outputs["answer"],
            "reference": example.outputs["answer"],
            "input": example.inputs["question"],
        },
    )
```

- 3. Labeled Score

```python

    # eval_labeled_score.py

    accuracy_evaluator = LangChainStringEvaluator(
        "labeled_score_string",
        config={
            "criteria": {
                "accuracy": "Score 1-10: How accurate is the answer?"
            },
            "llm": eval_llm,
            "normalize_by": 10.0,
        },
        prepare_data=lambda run, example: {
            "prediction": run.outputs["answer"],
            "reference": example.outputs["answer"],
            "input": example.inputs["question"],
        },
    )

```

---

## 6. ğŸ’¡ í•µì‹¬ êµí›ˆ

- 1. ë²„ì „ í˜¸í™˜ì„± ë§¤íŠ¸ë¦­ìŠ¤

  - `LangChain`ì˜ `í•µì‹¬ ëª¨ë“ˆ`, `í†µí•© íŒ¨í‚¤ì§€`(ollama, huggingface), `Pydantic`, `LangSmith` ê°„ `ë²„ì „ í˜¸í™˜ì„±` ë°˜ë“œì‹œ í™•ì¸í•  ê²ƒ.

- 2. ë‹¤ìš´ê·¸ë ˆì´ë“œ ì „ëµ

  - ì¶©ëŒ ë°œìƒ ì‹œ:
    - `langchain==0.3.7`ë¡œ ì‹œì‘
    - `ê´€ë ¨ í†µí•© íŒ¨í‚¤ì§€`ë“¤ì„ ì´ì— ë§ê²Œ `í•˜í–¥ ì¡°ì •`
    - `0.3.x` â†” `1.0.x` **`í˜¼ìš© ê¸ˆì§€`**

- 3. ë¡œì»¬ LLMì˜ ì¥ì 
  - ğŸ’° ë¹„ìš© 0ì›
  - ğŸ”’ ë°ì´í„° í”„ë¼ì´ë²„ì‹œ ë³´ì¥
  - ğŸ§© ê²°ê³¼ ì¬í˜„ì„± í™•ë³´
  - âš™ï¸ ì™„ì „í•œ ì œì–´ê¶Œ (Prompt, Parameter)

- 4. í‰ê°€ Best Practice
  - ë¡œì»¬ LLM = **`max_concurrency=1`**
  - `prepare_data` `ë§¤í•‘`ì„ `ì‹ ì¤‘íˆ ì„¤ê³„`
  - `ì†Œê·œëª¨ í…ŒìŠ¤íŠ¸` í›„ ì „ì²´ ë°ì´í„° í‰ê°€
  - `LangSmith`ì— ê¸°ë¡í•´ `ë¹„êµ ë¶„ì„`

---

## 7. ğŸš€ ë¹ ë¥¸ ì‹œì‘ (ë³µë¶™ìš©)

```bash

    # 1. í™˜ê²½ ìƒì„±
    pyenv virtualenv 3.12 lc_eval_env
    pyenv activate lc_eval_env

    # 2. ë²„ì „ë³„ ì„¤ì¹˜
    pip install langchain==0.3.7
    pip install langchain-core==0.3.15
    pip install langchain-community==0.3.5
    pip install langchain-ollama==0.2.0
    pip install langchain-huggingface==0.1.2
    pip install langsmith==0.1.147
    pip install pydantic==2.12.3
    pip install faiss-cpu pypdf python-dotenv

    # 3. Ollama ì„¤ì¹˜ ë° ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
    brew install ollama
    ollama pull qwen2.5-coder:7b-instruct

    # 4. í‰ê°€ ì‹¤í–‰
    python eval_labeled_criteria.py

```

---

## 8. ğŸ“š ì°¸ê³  ë¬¸ì„œ

### 1) ê³µì‹ ê°€ì´ë“œ

- [LangChain Docs](https://python.langchain.com/docs/)
- [LangSmith Evaluators](https://docs.smith.langchain.com/evaluation)
- [Ollama Models](https://ollama.com/library)
- [Qwen2.5-Coder](https://huggingface.co/Qwen/Qwen2.5-Coder-7B-Instruct)

---

### 2) ğŸ“ Note
- ë§ì€ íŠœí† ë¦¬ì–¼ì´ `Pydantic v1`ì„ ì‚¬ìš©í•˜ë¯€ë¡œ `ì£¼ì˜`
- `LangChain Migration Guide` ì°¸ê³  `í•„ìˆ˜`
- LangChain Discord ì»¤ë®¤ë‹ˆí‹°ëŠ” ë§¤ìš° ë¹ ë¥¸ ëŒ€ì‘
- ì´ˆê¸°ì—” ì†Œê·œëª¨ ë°ì´í„°ë¡œ í…ŒìŠ¤íŠ¸ í›„ í™•ì¥

---

### 3) ğŸ‰ ì„±ê³¼ ì§€í‘œ
- âœ… 5ë¬¸í•­ ê¸°ì¤€ 100% ì •í™•ë„
- âœ… API ë¹„ìš© $0
- âœ… ì™„ì „ ì¬í˜„ ê°€ëŠ¥
- âœ… Pydantic v1, v2 ì¶©ëŒ í•´ê²°
- âœ… M1 MacBook Air (16GB RAM) ì™„ë²½ ë™ì‘

---

<small>

> *ìµœì¢… ì—…ë°ì´íŠ¸: 2025.10.18.*
> 
> *ì‘ì„±ì: Jay*
> 
> *ìƒíƒœ: âœ… Production-Ready*

---