# ğŸ”§ FAISS ì‹¤ìŠµ - ì»¤ë„ ì¶©ëŒ & ë©”ëª¨ë¦¬ ë¶€ì¡± ë¬¸ì œ íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

> **ì‘ì„±ì¼:** 2025-09-26  
> **ì‘ì„±ì:** Jay  
> **ì†Œìš” ì‹œê°„:** 4ì‹œê°„ 30ë¶„  
> **ìµœì¢… ê²°ê³¼:** [**`HuggingFace Embeddings ì´ˆê²½ëŸ‰ ëª¨ë¸ í•´ê²°`**](../../09_VectorStore/02_FAISS.ipynb)

***

## 1. ë¬¸ì œ ìƒí™©

- **ëª©í‘œ:**  
  - `FAISS ë²¡í„° ì €ì¥ì†Œ` í•™ìŠµ ì¤‘ **ë²¡í„° ê²€ìƒ‰ ì‹œìŠ¤í…œ** êµ¬ì¶• í•„ìš”
  - Google Gemini ì„ë² ë”© ëª¨ë¸(3072ì°¨ì›)ì„ ì‚¬ìš©í•œ **FAISS ì¸ë±ìŠ¤** ìƒì„±
  - **`LangChain + FAISS + Google Embeddings`** í™˜ê²½ì—ì„œ ìœ ì‚¬ë„ ê²€ìƒ‰ êµ¬í˜„

- **í™˜ê²½:**
  ```markdown
    - `Python`: 3.13.5 (pyenv ê°€ìƒí™˜ê²½)
    - `LangChain`: ìµœì‹  ë²„ì „
    - `ì„ë² ë”© ëª¨ë¸`: `models/gemini-embedding-001` (3072ì°¨ì›)
    - `ë²¡í„° ì €ì¥ì†Œ`: FAISS (Facebook AI Similarity Search)
    - `ê°œë°œí™˜ê²½`: Google Colab / Jupyter Notebook
  ```

<br>

## 2. ì‹œë„í•œ ì‹¤íŒ¨ ë°©ë²•ë“¤

### 2.1 Google Gemini ì„ë² ë”© ë°©ì‹ ì‹œë„ âŒ

```python
from langchain_google_genai import GoogleGenerativeAIEmbeddings
from langchain_community.vectorstores import FAISS

# Google Gemini ì„ë² ë”© (3072ì°¨ì›)
embeddings = GoogleGenerativeAIEmbeddings(
    model="models/gemini-embedding-001",
    task_type="retrieval_document",
    google_api_key=os.getenv("GOOGLE_API_KEY")
)

# FAISS ë²¡í„°ìŠ¤í† ì–´ ìƒì„± ì‹œë„
vectorstore = FAISS.from_texts(
    texts=documents,
    embedding=embeddings
)
```

**ì‹¤íŒ¨ ì›ì¸:**
- ğŸš« **ë†’ì€ ì°¨ì›ìˆ˜**: 3072ì°¨ì›ìœ¼ë¡œ ì¸í•œ **ê³¼ë„í•œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰**
- ğŸ”¥ **ë©”ëª¨ë¦¬ ì˜¤ë²„í”Œë¡œìš°**: ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  **78-80%** ìƒíƒœì—ì„œ ì²˜ë¦¬ ë¶ˆê°€
- ğŸ’¥ **ì»¤ë„ ì¶©ëŒ**: `index.add(np.array(doc_embeddings))` ë¶€ë¶„ì—ì„œ ë°˜ë³µì  í¬ë˜ì‹œ

### 2.2 OpenAI ì„ë² ë”© ì‹œë„ âŒ

```python
from langchain_openai import OpenAIEmbeddings

# OpenAI ì„ë² ë”© (1536ì°¨ì›)
embeddings_openai = OpenAIEmbeddings(
    model="text-embedding-3-small",
    openai_api_key=os.getenv("OPENAI_API_KEY")
)
```

**ì‹¤íŒ¨ ì›ì¸:**
- ğŸ’¸ **API ìš”ê¸ˆ ë¶€ì¡±**: OpenAI í¬ë ˆë”§ ì†Œì§„ìœ¼ë¡œ ì‚¬ìš© ë¶ˆê°€ëŠ¥
- ğŸŒ **ë„¤íŠ¸ì›Œí¬ ì˜ì¡´ì„±**: ì¸í„°ë„· ì—°ê²° í•„ìˆ˜
- ğŸ“Š **ì—¬ì „í•œ ê³ ì°¨ì›**: 1536ì°¨ì›ìœ¼ë¡œ ì—¬ì „íˆ ë©”ëª¨ë¦¬ ë¶€ë‹´

### 2.3 ê¸°ë³¸ HuggingFace ì„ë² ë”© ì‹œë„ âŒ

```python
from langchain_community.embeddings import HuggingFaceEmbeddings

# ê¸°ë³¸ HuggingFace ëª¨ë¸ (768ì°¨ì›)
embeddings = HuggingFaceEmbeddings()
```

**ì‹¤íŒ¨ ì›ì¸:**
- âš ï¸ **Deprecation ê²½ê³ **: `LangChain 0.2.2`ì—ì„œ deprecated ìƒíƒœ
- ğŸ“¦ **íŒ¨í‚¤ì§€ ì¶©ëŒ**: êµ¬ë²„ì „ íŒ¨í‚¤ì§€ ì‚¬ìš©ìœ¼ë¡œ ì¸í•œ í˜¸í™˜ì„± ë¬¸ì œ
- ğŸ **Import ì—ëŸ¬**: ì˜¬ë°”ë¥´ì§€ ì•Šì€ import ê²½ë¡œ

<br>

## 3. í•µì‹¬ ë¬¸ì œ ì§„ë‹¨

### 3.1 ë©”ëª¨ë¦¬ ë¶€ì¡± & ì°¨ì›ì˜ ì €ì£¼ ğŸ›

- **í˜„ìƒ:** ê³ ì°¨ì› ì„ë² ë”©ìœ¼ë¡œ ì¸í•œ **ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬ ì˜¤ë²„í”Œë¡œìš°**
- **Google Gemini**: 3072ì°¨ì› â†’ ê³¼ë„í•œ ë©”ëª¨ë¦¬ ì†Œë¹„
- **OpenAI**: 1536ì°¨ì› â†’ ì—¬ì „íˆ ë†’ì€ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
- **ì¶”ì • ì›ì¸:** Colab/Jupyter í™˜ê²½ì˜ ì œí•œëœ RAMì—ì„œ ëŒ€ìš©ëŸ‰ ë²¡í„° ì²˜ë¦¬ ë¶ˆê°€

### 3.2 FAISS ì»¤ë„ ì¶©ëŒ íŒ¨í„´ ğŸš¨

```bash
Document 'hello world' embedded in 0.36 seconds
Document 'goodbye world' embedded in 0.37 seconds
# â†‘ ì—¬ê¸°ê¹Œì§€ëŠ” ì„±ê³µ
# â†“ index.add() í˜¸ì¶œ ì‹œì ì—ì„œ ì»¤ë„ í¬ë˜ì‹œ ë°œìƒ
í˜„ì¬ ì…€ ë˜ëŠ” ì´ì „ ì…€ì—ì„œ ì½”ë“œë¥¼ ì‹¤í–‰í•˜ëŠ” ë™ì•ˆ Kernelì´ ì¶©ëŒí–ˆìŠµë‹ˆë‹¤.
```

- **ì¶©ëŒ ì§€ì **: `index.add(np.array(doc_embeddings))` ì‹¤í–‰ ì‹œ
- **ë©”ëª¨ë¦¬ íŒ¨í„´**: ì„ë² ë”© ìƒì„±ì€ ì„±ê³µí•˜ì§€ë§Œ FAISS ì¸ë±ìŠ¤ ì¶”ê°€ ì‹œ ì‹¤íŒ¨
- **ì¬í˜„ì„±**: ë™ì¼í•œ ì§€ì ì—ì„œ ë°˜ë³µì ìœ¼ë¡œ ë°œìƒ

<br>

## 4. í•´ê²° ë°©í–¥ ì „í™˜

### 4.1 **`ì´ˆê²½ëŸ‰ HuggingFace Embeddings` ë°œê²¬ ğŸ’¡**

**í•µì‹¬ ì•„ì´ë””ì–´:** ê³ ì°¨ì› API ê¸°ë°˜ ëª¨ë¸ ëŒ€ì‹  **ì €ì°¨ì› ë¡œì»¬ ëª¨ë¸** ì‚¬ìš©

- **Google Gemini**: 3072ì°¨ì› â†’ **8ë°° ë©”ëª¨ë¦¬ ì‚¬ìš©**
- **OpenAI**: 1536ì°¨ì› â†’ **4ë°° ë©”ëª¨ë¦¬ ì‚¬ìš©**  
- **MiniLM-L6-v2**: 384ì°¨ì› â†’ **ê¸°ì¤€ ë©”ëª¨ë¦¬ ì‚¬ìš©** âœ…

### 4.2 **ìµœì‹  LangChain íŒ¨í‚¤ì§€ ì ìš©** ğŸ”„

```bash
# ğŸ¯ íŒ¨í‚¤ì§€ ì—…ë°ì´íŠ¸ & ì„¤ì¹˜
pip install -U langchain-huggingface sentence-transformers faiss-cpu
pip install -U langchain langchain-community
```

**í•µì‹¬ ë³€ê²½ì‚¬í•­:**
- `langchain_community.embeddings.HuggingFaceEmbeddings` âŒ
- `langchain_huggingface.HuggingFaceEmbeddings` âœ…

<br>

## 5. ìµœì¢… ì„±ê³µ êµ¬í˜„

### 5.1 ì™„ì„±ëœ ì´ˆê²½ëŸ‰ FAISS ì‹œìŠ¤í…œ

```python
import gc
import numpy as np
import time
from langchain_huggingface import HuggingFaceEmbeddings  # âœ… ìµœì‹  import
from langchain_community.vectorstores import FAISS
import warnings

# ê²½ê³  ë¬´ì‹œ
warnings.filterwarnings("ignore")

def ultra_light_faiss_updated():
    """ìµœì‹  LangChainìœ¼ë¡œ ìˆ˜ì •ëœ ì´ˆê²½ëŸ‰ FAISS"""
    
    print("ğŸš€ LangChainìœ¼ë¡œ ì´ˆê²½ëŸ‰ ì„ë² ë”© ì‹œì‘...")
    
    try:
        # 1ï¸âƒ£ ìµœì‹  HuggingFace Embeddings (384ì°¨ì›!)
        embeddings = HuggingFaceEmbeddings(
            model_name="sentence-transformers/all-MiniLM-L6-v2",
            model_kwargs={'device': 'cpu'},
            encode_kwargs={'normalize_embeddings': True}
        )
        
        print("âœ… ìµœì‹  ì„ë² ë”© ëª¨ë¸ ë¡œë”© ì™„ë£Œ!")
        print("ğŸ“ ì„ë² ë”© ì°¨ì›: 384 (Google Gemini ëŒ€ë¹„ 1/8 ì ˆì•½!)")
        
        # 2ï¸âƒ£ í…ŒìŠ¤íŠ¸ ë¬¸ì„œ
        documents = [
            "ìì—°ì–´ ì²˜ë¦¬ëŠ” ì»´í“¨í„°ê°€ ì¸ê°„ì˜ ì–¸ì–´ë¥¼ ì´í•´í•˜ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤.",
            "ë¨¸ì‹ ëŸ¬ë‹ì€ ë°ì´í„°ë¡œë¶€í„° íŒ¨í„´ì„ í•™ìŠµí•˜ëŠ” ë°©ë²•ì…ë‹ˆë‹¤.",
            "ë”¥ëŸ¬ë‹ì€ ì‹ ê²½ë§ì„ ì´ìš©í•œ ë¨¸ì‹ ëŸ¬ë‹ ê¸°ë²•ì…ë‹ˆë‹¤.",
            "FAISSëŠ” íš¨ìœ¨ì ì¸ ìœ ì‚¬ë„ ê²€ìƒ‰ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤.",
            "ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ëŠ” ì„ë² ë”©ì„ ì €ì¥í•˜ê³  ê²€ìƒ‰í•˜ëŠ” ì‹œìŠ¤í…œì…ë‹ˆë‹¤."
        ]
        
        # 3ï¸âƒ£ FAISS ë²¡í„°ìŠ¤í† ì–´ ìƒì„± (ì„±ê³µ!)
        print("ğŸ”„ FAISS ë²¡í„°ìŠ¤í† ì–´ ìƒì„± ì¤‘...")
        start_time = time.time()
        
        vectorstore = FAISS.from_texts(
            texts=documents,
            embedding=embeddings,
            metadatas=[{"id": i, "source": f"doc_{i}"} for i in range(len(documents))]
        )
        
        end_time = time.time()
        print(f"âœ… FAISS ìƒì„± ì™„ë£Œ! (ì†Œìš”ì‹œê°„: {end_time-start_time:.2f}ì´ˆ)")
        
        return vectorstore, embeddings
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        gc.collect()
        return None, None
```

### 5.2 ìœ ì‚¬ë„ ê²€ìƒ‰ & ê³ ê¸‰ ê¸°ëŠ¥ êµ¬í˜„

```python
def faiss_advanced_operations(vectorstore):
    """FAISS ê³ ê¸‰ ê¸°ëŠ¥ ì‹œì—°"""
    
    # 4ï¸âƒ£ ìœ ì‚¬ë„ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
    print("\nğŸ” ìœ ì‚¬ë„ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸...")
    query = "ë”¥ëŸ¬ë‹ê³¼ ë¨¸ì‹ ëŸ¬ë‹ì˜ ì°¨ì´ì "
    
    # ê¸°ë³¸ ìœ ì‚¬ë„ ê²€ìƒ‰
    results = vectorstore.similarity_search_with_score(query, k=3)
    
    print("ğŸ‰ ê²€ìƒ‰ ê²°ê³¼:")
    for i, (doc, score) in enumerate(results):
        similarity = 1 - score
        print(f"  {i+1}. ìœ ì‚¬ë„: {similarity:.4f}")
        print(f"      ë‚´ìš©: {doc.page_content}")
        print(f"      ë©”íƒ€ë°ì´í„°: {doc.metadata}\n")
    
    # 5ï¸âƒ£ ë¬¸ì„œ ì¶”ê°€ (add_documents)
    from langchain_core.documents import Document
    
    new_docs = [
        Document(
            page_content="TransformerëŠ” ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜ì„ ì‚¬ìš©í•˜ëŠ” ë”¥ëŸ¬ë‹ ëª¨ë¸ì…ë‹ˆë‹¤.",
            metadata={"source": "new_doc_1"}
        )
    ]
    
    vectorstore.add_documents(new_docs, ids=["transformer_doc"])
    print("âœ… ìƒˆ ë¬¸ì„œ ì¶”ê°€ ì™„ë£Œ!")
    
    # 6ï¸âƒ£ ë¬¸ì„œ ì‚­ì œ í…ŒìŠ¤íŠ¸
    test_ids = vectorstore.add_texts(
        ["ì‚­ì œ í…ŒìŠ¤íŠ¸ìš© ë¬¸ì„œ"],
        metadatas=[{"source": "test"}],
        ids=["delete_test"]
    )
    
    vectorstore.delete(test_ids)  # ì‚­ì œ
    print("âœ… ë¬¸ì„œ ì‚­ì œ ì™„ë£Œ!")
    
    return vectorstore
```

### 5.3 ì €ì¥ ë° ë¡œë“œ ì‹œìŠ¤í…œ

```python
def faiss_save_load_system(vectorstore, embeddings):
    """FAISS ì €ì¥ ë° ë¡œë“œ ì‹œìŠ¤í…œ"""
    
    # 7ï¸âƒ£ ë¡œì»¬ ì €ì¥
    vectorstore.save_local(
        folder_path="../09_VectorStore/faiss_light_index",
        index_name="faiss_index"
    )
    print("ğŸ’¾ FAISS ì¸ë±ìŠ¤ ì €ì¥ ì™„ë£Œ!")
    
    # 8ï¸âƒ£ ë¡œì»¬ì—ì„œ ë¡œë“œ
    loaded_vectorstore = FAISS.load_local(
        folder_path="../09_VectorStore/faiss_light_index",
        index_name="faiss_index",
        embeddings=embeddings,
        allow_dangerous_deserialization=True
    )
    
    # ë¡œë“œ ê²€ì¦
    test_query = "ìì—°ì–´ ì²˜ë¦¬"
    results = loaded_vectorstore.similarity_search(test_query, k=1)
    print(f"âœ… ë¡œë“œ ê²€ì¦ ì™„ë£Œ: {results[0].page_content[:50]}...")
    
    return loaded_vectorstore
```

<br>

## 6. ìµœì¢… ì„±ê³µ ê²°ê³¼ ğŸ‰

### 6.1 ì²˜ë¦¬ ê²°ê³¼ í†µê³„

```bash
ğŸš€ LangChainìœ¼ë¡œ ì´ˆê²½ëŸ‰ ì„ë² ë”© ì‹œì‘...
âœ… ìµœì‹  ì„ë² ë”© ëª¨ë¸ ë¡œë”© ì™„ë£Œ!
ğŸ“ ì„ë² ë”© ì°¨ì›: 384 (Google Gemini ëŒ€ë¹„ 1/8 ì ˆì•½!)
ğŸ”„ FAISS ë²¡í„°ìŠ¤í† ì–´ ìƒì„± ì¤‘...
âœ… FAISS ìƒì„± ì™„ë£Œ! (ì†Œìš”ì‹œê°„: 1.48ì´ˆ)

ğŸ‰ ê²€ìƒ‰ ê²°ê³¼:
  1. ìœ ì‚¬ë„: 0.5892
      ë‚´ìš©: ë”¥ëŸ¬ë‹ì€ ì‹ ê²½ë§ì„ ì´ìš©í•œ ë¨¸ì‹ ëŸ¬ë‹ ê¸°ë²•ì…ë‹ˆë‹¤.
      ë©”íƒ€ë°ì´í„°: {'id': 2, 'source': 'doc_2'}
  
  2. ìœ ì‚¬ë„: 0.4567
      ë‚´ìš©: ë¨¸ì‹ ëŸ¬ë‹ì€ ë°ì´í„°ë¡œë¶€í„° íŒ¨í„´ì„ í•™ìŠµí•˜ëŠ” ë°©ë²•ì…ë‹ˆë‹¤.
      ë©”íƒ€ë°ì´í„°: {'id': 1, 'source': 'doc_1'}

ğŸ’¾ ì¸ë±ìŠ¤ ì €ì¥ ì™„ë£Œ!
ğŸ‰ğŸ‰ğŸ‰ ìµœì‹  LangChainìœ¼ë¡œ FAISS ì™„ë£Œ! ğŸ‰ğŸ‰ğŸ‰
```

### 6.2 ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë¹„êµ

| ì„ë² ë”© ëª¨ë¸ | ì°¨ì› | ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ | ì»¤ë„ ì¶©ëŒ |
|-------------|------|-------------|----------|
| **Google Gemini** | 3072 | ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ | âŒ ì¶©ëŒ |
| **OpenAI Ada-002** | 1536 | ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ | âŒ ì¶©ëŒ |
| **HuggingFace ê¸°ë³¸** | 768 | ğŸ”¥ğŸ”¥ | âš ï¸ ê²½ê³  |
| **MiniLM-L6-v2** | 384 | ğŸ”¥ | âœ… ì„±ê³µ |

### 6.3 êµ¬í˜„ ì™„ë£Œ ê¸°ëŠ¥ë“¤

âœ… **FAISS ë²¡í„°ìŠ¤í† ì–´ ìƒì„±**: `from_documents`, `from_texts`  
âœ… **ìœ ì‚¬ë„ ê²€ìƒ‰**: `similarity_search`, `similarity_search_with_score`  
âœ… **ë¬¸ì„œ ê´€ë¦¬**: `add_documents`, `add_texts`, `delete`  
âœ… **ë©”íƒ€ë°ì´í„° í•„í„°ë§**: ì†ŒìŠ¤ë³„ ê²€ìƒ‰ ê¸°ëŠ¥  
âœ… **ì €ì¥/ë¡œë“œ**: `save_local`, `load_local`  
âœ… **ë©”ëª¨ë¦¬ ìµœì í™”**: ê°€ë¹„ì§€ ì»¬ë ‰ì…˜, ë°°ì¹˜ ì²˜ë¦¬  

<br>

## 7. êµí›ˆ ë° ì„±ê³¼ ğŸ“

### 7.1 ê¸°ìˆ ì  êµí›ˆ

- **ì°¨ì›ì˜ ì €ì£¼**: ê³ ì°¨ì› ë²¡í„°ëŠ” ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ ê¸°í•˜ê¸‰ìˆ˜ì ìœ¼ë¡œ ì¦ê°€ì‹œí‚´
- **ë¡œì»¬ vs API**: ë„¤íŠ¸ì›Œí¬ ê¸°ë°˜ APIë³´ë‹¤ ë¡œì»¬ ëª¨ë¸ì´ ë” ì•ˆì •ì ì´ê³  ë¹„ìš© íš¨ìœ¨ì 
- **íŒ¨í‚¤ì§€ ë²„ì „ ê´€ë¦¬**: LangChain ìƒíƒœê³„ì˜ ë¹ ë¥¸ ë³€í™”ì— ëŒ€ì‘í•˜ëŠ” ìµœì‹  íŒ¨í‚¤ì§€ ì‚¬ìš© ì¤‘ìš”
- **ë©”ëª¨ë¦¬ ê´€ë¦¬**: ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬ ì‹œ ëª…ì‹œì  ë©”ëª¨ë¦¬ ì •ë¦¬ í•„ìˆ˜

### 7.2 ë¬¸ì œí•´ê²° ì—­ëŸ‰ í–¥ìƒ

- **ì²´ê³„ì  ë¶„ì„**: ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰, ì°¨ì› ìˆ˜, íŒ¨í‚¤ì§€ ë²„ì „ì„ ì¢…í•©ì ìœ¼ë¡œ ê³ ë ¤
- **ëŒ€ì•ˆ ëª¨ìƒ‰**: API ë¶€ì¡± â†’ ë¡œì»¬ ëª¨ë¸, ê³ ì°¨ì› â†’ ì €ì°¨ì›ìœ¼ë¡œ ì „í™˜
- **ì„±ëŠ¥ ìµœì í™”**: 384ì°¨ì›ìœ¼ë¡œ 8ë°° ë©”ëª¨ë¦¬ ì ˆì•½í•˜ë©´ì„œ ì„±ëŠ¥ ìœ ì§€
- **ì•ˆì •ì„± í™•ë³´**: ì»¤ë„ ì¶©ëŒ ì—†ëŠ” ì•ˆì •ì ì¸ ì‹œìŠ¤í…œ êµ¬ì¶•

### 7.3 í•™ìŠµ ì„±ê³¼

- **FAISS ì™„ì „ ì •ë³µ**: ë²¡í„° ì €ì¥ì†Œ ìƒì„±ë¶€í„° ê³ ê¸‰ ê¸°ëŠ¥ê¹Œì§€ ì „ ê³¼ì • ë§ˆìŠ¤í„°
- **ì„ë² ë”© ëª¨ë¸ ì„ íƒ**: ìš©ë„ë³„ ìµœì  ëª¨ë¸ ì„ íƒ ê¸°ì¤€ í™•ë¦½
- **LangChain ìƒíƒœê³„**: ìµœì‹  íŒ¨í‚¤ì§€ êµ¬ì¡°ì™€ import ë°©ì‹ ì™„ì „ ì´í•´
- **ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±**: ì œí•œëœ í™˜ê²½ì—ì„œì˜ ìµœì í™” ê¸°ë²• ìŠµë“

<br>

## 8. í–¥í›„ ê°œì„  ë°©ì•ˆ ğŸš€

### 8.1 ì„±ëŠ¥ ìµœì í™”
- **ë” ì‘ì€ ëª¨ë¸**: `paraphrase-MiniLM-L3-v2` (17MB) í…ŒìŠ¤íŠ¸
- **ì–‘ìí™”**: ëª¨ë¸ ì••ì¶•ì„ í†µí•œ ì¶”ê°€ ë©”ëª¨ë¦¬ ì ˆì•½
- **ë³‘ë ¬ ì²˜ë¦¬**: ëŒ€ìš©ëŸ‰ ë¬¸ì„œ ì²˜ë¦¬ ì‹œ ë©€í‹°í”„ë¡œì„¸ì‹± ì ìš©

### 8.2 ê¸°ëŠ¥ í™•ì¥
- **í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰**: í‚¤ì›Œë“œ + ë²¡í„° ê²€ìƒ‰ ê²°í•©
- **ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸**: ë™ì  ë¬¸ì„œ ì¶”ê°€/ì‚­ì œ ì‹œìŠ¤í…œ
- **ë¶„ì‚° ì²˜ë¦¬**: ì—¬ëŸ¬ FAISS ì¸ë±ìŠ¤ ë³‘í•© ë° ê´€ë¦¬

### 8.3 ì•ˆì •ì„± í–¥ìƒ
- **ìë™ ë°±ì—…**: ì£¼ê¸°ì  ì¸ë±ìŠ¤ ì €ì¥ ì‹œìŠ¤í…œ
- **ì˜¤ë¥˜ ë³µêµ¬**: ë¶€ë¶„ ì‹¤íŒ¨ ì‹œ ë³µêµ¬ ë©”ì»¤ë‹ˆì¦˜
- **ëª¨ë‹ˆí„°ë§**: ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì‹¤ì‹œê°„ ì¶”ì 

<br>

## 9. í•µì‹¬ ì½”ë“œ ì •ë¦¬

### 9.1 ìµœì¢… í•´ê²° ì½”ë“œ
```python
# ğŸ¯ í•µì‹¬ í•´ê²° ë°©ë²•: ì´ˆê²½ëŸ‰ HuggingFace + ìµœì‹  íŒ¨í‚¤ì§€
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS

embeddings = HuggingFaceEmbeddings(
    model_name="sentence-transformers/all-MiniLM-L6-v2",  # 384ì°¨ì›
    model_kwargs={'device': 'cpu'},
    encode_kwargs={'normalize_embeddings': True}
)

vectorstore = FAISS.from_texts(
    texts=documents,
    embedding=embeddings
)
```

### 9.2 ì‚¬ìš©ë²•
```python
# ìœ ì‚¬ë„ ê²€ìƒ‰
results = vectorstore.similarity_search("ê²€ìƒ‰ì–´", k=3)

# ë¬¸ì„œ ì¶”ê°€
vectorstore.add_texts(["ìƒˆ ë¬¸ì„œ"], ids=["new_id"])

# ì €ì¥/ë¡œë“œ
vectorstore.save_local("./faiss_index")
loaded_db = FAISS.load_local("./faiss_index", embeddings=embeddings, 
                            allow_dangerous_deserialization=True)
```

<br>

***

**ğŸ† ê²°ë¡ : Google API ìš”ê¸ˆ ë¶€ì¡±ê³¼ ë©”ëª¨ë¦¬ ì¶©ëŒì„ ì´ˆê²½ëŸ‰ ë¡œì»¬ ëª¨ë¸ë¡œ í•´ê²°í•˜ì—¬ FAISS ë²¡í„° ê²€ìƒ‰ ì‹œìŠ¤í…œ ì™„ì „ ì •ë³µ!**

**í•µì‹¬ ì„±ê³µ ìš”ì¸: ì°¨ì› ì¶•ì†Œ(3072â†’384) + ë¡œì»¬í™” + ìµœì‹  íŒ¨í‚¤ì§€ + ì²´ê³„ì  ë©”ëª¨ë¦¬ ê´€ë¦¬**