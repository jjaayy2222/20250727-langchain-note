# ğŸ“˜ 03. ê¸°ë³¸ í”„ë¡¬í”„íŒ… ê¸°ë²• (Basic Prompting Techniques)

## í•µì‹¬ ìš”ì•½
- **Zero-shot í”„ë¡¬í”„íŒ…**ì€ ì˜ˆì‹œ ì—†ì´ ì‘ì—… ì„¤ëª…ë§Œìœ¼ë¡œ ê²°ê³¼ë¥¼ ì–»ëŠ” ê°€ì¥ ê°„ë‹¨í•œ í˜•íƒœì˜ í”„ë¡¬í”„íŠ¸
- **One-shotê³¼ Few-shot í”„ë¡¬í”„íŒ…**ì€ 1ê°œ ë˜ëŠ” ì—¬ëŸ¬ ê°œì˜ ì˜ˆì‹œë¥¼ ì œê³µí•˜ì—¬ ëª¨ë¸ì´ ì›í•˜ëŠ” íŒ¨í„´ì„ í•™ìŠµí•˜ë„ë¡ ìœ ë„
- **ì˜ˆì‹œì˜ í’ˆì§ˆ**ì´ ê²°ê³¼ë¥¼ ì¢Œìš°í•˜ë©°, ë‹¤ì–‘í•˜ê³  ê³ í’ˆì§ˆì˜ ì˜ˆì‹œë¥¼ ì œê³µí•˜ëŠ” ê²ƒì´ ì¤‘ìš”
- **ë³µì¡í•œ ì‘ì—…ì¼ìˆ˜ë¡** ë” ë§ì€ ì˜ˆì‹œ(3-5ê°œ)ê°€ í•„ìš”í•˜ë©°, ëª¨ë¸ì˜ ì…ë ¥ ê¸¸ì´ ì œí•œì„ ê³ ë ¤í•´ì•¼ í•¨

---

## ì£¼ìš” ê°œë…ê³¼ ì„¤ëª…

### ğŸ¯ **Zero-shot í”„ë¡¬í”„íŒ…**
- **ì •ì˜**: ì˜ˆì‹œ ì—†ì´ ì‘ì—… ì„¤ëª…ë§Œìœ¼ë¡œ LLMì—ê²Œ íƒœìŠ¤í¬ë¥¼ ìš”ì²­í•˜ëŠ” ë°©ì‹
- **ì¥ì **: ê°„ë‹¨í•˜ê³  ë¹ ë¥´ë©°, ì¶”ê°€ ì˜ˆì‹œ ì¤€ë¹„ ë¶ˆí•„ìš”
- **ë‹¨ì **: ë³µì¡í•œ ì‘ì—…ì´ë‚˜ íŠ¹ì • ì¶œë ¥ í˜•ì‹ì´ í•„ìš”í•  ë•Œ ì œí•œì 
- **ì ìš© ë¶„ì•¼**: ì§ˆë¬¸ ë‹µë³€, ê°„ë‹¨í•œ ë¶„ë¥˜, ë²ˆì—­ ë“±

### ğŸ”— **One-shot í”„ë¡¬í”„íŒ…**
- **ì •ì˜**: í•˜ë‚˜ì˜ ì˜ˆì‹œë¥¼ ì œê³µí•˜ì—¬ ëª¨ë¸ì´ ëª¨ë°©í•  ìˆ˜ ìˆë„ë¡ í•˜ëŠ” ë°©ì‹
- **íš¨ê³¼**: ì¶œë ¥ êµ¬ì¡°ë‚˜ íŒ¨í„´ì„ ëª…í™•íˆ ì œì‹œí•  ë•Œ ìœ ìš©
- **ì‚¬ìš© ì‹œê¸°**: íŠ¹ì • í˜•ì‹ì´ë‚˜ ìŠ¤íƒ€ì¼ì„ ì›í•  ë•Œ

### ğŸ“š **Few-shot í”„ë¡¬í”„íŒ…**
- **ì •ì˜**: ì—¬ëŸ¬ ê°œì˜ ì˜ˆì‹œ(ë³´í†µ 3-5ê°œ)ë¥¼ ì œê³µí•˜ì—¬ íŒ¨í„´ì„ í•™ìŠµì‹œí‚¤ëŠ” ë°©ì‹
- **ê¶Œì¥ ê°œìˆ˜**: ìµœì†Œ 3-5ê°œ, ë³µì¡í•œ ì‘ì—…ì€ ë” ë§ì´ í•„ìš”í•  ìˆ˜ ìˆìŒ
- **íŒ¨í„´ ì¸ì‹**: ì—¬ëŸ¬ ì˜ˆì‹œë¥¼ í†µí•´ ëª¨ë¸ì´ ì¼ê´€ëœ íŒ¨í„´ì„ íŒŒì•…

---

## í”„ë¡¬í”„íŠ¸ ì˜ˆì‹œ

### Zero-shot ì˜í™” ë¦¬ë·° ë¶„ë¥˜
```plaintext
# ê¸°ë³¸ Zero-shot ì˜ˆì‹œ
ì‘ì—…: ì˜í™” ë¦¬ë·°ë¥¼ POSITIVE, NEUTRAL, NEGATIVEë¡œ ë¶„ë¥˜

ë¦¬ë·°: "Her"ëŠ” AIê°€ ê³„ì† ì§„í™”í•˜ë„ë¡ í—ˆìš©í•  ê²½ìš° ì¸ë¥˜ê°€ í–¥í•˜ê³  ìˆëŠ” ë°©í–¥ì„ 
ë³´ì—¬ì£¼ëŠ” ì¶©ê²©ì ì¸ ì—°êµ¬ì…ë‹ˆë‹¤. ì´ëŸ° ê±¸ì‘ ê°™ì€ ì˜í™”ê°€ ë” ë§ì•˜ìœ¼ë©´ ì¢‹ê² ìŠµë‹ˆë‹¤.

ê°ì •:
```
**ì¶œë ¥**: `POSITIVE`

### Few-shot í”¼ì ì£¼ë¬¸ íŒŒì‹±
```plaintext
# Few-shot JSON íŒŒì‹± ì˜ˆì‹œ
ê³ ê°ì˜ í”¼ì ì£¼ë¬¸ì„ ìœ íš¨í•œ JSONìœ¼ë¡œ íŒŒì‹±í•˜ì„¸ìš”:

ì˜ˆì‹œ 1:
ì…ë ¥: ì¹˜ì¦ˆ, í† ë§ˆí†  ì†ŒìŠ¤, í˜í¼ë¡œë‹ˆê°€ ë“¤ì–´ê°„ ìŠ¤ëª° í”¼ìë¥¼ ì›í•©ë‹ˆë‹¤.
JSON ì‘ë‹µ:
```
{
  "size": "small",
  "type": "normal", 
  "ingredients": ["cheese", "tomato sauce", "pepperoni"]
}
```

ì˜ˆì‹œ 2:
ì…ë ¥: í† ë§ˆí†  ì†ŒìŠ¤, ë°”ì§ˆ, ëª¨ì§œë ë¼ê°€ ë“¤ì–´ê°„ ë¼ì§€ í”¼ì ì£¼ì„¸ìš”.
JSON ì‘ë‹µ:
```
{
  "size": "large",
  "type": "normal",
  "ingredients": ["tomato sauce", "basil", "mozzarella"]
}
```

ì´ì œ íŒŒì‹±í•´ì£¼ì„¸ìš”:
ì…ë ¥: ë¼ì§€ í”¼ìë¡œ, ë°˜ì€ ì¹˜ì¦ˆì™€ ëª¨ì§œë ë¼, ë‚˜ë¨¸ì§€ ë°˜ì€ í† ë§ˆí†  ì†ŒìŠ¤, í–„, íŒŒì¸ì• í”Œ ë„£ì–´ì£¼ì„¸ìš”.
JSON ì‘ë‹µ:
```

**ì¶œë ¥**:
```json
{
  "size": "large",
  "type": "half-half",
  "ingredients": [["cheese", "mozzarella"], ["tomato sauce", "ham", "pineapple"]]
}
```

---

## í™œìš© íŒ

### ğŸš€ **LangChainì—ì„œì˜ Zero-shot êµ¬í˜„**
```python
from langchain.prompts import PromptTemplate
from langchain.llms import VertexAI
from langchain.chains import LLMChain

# Zero-shot ë¶„ë¥˜ í…œí”Œë¦¿
zero_shot_template = """
ì‘ì—…: {task}

ì…ë ¥: {input}
ì¶œë ¥:"""

prompt = PromptTemplate(
    input_variables=["task", "input"],
    template=zero_shot_template
)

llm = VertexAI(model_name="gemini-pro", temperature=0.1)
chain = LLMChain(llm=llm, prompt=prompt)

# ì‹¤í–‰
result = chain.run(
    task="í…ìŠ¤íŠ¸ë¥¼ ê¸ì •/ë¶€ì •/ì¤‘ë¦½ìœ¼ë¡œ ë¶„ë¥˜",
    input="ì´ ì˜í™”ëŠ” ì •ë§ í›Œë¥­í–ˆìŠµë‹ˆë‹¤!"
)
```

### ğŸ“š **Few-shot ì²´ì¸ êµ¬ì„±**
```python
from langchain.prompts import FewShotPromptTemplate, PromptTemplate

# ì˜ˆì‹œ ì •ì˜
examples = [
    {
        "input": "ì‘ì€ í”¼ìì— ì¹˜ì¦ˆì™€ í˜í¼ë¡œë‹ˆ ë„£ì–´ì£¼ì„¸ìš”",
        "output": '{"size": "small", "toppings": ["cheese", "pepperoni"]}'
    },
    {
        "input": "í° í”¼ìì— í† ë§ˆí† ì†ŒìŠ¤ì™€ ë°”ì§ˆ ë„£ì–´ì£¼ì„¸ìš”", 
        "output": '{"size": "large", "toppings": ["tomato sauce", "basil"]}'
    }
]

# ì˜ˆì‹œ í…œí”Œë¦¿
example_template = """
ì…ë ¥: {input}
ì¶œë ¥: {output}"""

example_prompt = PromptTemplate(
    input_variables=["input", "output"],
    template=example_template
)

# Few-shot í”„ë¡¬í”„íŠ¸ êµ¬ì„±
few_shot_prompt = FewShotPromptTemplate(
    examples=examples,
    example_prompt=example_prompt,
    prefix="í”¼ì ì£¼ë¬¸ì„ JSONìœ¼ë¡œ ë³€í™˜í•˜ì„¸ìš”:\n\n",
    suffix="\nì…ë ¥: {input}\nì¶œë ¥:",
    input_variables=["input"]
)

chain = LLMChain(llm=llm, prompt=few_shot_prompt)
```

### ğŸ¯ **Gemini API Few-shot í™œìš©**
```python
import vertexai
from vertexai.generative_models import GenerativeModel

def create_few_shot_prompt(examples, new_input):
    """Few-shot í”„ë¡¬í”„íŠ¸ ìƒì„±"""
    prompt = "ë‹¤ìŒ ì˜ˆì‹œë“¤ì„ ì°¸ê³ í•˜ì—¬ íŒ¨í„´ì„ í•™ìŠµí•˜ê³  ìƒˆë¡œìš´ ì…ë ¥ì„ ì²˜ë¦¬í•˜ì„¸ìš”:\n\n"
    
    for i, example in enumerate(examples, 1):
        prompt += f"ì˜ˆì‹œ {i}:\n"
        prompt += f"ì…ë ¥: {example['input']}\n"
        prompt += f"ì¶œë ¥: {example['output']}\n\n"
    
    prompt += f"ìƒˆë¡œìš´ ì…ë ¥: {new_input}\nì¶œë ¥:"
    return prompt

# ì‚¬ìš© ì˜ˆì‹œ
examples = [
    {"input": "ì•ˆë…•í•˜ì„¸ìš”", "output": "Hello"},
    {"input": "ê°ì‚¬í•©ë‹ˆë‹¤", "output": "Thank you"},
    {"input": "ì£„ì†¡í•©ë‹ˆë‹¤", "output": "I'm sorry"}
]

model = GenerativeModel("gemini-pro")
prompt = create_few_shot_prompt(examples, "ì¢‹ì€ í•˜ë£¨ ë˜ì„¸ìš”")
response = model.generate_content(prompt)
```

### ğŸ“‹ **ì˜ˆì‹œ ì„ íƒ ê°€ì´ë“œë¼ì¸**

#### ğŸ¯ **ì¢‹ì€ ì˜ˆì‹œì˜ íŠ¹ì§•**
```python
# í’ˆì§ˆ ë†’ì€ ì˜ˆì‹œ ì„¸íŠ¸
good_examples = [
    {
        "input": "ì´ ì˜í™”ëŠ” ì •ë§ ì¬ë¯¸ìˆê³  ê°ë™ì ì´ì—ˆìŠµë‹ˆë‹¤.",
        "output": "POSITIVE",
        "reason": "ëª…í™•í•œ ê¸ì • í‘œí˜„"
    },
    {
        "input": "ê·¸ëƒ¥ ê·¸ëŸ° ì˜í™”ì˜€ì–´ìš”. íŠ¹ë³„í•  ê²Œ ì—†ë„¤ìš”.",
        "output": "NEUTRAL", 
        "reason": "ì¤‘ë¦½ì  í‘œí˜„"
    },
    {
        "input": "ì‹œê°„ ë‚­ë¹„ì˜€ìŠµë‹ˆë‹¤. ì •ë§ ì§€ë£¨í–ˆì–´ìš”.",
        "output": "NEGATIVE",
        "reason": "ëª…í™•í•œ ë¶€ì • í‘œí˜„"
    }
]
```

#### âŒ **í”¼í•´ì•¼ í•  ì˜ˆì‹œ**
```python
# ë¬¸ì œê°€ ìˆëŠ” ì˜ˆì‹œë“¤
bad_examples = [
    {
        "input": "ì˜í™”ê°€ ì¢‹ì•˜ëŠ”ë° ë‚˜ë¹´ì–´ìš”",  # ëª¨ìˆœëœ í‘œí˜„
        "output": "POSITIVE",  # ì˜ëª»ëœ ë¶„ë¥˜
        "issue": "í˜¼ë€ìŠ¤ëŸ¬ìš´ ì…ë ¥"
    },
    {
        "input": "ã…ã…ã… ê°œì›ƒê¹€ ã…‹ã…‹ã…‹",  # ì¸í„°ë„· ìŠ¬ë­
        "output": "POSITIVE",
        "issue": "ì¼ê´€ì„± ì—†ëŠ” ì–¸ì–´ ìŠ¤íƒ€ì¼"
    }
]
```

### ğŸ”„ **ë™ì  Few-shot ì˜ˆì‹œ ì„ íƒ**
```python
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np

class DynamicFewShotSelector:
    def __init__(self, example_pool):
        self.example_pool = example_pool
        self.vectorizer = TfidfVectorizer()
        self.example_vectors = self.vectorizer.fit_transform(
            [ex['input'] for ex in example_pool]
        )
    
    def select_examples(self, query, k=3):
        """ì¿¼ë¦¬ì™€ ê°€ì¥ ìœ ì‚¬í•œ kê°œ ì˜ˆì‹œ ì„ íƒ"""
        query_vector = self.vectorizer.transform([query])
        similarities = cosine_similarity(query_vector, self.example_vectors)
        
        # ìƒìœ„ kê°œ ì¸ë±ìŠ¤ ì„ íƒ
        top_indices = np.argsort(similarities[0])[-k:][::-1]
        
        return [self.example_pool[i] for i in top_indices]

# ì‚¬ìš©ë²•
selector = DynamicFewShotSelector(good_examples)
relevant_examples = selector.select_examples("ì´ ì˜í™”ëŠ” ìµœì•…ì´ì—ˆìŠµë‹ˆë‹¤", k=2)
```

### ğŸ“Š **ì‘ì—…ë³„ Few-shot ì „ëµ**

| ì‘ì—… ìœ í˜• | ê¶Œì¥ ì˜ˆì‹œ ìˆ˜ | ì£¼ì˜ì‚¬í•­ | ìµœì  ì„¤ì • |
|-----------|-------------|----------|-----------|
| í…ìŠ¤íŠ¸ ë¶„ë¥˜ | 3-5ê°œ | í´ë˜ìŠ¤ë³„ ê· ë“± ë°°ì¹˜ | Temperature: 0.1 |
| ë°ì´í„° ì¶”ì¶œ | 2-4ê°œ | ë‹¤ì–‘í•œ ì…ë ¥ í˜•ì‹ | Temperature: 0.2 |
| í˜•ì‹ ë³€í™˜ | 2-3ê°œ | ì •í™•í•œ ì¶œë ¥ í˜•ì‹ | Temperature: 0.0 |
| ì°½ì‘ ì‘ì—… | 1-2ê°œ | ìŠ¤íƒ€ì¼ ì¼ê´€ì„± | Temperature: 0.7 |

### ğŸ” **Zero-shot vs Few-shot ì„ íƒ ê¸°ì¤€**
```python
def choose_prompting_strategy(task_complexity, format_specificity, data_available):
    """í”„ë¡¬í”„íŒ… ì „ëµ ì„ íƒ ë„ìš°ë¯¸"""
    
    if task_complexity == "simple" and format_specificity == "low":
        return "zero_shot"
    elif format_specificity == "high" or task_complexity == "complex":
        if data_available >= 3:
            return "few_shot"
        else:
            return "one_shot" 
    else:
        return "few_shot"

# ì‚¬ìš© ì˜ˆì‹œ
strategy = choose_prompting_strategy(
    task_complexity="complex",
    format_specificity="high", 
    data_available=5
)
print(f"ê¶Œì¥ ì „ëµ: {strategy}")
```

### ğŸ“ **í”„ë¡¬í”„íŠ¸ ì„±ëŠ¥ í‰ê°€**
```python
def evaluate_prompting_performance(test_cases, prompt_template):
    """í”„ë¡¬í”„íŠ¸ ì„±ëŠ¥ í‰ê°€"""
    correct = 0
    total = len(test_cases)
    
    for case in test_cases:
        result = model.generate_content(
            prompt_template.format(input=case['input'])
        )
        
        if result.text.strip() == case['expected']:
            correct += 1
    
    accuracy = correct / total
    return {
        "accuracy": accuracy,
        "correct": correct,
        "total": total
    }

# A/B í…ŒìŠ¤íŠ¸
zero_shot_results = evaluate_prompting_performance(test_cases, zero_shot_template)
few_shot_results = evaluate_prompting_performance(test_cases, few_shot_template)

print(f"Zero-shot ì •í™•ë„: {zero_shot_results['accuracy']:.2%}")
print(f"Few-shot ì •í™•ë„: {few_shot_results['accuracy']:.2%}")
```

---

* ì¶œì²˜
  * [1] [Prompt Engineering from Google](https://www.kaggle.com/whitepaper-prompt-engineering)
