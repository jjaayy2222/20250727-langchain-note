{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c976a97f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8ab679",
   "metadata": {},
   "source": [
    "* ì¶œì²˜: LangChain ê³µì‹ ë¬¸ì„œ, ì¡°ì½”ë”©ì˜ ë­ì²´ì¸ìœ¼ë¡œ AI ì—ì´ì „íŠ¸ ì„œë¹„ìŠ¤ ë§Œë“¤ê¸°\n",
    "\n",
    "* [ê¹ƒí—ˆë¸Œ ì €ì¥ì†Œ ì¶œì²˜](https://github.com/sw-woo/hanbit-langchain): https://github.com/sw-woo/hanbit-langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6190853",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec160ae",
   "metadata": {},
   "source": [
    "### **01. `ë‹¤êµ­ì–´ ì´ë©”ì¼ ìƒì„±ê¸° ë§Œë“¤ê¸°`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9666f311",
   "metadata": {},
   "source": [
    "* *ì¶œì²˜: ìœ„ì— í‘œê¸°*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed30210e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5e08d5",
   "metadata": {},
   "source": [
    "#### **1) `êµì¬ ì„¤ëª…`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de097257",
   "metadata": {},
   "source": [
    "* **ëª©í‘œ**\n",
    "\n",
    "  * `Ollama`ê¸°ë°˜ì˜ `Llama 3.1 ëª¨ë¸` + `ë¡œì»¬ í™˜ê²½`\n",
    "\n",
    "  * `CTransformers` ì´ìš©í•œ `Local Llama 2` ëª¨ë¸ í™œìš©\n",
    "\n",
    "  * **ì‚¬ìš©ìê°€ ì„ íƒí•œ ì–¸ì–´ì— ë§ì¶° `ì´ë©”ì¼ ì£¼ì œ`, `ë°œì‹ ì`, `ìˆ˜ì‹ ì ì •ë³´` ì…ë ¥ â†’ `ìë™ìœ¼ë¡œ ì´ë©”ì¼ ë‚´ìš© ìƒì„±` â†’ ë‹¤êµ­ì–´ ìë™ ì´ë©”ì¼ ìƒì„±ê¸° êµ¬ì¶•í•˜ê¸°** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa914619",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41eda4c9",
   "metadata": {},
   "source": [
    "* **í•µì‹¬ í‚¤ì›Œë“œ**\n",
    "\n",
    "  * **`Ollama`**\n",
    "\n",
    "  * **`Llama 3.1`**: *`Ollama` í†µí•´ ì—°ê²°ë¨*\n",
    "\n",
    "  * **`Local Llama 2`**: *`CTransformers` ë¼ì´ë¸ŒëŸ¬ë¦¬ í†µí•´ ì‚¬ìš©ë¨*\n",
    "\n",
    "  * **`CTransformers`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5583f054",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c92307d",
   "metadata": {},
   "source": [
    "* **`LLaMa` ì‚¬ìš©í•˜ëŠ” ì´ìœ **\n",
    "\n",
    "  * **`Open source model`**: ì˜¤í”ˆ ê°€ì¤‘ì¹˜ ëª¨ë¸ ì œê³µ â†’ ëŒ€ê·œëª¨ í˜¸ì¶œ â†’ ë¹„ìš© ë¶€ë‹´ â†“ \n",
    "\n",
    "  * **`Local Llama 2`** â†’ ë°ì´í„° ì™¸ë¶€ ìœ ì¶œ âŒ â†’ í”„ë¼ì´ë²„ì‹œ, ì¤€ë²• ê·œì • ë¦¬ìŠ¤í¬ â†“\n",
    "\n",
    "  * ì¸í„°ë„· ë¶ˆì•ˆì •í•œ í™˜ê²½ì—ì„œë„ ë„¤íŠ¸ì›Œí¬ ì§€ì—° ì—†ì´ ì˜¤í”„ë¼ì¸ì—ì„œë„ ë™ì‘ â†’ ì¼ê´€ëœ ì‘ë‹µ ì†ë„ ì œê³µ \n",
    "\n",
    "  * **`í•˜ì´ë¸Œë¦¬ë“œ` ì „ëµ**: **`ìš”ì²­ ê¸¸ì´`, `ì–¸ì–´`, `í•˜ë“œì›¨ì–´ ì—¬ìœ `ì— ë”°ë¼ ë‘ ëª¨ë¸ì„ ë™ì ìœ¼ë¡œ ë°”ê¿ˆ â†’ ë¹„ìš©, í’ˆì§ˆ ë™ì‹œì— ìµœì í™”**\n",
    "\n",
    "    * **a. `Ollama` + `Llama 3.1`**: ê³ í’ˆì§ˆì´ í•„ìš”í•œ í•œêµ­ì–´ or ì¥ë¬¸ ì´ë©”ì¼ â†’ **`GPU`** ì„œë²„ì—ì„œ ì‹¤í–‰ â†’ ì²˜ë¦¬\n",
    "\n",
    "    * **b. `CTransformers` â†’ `Local Llama 2`**: ì§§ì€ ì˜ë¬¸ ì•Œë¦¼ ë©”ì¼ or ì˜¤í”„ë¼ì¸ í™˜ê²½ì—ì„œ ì‚¬ìš©\n",
    "\n",
    "  * **`Ollama`** = `LLM`ì„ ë¡œì»¬ í™˜ê²½ì—ì„œ ì‹¤í–‰í•  ìˆ˜ ìˆë„ë¡ ë„ì™€ì£¼ëŠ” ì˜¤í”ˆ ì†ŒìŠ¤ ë„êµ¬\n",
    "\n",
    "    * `ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬`, `ì‹¤í–‰ ëŸ°íƒ€ì„`, `langchainìš© ì–´ëŒ‘í„°` í†µí•©\n",
    "\n",
    "      * `ollama pull llama3.1` â†’ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ â†’ ë°”ë¡œ ì‚¬ìš© ê°€ëŠ¥\n",
    "\n",
    "      * `REST`, `gRPC`, `CLI` ë“± ì›í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ í˜¸ì¶œ ê°€ëŠ¥\n",
    "\n",
    "      * **`LangChain-Ollama` íŒ¨í‚¤ì§€ ì‚¬ìš© ì‹œ â†’ `ChatOpenAI`ì™€ ê±°ì˜ ë™ì¼í•œ ì¸í„°í˜ì´ìŠ¤ë¡œ ì½”ë“œì— ì—°ê²° ê°€ëŠ¥**\n",
    "\n",
    "    * `Linux`, `macOS`, `Windows` ë“± ì§€ì› â†’ ë…¸íŠ¸ë¶ or í´ë¼ìš°ë“œ GPU ì„œë²„ ëª¨ë‘ `ë°°í¬ ì ˆì°¨ ë™ì¼` â†’ `Llama 3.1` ì†ì‰½ê²Œ í™œìš©í•  ìˆ˜ ìˆëŠ” ëª¨ë¸ í—ˆë¸Œ ì—­í• \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d8c3a4",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c6faef",
   "metadata": {},
   "source": [
    "* **`Ollama` ì„¤ì¹˜ ë° í™˜ê²½ ì„¤ì •**\n",
    "\n",
    "  * **`Ollama` ì„¤ì¹˜**: [Ollama ì„¤ì¹˜ ë‹¤ìš´ë¡œë“œ í˜ì´ì§€](https://ollama.com/download)\n",
    "\n",
    "    * ì§€ì› í”Œë«í¼ (`Linux`, `macOS`, `Windows` ë“±)ì— ë§ëŠ” **`Ollama` ì„¤ì¹˜í•˜ê¸°**\n",
    "\n",
    "```bash\n",
    "\n",
    "            pip install langchain-ollama\n",
    "\n",
    "```\n",
    "\n",
    "* \n",
    "  * **`ì›í•˜ëŠ” ëª¨ë¸ ì„¤ì¹˜í•˜ê¸°`**\n",
    "\n",
    "    * **`í„°ë¯¸ë„`** ë¡œ ì´ë™ â†’ `Ollama pull <ëª¨ë¸ ì´ë¦„>` ì…ë ¥\n",
    "\n",
    "```bash\n",
    "\n",
    "            ollama pull llama3.1:8b                 # êµì¬ ì˜ˆì‹œ\n",
    "\n",
    "            # 70b ì´ìƒë¶€í„°ëŠ” ê³ ì„±ëŠ¥ GPU ì»´í“¨íŒ… íŒŒì›Œ í•„ìš”í•¨\n",
    "\n",
    "\n",
    "```\n",
    "* \n",
    "  * [8b ëª¨ë¸ ë‹¤ìš´ë¡œë“œ](https://ollama.com/library/llama3.1:8b)\n",
    "\n",
    "<br>\n",
    "\n",
    "* \n",
    "  * *ì¶”ê°€ ëª…ë ¹ì–´*\n",
    "\n",
    "    * *`ëª¨ë¸ ëª©ë¡ í™•ì¸`*: ***`ollama list`*** â†’ ë‹¤ìš´ë¡œë“œ ëœ ëª¨ë“  ëª¨ë¸ í™•ì¸í•˜ê³  ì‹¶ì„ ë•Œ\n",
    "\n",
    "    * *`ëª¨ë¸ê³¼ ì§ì ‘ ì±„íŒ…`*: ***`ollama run <ëª¨ë¸ ì´ë¦„>`*** â†’ ëª…ë ¹ ì¤„ì—ì„œ ì§ì ‘ ëª¨ë¸ê³¼ ëŒ€í™”í•˜ê³  ì‹¶ì„ ë•Œ\n",
    "\n",
    "    * *`ì¶”ê°€ ëª…ë ¹ì–´ í™•ì¸`*: ***`ollma help`*** â†’ ë” ë§ì€ ëª…ë ¹ì–´ í™•ì¸í•˜ê³  ì‹¶ì„ ë•Œ\n",
    "      * í˜¹ì€ [`Ollama ê³µì‹ ë¬¸ì„œ ì°¸ì¡°`](https://docs.ollama.com/)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078d1034",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16497774",
   "metadata": {},
   "source": [
    "* **`CTransformers` í™˜ê²½ ì„¤ì •**\n",
    "\n",
    "  * **`CTransformers`, `langchin-community` ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ í•„ìš” !**\n",
    "\n",
    "    * `CPU`ì—ì„œ `Transformer` ëª¨ë¸ ì‹¤í–‰ìœ„í•´ ì‚¬ìš© \n",
    "\n",
    "    * `LLaMa`, `GPT4ALL`, `MPT` ë“± ë‹¤ì–‘í•œ ëª¨ë¸ ì§€ì›\n",
    "\n",
    "```bash\n",
    "\n",
    "            pip install ctransformsers langchain-community\n",
    "\n",
    "```\n",
    "\n",
    "* \n",
    "  * **`Llama-2-7B-Chat`** ëª¨ë¸ì˜ ê²½ëŸ‰í™” ë²„ì „ ë‹¤ìš´ë¡œë“œ \n",
    "\n",
    "    * `CTransformers` = `GGML` í¬ë§·ìœ¼ë¡œ ì €ì¥ëœ ëª¨ë¸ ì‚¬ìš©\n",
    "\n",
    "    * [Llama-2-7B-Chat-GGML](https://huggingface.co/TheBloke/Llama-2-7B-Chat-GGML/tree/main) â†’ `llama-2-7b-chat.ggmlv3.q8_0.bin` ë‹¤ìš´ë¡œë“œ ë° ì‚¬ìš©\n",
    "\n",
    "    * ë‹¤ìš´ë¡œë“œ â†’ **`ë¡œì»¬ ë””ë ‰í„°ë¦¬`ì— `ì €ì¥`** â†’ `CTransformers` ë¼ì´ë¸ŒëŸ¬ë¦¬ì™€ í•¨ê»˜ ì‚¬ìš©í•  ì¤€ë¹„ ë§ˆì¹˜ê¸°"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e367cfc",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6ebe12",
   "metadata": {},
   "source": [
    "* **`Streamlit` ë° ê¸°íƒ€ íŒ¨í‚¤ì§€ ì„¤ì¹˜**\n",
    "\n",
    "  * **a. `Streamlit`**\n",
    "\n",
    "    * í„°ë¯¸ë„ (or ëª…ë ¹ í”„ë¦„í”„íŠ¸)ì—ì„œ ë‹¤ìŒ ëª…ë ¹ì–´ ì…ë ¥í•˜ê¸°\n",
    "\n",
    "```bash\n",
    "\n",
    "            pip install streamlit\n",
    "\n",
    "```\n",
    "* \n",
    "  * **b. `ê·¸ ì™¸ í•„ìš”í•œ íŒ¨í‚¤ì§€` ì„¤ì¹˜**\n",
    "\n",
    "    * ***`langchain.prompts`***: `LLM`ì— ì „ë‹¬í•œ í”„ë¡¬í”„íŠ¸ â†’ í…œí”Œë¦¿í™” â†’ ê´€ë¦¬í•˜ëŠ” ë° ì‚¬ìš©\n",
    "\n",
    "    * ***`CTransformers`***: ë‹¤ì–‘í•œ ì˜¤í”ˆ ì†ŒìŠ¤ `LLM` â†’ `CPU` í™˜ê²½ì—ì„œ ì‹¤í–‰í•  ìˆ˜ ìˆëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "\n",
    "    * ***`OllamaLLM`***: `Ollama` í†µí•´ ì œê³µë˜ëŠ” `Llama 3.1` ëª¨ë¸ í˜¸ì¶œ â†’ ì‚¬ìš© ê°€ëŠ¥\n",
    "\n",
    "```python\n",
    "\n",
    "            import streamlit as st\n",
    "            from langchain.prompts import PromptTemplate\n",
    "\n",
    "            # CTransformers â†’ Llama, GPT4ALL-J, MPT, Falcon ê°™ì€ ë‹¤ì–‘í•œ ì˜¤í”ˆ ì†ŒìŠ¤ ëª¨ë¸ ì§€ì›\n",
    "            from langchain_community.llms.ctransformers import CTransformers\n",
    "\n",
    "            # Ollama llama 3.1 model ì—°ê²°í•˜ê¸°\n",
    "            from langchain_ollama.llms import OllamaLLM\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db672072",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866a9070",
   "metadata": {},
   "source": [
    "* **`ì´ë©”ì¼ ì‘ë‹µ ìƒì„±í•˜ê¸°`**\n",
    "\n",
    "  * **a. `LLM ì‘ë‹µ ìƒì„± í•¨ìˆ˜`**\n",
    "\n",
    "    * `getLLMResponse()` = ì…ë ¥ â†’ `LLM` â†’ ì´ë©”ì¼ ì‘ë‹µ ìƒì„±"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35cec4b8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb2b827",
   "metadata": {},
   "source": [
    "#### **2) `í™˜ê²½ ì„¤ì •`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8b6b37",
   "metadata": {},
   "source": [
    "* **a. `Python 3.12 ë²„ì „ ì„¤ì¹˜ í™•ì¸ ë° ì„¤ì¹˜`**\n",
    "\n",
    "```bash\n",
    "\n",
    "        # ì„¤ì¹˜ ê°€ëŠ¥í•œ Python 3.12 ë²„ì „ ëª©ë¡ í™•ì¸í•˜ê¸°\n",
    "        pip intsll --list | grep \"3.12\"\n",
    "\n",
    "        # ìµœì‹  ì•ˆì • ë²„ì „ì¸ Python 3.12.x ì„¤ì¹˜ (ì˜ˆì‹œ: 3.12.4)\n",
    "        pyenv install 3.12.4\n",
    "\n",
    "        # ì´ë¯¸ ì„¤ì¹˜ë˜ì–´ ìˆë‹¤ë©´ \"already installed\" ë©”ì‹œì§€ê°€ ì¶œë ¥ë¨\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1632e92b",
   "metadata": {},
   "source": [
    "* **b. `ìƒˆ ê°€ìƒí™˜ê²½ ìƒì„±í•˜ê¸°`**\n",
    "\n",
    "```bash\n",
    "\n",
    "        # ì›í•˜ëŠ” ê°€ìƒí™˜ê²½ ì´ë¦„ìœ¼ë¡œ ìƒì„±í•˜ê¸°\n",
    "\n",
    "        # pyenv virtuenv <ì„¤ì¹˜í•œ Python ë²„ì „> <ì›í•˜ëŠ” ê°€ìƒí™˜ê²½ ì´ë¦„>\n",
    "\n",
    "        pyenv virtuenv 3.12.4. lc_multi_email_env\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59063ce",
   "metadata": {},
   "source": [
    "* **c. `ê°€ìƒ í™˜ê²½ í™œì„±í™”`**\n",
    "\n",
    "```bash\n",
    "\n",
    "        pyenv activate lc_multi_email_env\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1d38e1",
   "metadata": {},
   "source": [
    "* **d. `íŒ¨í‚¤ì§€ ì„¤ì¹˜ ë° ì•ˆì •í™”`**\n",
    "\n",
    "  * ê°€ìƒí™˜ê²½ í™œì„±í™”ëœ ìƒíƒœì—ì„œ [`requirements_multi_email.txt`](/requirements_multi_email.txt)ì˜ ëª¨ë“  íŒ¨í‚¤ì§€ ì„¤ì¹˜í•˜ê¸°\n",
    "\n",
    "  * [ì›ë³¸](https://github.com/sw-woo/hanbit-langchain/blob/main/requirements.txt)\n",
    "\n",
    "```bash\n",
    "\n",
    "        # requirements_multi_email.txtì˜ ëª¨ë“  íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
    "        pip install -r requirements_multi_email.txt\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8bf31b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b39098c",
   "metadata": {},
   "source": [
    "* **`ì´ë©”ì¼ ì‘ë‹µ ìƒì„±í•˜ê¸°`**\n",
    "\n",
    "  * `LLM` ì‘ë‹µì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14fe279b",
   "metadata": {},
   "source": [
    "<small> <small>\n",
    "\n",
    "* **`Llama-2-7B-Chatìš© ë˜í¼: CPUì—ì„œ Llama 2 ì‹¤í–‰`** ë³´ì¶© ì„¤ëª…\n",
    "\n",
    "  * `C Transformers is the Python library that provides bindings for transformer models implemented in C/C++ using the GGML library`\n",
    "\n",
    "  * ëª¨ë¸ `local` ì»´í“¨í„°ì— `ë‹¤ìš´` â†’ `model=\"ë‹¤ìš´ë°›ì€ ëª¨ë¸ëª…\"`ì„ `ì‘ì„±` â†’ ì§„í–‰\n",
    "\n",
    "  * ìš©ëŸ‰ì´ ì‘ì„ìˆ˜ë¡ `ê²½ëŸ‰í™”` ëœ ë²„ì „ â†’ *`â€»ì£¼ì˜: ì„±ëŠ¥ì´ ì¡°ê¸ˆ ë–¨ì–´ì§ˆ ìˆ˜ ìˆìŒ`*\n",
    "\n",
    "  * `GPT`ì™€ ê°™ì€ ì–¸ì–´ ëª¨ë¸\n",
    "    * ì´ëŸ¬í•œ `íŒŒì¼ í˜•ì‹` ì‚¬ìš© â†’ `ëª¨ë¸`ì˜ `í•™ìŠµëœ ê°€ì¤‘ì¹˜`ì™€ `êµ¬ì¡°`ë¥¼ `ì €ì¥` â†’ ì´ë¥¼ `ì¶”ë¡ `(`inference`) ì‹œ `ë¶ˆëŸ¬ì™€ì„œ` `ì‚¬ìš©`\n",
    "    * `ëª¨ë¸`ì„ `íš¨ìœ¨ì `ìœ¼ë¡œ `ì €ì¥`í•˜ê³  `ë¶ˆëŸ¬ì˜¬` ìˆ˜ ìˆê²Œ í•¨ â†’ **`ë‹¤ì–‘í•œ í”Œë«í¼`ê³¼ `í™˜ê²½`ì—ì„œ `ëª¨ë¸ ì¶”ë¡ `ì„ `ì›í™œ`í•˜ê²Œ í•  ìˆ˜ ìˆê²Œ í•¨**\n",
    "\n",
    "  * ë”°ë¼ì„œ, **`GGUF` ë° `GGML` íŒŒì¼ í˜•ì‹ = `GPT`ì™€ ê°™ì€ `ì–¸ì–´ ëª¨ë¸`ì˜ `ë§¥ë½`ì—ì„œ `ëª¨ë¸ ì¶”ë¡ `ì„ ìœ„í•´ `ì‚¬ìš©`ë˜ëŠ” `ì¤‘ìš”í•œ íŒŒì¼ í˜•ì‹`**\n",
    "\n",
    "* [Llama-2-7B-Chat.ggmlv3.q8_0.bin](https://huggingface.co/TheBloke/Llama-2-7B-Chat-GGML/tree/main)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb9b300",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd206334",
   "metadata": {},
   "source": [
    "#### **3) `ìƒˆë¡œìš´ ë²„ì „ìœ¼ë¡œ ì—…ê·¸ë ˆì´ë“œ` â†’ ì½”ë“œ ì¬ìƒì„±**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e0b6cc",
   "metadata": {},
   "source": [
    "* ***ê¸°ì¡´ì— ì„¤ì¹˜í•´ë’€ë˜ `llama3.2:3b`ê°€ ìˆì–´ `llama3.1:8b` ëŒ€ì‹  ì‚¬ìš© ì˜ˆì •***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4498bb2c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a2d5f3",
   "metadata": {},
   "source": [
    "##### **`â€ ğŸ“ ë‹¤êµ­ì–´ ì´ë©”ì¼ ìƒì„±ê¸° ì½”ë“œ ë³€ê²½ ì‚¬í•­`**\n",
    "\n",
    "* ìµœì‹  `Ollama` ë²„ì „ì€ íŒŒì¼ ë©”íƒ€ë°ì´í„° ê´€ë¦¬ê°€ ë” ì•ˆì •ì ì¸ **`GGUF` í¬ë§·** ê³µì‹ì ìœ¼ë¡œ ê¶Œì¥\n",
    "\n",
    "  * **a. `GGUF í¬ë§·` íŒŒì¼ë¡œ êµì²´í•˜ê¸°** \n",
    "    * *ë°˜ë©´, êµì¬ ì† ë²„ì „ ë° ì½”ë“œ: `GGML` íŒŒì¼ â†’ ì¢…ì¢… `unknown type` ì˜¤ë¥˜ ë°˜í™˜í•¨*\n",
    "    * ë”°ë¼ì„œ ìµœì‹  ëª¨ë¸ íŒŒì¼ë¡œ êµì²´í•˜ëŠ” ê²ƒì„ ê¶Œì¥: **`llama2-7b.gguf`** \n",
    "      * ì˜ˆì‹œ: `04_K_M.gguf`, `05_K_M.gguf` ë“±\n",
    "\n",
    "  * **b. `Modelfile` ìˆ˜ì • ë° ì €ì¥**\n",
    "    * `llama2-7b.ggub` íŒŒì¼ê³¼ ê°™ì€ í´ë”ì— ìˆì–´ì•¼ í•¨\n",
    "\n",
    "  * **c. `Ollama` ëª¨ë¸ ì¬ë“±ë¡**\n",
    "    * **`Ollama ì„œë²„ ì‹¤í–‰ ì¤‘ì¸ ìƒíƒœ`** â†’ í„°ë¯¸ë„ ì—´ê¸° â†’ íŒŒì¼ë“¤ì´ ìˆëŠ” í´ë”ë¡œ ì´ë™ â†’ ë‹¤ìŒ ëª…ë ¹ì–´ ì‹¤í–‰\n",
    "\n",
    "```bash\n",
    "\n",
    "                ollama create llama2-7b-imported -f Modelfile\n",
    "\n",
    "```\n",
    "\n",
    "<small> <small>\n",
    "\n",
    "* âš ï¸ *`Modelfile` ì €ì¥ ë° ì‹¤í–‰ ê³¼ì •ì—ì„œ ì˜¤ë¥˜ ë°œìƒìœ¼ë¡œ í•´ë‹¹ ëª¨ë¸ ì„ì‹œ ë³´ë¥˜*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6025d5df",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223bc7bd",
   "metadata": {},
   "source": [
    "* [**`app.py`**](../01_Multilingual-Email-Generator/app.py)\n",
    "\n",
    "<small> <small>\n",
    "\n",
    "```python\n",
    "\n",
    "                # app.py (ìƒˆ ì½”ë“œ)\n",
    "\n",
    "                import streamlit as st\n",
    "                from langchain.prompts import PromptTemplate\n",
    "                from langchain_ollama.llms import OllamaLLM\n",
    "\n",
    "                def getLLMResponse(form_input, email_sender, email_recipient, language):\n",
    "                    \"\"\"\n",
    "                    getLLMResponse í•¨ìˆ˜ëŠ” ì£¼ì–´ì§„ ì…ë ¥ì„ ì‚¬ìš©í•˜ì—¬ LLM(ëŒ€í˜• ì–¸ì–´ ëª¨ë¸)ìœ¼ë¡œë¶€í„° ì´ë©”ì¼ ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "\n",
    "                    ë§¤ê°œë³€ìˆ˜:\n",
    "                    - form_input: ì‚¬ìš©ìê°€ ì…ë ¥í•œ ì´ë©”ì¼ ì£¼ì œ.\n",
    "                    - email_sender: ì´ë©”ì¼ì„ ë³´ë‚¸ ì‚¬ëŒì˜ ì´ë¦„.\n",
    "                    - email_recipient: ì´ë©”ì¼ì„ ë°›ëŠ” ì‚¬ëŒì˜ ì´ë¦„.\n",
    "                    - language: ì´ë©”ì¼ì´ ìƒì„±ë  ì–¸ì–´ (í•œêµ­ì–´ ë˜ëŠ” ì˜ì–´).\n",
    "\n",
    "                    ë°˜í™˜ê°’:\n",
    "                    - LLMì´ ìƒì„±í•œ ì´ë©”ì¼ ì‘ë‹µ í…ìŠ¤íŠ¸.\n",
    "                    \"\"\"\n",
    "\n",
    "                    # ğŸ’¡ ì„¤ì¹˜ëœ 'llama3.2:3b' ëª¨ë¸ì„ ì‚¬ìš©í•˜ë„ë¡ ì§€ì •\n",
    "                    llm = OllamaLLM(model=\"llama3.2:3b\", temperature=0.7)\n",
    "\n",
    "                    # ì´ë©”ì¼ ìƒì„± í”„ë¡¬í”„íŠ¸\n",
    "                    if language == \"í•œêµ­ì–´\":\n",
    "                        template = \"\"\" \n",
    "                        ë‹¤ìŒ ì •ë³´ë¥¼ ì‚¬ìš©í•˜ì—¬ ì „ë¬¸ì ì¸ ì´ë©”ì¼ì„ í•œêµ­ì–´ë¡œ ì‘ì„±í•´ ì£¼ì„¸ìš”. \n",
    "                        \\n\\nì´ë©”ì¼ ì£¼ì œ: {email_topic}\n",
    "                        \\në³´ë‚¸ ì‚¬ëŒ: {sender}\\në°›ëŠ” ì‚¬ëŒ: {recipient}\n",
    "                        \\n\\nì´ë©”ì¼ ë‚´ìš©:\n",
    "                        \"\"\"\n",
    "                    else: \n",
    "                        template = \"\"\" \n",
    "                        Write a professional email in English using the following information.\n",
    "                        \\n\\nEmail Topic: {email_topic}\n",
    "                        \\nSender: {sender}\\nRecipient: {recipient}\n",
    "                        \\n\\nEmail content:\n",
    "                        \"\"\"\n",
    "\n",
    "                    # ìµœì¢… PROMPT ìƒì„±\n",
    "                    prompt = PromptTemplate(\n",
    "                        input_variables=[\"email_topic\", \"sender\", \"recipient\", \"language\"],\n",
    "                        template=template,\n",
    "                    )\n",
    "\n",
    "                    # LLMì„ ì‚¬ìš©í•˜ì—¬ ì‘ë‹µ ìƒì„±\n",
    "                    response = llm.invoke(prompt.format(email_topic=form_input, sender=email_sender, recipient=email_recipient, language=language))\n",
    "                    print(response)\n",
    "\n",
    "                    return response\n",
    "\n",
    "\n",
    "                st.set_page_config(\n",
    "                    page_title=\"ì´ë©”ì¼ ìƒì„±ê¸° ğŸ“®\",\n",
    "                    page_icon='ğŸ“®',\n",
    "                    layout='centered',\n",
    "                    initial_sidebar_state='collapsed'\n",
    "                )\n",
    "                st.header(\"ì´ë©”ì¼ ìƒì„±ê¸° ğŸ“® \")\n",
    "\n",
    "                # ì´ë©”ì¼ ì‘ì„± ì–¸ì–´ ì„ íƒ \n",
    "                language_choice = st.selectbox('ì´ë©”ì¼ì„ ì‘ì„±í•  ì–¸ì–´ë¥¼ ì„ íƒí•˜ì„¸ìš”:', ['í•œêµ­ì–´', 'English'])\n",
    "\n",
    "                form_input = st.text_area('ì´ë©”ì¼ ì£¼ì œë¥¼ ì…ë ¥í•˜ì„¸ìš”', height=100)\n",
    "\n",
    "                # ì‚¬ìš©ì ì…ë ¥ì„ ë°›ê¸° ìœ„í•œ UI ì—´ ìƒì„±\n",
    "                col1, col2 = st.columns([10, 10])\n",
    "                with col1:\n",
    "                    email_sender = st.text_input('ë³´ë‚¸ ì‚¬ëŒ ì´ë¦„')\n",
    "                with col2:\n",
    "                    email_recipient = st.text_input('ë°›ëŠ” ì‚¬ëŒ ì´ë¦„')\n",
    "\n",
    "                submit = st.button(\"ìƒì„±í•˜ê¸°\")\n",
    "\n",
    "                # 'ìƒì„±í•˜ê¸°' ë²„íŠ¼ì´ í´ë¦­ë˜ë©´, ì•„ë˜ ì½”ë“œë¥¼ ì‹¤í–‰í•˜ê¸°\n",
    "                if submit:\n",
    "                    if not form_input or not email_sender or not email_recipient:\n",
    "                        st.error(\"ì´ë©”ì¼ ì£¼ì œ, ë³´ë‚¸ ì‚¬ëŒ, ë°›ëŠ” ì‚¬ëŒ ì´ë¦„ì„ ëª¨ë‘ ì…ë ¥í•´ì•¼ í•©ë‹ˆë‹¤.\")\n",
    "                    else:\n",
    "                        with st.spinner('ìƒì„± ì¤‘ì…ë‹ˆë‹¤...'):\n",
    "                            response = getLLMResponse(form_input, email_sender, email_recipient, language_choice)\n",
    "                            st.write(response)\n",
    "\n",
    "\n",
    "                # ì‹¤í–‰ ë°©ë²•: í•´ë‹¹ í´ë”ë¡œ ì´ë™\n",
    "                # í„°ë¯¸ë„: streamlit run app.py\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc9b04b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90484f6",
   "metadata": {},
   "source": [
    "* [**`app.py`**](../01_Multilingual-Email-Generator/app.py) - **`local í™˜ê²½ì— ë§ì¶° ì‹¤í–‰`**\n",
    "\n",
    "  * **a. `Ollama ëª¨ë¸ ì´ë¦„ ì¼ì¹˜`ì‹œí‚¤ê¸°**\n",
    "\n",
    "```python\n",
    "\n",
    "            model=\"llama2-7b-imported\"          # ì‚¬ìš©í•  ëª¨ë¸ ì´ë¦„\n",
    "\n",
    "```\n",
    "* \n",
    "  * **b. `Ollama ì„œë²„ ì‹¤í–‰`**\n",
    "\n",
    "```bash\n",
    "\n",
    "            # ì½”ë“œ ì‹¤í–‰ ì „\n",
    "            ollama serve                        # ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì´ì–´ì•¼ í•¨\n",
    "\n",
    "```\n",
    "* \n",
    "  * **c. `ëª¨ë¸ íŒŒì¼ í˜•ì‹`**\n",
    "\n",
    "    * `GGML` íŒŒì¼ âŒ â†’ **`GGUF` íŒŒì¼ â­•ï¸**\n",
    "\n",
    "<br>\n",
    "\n",
    "* **`ë³€ê²½ ì‚¬í•­ ìš”ì•½`** - *`êµì¬ ì½”ë“œ` vs `app.py`*\n",
    "  \n",
    "  | êµ¬ë¶„      | êµì¬ ì´ˆê¸° ì½”ë“œ                                   | ìˆ˜ì •ëœ app.py ì½”ë“œ                                         | ë³€ê²½ ì´ìœ  ë° ëª©ì                                                                              |\n",
    "  |---------|--------------------------------------------|-------------------------------------------------------|----------------------------------------------------------------------------------------|\n",
    "  | `LLM` ëª¨ë“ˆ  | `from langchain.llms import CTransformers`   | `from langchain_ollama.llms import OllamaLLM`           | * **`Ollama` í™˜ê²½ ë³€ê²½**: `CTransformers` ëŒ€ì‹  **`ë¡œì»¬ Ollama ì„œë²„`ì— `ì§ì ‘ ì—°ê²°`í•˜ì—¬ `llama3.2:3b` ëª¨ë¸ì„ `ì‚¬ìš©`í•˜ê¸° ìœ„í•¨**          |\n",
    "  | `LLM` ê°ì²´  | `llm = CTransformers(...)`                   | `llm = OllamaLLM(model=\"llama3.2:3b\", temperature=0.7)` | * **`ì‚¬ìš©ì í™˜ê²½` ë§ì¶¤**: `CTransformers` ì½”ë“œ `ì œê±°`/`ì£¼ì„ ì²˜ë¦¬` â†’ **`Ollama`ì— ì„¤ì¹˜ëœ `llama3.2:3b` ëª¨ë¸ì„ `ì§€ì •`í•˜ì—¬ `ì‹¤ì œ ì‘ë™`í•˜ë„ë¡ ì„¤ì •** |\n",
    "  | í”„ë¡¬í”„íŠ¸    | `LLM`ì— ë” ëª…í™•í•œ ì§€ì¹¨ì„ ì œê³µí•˜ë„ë¡ í…œí”Œë¦¿ ë¯¸ì„¸ ë³€ê²½             | LLMì— ë” ëª…í™•í•œ ì§€ì¹¨ì„ ì œê³µí•˜ë„ë¡ í…œí”Œë¦¿ ë¯¸ì„¸ ë³€ê²½                        | * **`ì§€ì‹œ ê°•í™”`**: ëª¨ë¸ì—ê²Œ ì „ë¬¸ì ì¸ ì´ë©”ì¼ì„ **`íŠ¹ì • ì–¸ì–´`** *(í•œêµ­ì–´/ì˜ì–´)* ë¡œ **`ì‘ì„±`í•˜ë¼ê³  `ëª…í™•íˆ` ì§€ì‹œ â†’ ì›í•˜ëŠ” `ê²°ê³¼ë¬¼ í’ˆì§ˆ`ê³¼ `ì¼ê´€ì„±`ì„ `ë†’ì„`**                |\n",
    "  | ë¶ˆí•„ìš”í•œ ì½”ë“œ | `CTransformers` ë° `Llama-2-7b-chat` ê´€ë ¨ ì£¼ì„ ë° ì½”ë“œ | *ëª¨ë‘ ì œê±°* ë˜ëŠ” *ì£¼ì„ ì²˜ë¦¬*                                        | * **`í´ë¦°ì—…` ë° `íš¨ìœ¨í™”`**: ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬ ë° ëª¨ë¸ ê´€ë ¨ ì½”ë“œ ì •ë¦¬ â†’ **`ê°€ë…ì„±` ë†’ì„**                                       |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d781819e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d668a4b3",
   "metadata": {},
   "source": [
    "##### **`â ğŸ“ LLM íš¨ìœ¨ì„± ë¶„ì„`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81bf1cc",
   "metadata": {},
   "source": [
    "* **`Llama-2-7b-chat`** (*CTransformers*) **ëª¨ë¸ì„ ì œê±°í•˜ëŠ” ê²ƒì´ íš¨ìœ¨ì ì¸ ì´ìœ **\n",
    "\n",
    "  * **a. `í†µí•© í™˜ê²½ êµ¬ì„±` ë° `ê´€ë¦¬ì˜ ë‹¨ìˆœí™”`** *(Single Source of Truth)*\n",
    "\n",
    "    * **`Ollama`ì˜ ì—­í• **: `Ollama` = ë‹¤ì–‘í•œ `LLM`ì„ **`ë‹¤ìš´ë¡œë“œ`, `ê´€ë¦¬` ë° `ì‹¤í–‰`í•˜ëŠ” `í‘œì¤€í™”`ëœ `ì„œë²„` ì—­í• **\n",
    "      * ì˜ˆì‹œ: `llama3.2:3b`, `exaone3.5:7.8b` ë“±\n",
    "\n",
    "    * **`ë¹„íš¨ìœ¨ì„±`**: ë§Œì•½ OllamaLLM (Ollamaë¥¼ í†µí•´ ëª¨ë¸ ì‹¤í–‰)ê³¼ CTransformers (ë³„ë„ì˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ í†µí•´ ëª¨ë¸ íŒŒì¼ ì§ì ‘ ë¡œë“œ ë° ì‹¤í–‰)ë¥¼ ë™ì‹œì— ì‚¬ìš©í•˜ë ¤ê³  í•˜ë©´, `ë‹¤ìŒê³¼ ê°™ì€ ë¬¸ì œ ë°œìƒ`\n",
    "\n",
    "      * *`ìì› ì¤‘ë³µ`*: ë‘ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ *`ë©”ëª¨ë¦¬` / `CPU` / `GPU` ìì›ì„ ë†“ê³  `ê²½ìŸ`í•˜ê±°ë‚˜ `ì¶©ëŒ`í•  ê°€ëŠ¥ì„±*\n",
    "\n",
    "      * *`ì„¤ì • ë³µì¡ì„±`*: *`ëª¨ë¸ íŒŒì¼ ê²½ë¡œ`, `ë¡œë“œ ì„¤ì •`* *(quantization, CPU/GPU í• ë‹¹ ë“±)* ì„ `Ollama`ì™€ `CTransformers` ë‘ ê³³ `ëª¨ë‘`ì—ì„œ `ê´€ë¦¬` â†’ *`ì„¤ì •`ì´ `ë³µì¡`í•´ì§€ê³  `ì˜¤ë¥˜ ê°€ëŠ¥ì„±`ì´ `ë†’ì•„ì§`*\n",
    "\n",
    "    * **`íš¨ìœ¨ì„±`**: `OllamaLLM` í•˜ë‚˜ë§Œ ì‚¬ìš© = `ëª¨ë“  ëª¨ë¸ ì‹¤í–‰`ì„ `Ollama ì„œë²„`ì— ë§¡ê¹€ â†’ **`ê´€ë¦¬ í¬ì¸íŠ¸`ê°€ `í•˜ë‚˜ë¡œ í†µì¼`ë˜ì–´ `ë§¤ìš°` `ê¹”ë”`í•˜ê³  `íš¨ìœ¨ì `**\n",
    "\n",
    "  * **b. `ì„±ëŠ¥` ë° `ê¸°ëŠ¥ ì¸¡ë©´`ì˜ `ì´ì `**\n",
    "\n",
    "    * **`ìµœì‹  ê¸°ìˆ  í™œìš©`**: **`Ollama`ëŠ” `ì§€ì†ì `ìœ¼ë¡œ `ì—…ë°ì´íŠ¸`** â†’ **`ìµœì‹  ëª¨ë¸`ê³¼ `ìµœì í™”`ëœ ì‹¤í–‰ `í™˜ê²½`ì„ `ì§€ì›`í•¨**\n",
    "      * *ìµœì‹  ëª¨ë¸ ì˜ˆì‹œ: `Llama 3.2`, `Exaone 3.5` ë“±*\n",
    "      * *ìµœì í™”ëœ ì‹¤í–‰ í™˜ê²½ ì˜ˆì‹œ: `CUDA`, `Metal` ë“±*\n",
    "\n",
    "    * **`ëª¨ë¸ êµì²´ì˜ ìš©ì´ì„±`**: \n",
    "\n",
    "      * **`Ollama í™˜ê²½`**: **`ì½”ë“œ í¬ê²Œ ë³€ê²½ âŒ` â†’ `model=\"ëª¨ë¸ëª…\"`ë§Œ ë°”ê¿ˆ â†’ `ì¦‰ì‹œ ë‹¤ë¥¸ ëª¨ë¸`** *(ì˜ˆ: llama3.2:3b â†’ exaone3.5:7.8b)* ë¡œ **`ì‹¤í—˜ ê°€ëŠ¥`**\n",
    "\n",
    "      * *`CTransformers`*: *`ëª¨ë¸ì„ ë³€ê²½í•  ë•Œë§ˆë‹¤` `ìƒˆë¡œìš´ .gguf íŒŒì¼` (í˜¹ì€ `.ggml íŒŒì¼`)ì„ `ë‹¤ìš´ë¡œë“œ` â†’ `ë¡œë“œ ì„¤ì •`ì„ `ë‹¤ì‹œ êµ¬ì„±`í•´ì•¼ í•˜ëŠ” ë²ˆê±°ë¡œì›€ ë°œìƒ*\n",
    "\n",
    "\n",
    "* ê²°ë¡ ì ìœ¼ë¡œ, **í˜„ì¬ `Ollama`ë¥¼ `ì‚¬ìš©`í•˜ê³  ìˆëŠ” ê²½ìš°**, **`OllamaLLM`ë§Œì„ ì‚¬ìš© â†’ `í†µí•©ëœ í™˜ê²½`ì—ì„œ `ìµœì‹  ëª¨ë¸`ì„ `í™œìš©`í•˜ëŠ” ê²ƒ = `ê°€ì¥ íš¨ìœ¨ì `ì´ê³  `ì•ˆì •ì ì¸ ë¡œì»¬ LLM ê°œë°œ ë°©ì‹`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6ee481",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbd75a0",
   "metadata": {},
   "source": [
    "##### **`â‚ í™˜ê²½ ì„¤ì •`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515e5f63",
   "metadata": {},
   "source": [
    "* âš ï¸ ì‹¤í–‰ ì „ í•„ìˆ˜ ì¤€ë¹„ ì‚¬í•­\n",
    "\n",
    "  * `mac í„°ë¯¸ë„`\n",
    "\n",
    "```bash\n",
    "\n",
    "            # Ollama ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì´ì–´ì•¼ í•¨\n",
    "            ollama serve\n",
    "\n",
    "            # `llama3.2:3b` ëª¨ë¸ì´ ì„¤ì¹˜ë˜ì–´ ìˆì–´ì•¼ í•¨\n",
    "            ps aux | grep ollama            # ollama ì„¤ì¹˜ëœ ëª¨ë¸ í™•ì¸í•˜ê¸°\n",
    "            \n",
    "            # ì„¤ì¹˜ëœ ëª¨ë¸ì´ ì—†ë‹¤ë©´ ì„¤ì¹˜í•˜ê¸°\n",
    "            ollama run llama3.2:3b\n",
    "\n",
    "            # ì„¤ì¹˜ëœ ëª©ë¡ í™•ì¸í•˜ê¸° \n",
    "            ollama list                     # í…ŒìŠ¤íŠ¸ë¡œ ì •ìƒ ë™ì‘í•˜ëŠ”ì§€ í™•ì¸í•˜ê¸° \n",
    "\n",
    "            # `langchain`, `langchain-ollama` ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì–´ ìˆì–´ì•¼ í•¨\n",
    "\n",
    "            pip install langchain langchain-ollama\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8181e0e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e48ad7f",
   "metadata": {},
   "source": [
    "##### **`âƒ Python Scriptë¡œ ì‹¤í–‰í•˜ê¸°`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b27ba6",
   "metadata": {},
   "source": [
    "* [**`app.py`**](../01_Multilingual-Email-Generator/app.py)\n",
    "\n",
    "  * ![Streamlit_1](../01_Multilingual-Email-Generator/img/app_py_1.png)\n",
    "\n",
    "  * ![Streamlit_2](../01_Multilingual-Email-Generator/img/app_py_2.png)\n",
    "\n",
    "  * ![Streamlit_3](../01_Multilingual-Email-Generator/img/app_py_3.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20352047",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5e3d0b",
   "metadata": {},
   "source": [
    "##### **`â„ ì£¼í”¼í„° ë…¸íŠ¸ë¶ìœ¼ë¡œ ì‹¤í–‰í•´ë³´ê¸°`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62a9547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„í¬íŠ¸ í•´ë³´ê¸°\n",
    "import sys\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "print(\"âœ… í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ì™„ë£Œ.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e19ce52",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* **`âœ… í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ì™„ë£Œ.`** - (`0.9s`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c49058",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLLMResponse(form_input, email_sender, email_recipient, language):\n",
    "    \"\"\"\n",
    "    getLLMResponse í•¨ìˆ˜ëŠ” ì£¼ì–´ì§„ ì…ë ¥ì„ ì‚¬ìš©í•˜ì—¬ LLM(ëŒ€í˜• ì–¸ì–´ ëª¨ë¸)ìœ¼ë¡œë¶€í„° ì´ë©”ì¼ ì‘ë‹µì„ ìƒì„±í•¨\n",
    "\n",
    "    ë§¤ê°œë³€ìˆ˜:\n",
    "    - form_input: ì‚¬ìš©ìê°€ ì…ë ¥í•œ ì´ë©”ì¼ ì£¼ì œ.\n",
    "    - email_sender: ì´ë©”ì¼ì„ ë³´ë‚¸ ì‚¬ëŒì˜ ì´ë¦„.\n",
    "    - email_recipient: ì´ë©”ì¼ì„ ë°›ëŠ” ì‚¬ëŒì˜ ì´ë¦„.\n",
    "    - language: ì´ë©”ì¼ì´ ìƒì„±ë  ì–¸ì–´ (í•œêµ­ì–´ ë˜ëŠ” ì˜ì–´).\n",
    "\n",
    "    ë°˜í™˜ê°’:\n",
    "    - LLMì´ ìƒì„±í•œ ì´ë©”ì¼ ì‘ë‹µ í…ìŠ¤íŠ¸.\n",
    "    \"\"\"\n",
    "\n",
    "    # OllamaLLM ê°ì²´ ìƒì„± = 'llama3.2:3b' ëª¨ë¸ ì‚¬ìš©\n",
    "    # ì°¸ê³ : Ollamaê°€ ë‹¤ë¥¸ í¬íŠ¸ì—ì„œ ì‹¤í–‰ ì¤‘ì´ë¼ë©´ base_urlì„ ì§€ì •í•´ì•¼ í•¨\n",
    "    try:\n",
    "        llm = OllamaLLM(model=\"llama3.2:3b\", temperature=0.7)\n",
    "    except Exception as e:\n",
    "        print(f\"Ollama ì—°ê²° ì˜¤ë¥˜: {e}\", file=sys.stderr)\n",
    "        print(\"Ollama ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€, ëª¨ë¸ì´ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•´ ì£¼ì„¸ìš”.\", file=sys.stderr)\n",
    "        return \"ERROR: Ollama LLM connection failed.\"\n",
    "\n",
    "\n",
    "    # ì´ë©”ì¼ ìƒì„± í”„ë¡¬í”„íŠ¸\n",
    "    if language == \"í•œêµ­ì–´\":\n",
    "        template = \"\"\" \n",
    "        ë‹¤ìŒ ì •ë³´ë¥¼ ì‚¬ìš©í•˜ì—¬ ì „ë¬¸ì ì¸ ì´ë©”ì¼ì„ í•œêµ­ì–´ë¡œ ì‘ì„±í•´ ì£¼ì„¸ìš”. \n",
    "        \n",
    "        ì´ë©”ì¼ ì£¼ì œ: {email_topic}\n",
    "        ë³´ë‚¸ ì‚¬ëŒ: {sender}\n",
    "        ë°›ëŠ” ì‚¬ëŒ: {recipient}\n",
    "        \n",
    "        ì´ë©”ì¼ ë‚´ìš©:\n",
    "        \"\"\"\n",
    "    else: \n",
    "        template = \"\"\" \n",
    "        Write a professional email in English using the following information.\n",
    "        \n",
    "        Email Topic: {email_topic}\n",
    "        Sender: {sender}\n",
    "        Recipient: {recipient}\n",
    "        \n",
    "        Email content:\n",
    "        \"\"\"\n",
    "\n",
    "    # ìµœì¢… PROMPT ìƒì„±\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"email_topic\", \"sender\", \"recipient\", \"language\"],\n",
    "        template=template,\n",
    "    )\n",
    "\n",
    "    # LLM â†’ ì‘ë‹µ ìƒì„±\n",
    "    response = llm.invoke(prompt.format(email_topic=form_input, sender=email_sender, recipient=email_recipient, language=language))\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e39e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# í…ŒìŠ¤íŠ¸ ì‹¤í–‰\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "# === 1ì°¨ í…ŒìŠ¤íŠ¸: í•œêµ­ì–´ ì´ë©”ì¼ ===\n",
    "\n",
    "email_topic_kr = \"ë‹¤ìŒ ë¶„ê¸° ë§ˆì¼€íŒ… ì „ëµ ë³€ê²½ ì‚¬í•­ ë³´ê³ \"\n",
    "email_sender_kr = \"ê¹€ì˜í¬ ë¶€ì¥\"\n",
    "email_recipient_kr = \"ì´ì² ìˆ˜ íŒ€ì¥\"\n",
    "language_choice_kr = \"í•œêµ­ì–´\"\n",
    "\n",
    "print(f\"\\n--- [1ì°¨ í…ŒìŠ¤íŠ¸: {language_choice_kr}] ---\")\n",
    "print(\"ìƒì„± ì¤‘... (Ollama ì‘ë‹µ ëŒ€ê¸°)\")\n",
    "response_kr = getLLMResponse(email_topic_kr, email_sender_kr, email_recipient_kr, language_choice_kr)\n",
    "\n",
    "print(\"\\n[ìƒì„±ëœ í•œêµ­ì–´ ì´ë©”ì¼ ë‚´ìš©]\\n\")\n",
    "print(response_kr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8004c59",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* **`test_1`(*`ver_ko`*)** - (`31.8s`)\n",
    "\n",
    "<br>\n",
    "\n",
    "* \n",
    "  * *`Llama ëª¨ë¸ì´ í•œêµ­ì–´ì— ê°€ì§„ í•œê³„ì ì´ ë³´ì„`*\n",
    "\n",
    "    ```markdown\n",
    "\n",
    "    --- [1ì°¨ í…ŒìŠ¤íŠ¸: í•œêµ­ì–´] ---\n",
    "    ìƒì„± ì¤‘... (Ollama ì‘ë‹µ ëŒ€ê¸°)\n",
    "\n",
    "    [ìƒì„±ëœ í•œêµ­ì–´ ì´ë©”ì¼ ë‚´ìš©]\n",
    "\n",
    "    subject: ë‹¤ìŒ ë¶„ê¸° ë§ˆì¼€íŒ… ì „ëµ ë³€ê²½ ì‚¬í•­ ë³´ê³ \n",
    "\n",
    "    dear ì´ì² ìˆ˜ íŒ€ì¥,\n",
    "\n",
    "    ì•ˆë…•í•˜ì„¸ìš”. kimyoungheeì…ë‹ˆë‹¤.\n",
    "\n",
    "    ì´ë²ˆ ë‹¬ì€ ìƒˆë¡œìš´ ë¶„ê¸°ë¡œè¿›å…¥í•©ë‹ˆë‹¤. ì´ì— ë”°ë¼ ë§ˆì¼€íŒ… ì „ëµë„ ë³€ê²½ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.\n",
    "\n",
    "    ì œê°€ ì œì•ˆí•œ ë³€ê²½ ì‚¬í•­ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\n",
    "\n",
    "    1.  **ë§ˆì¼€íŒ… objetivoì˜ ë³€ê²½** : í˜„ì¬ì˜ objectivesë¥¼ reviewí•˜ê³ , ìƒˆë¡œ ì •ì˜í•˜ëŠ” objectiveê°€ í•„ìš”í•©ë‹ˆë‹¤.\n",
    "    2.  **Target audienceì˜ í™•ì¥** : ìƒˆë¡œìš´ target audienceë¥¼ ì¶”ê°€í•˜ì—¬ ë§ˆì¼€íŒ… ì „ëµì„ ë³€ê²½í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "    3.  **ë§ˆì¼€íŒ… ì±„ë„ì˜ diversification** : ê¸°ì¡´ì˜ channelì— ìƒˆë¡œìš´ channelì„ ì¶”ê°€í•˜ì—¬ ë§ˆì¼€íŒ… ì „ëµì„ ë³´ë‹¤ Ä‘a dáº¡ngí™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "    4.  **ë§ˆì¼€íŒ… budgetì˜ increase** : í˜„ì¬ì˜ budgetë¥¼ reviewí•˜ê³ , ìƒˆë¡œ ì¦ê°€í•˜ëŠ” budgetê°€ í•„ìš”í•©ë‹ˆë‹¤.\n",
    "\n",
    "    ì´ ë³€ê²½ ì‚¬í•­ì€ íŒ€ê³¼ ë™ë“±í•œ ì˜ê²¬ì„ benÃ¶tìŠµë‹ˆë‹¤.å› æ­¤, I propose a meeting to discuss these changes in more detail. The proposed meeting date and time is [insert date and time].\n",
    "\n",
    "    If you have any questions or concerns, please don't hesitate to reach out to me.\n",
    "\n",
    "    Thank you for your time and consideration.\n",
    "\n",
    "    Best regards,\n",
    "\n",
    "    kimyounghee ë¶€ì¥\n",
    "\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a975a368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 2ì°¨ í…ŒìŠ¤íŠ¸: ì˜ì–´ ì´ë©”ì¼ ===\n",
    "email_topic_en = \"Follow-up on the Q3 Financial Review meeting action items\"\n",
    "email_sender_en = \"Alice Johnson\"\n",
    "email_recipient_en = \"Bob Williams\"\n",
    "language_choice_en = \"English\"\n",
    "\n",
    "print(f\"\\n--- [2ì°¨ í…ŒìŠ¤íŠ¸: {language_choice_en}] ---\")\n",
    "print(\"ìƒì„± ì¤‘... (Ollama ì‘ë‹µ ëŒ€ê¸°)\")\n",
    "response_en = getLLMResponse(email_topic_en, email_sender_en, email_recipient_en, language_choice_en)\n",
    "\n",
    "print(\"\\n[ìƒì„±ëœ ì˜ì–´ ì´ë©”ì¼ ë‚´ìš©]\\n\")\n",
    "print(response_en)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c124937",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* **`test_2`** (*`ver_eng`*) - (`21.6s`)\n",
    "\n",
    "    ```markdown\n",
    "\n",
    "    --- [2ì°¨ í…ŒìŠ¤íŠ¸: English] ---\n",
    "    ìƒì„± ì¤‘... (Ollama ì‘ë‹µ ëŒ€ê¸°)\n",
    "\n",
    "    [ìƒì„±ëœ ì˜ì–´ ì´ë©”ì¼ ë‚´ìš©]\n",
    "\n",
    "    Here is a professional email:\n",
    "\n",
    "    Subject: Follow-up on the Q3 Financial Review Meeting Action Items\n",
    "\n",
    "    Dear Bob,\n",
    "\n",
    "    I hope this email finds you well. I am writing to follow up on the action items discussed during our Q3 Financial Review meeting, which took place on [Date of Meeting]. As per our agreement, I would like to confirm the status of each item and request any updates or progress reports.\n",
    "\n",
    "    Could you please provide me with a brief update on the following action items:\n",
    "\n",
    "    * [Item 1: Insert specific action item 1]\n",
    "    * [Item 2: Insert specific action item 2]\n",
    "    * [Item 3: Insert specific action item 3]\n",
    "\n",
    "    Additionally, I would appreciate any information regarding the current status of our Q4 budget projections and any potential adjustments that may be required.\n",
    "\n",
    "    If you have any questions or concerns, please do not hesitate to reach out. I look forward to hearing back from you soon.\n",
    "\n",
    "    Best regards,\n",
    "\n",
    "    Alice Johnson\n",
    "\n",
    "    ```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lc_multi_email_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
