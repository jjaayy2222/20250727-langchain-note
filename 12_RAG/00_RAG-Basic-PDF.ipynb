{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14bd064b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7cf4d9",
   "metadata": {},
   "source": [
    "* 출처: LangChain 공식 문서 또는 해당 교재명\n",
    "* 원본 URL: https://smith.langchain.com/hub/teddynote/summary-stuff-documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14946d5",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec08597",
   "metadata": {},
   "source": [
    "## **`CH12 RAG`** *Retrieval Augmented Generation*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0234d0f0",
   "metadata": {},
   "source": [
    "* **`RAG`**: `Retrieval-Augmented Generation` \n",
    "\n",
    "  * 자연어 처리(`NLP`) 분야에서의 혁신적인 기술\n",
    "\n",
    "  * 기존의 언어 모델의 한계를 넘어서 정보 검색과 생성을 통합하는 방법론\n",
    "\n",
    "<br>\n",
    "\n",
    "* 기본 역할: \n",
    "\n",
    "  * 풍부한 정보를 담고 있는 대규모 문서 데이터베이스에서 관련 정보 검색\n",
    "\n",
    "  * 언어 모델이 더 정확하고 상세한 답변을 생성할 수 있게 함\n",
    "\n",
    "  * 예시: *`최신 뉴스 이벤트`나 `특정 분야의 전문 지식`과 같은 주제에 대해 질문 → `RAG`는 관련 문서를 찾아 그 내용을 바탕으로 답변을 구성*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd13c430",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d46aac0",
   "metadata": {},
   "source": [
    "### **1. `RAG의 8단계 프로세스`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417e3726",
   "metadata": {},
   "source": [
    "#### **1) `사전 준비단계`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f433dc09",
   "metadata": {},
   "source": [
    "* `RAG`의 사전 준비단계\n",
    "  * ![RAG의 사전 준비단계](../12_RAG/images/rag-process-1.png)\n",
    "\n",
    "<br>\n",
    "\n",
    "* \n",
    "  * a. **`도큐먼트 로드` (`Document Loader`)**: \n",
    "    * 외부 데이터 소스에서 **`필요한 문서를 로드` → `초기 처리`**\n",
    "    * ≒ 마치 책을 여러 권 챙겨 도서관에서 공부하는 것과 비슷 / 학생이 공부하기 전에 필요한 책들을 책장에서 골라오는 과정\n",
    "\n",
    "  * b. **`텍스트 분할`** (`Text Splitter`): \n",
    "    * **로드된 문서를 처리 가능한 `작은 단위`로 `분할`**\n",
    "    * ≒ 큰 책을 챕터별로 나누는 것과 유사\n",
    "\n",
    "  * c. **`임베딩`** (`Embedding`): \n",
    "    * 각 **`문서` 또는 `문서의 일부`를 `벡터` 형태로 `변환`** → **문서의 의미 수치화**\n",
    "    * ≒ 책의 내용을 요약하여 핵심 키워드로 표현하는 것과 비슷\n",
    "\n",
    "  * d. **`벡터스토어`** (`Vector Store`) 저장: \n",
    "    * **`임베딩된 벡터`들을 `데이터베이스`에 `저장`**\n",
    "    * ≒ 요약된 키워드를 색인화하여 나중에 빠르게 찾을 수 있도록 하는 과정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ca3e7d",
   "metadata": {},
   "source": [
    "#### **2) `런타임 (RunTime 단계)`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a222a4",
   "metadata": {},
   "source": [
    "* `Runtime`\n",
    "  * ![runtime](../12_RAG/images/rag-process-2.png)\n",
    "\n",
    "<br>\n",
    "\n",
    "* \n",
    "  * e. **`검색기`** (`Retriever`): \n",
    "    * **`질문`** → 이와 관련된 벡터를 **`벡터 데이터베이스`에서 검색**\n",
    "    * ≒ 질문에 가장 잘 맞는 책의 챕터를 찾는 것과 유사\n",
    "\n",
    "  * f. **`프롬프트`** (`Prompt`): \n",
    "    * **`검색된 정보`를 `바탕`으로 언어 모델을 위한 `질문`을 `구성`**\n",
    "    * **`=` 정보를 바탕으로 `어떻게 질문`할지 `결정`하는 과정**\n",
    "\n",
    "  * g. **`LLM`** (Large Language Model): \n",
    "    * 구성된 `프롬프트` 사용 **→ `언어 모델`이 `답변`을 `생성`**\n",
    "    * ≒ 수집된 정보를 바탕으로 과제 or 보고서를 작성하는 학생과 같음\n",
    "\n",
    "  * h. **`체인` (`Chain`) 생성**: \n",
    "    * 이전의 **`모든 과정`의 `하나의 파이프라인`으로 묶어주는 `체인`(`Chain`)** 을 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad018cf",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e65090",
   "metadata": {},
   "source": [
    "#### **3) `PDF 문서 기반 QA`** *(Question-Answer)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c9dc6e",
   "metadata": {},
   "source": [
    "* **`RAG 기본 구조 이해하기 - 1` = `사전작업`** *(1~4단계)*\n",
    "\n",
    "  * ![사전 작업단계](../12_RAG/images/rag1.png)\n",
    "  * ![RAG 작업단계1](../12_RAG/images/rag-process-1.png)\n",
    "\n",
    "<br>\n",
    "\n",
    "* 사전 작업 단계: 데이터 소스를 `Vector DB`에 문서를 **`로드`-`분할`-`임베딩`-`저장`** 하는 **`4단계`를 진행**\n",
    "\n",
    "  * 1단계: **`문서로드`(`Document Load`)** = 문서 내용 불러오기\n",
    "  * 2단계: **`분할`(`Text Split`)**: 문서를 `특정 기준`(`Chunk`)으로 분할하기\n",
    "  * 3단계: **`임베딩`(`Embedding`)**: 분할된(`Chunk`) → **`임베딩`** → 저장하기\n",
    "  * 4단계: **`벡터DB 저장`**: `임베딩된 Chunk` → `DB`에 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f36c56",
   "metadata": {},
   "source": [
    "* **`RAG - 2 = 수행`** *(RunTime)* - 5~8단계\n",
    "  * ![RAG2](../12_RAG/images/rag2.png)\n",
    "  * ![runtime단계](../12_RAG/images/rag-process-2.png)\n",
    "\n",
    "<br>\n",
    "\n",
    "* 수행 단계\n",
    "  * 5단계: **`검색기`(`Retriever`)**\n",
    "    * `쿼리`(`Query`) → `DB`에서 `검색`하여 결과를 가져오기 위하여 `리트리버`를 `정의`하기\n",
    "    * 리트리버 = 검색 알고리즘 / 아래 2개의 종류\n",
    "      * **`Dense`**: **`유사도 기반 검색`**\n",
    "      * **`Sparse`**: **`키워드 기반 검색`**\n",
    "\n",
    "  * 6단계: **`프롬프트`**\n",
    "    * **`RAG`를 수행하기 위한 `프롬프트 생성`**\n",
    "    * 프롬프트의 `context` = **`문서에서 검색된 내용`**\n",
    "    * 프롬프트 엔지니어링 → `답변의 형식`을 `지정 가능`\n",
    "  \n",
    "  * 7단계: **`LLM`**\n",
    "    * **`모델` 정의하기**\n",
    "    * GPT-3.5, GPT-4, Claude, gemini-2.5-flash, ...\n",
    "  \n",
    "  * 8단계: **`Chain`** = **`프롬프트` - `LLM` - `출력` 에 이르는 체인을 생성**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f460f9e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8806fdf0",
   "metadata": {},
   "source": [
    "* **`실습 활용 문서`**\n",
    "\n",
    "  * `소프트웨어정책연구소(SPRi) - 2023년 12월호`\n",
    "\n",
    "    * 저자: 유재흥(AI정책연구실 책임연구원), 이지수(AI정책연구실 위촉연구원)\n",
    "    * [링크](https://spri.kr/posts/view/23669): https://spri.kr/posts/view/23669\n",
    "    * 파일명: [`SPRI_AI_Brief_2023년12월호_F.pdf`](../12_RAG/data/SPRI_AI_Brief_2023년12월호_F.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6216ae",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882ca0af",
   "metadata": {},
   "source": [
    "* **`환경설정`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87635a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API 키를 환경변수로 관리하기 위한 설정 파일\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API 키 정보 로드\n",
    "load_dotenv()                           # True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72357db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import Client\n",
    "from langsmith import traceable\n",
    "\n",
    "import os\n",
    "\n",
    "# LangSmith 환경 변수 확인\n",
    "\n",
    "print(\"\\n--- LangSmith 환경 변수 확인 ---\")\n",
    "langchain_tracing_v2 = os.getenv('LANGCHAIN_TRACING_V2')\n",
    "langchain_project = os.getenv('LANGCHAIN_PROJECT')\n",
    "langchain_api_key_status = \"설정됨\" if os.getenv('LANGCHAIN_API_KEY') else \"설정되지 않음\" # API 키 값은 직접 출력하지 않음\n",
    "\n",
    "if langchain_tracing_v2 == \"true\" and os.getenv('LANGCHAIN_API_KEY') and langchain_project:\n",
    "    print(f\"✅ LangSmith 추적 활성화됨 (LANGCHAIN_TRACING_V2='{langchain_tracing_v2}')\")\n",
    "    print(f\"✅ LangSmith 프로젝트: '{langchain_project}'\")\n",
    "    print(f\"✅ LangSmith API Key: {langchain_api_key_status}\")\n",
    "    print(\"  -> 이제 LangSmith 대시보드에서 이 프로젝트를 확인해 보세요.\")\n",
    "else:\n",
    "    print(\"❌ LangSmith 추적이 완전히 활성화되지 않았습니다. 다음을 확인하세요:\")\n",
    "    if langchain_tracing_v2 != \"true\":\n",
    "        print(f\"  - LANGCHAIN_TRACING_V2가 'true'로 설정되어 있지 않습니다 (현재: '{langchain_tracing_v2}').\")\n",
    "    if not os.getenv('LANGCHAIN_API_KEY'):\n",
    "        print(\"  - LANGCHAIN_API_KEY가 설정되어 있지 않습니다.\")\n",
    "    if not langchain_project:\n",
    "        print(\"  - LANGCHAIN_PROJECT가 설정되어 있지 않습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a6147e",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 셀 출력\n",
    "\n",
    "    ```bash\n",
    "    --- LangSmith 환경 변수 확인 ---\n",
    "    ✅ LangSmith 추적 활성화됨 (LANGCHAIN_TRACING_V2='true')\n",
    "    ✅ LangSmith 프로젝트: 'LangChain-prantice'\n",
    "    ✅ LangSmith API Key: 설정됨\n",
    "    -> 이제 LangSmith 대시보드에서 이 프로젝트를 확인해 보세요.\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4081b662",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb463829",
   "metadata": {},
   "source": [
    "#### **3) `RAG 기본 파이프라인`** *(1~8단계)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9faf29cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_huggingface import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b9e38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단계 1: 문서 로드(Load Documents)\n",
    "\n",
    "loader = PyMuPDFLoader(\"../12_RAG/data/SPRI_AI_Brief_2023년12월호_F.pdf\")\n",
    "docs = loader.load()\n",
    "print(f\"문서의 페이지수: {len(docs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8759d857",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 문서의 페이지수: 23 (`0.9s`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01bcd46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단계 2: 문서 분할(Split Documents)\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=50)\n",
    "split_documents = text_splitter.split_documents(docs)\n",
    "print(f\"분할된 청크의수: {len(split_documents)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3d41f1",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 분할된 청크의수: 43 (`0.0s`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db83865a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단계 3: 임베딩(Embedding) 생성\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "import warnings\n",
    "\n",
    "# 경고 무시\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# HuggingFace Embeddings 사용\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    model_kwargs={'device': 'cpu'},\n",
    "    encode_kwargs={'normalize_embeddings': True}\n",
    ")\n",
    "\n",
    "print(\"✅ hugging-face 임베딩 모델 로딩 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a028453",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* ✅ hugging-face 임베딩 모델 로딩 완료! (`7.2s`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51291589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단계 4: DB 생성(Create DB) 및 저장\n",
    "\n",
    "# 벡터스토어 생성하기\n",
    "vectorstore = FAISS.from_documents(\n",
    "    documents=split_documents, \n",
    "    embedding=embeddings\n",
    ")\n",
    "\n",
    "print(\"🎉 Hugginface model을 사용하여 로컬에서 벡터스토어(FAISS)가 성공적으로 생성되었습니다!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e57fec",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 🎉 Hugginface model을 사용하여 로컬에서 벡터스토어(FAISS)가 성공적으로 생성되었습니다! (`1.0s`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7382d04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단계 5: 검색기(Retriever) 생성\n",
    "# 문서에 포함되어 있는 정보를 검색하고 생성하기\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3478052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검색기에 쿼리를 날려 검색된 chunk 결과 확인하기\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"      # 병렬처리 비활성화\n",
    "\n",
    "# 검색기에 쿼리를 날려 검색된 chunk 결과 확인하기\n",
    "retriever.invoke(\"삼성전자가 자체 개발한 AI 의 이름은?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cecc11fb",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* `chunk` 확인하기\n",
    "\n",
    "    ```python\n",
    "    [Document(id='e84c1482-442c-44e2-8c6d-7a51702ce0e0', metadata={'producer': 'Hancom PDF 1.3.0.542', 'creator': 'Hwp 2018 10.0.0.13462', 'creationdate': '2023-12-08T13:28:38+09:00', 'source': '../12_RAG/data/SPRI_AI_Brief_2023년12월호_F.pdf', 'file_path': '../12_RAG/data/SPRI_AI_Brief_2023년12월호_F.pdf', 'total_pages': 23, 'format': 'PDF 1.4', 'title': '', 'author': 'dj', 'subject': '', 'keywords': '', 'moddate': '2023-12-08T13:28:38+09:00', 'trapped': '', 'modDate': \"D:20231208132838+09'00'\", 'creationDate': \"D:20231208132838+09'00'\", 'page': 20}, page_content='<AI 기술 유형 평균 기술 대비 갖는 임금 프리미엄>'),\n",
    "    Document(id='e0ce8fed-10cb-4cb4-bc8c-478a90bfbdf3', metadata={'producer': 'Hancom PDF 1.3.0.542', 'creator': 'Hwp 2018 10.0.0.13462', 'creationdate': '2023-12-08T13:28:38+09:00', 'source': '../12_RAG/data/SPRI_AI_Brief_2023년12월호_F.pdf', 'file_path': '../12_RAG/data/SPRI_AI_Brief_2023년12월호_F.pdf', 'total_pages': 23, 'format': 'PDF 1.4', 'title': '', 'author': 'dj', 'subject': '', 'keywords': '', 'moddate': '2023-12-08T13:28:38+09:00', 'trapped': '', 'modDate': \"D:20231208132838+09'00'\", 'creationDate': \"D:20231208132838+09'00'\", 'page': 22}, page_content='홈페이지 : https://spri.kr/\\n보고서와 관련된 문의는 AI정책연구실(jayoo@spri.kr, 031-739-7352)으로 연락주시기 바랍니다.'),\n",
    "    Document(id='cf8f1453-b998-43ac-9cb0-2d18a758cbae', metadata={'producer': 'Hancom PDF 1.3.0.542', 'creator': 'Hwp 2018 10.0.0.13462', 'creationdate': '2023-12-08T13:28:38+09:00', 'source': '../12_RAG/data/SPRI_AI_Brief_2023년12월호_F.pdf', 'file_path': '../12_RAG/data/SPRI_AI_Brief_2023년12월호_F.pdf', 'total_pages': 23, 'format': 'PDF 1.4', 'title': '', 'author': 'dj', 'subject': '', 'keywords': '', 'moddate': '2023-12-08T13:28:38+09:00', 'trapped': '', 'modDate': \"D:20231208132838+09'00'\", 'creationDate': \"D:20231208132838+09'00'\", 'page': 17}, page_content='1. 정책/법제  \\n2. 기업/산업 \\n3. 기술/연구 \\n 4. 인력/교육\\n영국 과학혁신기술부, AI 안전 연구소 설립 발표\\nn 영국 과학혁신기술부가 첨단 AI 시스템에 대한 평가를 통해 안전성을 보장하기 위한 AI \\n안전 연구소를 설립한다고 발표\\nn AI 안전 연구소는 핵심 기능으로 첨단 AI 시스템 평가 개발과 시행, AI 안전 연구 촉진, \\n정보교류 활성화를 추진할 계획\\nKEY Contents\\n£ 영국 AI 안전 연구소, 첨단 AI 시스템 평가와 AI 안전 연구, 정보 교류 추진\\nn 영국 과학혁신기술부가 2023년 11월 2일 첨단 AI 안전에 중점을 둔 국가 연구기관으로 AI \\n안전 연구소(AI Safety Institute)를 설립한다고 발표\\n∙AI 안전 연구소는 첨단 AI의 위험을 이해하고 거버넌스 마련에 필요한 사회·기술적 인프라 개발을 통해 \\n영국을 AI 안전 연구의 글로벌 허브로 확립하는 것을 목표로 함\\n∙영국 정부는 향후 10년간 연구소에 공공자금을 투자해 연구를 지원할 계획으로, 연구소는 △첨단 AI 시스템 \\n평가 개발과 시행 △AI 안전 연구 촉진 △정보 교류 활성화를 핵심 기능으로 함\\nn (첨단 AI 시스템 평가 개발과 시행) 시스템의 안전 관련 속성을 중심으로 안전과 보안 기능을 이해\\n하고 사회적 영향을 평가\\n∙평가 우선순위는 △사이버범죄 조장, 허위 정보 유포 등 악의적으로 활용될 수 있는 기능 △사회에 미치는 \\n영향 △시스템 안전과 보안 △인간의 통제력 상실 가능성 순\\n∙연구소는 외부 기관과 협력해 자체 시스템 평가를 개발 및 수행하고, 평가와 관련된 의견 공유 및 지침 \\n마련을 위해 전문가 커뮤니티를 소집할 계획\\nn (AI 안전 연구 촉진) 외부 연구자를 소집하고 다양한 예비 연구 프로젝트를 통해 AI 안전 기초연구를 수행\\n∙AI 시스템의 효과적 거버넌스를 위한 도구 개발* 및 안전한 AI 시스템 개발을 위한 새로운 접근 방식 연구를 수행'),\n",
    "    Document(id='b9f35d59-9547-4da9-911c-2eba1898dd5a', metadata={'producer': 'Hancom PDF 1.3.0.542', 'creator': 'Hwp 2018 10.0.0.13462', 'creationdate': '2023-12-08T13:28:38+09:00', 'source': '../12_RAG/data/SPRI_AI_Brief_2023년12월호_F.pdf', 'file_path': '../12_RAG/data/SPRI_AI_Brief_2023년12월호_F.pdf', 'total_pages': 23, 'format': 'PDF 1.4', 'title': '', 'author': 'dj', 'subject': '', 'keywords': '', 'moddate': '2023-12-08T13:28:38+09:00', 'trapped': '', 'modDate': \"D:20231208132838+09'00'\", 'creationDate': \"D:20231208132838+09'00'\", 'page': 12}, page_content='SPRi AI Brief |  \\n2023-12월호\\n10\\n삼성전자, 자체 개발 생성 AI ‘삼성 가우스’ 공개\\nn 삼성전자가 온디바이스에서 작동 가능하며 언어, 코드, 이미지의 3개 모델로 구성된 자체 개발 생성 \\nAI 모델 ‘삼성 가우스’를 공개\\nn 삼성전자는 삼성 가우스를 다양한 제품에 단계적으로 탑재할 계획으로, 온디바이스 작동이 가능한 \\n삼성 가우스는 외부로 사용자 정보가 유출될 위험이 없다는 장점을 보유\\nKEY Contents\\n£ 언어, 코드, 이미지의 3개 모델로 구성된 삼성 가우스, 온디바이스 작동 지원\\nn 삼성전자가 2023년 11월 8일 열린 ‘삼성 AI 포럼 2023’ 행사에서 자체 개발한 생성 AI 모델 \\n‘삼성 가우스’를 최초 공개\\n∙정규분포 이론을 정립한 천재 수학자 가우스(Gauss)의 이름을 본뜬 삼성 가우스는 다양한 상황에 \\n최적화된 크기의 모델 선택이 가능\\n∙삼성 가우스는 라이선스나 개인정보를 침해하지 않는 안전한 데이터를 통해 학습되었으며, \\n온디바이스에서 작동하도록 설계되어 외부로 사용자의 정보가 유출되지 않는 장점을 보유\\n∙삼성전자는 삼성 가우스를 활용한 온디바이스 AI 기술도 소개했으며, 생성 AI 모델을 다양한 제품에 \\n단계적으로 탑재할 계획\\nn 삼성 가우스는 △텍스트를 생성하는 언어모델 △코드를 생성하는 코드 모델 △이미지를 생성하는 \\n이미지 모델의 3개 모델로 구성\\n∙언어 모델은 클라우드와 온디바이스 대상 다양한 모델로 구성되며, 메일 작성, 문서 요약, 번역 업무의 \\n처리를 지원\\n∙코드 모델 기반의 AI 코딩 어시스턴트 ‘코드아이(code.i)’는 대화형 인터페이스로 서비스를 제공하며 \\n사내 소프트웨어 개발에 최적화\\n∙이미지 모델은 창의적인 이미지를 생성하고 기존 이미지를 원하는 대로 바꿀 수 있도록 지원하며 \\n저해상도 이미지의 고해상도 전환도 지원\\nn IT 전문지 테크리퍼블릭(TechRepublic)은 온디바이스 AI가 주요 기술 트렌드로 부상했다며,')]\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ee8c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단계 6: 프롬프트 생성(Create Prompt)\n",
    "\n",
    "# 프롬프트 생성하기\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"You are an assistant for question-answering tasks. \n",
    "Use the following pieces of retrieved context to answer the question. \n",
    "If you don't know the answer, just say that you don't know. \n",
    "Answer in Korean.\n",
    "\n",
    "#Question: \n",
    "{question} \n",
    "#Context: \n",
    "{context} \n",
    "\n",
    "#Answer:\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4e5daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6db7424",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* `print(prompt)` 확인\n",
    "    ```bash\n",
    "\n",
    "    input_variables=['context', 'question'] input_types={} partial_variables={} template=\"You are an assistant for question-answering tasks. \\nUse the following pieces of retrieved context to answer the question. \\nIf you don't know the answer, just say that you don't know. \\nAnswer in Korean.\\n\\n#Question: \\n{question} \\n#Context: \\n{context} \\n\\n#Answer:\"\n",
    "    \n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a0881b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prompt.template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7eadd7",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* `print(prompt.template)` 확인하기 = *프롬프트 내용만 확인하기*\n",
    "\n",
    "    ```markdown\n",
    "\n",
    "    You are an assistant for question-answering tasks. \n",
    "    Use the following pieces of retrieved context to answer the question. \n",
    "    If you don't know the answer, just say that you don't know. \n",
    "    Answer in Korean.\n",
    "\n",
    "    #Question: \n",
    "    {question} \n",
    "    #Context: \n",
    "    {context} \n",
    "\n",
    "    #Answer:\n",
    "\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d2e479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단계 7: 언어모델(LLM) 생성\n",
    "# 모델(LLM) 생성하기\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# API 키 확인\n",
    "if not os.getenv(\"GOOGLE_API_KEY\"):\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = input(\"Enter your Google API key: \")\n",
    "\n",
    "# LLM 초기화\n",
    "gemini_lc = ChatGoogleGenerativeAI(\n",
    "        model=\"gemini-2.5-flash-lite\",\n",
    "        temperature=0,                                              # temperature = 0으로 설정  \n",
    "        max_output_tokens=4096,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95e42b2",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* `LLM` 생성하기\n",
    "\n",
    "    ```bash\n",
    "    E0000 00:00:1759658522.522070  683443 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbbd7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단계 8: 체인(Chain) 생성\n",
    "\n",
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | gemini_lc\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694b98e0",
   "metadata": {},
   "source": [
    "* 생성된 체인에 **`쿼리`** (`질문`)을 입력 → 실행하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d730a3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 체인 실행(Run Chain)\n",
    "# 문서에 대한 질의를 입력하고, 답변을 출력하기\n",
    "question = \"삼성전자가 자체 개발한 AI 의 이름은?\"\n",
    "response = chain.invoke(question)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b34032c",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 삼성전자가 자체 개발한 AI의 이름은 '삼성 가우스'입니다.   (`1.2s`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5a6766",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99113bb5",
   "metadata": {},
   "source": [
    "* next: ***`02. 네이버 뉴스기사 QA (Question-Answer)`***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a4f342",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lc_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
