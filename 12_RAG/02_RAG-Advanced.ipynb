{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14bd064b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7cf4d9",
   "metadata": {},
   "source": [
    "* 출처: LangChain 공식 문서 또는 해당 교재명\n",
    "* 원본 URL: https://smith.langchain.com/hub/teddynote/summary-stuff-documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14946d5",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d46aac0",
   "metadata": {},
   "source": [
    "### **2. `LangChain의 RAG 파헤치기`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f433dc09",
   "metadata": {},
   "source": [
    "![rag1](../12_RAG/images/rag1.png)\n",
    "![rag2](../12_RAG/images/rag2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ca3e7d",
   "metadata": {},
   "source": [
    "#### **1) `질문 처리`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3eaa4ee",
   "metadata": {},
   "source": [
    "* **`질문 처리`**: 사용자의 질문을 받아 이를 처리 → 관련 데이터를 찾는 작업\n",
    "\n",
    "<br>\n",
    "\n",
    "* 필요한 구성 요소:\n",
    "\n",
    "  * **`데이터 소스 연결`**: \n",
    "    * 질문에 대한 답변을 찾기 위해 다양한 텍스트 데이터 소스에 연결해야 함 \n",
    "    * `LangChain` = 다양한 데이터 소스와의 연결을 간편하게 설정할 수 있도록 도움\n",
    "\n",
    "  * **`데이터 인덱싱 및 검색`**: \n",
    "    * 데이터 소스에서 관련 정보를 효율적으로 찾기 위해, 데이터는 인덱싱되어야 함\n",
    "    * `LangChain` = 인덱싱 과정을 자동화하고, 사용자의 질문과 관련된 데이터를 검색하는 데 필요한 도구를 제공"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c9abe0",
   "metadata": {},
   "source": [
    "#### **2) `답변 생성`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9b8e0d",
   "metadata": {},
   "source": [
    "* 관련 데이터를 찾은 후 → 사용자의 질문에 **`답변 생성`** \n",
    "\n",
    "<br>\n",
    "\n",
    "* **`중요`** 구성 요소:\n",
    "\n",
    "  * **`답변 생성 모델`**: \n",
    "    * `LangChain` = **`고급 자연어 처리`(`NLP`) 모델** 사용 → 검색된 데이터로부터 **`답변`을 `생성`할 수 있는 기능 제공**\n",
    "    * 사용자의 질문과 검색된 데이터를 입력 → **`적절한 답변`을 `생성`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad018cf",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e65090",
   "metadata": {},
   "source": [
    "#### **3) `아키텍처`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be794d71",
   "metadata": {},
   "source": [
    "* [**`Q&A소개`**](https://python.langchain.com/docs/tutorials/rag/) → `RAG` app 구현해보기\n",
    "\n",
    "<br>\n",
    "\n",
    "* 주요 구성 요소\n",
    "  * **`인덱싱`**:\n",
    "    * 소스에서 데이터를 수집하고 인덱싱하는 파이프라인\n",
    "    * 이 작업은 *`보통 오프라인에서 발생`*\n",
    "\n",
    "\n",
    "  * **`검색 및 생성`**:\n",
    "    * **`실제 RAG 체인`**\n",
    "    * `사용자 쿼리`를 실행 시간에 받아 `인덱스`에서 `관련 데이터`를 `검색` → 그 데이터를 `모델`에 `전달`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f53a21",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb3238c",
   "metadata": {},
   "source": [
    "#### **4) `인덱싱`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc871ff",
   "metadata": {},
   "source": [
    "* **`process_1`**\n",
    "\n",
    "  * ![process_1](../12_RAG/images/rag-process-1.png)\n",
    "\n",
    "*  * **a. `로드`**: \n",
    "      *  먼저 데이터를 로드해야 함\n",
    "      *  [**`DocumentLoaders`**](https://python.langchain.com/docs/how_to/#document-loaders) 사용\n",
    "\n",
    "   * **b. `분할`**:\n",
    "      * [**`Text splitters`**](https://python.langchain.com/docs/how_to/#text-splitters) = 큰 `Documents`를 `더 작은 청크`로 나눔 \n",
    "      * **`데이터`를 `인덱싱`하고 `모델`에 `전달`하는 데 `유용` = `큰 청크`는 `검색하기 어렵고` 모델의 유한한 컨텍스트 창에 맞지 않음**\n",
    "\n",
    "   * **c. `저장`**: \n",
    "      * 나중에 검색할 수 있도록 `분할`을 `저장`하고 `인덱싱할 장소`가 `필요`\n",
    "      * [**`VectorStore`**](https://python.langchain.com/docs/how_to/#vector-stores), [**`Embeddings` 모델**](https://python.langchain.com/docs/how_to/embed_text/) 사용 → 수행"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b693cf",
   "metadata": {},
   "source": [
    "#### **5) `검색 및 생성`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ef019a",
   "metadata": {},
   "source": [
    "* **`process_2`**\n",
    "\n",
    "  * ![process_2](../12_RAG/images/rag-process-2.png)\n",
    "\n",
    "*  * **d. `검색`**: \n",
    "      * 사용자 입력 → `Retriever`를 사용하여 저장소에서 관련 분할을 검색함\n",
    "  \n",
    "   * **e. `생성`**: \n",
    "     * **`ChatModel` / `LLM`** = `질문` + `검색된 데이터`를 포함한 `프롬프트`를 사용 → **`답변 생성`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27bd7d3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8806fdf0",
   "metadata": {},
   "source": [
    "* **`실습 활용 문서`**\n",
    "\n",
    "  * `소프트웨어정책연구소(SPRi) - 2023년 12월호`\n",
    "\n",
    "    * 저자: 유재흥(AI정책연구실 책임연구원), 이지수(AI정책연구실 위촉연구원)\n",
    "    * [링크](https://spri.kr/posts/view/23669): https://spri.kr/posts/view/23669\n",
    "    * 파일명: [`SPRI_AI_Brief_2023년12월호_F.pdf`](../12_RAG/data/SPRI_AI_Brief_2023년12월호_F.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6216ae",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882ca0af",
   "metadata": {},
   "source": [
    "* **`환경설정`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87635a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API 키를 환경변수로 관리하기 위한 설정 파일\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API 키 정보 로드\n",
    "load_dotenv()                           # True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72357db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import Client\n",
    "from langsmith import traceable\n",
    "\n",
    "import os\n",
    "\n",
    "# LangSmith 환경 변수 확인\n",
    "\n",
    "print(\"\\n--- LangSmith 환경 변수 확인 ---\")\n",
    "langchain_tracing_v2 = os.getenv('LANGCHAIN_TRACING_V2')\n",
    "langchain_project = os.getenv('LANGCHAIN_PROJECT')\n",
    "langchain_api_key_status = \"설정됨\" if os.getenv('LANGCHAIN_API_KEY') else \"설정되지 않음\" # API 키 값은 직접 출력하지 않음\n",
    "\n",
    "if langchain_tracing_v2 == \"true\" and os.getenv('LANGCHAIN_API_KEY') and langchain_project:\n",
    "    print(f\"✅ LangSmith 추적 활성화됨 (LANGCHAIN_TRACING_V2='{langchain_tracing_v2}')\")\n",
    "    print(f\"✅ LangSmith 프로젝트: '{langchain_project}'\")\n",
    "    print(f\"✅ LangSmith API Key: {langchain_api_key_status}\")\n",
    "    print(\"  -> 이제 LangSmith 대시보드에서 이 프로젝트를 확인해 보세요.\")\n",
    "else:\n",
    "    print(\"❌ LangSmith 추적이 완전히 활성화되지 않았습니다. 다음을 확인하세요:\")\n",
    "    if langchain_tracing_v2 != \"true\":\n",
    "        print(f\"  - LANGCHAIN_TRACING_V2가 'true'로 설정되어 있지 않습니다 (현재: '{langchain_tracing_v2}').\")\n",
    "    if not os.getenv('LANGCHAIN_API_KEY'):\n",
    "        print(\"  - LANGCHAIN_API_KEY가 설정되어 있지 않습니다.\")\n",
    "    if not langchain_project:\n",
    "        print(\"  - LANGCHAIN_PROJECT가 설정되어 있지 않습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a6147e",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 셀 출력\n",
    "\n",
    "    ```bash\n",
    "    --- LangSmith 환경 변수 확인 ---\n",
    "    ✅ LangSmith 추적 활성화됨 (LANGCHAIN_TRACING_V2='true')\n",
    "    ✅ LangSmith 프로젝트: 'LangChain-prantice'\n",
    "    ✅ LangSmith API Key: 설정됨\n",
    "    -> 이제 LangSmith 대시보드에서 이 프로젝트를 확인해 보세요.\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4081b662",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb463829",
   "metadata": {},
   "source": [
    "#### **3) `RAG 기본 파이프라인`** *(1~8단계)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9faf29cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma, FAISS\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_huggingface import HuggingFaceEmbeddings     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7ecccd",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* USER_AGENT environment variable not set, consider setting it to identify your requests.   (`3.6s`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b9e38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단계 1: 문서 로드(Load Documents)\n",
    "# 뉴스기사 내용을 로드, 청크 나누기, 인덱싱\n",
    "url = \"https://n.news.naver.com/article/437/0000378416\"\n",
    "\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(url,),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            \"div\",\n",
    "            attrs={\"class\": [\"newsct_article _article_body\", \"media_end_head_title\"]},\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "\n",
    "docs = loader.load()                                # 0.4s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ecc264",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(docs))                                   # <class 'list'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01bcd46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단계 2: 문서 분할(Split Documents)\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=50)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "print(f\"분할된 청크의수: {len(splits)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb8e772",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 분할된 청크의수: 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db83865a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단계 3: 임베딩(Embedding) 생성\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "import warnings\n",
    "\n",
    "# 경고 무시\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# HuggingFace Embeddings 사용\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    model_kwargs={'device': 'cpu'},\n",
    "    encode_kwargs={'normalize_embeddings': True}\n",
    ")\n",
    "\n",
    "print(\"✅ hugging-face 임베딩 모델 로딩 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a028453",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* ✅ hugging-face 임베딩 모델 로딩 완료! (`6.4s`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51291589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단계 4: 벡터스토어 생성하기\n",
    "vectorstore = FAISS.from_documents(\n",
    "    documents=splits,\n",
    "    embedding=embeddings\n",
    ")\n",
    "\n",
    "print(\"🎉 Hugginface model을 사용하여 로컬에서 벡터스토어(FAISS)가 성공적으로 생성되었습니다!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e57fec",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 🎉 Hugginface model을 사용하여 로컬에서 벡터스토어(FAISS)가 성공적으로 생성되었습니다!    (`0.3s`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7382d04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단계 5: 검색(Search)\n",
    "# 뉴스에 포함되어 있는 정보를 검색하고 생성하기\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3478052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검색기에 쿼리를 날려 검색된 chunk 결과 확인하기\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"      # 병렬처리 비활성화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ee8c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단계 6: 프롬프트 생성(Create Prompt)\n",
    "# 프롬프트 생성하기\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4e5daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6db7424",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* `print(prompt)` 확인\n",
    "    ```bash\n",
    "    input_variables=['context', 'question'] input_types={} partial_variables={} metadata={'lc_hub_owner': 'rlm', 'lc_hub_repo': 'rag-prompt', 'lc_hub_commit_hash': '50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6e'} messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"), additional_kwargs={})]\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d2e479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단계 7: 언어모델(LLM) 생성\n",
    "# 모델(LLM) 생성하기\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# API 키 확인\n",
    "if not os.getenv(\"GOOGLE_API_KEY\"):\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = input(\"Enter your Google API key: \")\n",
    "\n",
    "# LLM 초기화\n",
    "gemini_lc = ChatGoogleGenerativeAI(\n",
    "        model=\"gemini-2.5-flash-lite\",\n",
    "        temperature=0,                                              # temperature = 0으로 설정  \n",
    "        max_output_tokens=4096,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95e42b2",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* `LLM` 생성하기\n",
    "\n",
    "    ```bash\n",
    "    E0000 00:00:1759663618.303843  752051 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a18b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    # 검색한 문서 결과를 하나의 문단으로 합쳐서 출력\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbbd7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단계 8: 체인(Chain) 생성\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | gemini_lc\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694b98e0",
   "metadata": {},
   "source": [
    "* 생성된 체인에 **`쿼리`** (`질문`)을 입력 → 실행하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d730a3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단계 9: 체인 실행(Run Chain)\n",
    "# 문서에 대한 질의를 입력하고, 답변을 출력하기\n",
    "question = \"부영그룹의 출산 장려 정책에 대해 설명해주세요\"\n",
    "response = rag_chain.invoke(question)\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"URL: {url}\")\n",
    "print(f\"문서의 수: {len(docs)}\")\n",
    "print(\"===\" * 20)\n",
    "print(f\"[HUMAN]\\n{question}\\n\")\n",
    "print(f\"[AI]\\n{response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b34032c",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 체인 실행 결과  (`1.1s`)\n",
    "\n",
    "    ```markdown\n",
    "    URL: https://n.news.naver.com/article/437/0000378416\n",
    "    문서의 수: 1\n",
    "    ============================================================\n",
    "    [HUMAN]\n",
    "    부영그룹의 출산 장려 정책에 대해 설명해주세요\n",
    "\n",
    "    [AI]\n",
    "    부영그룹은 2021년 이후 태어난 직원 자녀에게 1억원을 지원하는 파격적인 출산 장려 정책을 발표했습니다. 또한, 셋째 자녀를 출산하는 직원에게는 국민주택을 제공하겠다는 계획도 밝혔습니다. 이러한 정책은 직원들의 경제적 부담을 줄여 출산을 장려하기 위한 것으로 보입니다.\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e46b21c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2257ead1",
   "metadata": {},
   "source": [
    "### **3. `단계 1`: `문서 로드`** *(Load Documents)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ff5bad",
   "metadata": {},
   "source": [
    "* *참고: [공식문서 링크 - Document loaders](https://python.langchain.com/docs/how_to/#document-loaders)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54e0b61",
   "metadata": {},
   "source": [
    "#### **1) `웹페이지`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f680b55a",
   "metadata": {},
   "source": [
    "* **`WebBaseLoader`** = 저장된 웹페에지에서 필요한 부분만을 파싱하기 위해 **`bs4.SoupStrainer`** 사용\n",
    "\n",
    "  * *`bs4.SoupStrainer` = 편리하게 웹에서 원하는 요소를 가져올 수 있도록 해줌*\n",
    "```python\n",
    "\n",
    "      bs4.SoupStrainer(\n",
    "          \"div\",\n",
    "          attrs={\"class\": [\"newsct_article _article_body\", \"media_end_head_title\"]}, # 클래스 명을 입력\n",
    "      )\n",
    "\n",
    "      bs4.SoupStrainer(\n",
    "          \"article\",\n",
    "          attrs={\"id\": [\"dic_area\"]}, # 클래스 명을 입력\n",
    "      )\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4271015a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test - BBC 기사\n",
    "\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://www.bbc.com/news/business-68092814\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            \"main\",\n",
    "            attrs={\"id\": [\"main-content\"]},\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "\n",
    "docs = loader.load()\n",
    "print(f\"문서의 수: {len(docs)}\")\n",
    "docs[0].page_content[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87976dae",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 문서의 수: 1    (`1.8s`)\n",
    "\n",
    "    ```markdown\n",
    "    'Could AI \\'trading bots\\' transform the world of investing?1 February 2024ShareSaveJonty BloomBusiness reporterShareSaveGetty ImagesIt is hard for both humans and computers to predict stock market movementsSearch for \"AI investing\" online, and you\\'ll be flooded with endless offers to let artificial intelligence manage your money.I recently spent half an hour finding out what so-called AI \"trading bots\" could apparently do with my investments.Many prominently suggest that they can give me lucrative'\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2fa6b8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8779687f",
   "metadata": {},
   "source": [
    "#### **2) `PDF`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d815d07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "# PDF 파일 로드. 파일의 경로 입력\n",
    "loader = PyPDFLoader(\"../12_RAG/data/SPRI_AI_Brief_2023년12월호_F.pdf\")\n",
    "\n",
    "# 페이지 별 문서 로드\n",
    "docs = loader.load()\n",
    "print(f\"문서의 수: {len(docs)}\")\n",
    "\n",
    "# 10번째 페이지의 내용 출력\n",
    "print(f\"\\n[페이지내용]\\n{docs[10].page_content[:500]}\")\n",
    "print(f\"\\n[metadata]\\n{docs[10].metadata}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecec81b8",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 문서의 수: 23  (`2.3s`)\n",
    "\n",
    "    ```markdown\n",
    "    [페이지내용]\n",
    "    SPRi AI Brief |  2023-12월호\n",
    "    8\n",
    "    코히어, 데이터 투명성 확보를 위한 데이터 출처 탐색기 공개n코히어와 12개 기관이  광범위한 데이터셋에 대한 감사를 통해 원본 데이터 출처, 재라이선스 상태, 작성자 등 다양한 정보를 제공하는 ‘데이터 출처 탐색기’ 플랫폼을 출시n대화형 플랫폼을 통해 개발자는 데이터셋의 라이선스 상태를 쉽게 파악할 수 있으며 데이터셋의 구성과 계보도 추적 가능\n",
    "    KEY Contents\n",
    "    £데이터 출처 탐색기, 광범위한 데이터셋 정보 제공을 통해 데이터 투명성 향상nAI 기업 코히어(Cohere)가 매사추세츠 공과⼤(MIT), 하버드⼤ 로스쿨, 카네기멜론⼤ 등 12개 기관과 함께 2023년 10월 25일 ‘데이터 출처 탐색기(Data Provenance Explorer)’ 플랫폼을 공개∙AI 모델 훈련에 사용되는 데이터셋의 불분명한 출처로 인해 데이터 투명성이 확보되지 않아 다양한 법적·윤리적 문제가 발생∙이에 연구진은 가장 널리 사용되는 2,000여\n",
    "\n",
    "    [metadata]\n",
    "    ```\n",
    "    ```python\n",
    "    {'producer': 'Hancom PDF 1.3.0.542', 'creator': 'Hwp 2018 10.0.0.13462', 'creationdate': '2023-12-08T13:28:38+09:00', 'author': 'dj', 'moddate': '2023-12-08T13:28:38+09:00', 'pdfversion': '1.4', 'source': '../12_RAG/data/SPRI_AI_Brief_2023년12월호_F.pdf', 'total_pages': 23, 'page': 10, 'page_label': '11'}\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5679deb",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd255764",
   "metadata": {},
   "source": [
    "#### **3) `CSV`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bc929d",
   "metadata": {},
   "source": [
    "* `CSV`는 페이지 번호 대신 **`행번호`** 로 데이터 조회하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0429f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "\n",
    "# CSV 파일 로드\n",
    "loader = CSVLoader(file_path=\"../12_RAG/data/titanic.csv\")\n",
    "docs = loader.load()\n",
    "print(f\"문서의 수: {len(docs)}\")\n",
    "\n",
    "# 10번째 페이지의 내용 출력\n",
    "print(f\"\\n[페이지내용]\\n{docs[10].page_content[:500]}\")\n",
    "print(f\"\\n[metadata]\\n{docs[10].metadata}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d169f5",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 문서의 수: 891   (`0.0s`)\n",
    "\n",
    "    ```markdown\n",
    "    [페이지내용]\n",
    "    PassengerId: 11\n",
    "    Survived: 1\n",
    "    Pclass: 3\n",
    "    Name: Sandstrom, Miss. Marguerite Rut\n",
    "    Sex: female\n",
    "    Age: 4\n",
    "    SibSp: 1\n",
    "    Parch: 1\n",
    "    Ticket: PP 9549\n",
    "    Fare: 16.7\n",
    "    Cabin: G6\n",
    "    Embarked: S\n",
    "\n",
    "    [metadata]\n",
    "    ```\n",
    "    ```python\n",
    "    {'source': '../12_RAG/data/titanic.csv', 'row': 10}\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2751b435",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00bd0066",
   "metadata": {},
   "source": [
    "#### **4) `TXT`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94bf71ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "loader = TextLoader(\"../12_RAG/data/appendix-keywords.txt\")\n",
    "\n",
    "docs = loader.load()\n",
    "print(f\"문서의 수: {len(docs)}\")\n",
    "\n",
    "# 10번째 페이지의 내용 출력\n",
    "print(f\"\\n[페이지내용]\\n{docs[0].page_content[:500]}\")\n",
    "print(f\"\\n[metadata]\\n{docs[0].metadata}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5aaf07",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 문서의 수: 1  (`0.0s`)\n",
    "\n",
    "    ```markdown\n",
    "    [페이지내용]\n",
    "    Semantic Search\n",
    "\n",
    "    정의: 의미론적 검색은 사용자의 질의를 단순한 키워드 매칭을 넘어서 그 의미를 파악하여 관련된 결과를 반환하는 검색 방식입니다.\n",
    "    예시: 사용자가 \"태양계 행성\"이라고 검색하면, \"목성\", \"화성\" 등과 같이 관련된 행성에 대한 정보를 반환합니다.\n",
    "    연관키워드: 자연어 처리, 검색 알고리즘, 데이터 마이닝\n",
    "\n",
    "    Embedding\n",
    "\n",
    "    정의: 임베딩은 단어나 문장 같은 텍스트 데이터를 저차원의 연속적인 벡터로 변환하는 과정입니다. 이를 통해 컴퓨터가 텍스트를 이해하고 처리할 수 있게 합니다.\n",
    "    예시: \"사과\"라는 단어를 [0.65, -0.23, 0.17]과 같은 벡터로 표현합니다.\n",
    "    연관키워드: 자연어 처리, 벡터화, 딥러닝\n",
    "\n",
    "    Token\n",
    "\n",
    "    정의: 토큰은 텍스트를 더 작은 단위로 분할하는 것을 의미합니다. 이는 일반적으로 단어, 문장, 또는 구절일 수 있습니다.\n",
    "    예시: 문장 \"나는 학교에 간다\"를 \"나는\", \"학교에\", \"간다\"로 분할합니다.\n",
    "    연관키워드: 토큰화, 자연어\n",
    "\n",
    "    [metadata]\n",
    "    ```\n",
    "    ```python\n",
    "    {'source': '../12_RAG/data/appendix-keywords.txt'}\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a0c278",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce03c1d",
   "metadata": {},
   "source": [
    "#### **5) `폴더 내의 모든 파일 로드`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e07b2c3",
   "metadata": {},
   "source": [
    "* 폴더 내의 모든 `.txt` 파일을 로드하는 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fe7f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "\n",
    "loader = DirectoryLoader(\"../12_RAG/data\", glob=\"*.txt\", show_progress=True)\n",
    "docs = loader.load()\n",
    "\n",
    "print(f\"문서의 수: {len(docs)}\")\n",
    "\n",
    "# 10번째 페이지의 내용 출력\n",
    "print(f\"\\n[페이지내용]\\n{docs[0].page_content[:500]}\")\n",
    "print(f\"\\n[metadata]\\n{docs[0].metadata}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5aea50",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 상대 경로 수정 → 해당 경로에서 모든 `.txt` 파일 로드하기  (`3.4s`)\n",
    "\n",
    "    ```markdown\n",
    "    0%|          | 0/6 [00:00<?, ?it/s]libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n",
    "    17%|█▋        | 1/6 [00:03<00:16,  3.26s/it]libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n",
    "    libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n",
    "    libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n",
    "    libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n",
    "    83%|████████▎ | 5/6 [00:03<00:00,  1.96it/s]libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n",
    "    100%|██████████| 6/6 [00:03<00:00,  1.76it/s]\n",
    "    \n",
    "    문서의 수: 6\n",
    "\n",
    "    [페이지내용]\n",
    "    Semantic Search\n",
    "\n",
    "    정의: 의미론적 검색은 사용자의 질의를 단순한 키워드 매칭을 넘어서 그 의미를 파악하여 관련된 결과를 반환하는 검색 방식입니다. 예시: 사용자가 \"태양계 행성\"이라고 검색하면, \"목성\", \"화성\" 등과 같이 관련된 행성에 대한 정보를 반환합니다. 연관키워드: 자연어 처리, 검색 알고리즘, 데이터 마이닝\n",
    "\n",
    "    Embedding\n",
    "\n",
    "    정의: 임베딩은 단어나 문장 같은 텍스트 데이터를 저차원의 연속적인 벡터로 변환하는 과정입니다. 이를 통해 컴퓨터가 텍스트를 이해하고 처리할 수 있게 합니다. 예시: \"사과\"라는 단어를 [0.65, -0.23, 0.17]과 같은 벡터로 표현합니다. 연관키워드: 자연어 처리, 벡터화, 딥러닝\n",
    "\n",
    "    Token\n",
    "\n",
    "    정의: 토큰은 텍스트를 더 작은 단위로 분할하는 것을 의미합니다. 이는 일반적으로 단어, 문장, 또는 구절일 수 있습니다. 예시: 문장 \"나는 학교에 간다\"를 \"나는\", \"학교에\", \"간다\"로 분할합니다. 연관키워드: 토큰화, 자연어\n",
    "\n",
    "    [metadata]\n",
    "    ```\n",
    "    ```python\n",
    "    {'source': '../12_RAG/data/appendix-keywords-CP949.txt'}\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1a9edf",
   "metadata": {},
   "source": [
    "* 폴더 내 모든 `.pdf` 파일 로드하는 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73f9a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "\n",
    "loader = DirectoryLoader(\"../12_RAG/data\", glob=\"*.pdf\")\n",
    "docs = loader.load()\n",
    "\n",
    "print(f\"문서의 수: {len(docs)}\\n\")\n",
    "print(\"[메타데이터]\\n\")\n",
    "print(docs[0].metadata)\n",
    "print(\"\\n========= [앞부분] 미리보기 =========\\n\")\n",
    "print(docs[0].page_content[2500:3000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db576ca3",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* Warning: No languages specified, defaulting to English.\n",
    "* 문서의 수: 1  (`29.1s`)\n",
    "\n",
    "    ```markdown\n",
    "    [메타데이터]\n",
    "    ```\n",
    "\n",
    "    ```python\n",
    "    {'source': '../12_RAG/data/SPRI_AI_Brief_2023년12월호_F.pdf'}\n",
    "    ```\n",
    "\n",
    "    ```markdown\n",
    "    ========= [앞부분] 미리보기 =========\n",
    "\n",
    "    하는 기업에게 안전 테스트 결과와 시스템에 관한\n",
    "\n",
    "    주요 정보를 미국 정부와 공유할 것을 요구하고, AI 시스템의 안전성과 신뢰성 확인을 위한 표준 및\n",
    "\n",
    "    AI 생성 콘텐츠 표시를 위한 표준과 모범사례 확립을 추진\n",
    "\n",
    "    △1026 플롭스(FLOPS, Floating Point Operation Per Second)를 초과하는 컴퓨팅 성능 또는 생물학적 서열 데이터를 주로 사용하고 1023플롭스를 초과하는 컴퓨팅 성능을 사용하는 모델 △단일 데이터센터에서 1,000Gbit/s 이상의 네트워킹으로 연결되며 AI 훈련에서 이론상 최대 1020 플롭스를 처리할 수 있는 컴퓨팅 용량을 갖춘 컴퓨팅 클러스터가 정보공유 요구대상\n",
    "\n",
    "    n (형평성과 시민권 향상) 법률, 주택, 보건 분야에서 AI의 무책임한 사용으로 인한 차별과 편견 및 기타\n",
    "\n",
    "    문제를 방지하는 조치를 확대\n",
    "\n",
    "    형사사법 시스템에서 AI 사용 모범사례를 개발하고, 주택 임대 시 AI 알고리즘 차별을 막기 위한 명확한\n",
    "\n",
    "    지침을 제공하며, 보건복지\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f63973",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2787bb6f",
   "metadata": {},
   "source": [
    "#### **6) `Python`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e912d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PythonLoader\n",
    "\n",
    "loader = DirectoryLoader(\"../12_RAG/data\", glob=\"*.py\", loader_cls=PythonLoader)\n",
    "docs = loader.load()\n",
    "\n",
    "print(f\"문서의 수: {len(docs)}\\n\")\n",
    "print(\"[메타데이터]\\n\")\n",
    "print(docs[0].metadata)\n",
    "print(\"\\n========= [앞부분] 미리보기 =========\\n\")\n",
    "print(docs[0].page_content[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d222b885",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 문서의 수: 1 (`0.0s`)\n",
    "\n",
    "    ```markdown\n",
    "    [메타데이터]\n",
    "    ```\n",
    "    ```python\n",
    "    {'source': '../12_RAG/data/audio_utils.py'}\n",
    "    ```\n",
    "\n",
    "    ```markdown\n",
    "    ========= [앞부분] 미리보기 =========\n",
    "    ```\n",
    "\n",
    "    ```python\n",
    "    import re\n",
    "    import os\n",
    "    from pytube import YouTube\n",
    "    from moviepy.editor import AudioFileClip, VideoFileClip\n",
    "    from pydub import AudioSegment\n",
    "    from pydub.silence import detect_nonsilent\n",
    "\n",
    "\n",
    "    def extract_abr(abr):\n",
    "        youtube_audio_pattern = re.compile(r\"\\d+\")\n",
    "        kbps = youtube_audio_pattern.search(abr)\n",
    "        if kbps:\n",
    "            kbps = kbps.group()\n",
    "            return int(kbps)\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "\n",
    "    def get_audio_filepath(filename):\n",
    "        # audio 폴더가 없으면 생성\n",
    "        if not os.path.isdir(\"audio\"):\n",
    "            os.mkdir(\"au\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063c80cb",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8d743e",
   "metadata": {},
   "source": [
    "### **4. `단계 2`: `문서 분할`** *(Split Documents)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a097ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 뉴스기사의 내용 로드, 청크 나누기, 인덱싱\n",
    "\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://www.bbc.com/news/business-68092814\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            \"main\",\n",
    "            attrs={\"id\": [\"main-content\"]},\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "\n",
    "docs = loader.load()\n",
    "print(f\"문서의 수: {len(docs)}\")\n",
    "docs[0].page_content[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbde85dd",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 문서의 수: 1   (`0.4s`)\n",
    "\n",
    "    ```markdown\n",
    "    'Could AI \\'trading bots\\' transform the world of investing?1 February 2024ShareSaveJonty BloomBusiness reporterShareSaveGetty ImagesIt is hard for both humans and computers to predict stock market movementsSearch for \"AI investing\" online, and you\\'ll be flooded with endless offers to let artificial intelligence manage your money.I recently spent half an hour finding out what so-called AI \"trading bots\" could apparently do with my investments.Many prominently suggest that they can give me lucrative'\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9021779",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8bf47b",
   "metadata": {},
   "source": [
    "#### **1) `CharacterTextSplitter`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54a8f11",
   "metadata": {},
   "source": [
    "* **`가장 간단한 방법` = `문자 기준으로 분할`**\n",
    "\n",
    "  * 기본값: **`\"\\n\\n\"`**\n",
    "\n",
    "  * **`청크 길이` = `문자의 수`로 측정**\n",
    "    * 텍스트가 어떻게 분할되는지: **`단일 문자 단위`**\n",
    "    * 청크 크기가 어떻게 측정되는지: **`len of characters`**\n",
    "\n",
    "  * *[시각화 에제](https://chunkviz.up.railway.app/)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62e9488",
   "metadata": {},
   "source": [
    "* **`CharacterTextSplitter` 클래스** = 텍스트를 특정 크기의 청크로 분할하는 기능 제공\n",
    "\n",
    "  * **`separator`** 매개변수\n",
    "    * 청크를 구분하는 데 사용되는 문자열을 지정\n",
    "    * 두 개의 개행 문자( **`\"\\n\\n\"`** )를 사용\n",
    "\n",
    "  * **`chunk_size`** = 각 청크의 `최대 길이` 결정\n",
    "\n",
    "  * **`chunk_overlap`** = 인접한 청크 간에 `겹치는 문자의 수` 지정\n",
    "\n",
    "  * **`length_function`** \n",
    "    * `청크의 길이`를 `계산`하는 데 사용되는 함수\n",
    "    * 기본적으로 문자열의 길이를 반환하는 **`len 함수` 사용**\n",
    "\n",
    "  * **`is_separator_regex`** = `separator`가 `정규 표현식`으로 `해석`될지 `여부`를 `결정`하는 `불리언 값`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3253d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\\n\",           # 청크 구분 문자열\n",
    "    chunk_size=100,             # 청크 최대 길이 (청크 사이즈)\n",
    "    chunk_overlap=10,           # 청크 겹치기 허용\n",
    "    length_function=len,        # 청크 길이 계산 함수\n",
    "    is_separator_regex=False,   # 정규 표현식으로 해석 X\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a5bd5e",
   "metadata": {},
   "source": [
    "* **`text_splitter`** 객체의 **`create_documents`** 메소드 사용 → 주어진 텍스트 (`state_of_the_union`)를 여러 문서로 분할 → 그 결과를 **`texts`** 변수에 저장 → 이후 `texts`의 첫 번째 문서를 출력하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a45631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chain of density 논문의 일부 내용을 불러오기\n",
    "\n",
    "with open(\"../12_RAG/data/chain-of-density.txt\", \"r\") as f:\n",
    "    text = f.read()[:500]\n",
    "\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    chunk_size=100, \n",
    "    chunk_overlap=10, \n",
    "    separator=\"\\n\\n\"            # 기본 청크 구분 단위 (문단 단위)\n",
    ")\n",
    "\n",
    "text_splitter.split_text(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462b0869",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 기본 청크 구분 단위 = **`문단 단위`**\n",
    "\n",
    "    ```markdown\n",
    "    ['Selecting the “right” amount of information to include in a summary is a difficult task. \\nA good summary should be detailed and entity-centric without being overly dense and hard to follow. To better understand this tradeoff, we solicit increasingly dense GPT-4 summaries with what we refer to as a “Chain of Density” (CoD) prompt. Specifically, GPT-4 generates an initial entity-sparse summary before iteratively incorporating missing salient entities without increasing the length. Summaries genera']\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d0406a",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = CharacterTextSplitter(\n",
    "    chunk_size=100, \n",
    "    chunk_overlap=10, \n",
    "    separator=\"\\n\"              # 청크 구분 문자열 변경 (줄 단위)\n",
    "    )\n",
    "\n",
    "text_splitter.split_text(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59971ab2",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 청크 구분 문자열 = **`줄 단위`**\n",
    "\n",
    "    ```markdown\n",
    "    ['Selecting the “right” amount of information to include in a summary is a difficult task.',\n",
    "    'A good summary should be detailed and entity-centric without being overly dense and hard to follow. To better understand this tradeoff, we solicit increasingly dense GPT-4 summaries with what we refer to as a “Chain of Density” (CoD) prompt. Specifically, GPT-4 generates an initial entity-sparse summary before iteratively incorporating missing salient entities without increasing the length. Summaries genera']\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1153cc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = CharacterTextSplitter(\n",
    "    chunk_size=100, \n",
    "    chunk_overlap=10,\n",
    "    separator=\" \"              # 청크 구분 문자열 변경 (공백 단위)\n",
    "    )\n",
    "\n",
    "text_splitter.split_text(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff43214e",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 청크 구분 문자열 = **`공백 단위`**\n",
    "\n",
    "    ```markdown\n",
    "    ['Selecting the “right” amount of information to include in a summary is a difficult task. \\nA good',\n",
    "    'A good summary should be detailed and entity-centric without being overly dense and hard to follow.',\n",
    "    'to follow. To better understand this tradeoff, we solicit increasingly dense GPT-4 summaries with',\n",
    "    'with what we refer to as a “Chain of Density” (CoD) prompt. Specifically, GPT-4 generates an initial',\n",
    "    'an initial entity-sparse summary before iteratively incorporating missing salient entities without',\n",
    "    'without increasing the length. Summaries genera']\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddff2f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = CharacterTextSplitter(\n",
    "    chunk_size=100, \n",
    "    chunk_overlap=0,           # 청크 중복 허용 X \n",
    "    separator=\" \"              # 청크 구분 문자열 변경 (공백 단위)\n",
    "    )\n",
    "\n",
    "text_splitter.split_text(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3432b7a",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 청크 중복 허용 X\n",
    "\n",
    "    ```markdown\n",
    "    ['Selecting the “right” amount of information to include in a summary is a difficult task. \\nA good',\n",
    "    'summary should be detailed and entity-centric without being overly dense and hard to follow. To',\n",
    "    'better understand this tradeoff, we solicit increasingly dense GPT-4 summaries with what we refer to',\n",
    "    'as a “Chain of Density” (CoD) prompt. Specifically, GPT-4 generates an initial entity-sparse summary',\n",
    "    'before iteratively incorporating missing salient entities without increasing the length. Summaries',\n",
    "    'genera']\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c08b4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = CharacterTextSplitter(\n",
    "    chunk_size=1000,           # 청크 단위 = 크게 잡음\n",
    "    chunk_overlap=100,         # 청크 중복 크게 허용 \n",
    "    separator=\" \"              # 청크 구분 문자열 변경 (공백 단위)\n",
    "    )\n",
    "\n",
    "# text 파일을 청크로 나누기\n",
    "text_splitter.split_text(text)\n",
    "\n",
    "# document를 청크로 나누기\n",
    "split_docs = text_splitter.split_documents(docs)\n",
    "len(split_docs)                # 8 \n",
    "print(f\"분할된 문서의 수: {len(split_docs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9139698a",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 분할된 문서의 수: 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ebca00",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(split_docs))         # <class 'list'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bb9226",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_docs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c85aae",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 새롭게 분할한 문서 내용 \n",
    "\n",
    "    ```python\n",
    "    Document(metadata={'source': 'https://www.bbc.com/news/business-68092814'}, page_content='Could AI \\'trading bots\\' transform the world of investing?1 February 2024ShareSaveJonty BloomBusiness reporterShareSaveGetty ImagesIt is hard for both humans and computers to predict stock market movementsSearch for \"AI investing\" online, and you\\'ll be flooded with endless offers to let artificial intelligence manage your money.I recently spent half an hour finding out what so-called AI \"trading bots\" could apparently do with my investments.Many prominently suggest that they can give me lucrative returns. Yet as every reputable financial firm warns - your capital may be at risk.Or putting it more simply - you could lose your money - whether it is a human or a computer that is making stock market decisions on your behalf.Yet such has been the hype about the ability of AI over the past few years, that almost one in three investors would be happy to let a trading bot make all the decisions for them, according to one 2023 survey in the US.John Allan says investors should be more cautious')\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6797759e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 뉴스기사의 내용 로드, 청크 나누기, 인덱싱\n",
    "\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://www.bbc.com/news/business-68092814\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            \"main\",\n",
    "            attrs={\"id\": [\"main-content\"]},\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "\n",
    "# splitter 정의하기\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    chunk_size=1000, \n",
    "    chunk_overlap=100, \n",
    "    separator=\" \"\n",
    ")\n",
    "\n",
    "# 문서를 로드시 바로 분할까지 수행합하기\n",
    "split_docs = loader.load_and_split(text_splitter=text_splitter)\n",
    "print(f\"문서의 수: {len(docs)}\")\n",
    "docs[0].page_content[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ebce1e7",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 문서의 수: 1  (`2.3s`)\n",
    "\n",
    "    ```markdown\n",
    "    'Could AI \\'trading bots\\' transform the world of investing?1 February 2024ShareSaveJonty BloomBusiness reporterShareSaveGetty ImagesIt is hard for both humans and computers to predict stock market movementsSearch for \"AI investing\" online, and you\\'ll be flooded with endless offers to let artificial intelligence manage your money.I recently spent half an hour finding out what so-called AI \"trading bots\" could apparently do with my investments.Many prominently suggest that they can give me lucrative'\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1974fefa",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e4ec16",
   "metadata": {},
   "source": [
    "#### **2) `RecursiveTextSplitter`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9f1b9f",
   "metadata": {},
   "source": [
    "* **`일반 텍스트에 권장되는 텍스트 분할기`**\n",
    "\n",
    "  * 텍스트가 어떻게 분할 규칙: **`list of separators`**\n",
    "\n",
    "  * 청크 크기가 어떻게 측정되는가: **`len of characters`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8e396a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# langchain 패키지에서 RecursiveCharacterTextSplitter 클래스 가져오기\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19cac799",
   "metadata": {},
   "source": [
    "* **`RecursiveCharacterTextSplitter` 클래스** = 텍스트를 `재귀적으로 분할`하는 기능 제공\n",
    "\n",
    "  * **`chunk_size`** = 분할할 청크의 크기\n",
    "  * **`chunk_overlap`** = 인접 청크 간의 겹침 크기\n",
    "  * **`length_function`** = 청크의 길이를 계산하는 함수\n",
    "  * **`is_separator_regex`** = 구분자가 정규 표현식인지 여부를 지정하는 매개변수\n",
    "\n",
    "    * *예시: 청크 크기를 100, 겹침 크기를 20으로 설정하고, 길이 계산 함수로 `len`을 사용하며, 구분자가 정규 표현식이 아님을 나타내기 위해 `is_separator_regex`를 `False`로 설정*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f7df45",
   "metadata": {},
   "outputs": [],
   "source": [
    "recursive_text_splitter = RecursiveCharacterTextSplitter(\n",
    "    # 정말 작은 청크 크기로 설정\n",
    "    chunk_size=100,\n",
    "    chunk_overlap=10,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d3a3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chain of density 논문의 일부 내용을 불러오기\n",
    "with open(\"../12_RAG/data/chain-of-density.txt\", \"r\") as f:\n",
    "    text = f.read()[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8761dd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# character text splitter\n",
    "character_text_splitter = CharacterTextSplitter(\n",
    "    chunk_size=100, \n",
    "    chunk_overlap=10, \n",
    "    separator=\" \"\n",
    ")\n",
    "\n",
    "for sent in character_text_splitter.split_text(text):\n",
    "    print(sent)\n",
    "print(\"===\" * 20)\n",
    "\n",
    "\n",
    "# recursive_text_splitter\n",
    "recursive_text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=100, \n",
    "    chunk_overlap=10\n",
    ")\n",
    "\n",
    "for sent in recursive_text_splitter.split_text(text):\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc52c211",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* `character text splitter`\n",
    "    ```markdown\n",
    "    Selecting the “right” amount of information to include in a summary is a difficult task. \n",
    "    A good\n",
    "    A good summary should be detailed and entity-centric without being overly dense and hard to follow.\n",
    "    to follow. To better understand this tradeoff, we solicit increasingly dense GPT-4 summaries with\n",
    "    with what we refer to as a “Chain of Density” (CoD) prompt. Specifically, GPT-4 generates an initial\n",
    "    an initial entity-sparse summary before iteratively incorporating missing salient entities without\n",
    "    without increasing the length. Summaries genera\n",
    "    ============================================================\n",
    "    ```\n",
    "\n",
    "* `recursive_text_splitter`\n",
    "\n",
    "    ```markdown\n",
    "    Selecting the “right” amount of information to include in a summary is a difficult task.\n",
    "    A good summary should be detailed and entity-centric without being overly dense and hard to follow.\n",
    "    follow. To better understand this tradeoff, we solicit increasingly dense GPT-4 summaries with what\n",
    "    with what we refer to as a “Chain of Density” (CoD) prompt. Specifically, GPT-4 generates an\n",
    "    an initial entity-sparse summary before iteratively incorporating missing salient entities without\n",
    "    without increasing the length. Summaries genera\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b25df96",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754d9b1a",
   "metadata": {},
   "source": [
    "#### **3) `Semantic Similarity`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d700f9",
   "metadata": {},
   "source": [
    "* **`의미적 유사성을 기준`** → 텍스트 분할\n",
    "\n",
    "  * 출처 : [Greg Kamradt's Notebook](https://github.com/FullStackRetrieval-com/RetrievalTutorials/blob/main/tutorials/LevelsOfTextSplitting/5_Levels_Of_Text_Splitting.ipynb)\n",
    "\n",
    "  * `높은 수준` (`high level`)에서 문장으로 분할 → **`3개의 문장으로 그룹화`** → **`임베딩 공간`** → **`유사한 문장`을 `병합`하는 방식**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ffe703",
   "metadata": {},
   "source": [
    "* 사전 `VS Code` 터미널에서 설치할 것\n",
    "```bash\n",
    "\n",
    "        pip install -U langchain langchain_experimental -q\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde447e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "# SemanticChunker 생성하기\n",
    "semantic_text_splitter = SemanticChunker(\n",
    "    embeddings, \n",
    "    add_start_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575a02ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chain of density 논문의 일부 내용 불러오기\n",
    "with open(\"data/chain-of-density.txt\", \"r\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "for sent in semantic_text_splitter.split_text(text):\n",
    "    print(sent,\"\\n\")\n",
    "    print(\"\\n\", \"===\" * 20,\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d38a90",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* `Sementic Similarity` (`0.4s`)\n",
    "\n",
    "    ```markdown\n",
    "    Selecting the “right” amount of information to include in a summary is a difficult task. A good summary should be detailed and entity-centric without being overly dense and hard to follow. To better understand this tradeoff, we solicit increasingly dense GPT-4 summaries with what we refer to as a “Chain of Density” (CoD) prompt. Specifically, GPT-4 generates an initial entity-sparse summary before iteratively incorporating missing salient entities without increasing the length. Summaries generated by CoD are more abstractive, exhibit more fusion, and have less of a lead bias than GPT-4 summaries generated by a vanilla prompt. We conduct a human preference study on 100 CNN DailyMail articles and find that that humans prefer GPT-4 summaries that are more dense than those generated by a vanilla prompt and almost as dense as human written summaries. Qualitative analysis supports the notion that there exists a tradeoff between infor-mativeness and readability. 500 annotated CoD summaries, as well as an extra 5,000 unannotated summaries, are freely available on HuggingFace. Introduction\n",
    "\n",
    "    Automatic summarization has come a long way in the past few years, largely due to a paradigm shift away from supervised fine-tuning on labeled datasets to zero-shot prompting with Large Language Models (LLMs), such as GPT-4 (OpenAI, 2023). Without additional training, careful prompting can enable fine-grained control over summary characteristics, such as length (Goyal et al., 2022), topics (Bhaskar et al., 2023), and style (Pu and Demberg, 2023). An overlooked aspect is the information density of an summary. In theory, as a compression of another text, a summary should be denser–containing a higher concentration of information–than the source document. Given the high latency of LLM decoding (Kad-dour et al., 2023), covering more information in fewer words is a worthy goal, especially for real-time applications. Yet, how dense is an open question. \n",
    "\n",
    "\n",
    "    ============================================================ \n",
    "\n",
    "    A summary is uninformative if it contains insufficient detail. If it contains too much information, however, it can be-come difficult to follow without having to increase the overall length. Conveying more information subject to a fixed token budget requires a combination of abstrac-tion, compression, and fusion. There is a limit to how much space can be made for additional information before becoming illegible or even factually incorrect. \n",
    "\n",
    "\n",
    "    ============================================================\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18c3c5f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d64807",
   "metadata": {},
   "source": [
    "### **3. `단계 3`: `임베딩`** *(Embedding)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051c91f3",
   "metadata": {},
   "source": [
    "#### **1) `유료 과금 임베딩`** *(OpenAI)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3987d5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "\n",
    "# 단계 3: 임베딩 & 벡터스토어 생성(Create Vectorstore)\n",
    "# 벡터스토어 생성하기\n",
    "vectorstore = FAISS.from_documents(\n",
    "    documents=splits, embedding=OpenAIEmbeddings())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbfb66b",
   "metadata": {},
   "source": [
    "* **`OpenAI`** `Embeddding` 모델들의 목록\n",
    "\n",
    "  * 기본값 = `text-embedding-ada-002`\n",
    "\n",
    "  * ![openai-embedding-model](../12_RAG/images/openai-embedding-model.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848cf6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = FAISS.from_documents(\n",
    "    documents=splits, embedding=OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7fa8d02",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* Warning: model not found. Using cl100k_base encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c781665",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34acb9ec",
   "metadata": {},
   "source": [
    "#### **2) `무료 Open Source 기반 임베딩`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64536899",
   "metadata": {},
   "source": [
    "* 사전에 `VS Code` 터미널에 설치할 것\n",
    "```bash\n",
    "\n",
    "        pip install fastembed -q\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7912167",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
    "\n",
    "# 단계 3: 임베딩 & 벡터스토어 생성(Create Vectorstore)\n",
    "# 벡터스토어 생성하기\n",
    "vectorstore = FAISS.from_documents(\n",
    "    documents=splits, embedding=HuggingFaceBgeEmbeddings()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6294db",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* `HuggingFaceBgeEmbeddings` 설치 결과 (`1m 32.6s`)\n",
    "\n",
    "  * ![설치 결과](../12_RAG/images/huggingface-embedding-bge.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1acb5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings.fastembed import FastEmbedEmbeddings\n",
    "\n",
    "vectorstore = FAISS.from_documents(\n",
    "    documents=splits, \n",
    "    embedding=FastEmbedEmbeddings())        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e572cd",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* FastEmbedEmbeddings 설치 결과 (`11.3s`)\n",
    "\n",
    "  * ![설치 결과](../12_RAG/images/FastEmbedEmbeddings.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9322b24",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5386c88",
   "metadata": {},
   "source": [
    "### **4. `단계 4`: `벡터스토어 생성`** *(Create Vectorstore)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ffec45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# FAISS DB 적용\n",
    "vectorstore = FAISS.from_documents(\n",
    "    documents=splits, embedding=embeddings)                 # 0.3s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5ca757",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "# Chroma DB 적용\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=splits, embedding=embeddings)                 # 2.3s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e11cd4",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5cda4a0",
   "metadata": {},
   "source": [
    "### **5. `단계 5`: `Retriever 생성`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9bc73e",
   "metadata": {},
   "source": [
    "* **`Retriever`**\n",
    "\n",
    "  * 구조화되지 않은 쿼리가 주어지면 문서를 반환하는 인터페이스\n",
    "\n",
    "  * 문서를 저장할 필요 없이 문서를 반환(또는 검색)\n",
    "\n",
    "    * *참고: [공식 도큐먼트](https://python.langchain.com/docs/how_to/#retrievers)*\n",
    "\n",
    "  * 생성된 VectorStore에 **`as_retriever()`** 로 가져와서 **`Retriever`를 생성**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b07f84f",
   "metadata": {},
   "source": [
    "#### **1) `유사도 기반 검색`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f53956",
   "metadata": {},
   "source": [
    "* 기본값 = **`코사인 유사도`** = **`similarity`** 적용됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86fafb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"회사의 저출생 정책이 뭐야?\"\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_type=\"similarity\")\n",
    "search_result = retriever.get_relevant_documents(query)\n",
    "print(search_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c903ca",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 유사도 기반 검색 (`0.1s`)\n",
    "\n",
    "    ```python\n",
    "    [Document(metadata={'source': 'https://n.news.naver.com/article/437/0000378416'}, page_content=\"출산 직원에게 '1억원' 쏜다…회사의 파격적 저출생 정책\"), Document(metadata={'source': 'https://n.news.naver.com/article/437/0000378416'}, page_content=\"[앵커]올해 아이 낳을 계획이 있는 가족이라면 솔깃할 소식입니다. 정부가 저출생 대책으로 매달 주는 부모 급여, 0세 아이는 100만원으로 올렸습니다. 여기에 첫만남이용권, 아동수당까지 더하면 아이 돌까지 1년 동안 1520만원을 받습니다. 지자체도 경쟁하듯 지원에 나섰습니다. 인천시는 새로 태어난 아기, 18살될 때까지 1억원을 주겠다. 광주시도 17살될 때까지 7400만원 주겠다고 했습니다. 선거 때면 나타나서 아이 낳으면 현금 주겠다고 밝힌 사람이 있었죠. 과거에는 표만 노린 '황당 공약'이라는 비판이 따라다녔습니다. 그런데 지금은 출산율이 이보다 더 나쁠 수 없다보니, 이런 현금성 지원을 진지하게 정책화 하는 상황까지 온 겁니다. 게다가 기업들도 뛰어들고 있습니다. 이번에는 출산한 직원에게 단번에 1억원을 주겠다는 회사까지 나타났습니다.이상화 기자가 취재했습니다.[기자]한 그룹사가 오늘 파격적인 저출생 정책을 내놨습니다.2021년 이후 태어난 직원 자녀에 1억원씩, 총 70억원을 지원하고 앞으로도 이 정책을 이어가기로 했습니다.해당 기간에 연년생과 쌍둥이 자녀가 있으면 총 2억원을 받게 됩니다.[오현석/부영그룹 직원 : 아이 키우는 데 금전적으로 많이 힘든 세상이잖아요. 교육이나 생활하는 데 큰 도움이 될 거라 생각합니다.]만약 셋째까지 낳는 경우엔 국민주택을 제공하겠다는 뜻도 밝혔습니다.[이중근/부영그룹 회장 : 3년 이내에 세 아이를 갖는 분이 나올 것이고 따라서 주택을 제공할 수 있는 계기가 될 것으로 생각하고.][조용현/부영그룹 직원 : 와이프가 셋째도 갖고 싶어 했는데 경제적 부담 때문에 부정적이었거든요. (이제) 긍정적으로 생각할 수 있을 것 같습니다.]오늘 행사에서는, 회사가 제공하는 출산장려금은 받는 직원들의 세금 부담을 고려해 정부가 면세해달라는 제안도 나왔습니다.이같은 출산장려책은 점점 확산하는 분위기입니다.법정기간보다 육아휴직을 길게 주거나, 남성 직원의 육아휴직을 의무화한 곳도 있습니다.사내 어린이집을 밤 10시까지 운영하고\"), Document(metadata={'source': 'https://n.news.naver.com/article/437/0000378416'}, page_content='남성 직원의 육아휴직을 의무화한 곳도 있습니다.사내 어린이집을 밤 10시까지 운영하고 셋째를 낳으면 무조건 승진시켜 주기도 합니다.한 회사는 지난해 네쌍둥이를 낳은 직원에 의료비를 지원해 관심을 모았습니다.정부 대신 회사가 나서는 출산장려책이 사회적 분위기를 바꿀 거라는 기대가 커지는 가운데, 여력이 부족한 중소지원이 필요하다는 목소리도 나옵니다.[영상디자인 곽세미]')]\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb45d7b",
   "metadata": {},
   "source": [
    "* **`similarity_score_threshold`** = 유사도 기반 검색에서 **`score_threshold`** 이상인 결과만 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30817328",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"회사의 저출생 정책이 뭐야?\"\n",
    "\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity_score_threshold\", \n",
    "    search_kwargs={\"score_threshold\": 0.4}\n",
    ")\n",
    "\n",
    "search_result = retriever.get_relevant_documents(query)\n",
    "\n",
    "print(search_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881b454f",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* **`score_threshold`** = 0.4 로 조정\n",
    "  * *`score_threshold` = 0.8로 조정 시 나오지 않음*\n",
    "\n",
    "    ```python\n",
    "    [Document(metadata={'source': 'https://n.news.naver.com/article/437/0000378416'}, page_content=\"출산 직원에게 '1억원' 쏜다…회사의 파격적 저출생 정책\")]\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17bfe3e5",
   "metadata": {},
   "source": [
    "* **`MMR`** *(maximum marginal search result)* 사용해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33994a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"회사의 저출생 정책이 뭐야?\"\n",
    "\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"mmr\",                      # 검색유형을 MMR로 바꾸기\n",
    "    search_kwargs={\"k\": 2}\n",
    "    )\n",
    "\n",
    "search_result = retriever.get_relevant_documents(query)\n",
    "\n",
    "print(search_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56cb934f",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* **`MMR`**\n",
    "\n",
    "    ```python\n",
    "    [Document(metadata={'source': 'https://n.news.naver.com/article/437/0000378416'}, page_content=\"출산 직원에게 '1억원' 쏜다…회사의 파격적 저출생 정책\"), Document(metadata={'source': 'https://n.news.naver.com/article/437/0000378416'}, page_content='남성 직원의 육아휴직을 의무화한 곳도 있습니다.사내 어린이집을 밤 10시까지 운영하고 셋째를 낳으면 무조건 승진시켜 주기도 합니다.한 회사는 지난해 네쌍둥이를 낳은 직원에 의료비를 지원해 관심을 모았습니다.정부 대신 회사가 나서는 출산장려책이 사회적 분위기를 바꿀 거라는 기대가 커지는 가운데, 여력이 부족한 중소지원이 필요하다는 목소리도 나옵니다.[영상디자인 곽세미]')]\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b194b67",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc7e6fd",
   "metadata": {},
   "source": [
    "#### **2) `다양한 쿼리 생성`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83055245",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# API 키 확인\n",
    "if not os.getenv(\"GOOGLE_API_KEY\"):\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = input(\"Enter your Google API key: \")\n",
    "\n",
    "# LLM 초기화\n",
    "gemini_lc = ChatGoogleGenerativeAI(\n",
    "        model=\"gemini-2.5-flash-lite\",\n",
    "        temperature=0,                                              # temperature = 0으로 설정  \n",
    "        max_output_tokens=4096,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0c107c",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"회사의 저출생 정책이 뭐야?\"\n",
    "\n",
    "retriever_from_llm = MultiQueryRetriever.from_llm(\n",
    "    retriever=vectorstore.as_retriever(), llm=gemini_lc\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b86d6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set logging for the queries\n",
    "import logging\n",
    "\n",
    "logging.basicConfig()\n",
    "logging.getLogger(\"langchain.retrievers.multi_query\").setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578da4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(unique_docs))                    # <class 'list'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e68b16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_docs = retriever_from_llm.get_relevant_documents(query=question)\n",
    "len(unique_docs)\n",
    "print(f\"문서의 수: {len(unique_docs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9260f8fc",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 문서의 수: 3  (`1.3s`)\n",
    "\n",
    "    ```python\n",
    "    INFO:langchain.retrievers.multi_query:Generated queries: ['부영그룹의 저출산 대책은 무엇인가요?', '부영그룹이 출산을 장려하기 위해 시행하는 정책들을 알려주세요.', '부영그룹의 출산 지원 정책에 대한 자세한 내용을 알고 싶습니다.']\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4391f5",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92849043",
   "metadata": {},
   "source": [
    "#### **3) `Ensemble Retriever`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b2feba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "doc_list = [\n",
    "    \"난 오늘 많이 먹어서 배가 정말 부르다\",\n",
    "    \"떠나는 저 배가 오늘 마지막 배인가요?\",\n",
    "    \"내가 제일 좋아하는 과일들은 배, 사과, 키워, 수박 입니다.\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a4ce58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the bm25 retriever and faiss retriever\n",
    "bm25_retriever = BM25Retriever.from_texts(doc_list)\n",
    "bm25_retriever.k = 2\n",
    "\n",
    "faiss_vectorstore = FAISS.from_texts(doc_list, embeddings)\n",
    "faiss_retriever = faiss_vectorstore.as_retriever(search_kwargs={\"k\": 2})\n",
    "\n",
    "# initialize the ensemble retriever\n",
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=[bm25_retriever, faiss_retriever], \n",
    "    weights=[0.5, 0.5]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e20183",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print(docs):\n",
    "    for i, doc in enumerate(docs):\n",
    "        print(f\"[{i+1}] {doc.page_content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae592d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_query = \"나 요즘 배에 정말 살이 많이 쪘어...\"\n",
    "print(f\"[Query]\\n{sample_query}\\n\")\n",
    "relevant_docs = bm25_retriever.get_relevant_documents(sample_query)\n",
    "print(\"[BM25 Retriever]\")\n",
    "pretty_print(relevant_docs)\n",
    "print(\"===\" * 20)\n",
    "relevant_docs = faiss_retriever.get_relevant_documents(sample_query)\n",
    "print(\"[FAISS Retriever]\")\n",
    "pretty_print(relevant_docs)\n",
    "print(\"===\" * 20)\n",
    "relevant_docs = ensemble_retriever.get_relevant_documents(sample_query)\n",
    "print(\"[Ensemble Retriever]\")\n",
    "pretty_print(relevant_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41660a5",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* `sample_query`\n",
    "\n",
    "    ```markdown\n",
    "    [Query]\n",
    "    나 요즘 배에 정말 살이 많이 쪘어...\n",
    "\n",
    "    [BM25 Retriever]\n",
    "    [1] 난 오늘 많이 먹어서 배가 정말 부르다\n",
    "    [2] 내가 제일 좋아하는 과일들은 배, 사과, 키워, 수박 입니다.\n",
    "    ============================================================\n",
    "    [FAISS Retriever]\n",
    "    [1] 떠나는 저 배가 오늘 마지막 배인가요?\n",
    "    [2] 난 오늘 많이 먹어서 배가 정말 부르다\n",
    "    ============================================================\n",
    "    [Ensemble Retriever]\n",
    "    [1] 난 오늘 많이 먹어서 배가 정말 부르다\n",
    "    [2] 떠나는 저 배가 오늘 마지막 배인가요?\n",
    "    [3] 내가 제일 좋아하는 과일들은 배, 사과, 키워, 수박 입니다.\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acc622c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_query = \"바다 위에 떠다니는 배들이 많다\"\n",
    "print(f\"[Query]\\n{sample_query}\\n\")\n",
    "relevant_docs = bm25_retriever.get_relevant_documents(sample_query)\n",
    "print(\"[BM25 Retriever]\")\n",
    "pretty_print(relevant_docs)\n",
    "print(\"===\" * 20)\n",
    "relevant_docs = faiss_retriever.get_relevant_documents(sample_query)\n",
    "print(\"[FAISS Retriever]\")\n",
    "pretty_print(relevant_docs)\n",
    "print(\"===\" * 20)\n",
    "relevant_docs = ensemble_retriever.get_relevant_documents(sample_query)\n",
    "print(\"[Ensemble Retriever]\")\n",
    "pretty_print(relevant_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10552a9",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* `sample_query_2`\n",
    "\n",
    "    ```markdown\n",
    "    [Query]\n",
    "    바다 위에 떠다니는 배들이 많다\n",
    "\n",
    "    [BM25 Retriever]\n",
    "    [1] 내가 제일 좋아하는 과일들은 배, 사과, 키워, 수박 입니다.\n",
    "    [2] 떠나는 저 배가 오늘 마지막 배인가요?\n",
    "    ============================================================\n",
    "    [FAISS Retriever]\n",
    "    [1] 떠나는 저 배가 오늘 마지막 배인가요?\n",
    "    [2] 난 오늘 많이 먹어서 배가 정말 부르다\n",
    "    ============================================================\n",
    "    [Ensemble Retriever]\n",
    "    [1] 떠나는 저 배가 오늘 마지막 배인가요?\n",
    "    [2] 내가 제일 좋아하는 과일들은 배, 사과, 키워, 수박 입니다.\n",
    "    [3] 난 오늘 많이 먹어서 배가 정말 부르다\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb2eab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_query = \"ships\"\n",
    "print(f\"[Query]\\n{sample_query}\\n\")\n",
    "relevant_docs = bm25_retriever.get_relevant_documents(sample_query)\n",
    "print(\"[BM25 Retriever]\")\n",
    "pretty_print(relevant_docs)\n",
    "print(\"===\" * 20)\n",
    "relevant_docs = faiss_retriever.get_relevant_documents(sample_query)\n",
    "print(\"[FAISS Retriever]\")\n",
    "pretty_print(relevant_docs)\n",
    "print(\"===\" * 20)\n",
    "relevant_docs = ensemble_retriever.get_relevant_documents(sample_query)\n",
    "print(\"[Ensemble Retriever]\")\n",
    "pretty_print(relevant_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19ec07a",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* `sample_query_3`\n",
    "\n",
    "    ```markdown\n",
    "    [Query]\n",
    "    ships\n",
    "\n",
    "    [BM25 Retriever]\n",
    "    [1] 내가 제일 좋아하는 과일들은 배, 사과, 키워, 수박 입니다.\n",
    "    [2] 떠나는 저 배가 오늘 마지막 배인가요?\n",
    "    ============================================================\n",
    "    [FAISS Retriever]\n",
    "    [1] 난 오늘 많이 먹어서 배가 정말 부르다\n",
    "    [2] 떠나는 저 배가 오늘 마지막 배인가요?\n",
    "    ============================================================\n",
    "    [Ensemble Retriever]\n",
    "    [1] 떠나는 저 배가 오늘 마지막 배인가요?\n",
    "    [2] 내가 제일 좋아하는 과일들은 배, 사과, 키워, 수박 입니다.\n",
    "    [3] 난 오늘 많이 먹어서 배가 정말 부르다\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9ef26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_query = \"pear\"\n",
    "print(f\"[Query]\\n{sample_query}\\n\")\n",
    "relevant_docs = bm25_retriever.get_relevant_documents(sample_query)\n",
    "print(\"[BM25 Retriever]\")\n",
    "pretty_print(relevant_docs)\n",
    "print(\"===\" * 20)\n",
    "relevant_docs = faiss_retriever.get_relevant_documents(sample_query)\n",
    "print(\"[FAISS Retriever]\")\n",
    "pretty_print(relevant_docs)\n",
    "print(\"===\" * 20)\n",
    "relevant_docs = ensemble_retriever.get_relevant_documents(sample_query)\n",
    "print(\"[Ensemble Retriever]\")\n",
    "pretty_print(relevant_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5247b9cc",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* `sample_query_4`\n",
    "\n",
    "    ```markdown\n",
    "    [Query]\n",
    "    pear\n",
    "\n",
    "    [BM25 Retriever]\n",
    "    [1] 내가 제일 좋아하는 과일들은 배, 사과, 키워, 수박 입니다.\n",
    "    [2] 떠나는 저 배가 오늘 마지막 배인가요?\n",
    "    ============================================================\n",
    "    [FAISS Retriever]\n",
    "    [1] 난 오늘 많이 먹어서 배가 정말 부르다\n",
    "    [2] 내가 제일 좋아하는 과일들은 배, 사과, 키워, 수박 입니다.\n",
    "    ============================================================\n",
    "    [Ensemble Retriever]\n",
    "    [1] 내가 제일 좋아하는 과일들은 배, 사과, 키워, 수박 입니다.\n",
    "    [2] 난 오늘 많이 먹어서 배가 정말 부르다\n",
    "    [3] 떠나는 저 배가 오늘 마지막 배인가요?\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01d7cbb",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d737c3cc",
   "metadata": {},
   "source": [
    "### **6. `단계 6`: `프롬프트 생성`** *(Create Prompt)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a646b40a",
   "metadata": {},
   "source": [
    "* **`프롬프트 엔지니어링`** = 주어진 데이터(`context`)를 토대로 우리가 원하는 결과를 도출할 때 중요한 역할\n",
    "\n",
    "  * `tip_1`\n",
    "    * **`retriever`** 에서 도출한 결과에서 중요한 정보가 누락된다면 → **`retriever`** 의 `로직`을 `수정`해야 함\n",
    "    * **`retriever`** 에서 도출한 결과가 많은 정보를 포함하고 있지만, **`llm`** 이 그 중에서 중요한 정보를 찾지 못한거나 원하는 형태로 출력하지 않는다면 → **`프롬프트`를 수정해야 함`**\n",
    "\n",
    "  * `tip_2`\n",
    "    * `LangSmith` 의 `hub` 에는 검증된 프롬프트가 많이 업로드 되어 있음\n",
    "    * 검증된 프롬프트를 활용하거나 약간 수정한다면 비용과 시간을 절약할 수 있음\n",
    "    * [LangSmith-hub-rag](https://smith.langchain.com/hub/search?q=rag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993f32d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ea90e6",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* `langchain`의 `hub`에서 받은 프롬프트\n",
    "\n",
    "    ```bash\n",
    "    ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, metadata={'lc_hub_owner': 'rlm', 'lc_hub_repo': 'rag-prompt', 'lc_hub_commit_hash': '50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6e'}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"), additional_kwargs={})])\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94882ad4",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb356d6",
   "metadata": {},
   "source": [
    "### **7. `단계 7`: `언어모델 생성`** *(Create LLM)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a11566",
   "metadata": {},
   "source": [
    "* **`gemini 모델 사용해보기`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72da48c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from google import genai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c65f0a",
   "metadata": {},
   "source": [
    "* 토큰 사용량 확인해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b16e515",
   "metadata": {},
   "outputs": [],
   "source": [
    "# .env 파일에서 환경 변수 로드\n",
    "load_dotenv()\n",
    "\n",
    "# GOOGLE_API_KEY 확인 (로컬 환경 변수 사용)\n",
    "if \"GOOGLE_API_KEY\" not in os.environ:\n",
    "    raise ValueError(\"GOOGLE_API_KEY 환경 변수가 설정되지 않았습니다. .env 파일을 확인해 주세요.\")\n",
    "\n",
    "# 클라이언트 객체 초기화 (모듈 임포트 전에 처리)\n",
    "GENAI_CLIENT = genai.Client(api_key=os.environ[\"GOOGLE_API_KEY\"])\n",
    "\n",
    "# utils 폴더에서 함수 임포트\n",
    "from utils.local_gemini_billing import generate_and_track_tokens\n",
    "\n",
    "print(\"✅ 초기화 및 함수 로드 성공\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2826951b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용자 쿼리\n",
    "test_prompt = \"대한민국의 수도는 어디인가요?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41322163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 초기화된 GENAI_CLIENT 객체를 함수의 첫 번째 인수로 전달합니다.\n",
    "answer, tokens = generate_and_track_tokens(GENAI_CLIENT, test_prompt, \"gemini-2.5-flash-lite\")\n",
    "\n",
    "print(f\"답변: {answer}\")\n",
    "\n",
    "if tokens:\n",
    "    print(\"\\n--------------------------------------------------\")\n",
    "    print(\"✨ Gemini 모델 API 토큰 사용량 (과금 정보) ✨\")\n",
    "    print(f\"  - 전체 사용 토큰: {tokens['total_tokens']}\")\n",
    "    print(\"--------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5b946a",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 사용 모델: gemini-2.5-flash-lite\n",
    "* 질문: 대한민국의 수도는 어디인가요?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285d12a5",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 과금 게산해보기 (`gemini`)\n",
    "\n",
    "    ```markdown\n",
    "    응답: 대한민국의 수도는 **서울**입니다.\n",
    "\n",
    "    --------------------------------------------------\n",
    "    ✨ Gemini 모델 API 토큰 사용량 (과금 정보) ✨\n",
    "    - 입력(프롬프트) 토큰: 10\n",
    "    - 출력(응답) 토큰: 10\n",
    "    - 전체 사용 토큰: 20\n",
    "    --------------------------------------------------\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4018a8bc",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8cb0518",
   "metadata": {},
   "source": [
    "* **`HuggingFace`에 업로드 되어 있는 오픈소스 모델**\n",
    "\n",
    "  * *참고: [HuggingFace LLM Leaderboard](https://huggingface.co/spaces/open-llm-leaderboard/open_llm_leaderboard)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24c2a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HuggingFaceHub 객체 생성\n",
    "from langchain.llms import HuggingFaceHub\n",
    "\n",
    "repo_id = \"google/flan-t5-xxl\"\n",
    "\n",
    "t5_model = HuggingFaceHub(\n",
    "    repo_id=repo_id, model_kwargs={\"temperature\": 0.1, \"max_length\": 512}\n",
    ")\n",
    "\n",
    "t5_model.invoke(\"Where is the capital of South Korea?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42408da9",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 'seoul'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65dab390",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e91d9e2",
   "metadata": {},
   "source": [
    "#### **1) `RAG 템플릿 실험`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be9f2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단계 1: 문서 로드(Load Documents)\n",
    "# 문서를 로드, 청크 나누기, 인덱싱\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "# PDF 파일 로드. 파일의 경로 입력\n",
    "file_path = \"../12_RAG/data/SPRI_AI_Brief_2023년12월호_F.pdf\"\n",
    "loader = PyPDFLoader(file_path=file_path)\n",
    "\n",
    "# 단계 2: 문서 분할(Split Documents)\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=50)\n",
    "\n",
    "split_docs = loader.load_and_split(text_splitter=text_splitter)             # 1.9s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc905da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단계 3, 4: 임베딩 & 벡터스토어 생성(Create Vectorstore)\n",
    "# 벡터스토어 생성하기\n",
    "vectorstore = FAISS.from_documents(documents=splits, embedding=embeddings)\n",
    "\n",
    "# 단계 5: 리트리버 생성(Create Retriever)\n",
    "# 사용자의 질문(query) 에 부합하는 문서를 검색하기\n",
    "retriever = vectorstore.as_retriever(search_type=\"similarity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457a96ea",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 유사도 기반 `retriever`\n",
    "\n",
    "    ```python\n",
    "    [Document(id='a3c05b85-9b92-4a13-be69-475b5e4a4feb', metadata={'source': 'https://n.news.naver.com/article/437/0000378416'}, page_content=\"출산 직원에게 '1억원' 쏜다…회사의 파격적 저출생 정책\"), Document(id='749b0ead-ad1b-4494-be15-c3bb3517a63c', metadata={'source': 'https://n.news.naver.com/article/437/0000378416'}, page_content=\"[앵커]올해 아이 낳을 계획이 있는 가족이라면 솔깃할 소식입니다. 정부가 저출생 대책으로 매달 주는 부모 급여, 0세 아이는 100만원으로 올렸습니다. 여기에 첫만남이용권, 아동수당까지 더하면 아이 돌까지 1년 동안 1520만원을 받습니다. 지자체도 경쟁하듯 지원에 나섰습니다. 인천시는 새로 태어난 아기, 18살될 때까지 1억원을 주겠다. 광주시도 17살될 때까지 7400만원 주겠다고 했습니다. 선거 때면 나타나서 아이 낳으면 현금 주겠다고 밝힌 사람이 있었죠. 과거에는 표만 노린 '황당 공약'이라는 비판이 따라다녔습니다. 그런데 지금은 출산율이 이보다 더 나쁠 수 없다보니, 이런 현금성 지원을 진지하게 정책화 하는 상황까지 온 겁니다. 게다가 기업들도 뛰어들고 있습니다. 이번에는 출산한 직원에게 단번에 1억원을 주겠다는 회사까지 나타났습니다.이상화 기자가 취재했습니다.[기자]한 그룹사가 오늘 파격적인 저출생 정책을 내놨습니다.2021년 이후 태어난 직원 자녀에 1억원씩, 총 70억원을 지원하고 앞으로도 이 정책을 이어가기로 했습니다.해당 기간에 연년생과 쌍둥이 자녀가 있으면 총 2억원을 받게 됩니다.[오현석/부영그룹 직원 : 아이 키우는 데 금전적으로 많이 힘든 세상이잖아요. 교육이나 생활하는 데 큰 도움이 될 거라 생각합니다.]만약 셋째까지 낳는 경우엔 국민주택을 제공하겠다는 뜻도 밝혔습니다.[이중근/부영그룹 회장 : 3년 이내에 세 아이를 갖는 분이 나올 것이고 따라서 주택을 제공할 수 있는 계기가 될 것으로 생각하고.][조용현/부영그룹 직원 : 와이프가 셋째도 갖고 싶어 했는데 경제적 부담 때문에 부정적이었거든요. (이제) 긍정적으로 생각할 수 있을 것 같습니다.]오늘 행사에서는, 회사가 제공하는 출산장려금은 받는 직원들의 세금 부담을 고려해 정부가 면세해달라는 제안도 나왔습니다.이같은 출산장려책은 점점 확산하는 분위기입니다.법정기간보다 육아휴직을 길게 주거나, 남성 직원의 육아휴직을 의무화한 곳도 있습니다.사내 어린이집을 밤 10시까지 운영하고\"), Document(id='2c8854a8-18ef-40c6-84d7-e6968b9dd3dc', metadata={'source': 'https://n.news.naver.com/article/437/0000378416'}, page_content='남성 직원의 육아휴직을 의무화한 곳도 있습니다.사내 어린이집을 밤 10시까지 운영하고 셋째를 낳으면 무조건 승진시켜 주기도 합니다.한 회사는 지난해 네쌍둥이를 낳은 직원에 의료비를 지원해 관심을 모았습니다.정부 대신 회사가 나서는 출산장려책이 사회적 분위기를 바꿀 거라는 기대가 커지는 가운데, 여력이 부족한 중소지원이 필요하다는 목소리도 나옵니다.[영상디자인 곽세미]')]\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb48a600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 유사도 높은 K 개의 문서를 검색하기\n",
    "k = 3\n",
    "\n",
    "# (Sparse) bm25 retriever and (Dense) faiss retriever 를 초기화하기\n",
    "bm25_retriever = BM25Retriever.from_documents(split_docs)\n",
    "bm25_retriever.k = k\n",
    "\n",
    "faiss_vectorstore = FAISS.from_documents(split_docs, embeddings)\n",
    "faiss_retriever = faiss_vectorstore.as_retriever(search_kwargs={\"k\": k})\n",
    "\n",
    "# initialize the ensemble retriever\n",
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=[bm25_retriever, faiss_retriever], weights=[0.5, 0.5]\n",
    ")\n",
    "                                                            # 1.8s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ada6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단계 6: 프롬프트 생성(Create Prompt)\n",
    "# 프롬프트 생성하기\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423e6955",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* `rag-prompt`\n",
    "\n",
    "    ```bash\n",
    "    input_variables=['context', 'question'] input_types={} partial_variables={} metadata={'lc_hub_owner': 'rlm', 'lc_hub_repo': 'rag-prompt', 'lc_hub_commit_hash': '50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6e'} messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"), additional_kwargs={})]\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca9c9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단계 7: 언어모델 생성(Create LLM)\n",
    "# LLM 생성하기\n",
    "from google.genai.errors import APIError\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# API 키 확인\n",
    "if not os.getenv(\"GOOGLE_API_KEY\"):\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = input(\"Enter your Google API key: \")\n",
    "\n",
    "# LLM 초기화\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "        model=\"gemini-2.5-flash\",\n",
    "        temperature=0,                                              # temperature = 0으로 설정  \n",
    "        max_output_tokens=4096,\n",
    "    )\n",
    "\n",
    "def format_docs(docs):\n",
    "    # 검색한 문서 결과를 하나의 문단으로 합치기\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8542a20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단계 8: 체인 생성(Create Chain)\n",
    "rag_chain = (\n",
    "    {\"context\": ensemble_retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"PDF Path: {file_path}\")\n",
    "print(f\"문서의 수: {len(docs)}\")\n",
    "print(\"===\" * 20)\n",
    "print(f\"[HUMAN]\\n{question}\\n\")\n",
    "print(f\"[AI]\\n{response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1b40cd",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* `query_1` \n",
    "\n",
    "  ```markdown\n",
    "    PDF Path: data/SPRI_AI_Brief_2023년12월호_F.pdf\n",
    "    문서의 수: 23\n",
    "    ============================================================\n",
    "    [HUMAN]\n",
    "    삼성 가우스에 대해 설명해주세요\n",
    "\n",
    "    [AI]\n",
    "    삼성 가우스는 삼성전자가 개발한 생성 AI 모델로, 언어, 코드, 이미지의 3개 모델로 구성되어 있습니다. 이 모델은 온디바이스에서 작동 가능하며, 외부로 사용자 정보가 유출되지 않는 안전한 데이터를 통해 학습되었습니다. 삼성전자는 삼성 가우스를 다양한 제품에 단계적으로 탑재할 계획을 가지고 있습니다.\n",
    "  ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37dcc335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단계 8: 체인 실행(Run Chain)\n",
    "# 문서에 대한 질의를 입력하고, 답변을 출력하기\n",
    "question = \"삼성 가우스에 대해 설명해주세요\"\n",
    "response = rag_chain.invoke(question)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e724bc1d",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* `query_2` (`4.7s`)\n",
    "\n",
    "    ```markdown\n",
    "    삼성 가우스는 삼성전자가 자체 개발한 생성형 AI 모델로, 2023년 11월 '삼성 AI 포럼'에서 공개되었습니다. 이 모델은 언어, 코드, 이미지의 세 가지 모델로 구성되며, 온디바이스에서 작동하여 사용자 정보 유출 위험이 없는 것이 특징입니다. 삼성전자는 메일 작성, 문서 요약, 코딩 지원, 이미지 생성 및 편집 등 다양한 기능을 제공하는 가우스를 여러 제품에 단계적으로 탑재할 계획입니다.\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a07aae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단계 8: 체인 실행(Run Chain)\n",
    "# 문서에 대한 질의를 입력하고, 답변을 출력하기\n",
    "question = \"미래의 AI 소프트웨어 매출 전망은 어떻게 되나요?\"\n",
    "response = rag_chain.invoke(question)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8b5829",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* `query_3` (`7.2s`)\n",
    "\n",
    "    ```markdown\n",
    "    IDC는 AI 소프트웨어 시장이 2027년에 2,510억 달러에 달할 것으로 전망합니다. 이는 2022년 640억 달러에서 연평균 31.4% 성장한 수치입니다. 특히 생성 AI 플랫폼과 애플리케이션은 2027년까지 283억 달러의 매출을 창출할 것으로 예상됩니다.\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fd2123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단계 8: 체인 실행(Run Chain)\n",
    "# 문서에 대한 질의를 입력하고, 답변을 출력하기\n",
    "question = \"YouTube 가 2024년에 의무화 한 것은 무엇인가요?\"\n",
    "response = rag_chain.invoke(question)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c885c25a",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* `query_4` (`3.8s`)\n",
    "\n",
    "    ```markdown\n",
    "    YouTube는 2024년부터 생성 AI를 사용한 콘텐츠에 AI 라벨 표시를 의무화했습니다. 이를 준수하지 않을 경우 콘텐츠가 삭제되거나 크리에이터에 대한 수익 배분이 중단될 수 있습니다. 또한, AI 생성 콘텐츠가 신원 파악이 가능한 개인을 모방한 경우 개인정보 침해 신고 절차에 따라 콘텐츠 삭제 요청도 받을 계획입니다.\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5a6766",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99113bb5",
   "metadata": {},
   "source": [
    "* next: ***`03-Conversation with History`***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a4f342",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lc_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
