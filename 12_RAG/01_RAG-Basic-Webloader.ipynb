{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14bd064b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7cf4d9",
   "metadata": {},
   "source": [
    "* 출처: LangChain 공식 문서 또는 해당 교재명\n",
    "* 원본 URL: https://smith.langchain.com/hub/teddynote/summary-stuff-documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14946d5",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d46aac0",
   "metadata": {},
   "source": [
    "### **1. `RAG의 8단계 프로세스`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417e3726",
   "metadata": {},
   "source": [
    "#### **1) `사전 준비단계`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f433dc09",
   "metadata": {},
   "source": [
    "* `RAG`의 사전 준비단계\n",
    "  * ![RAG의 사전 준비단계](../12_RAG/images/rag-process-1.png)\n",
    "\n",
    "<br>\n",
    "\n",
    "* \n",
    "  * a. **`도큐먼트 로드` (`Document Loader`)**: \n",
    "    * 외부 데이터 소스에서 **`필요한 문서를 로드` → `초기 처리`**\n",
    "    * ≒ 마치 책을 여러 권 챙겨 도서관에서 공부하는 것과 비슷 / 학생이 공부하기 전에 필요한 책들을 책장에서 골라오는 과정\n",
    "\n",
    "  * b. **`텍스트 분할`** (`Text Splitter`): \n",
    "    * **로드된 문서를 처리 가능한 `작은 단위`로 `분할`**\n",
    "    * ≒ 큰 책을 챕터별로 나누는 것과 유사\n",
    "\n",
    "  * c. **`임베딩`** (`Embedding`): \n",
    "    * 각 **`문서` 또는 `문서의 일부`를 `벡터` 형태로 `변환`** → **문서의 의미 수치화**\n",
    "    * ≒ 책의 내용을 요약하여 핵심 키워드로 표현하는 것과 비슷\n",
    "\n",
    "  * d. **`벡터스토어`** (`Vector Store`) 저장: \n",
    "    * **`임베딩된 벡터`들을 `데이터베이스`에 `저장`**\n",
    "    * ≒ 요약된 키워드를 색인화하여 나중에 빠르게 찾을 수 있도록 하는 과정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ca3e7d",
   "metadata": {},
   "source": [
    "#### **2) `런타임 (RunTime 단계)`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a222a4",
   "metadata": {},
   "source": [
    "* `Runtime`\n",
    "  * ![runtime](../12_RAG/images/rag-process-2.png)\n",
    "\n",
    "<br>\n",
    "\n",
    "* \n",
    "  * e. **`검색기`** (`Retriever`): \n",
    "    * **`질문`** → 이와 관련된 벡터를 **`벡터 데이터베이스`에서 검색**\n",
    "    * ≒ 질문에 가장 잘 맞는 책의 챕터를 찾는 것과 유사\n",
    "\n",
    "  * f. **`프롬프트`** (`Prompt`): \n",
    "    * **`검색된 정보`를 `바탕`으로 언어 모델을 위한 `질문`을 `구성`**\n",
    "    * **`=` 정보를 바탕으로 `어떻게 질문`할지 `결정`하는 과정**\n",
    "\n",
    "  * g. **`LLM`** (Large Language Model): \n",
    "    * 구성된 `프롬프트` 사용 **→ `언어 모델`이 `답변`을 `생성`**\n",
    "    * ≒ 수집된 정보를 바탕으로 과제 or 보고서를 작성하는 학생과 같음\n",
    "\n",
    "  * h. **`체인` (`Chain`) 생성**: \n",
    "    * 이전의 **`모든 과정`의 `하나의 파이프라인`으로 묶어주는 `체인`(`Chain`)** 을 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad018cf",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e65090",
   "metadata": {},
   "source": [
    "#### **3) `PDF 문서 기반 QA`** *(Question-Answer)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c9dc6e",
   "metadata": {},
   "source": [
    "* **`RAG 기본 구조 이해하기 - 1` = `사전작업`** *(1~4단계)*\n",
    "\n",
    "  * ![사전 작업단계](../12_RAG/images/rag1.png)\n",
    "  * ![RAG 작업단계1](../12_RAG/images/rag-process-1.png)\n",
    "\n",
    "<br>\n",
    "\n",
    "* 사전 작업 단계: 데이터 소스를 `Vector DB`에 문서를 **`로드`-`분할`-`임베딩`-`저장`** 하는 **`4단계`를 진행**\n",
    "\n",
    "  * 1단계: **`문서로드`(`Document Load`)** = 문서 내용 불러오기\n",
    "  * 2단계: **`분할`(`Text Split`)**: 문서를 `특정 기준`(`Chunk`)으로 분할하기\n",
    "  * 3단계: **`임베딩`(`Embedding`)**: 분할된(`Chunk`) → **`임베딩`** → 저장하기\n",
    "  * 4단계: **`벡터DB 저장`**: `임베딩된 Chunk` → `DB`에 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f36c56",
   "metadata": {},
   "source": [
    "* **`RAG - 2 = 수행`** *(RunTime)* - 5~8단계\n",
    "  * ![RAG2](../12_RAG/images/rag2.png)\n",
    "  * ![runtime단계](../12_RAG/images/rag-process-2.png)\n",
    "\n",
    "<br>\n",
    "\n",
    "* 수행 단계\n",
    "  * 5단계: **`검색기`(`Retriever`)**\n",
    "    * `쿼리`(`Query`) → `DB`에서 `검색`하여 결과를 가져오기 위하여 `리트리버`를 `정의`하기\n",
    "    * 리트리버 = 검색 알고리즘 / 아래 2개의 종류\n",
    "      * **`Dense`**: **`유사도 기반 검색`**\n",
    "      * **`Sparse`**: **`키워드 기반 검색`**\n",
    "\n",
    "  * 6단계: **`프롬프트`**\n",
    "    * **`RAG`를 수행하기 위한 `프롬프트 생성`**\n",
    "    * 프롬프트의 `context` = **`문서에서 검색된 내용`**\n",
    "    * 프롬프트 엔지니어링 → `답변의 형식`을 `지정 가능`\n",
    "  \n",
    "  * 7단계: **`LLM`**\n",
    "    * **`모델` 정의하기**\n",
    "    * GPT-3.5, GPT-4, Claude, gemini-2.5-flash, ...\n",
    "  \n",
    "  * 8단계: **`Chain`** = **`프롬프트` - `LLM` - `출력` 에 이르는 체인을 생성**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f460f9e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76f8a66",
   "metadata": {},
   "source": [
    "### **2. `네이버 뉴스 기반 QA`** *(Question-Answering)* **`챗봇`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8806fdf0",
   "metadata": {},
   "source": [
    "* **`뉴스기사 QA 앱 구축해보기`**\n",
    "  * 네이버 뉴스기사의 내용에 대해 질문할 수 있는 뉴스기사 QA 앱을 구축\n",
    "  * `Chroma 벡터 스토어`를 사용할 것"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4203de7",
   "metadata": {},
   "source": [
    "* 간단한 `인덱싱 파이프라인`과 `RAG 체인`을 약 20줄의 코드로 구현 가능\n",
    "\n",
    "<br>\n",
    "\n",
    "* 라이브러리 설명\n",
    "\n",
    "  * **`bs4`** = 웹 페이지를 파싱하기 위한 라이브러리\n",
    "  * **`langchain`** \n",
    "    * `AI`와 관련된 다양한 기능을 제공하는 라이브러리\n",
    "    * `텍스트 분할`(RecursiveCharacterTextSplitter), `문서 로딩`(WebBaseLoader), `벡터 저장`(Chroma, FAISS), `출력 파싱`(StrOutputParser), `실행 가능한 패스스루`(RunnablePassthrough) 등을 사용할 예정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6216ae",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882ca0af",
   "metadata": {},
   "source": [
    "* **`환경설정`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87635a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API 키를 환경변수로 관리하기 위한 설정 파일\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API 키 정보 로드\n",
    "load_dotenv()                           # True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72357db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import Client\n",
    "from langsmith import traceable\n",
    "\n",
    "import os\n",
    "\n",
    "# LangSmith 환경 변수 확인\n",
    "\n",
    "print(\"\\n--- LangSmith 환경 변수 확인 ---\")\n",
    "langchain_tracing_v2 = os.getenv('LANGCHAIN_TRACING_V2')\n",
    "langchain_project = os.getenv('LANGCHAIN_PROJECT')\n",
    "langchain_api_key_status = \"설정됨\" if os.getenv('LANGCHAIN_API_KEY') else \"설정되지 않음\" # API 키 값은 직접 출력하지 않음\n",
    "\n",
    "if langchain_tracing_v2 == \"true\" and os.getenv('LANGCHAIN_API_KEY') and langchain_project:\n",
    "    print(f\"✅ LangSmith 추적 활성화됨 (LANGCHAIN_TRACING_V2='{langchain_tracing_v2}')\")\n",
    "    print(f\"✅ LangSmith 프로젝트: '{langchain_project}'\")\n",
    "    print(f\"✅ LangSmith API Key: {langchain_api_key_status}\")\n",
    "    print(\"  -> 이제 LangSmith 대시보드에서 이 프로젝트를 확인해 보세요.\")\n",
    "else:\n",
    "    print(\"❌ LangSmith 추적이 완전히 활성화되지 않았습니다. 다음을 확인하세요:\")\n",
    "    if langchain_tracing_v2 != \"true\":\n",
    "        print(f\"  - LANGCHAIN_TRACING_V2가 'true'로 설정되어 있지 않습니다 (현재: '{langchain_tracing_v2}').\")\n",
    "    if not os.getenv('LANGCHAIN_API_KEY'):\n",
    "        print(\"  - LANGCHAIN_API_KEY가 설정되어 있지 않습니다.\")\n",
    "    if not langchain_project:\n",
    "        print(\"  - LANGCHAIN_PROJECT가 설정되어 있지 않습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a6147e",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 셀 출력\n",
    "\n",
    "    ```bash\n",
    "    --- LangSmith 환경 변수 확인 ---\n",
    "    ✅ LangSmith 추적 활성화됨 (LANGCHAIN_TRACING_V2='true')\n",
    "    ✅ LangSmith 프로젝트: 'LangChain-prantice'\n",
    "    ✅ LangSmith API Key: 설정됨\n",
    "    -> 이제 LangSmith 대시보드에서 이 프로젝트를 확인해 보세요.\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4081b662",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9faf29cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_huggingface import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4f3bdb",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* USER_AGENT environment variable not set, consider setting it to identify your requests.   (`3.7s`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a0bc6e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619a7754",
   "metadata": {},
   "source": [
    "* `웹 페이지`의 내용을 `로드` → `텍스트`를 `청크`로 나눔 → `인덱싱` → `관련`된 텍스트 `스니펫 검색` → `새로운 내용`을 `생성`하는 `과정 구현`하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501962e5",
   "metadata": {},
   "source": [
    "* **`WebBaseLoader`** = 지정된 웹 페이지에서 필요한 부분만 파싱하기 위해 **`bs4.SoupStrainer`** 사용\n",
    "\n",
    "  * *참고: `bs4.SoupStarainer` = 편리하게 웹에서 원하는 요소를 가져올 수 있도록 해줌*\n",
    "\n",
    "```python\n",
    "\n",
    "      bs4.SoupStrainer(\n",
    "          \"div\",\n",
    "          attrs={\"class\": [\"newsct_article _article_body\", \"media_end_head_title\"]},\n",
    "      )\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88460b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 뉴스기사 내용 로드 → 청크로 나눔 → 인덱싱하기\n",
    "\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://n.news.naver.com/article/437/0000378416\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            \"div\",\n",
    "            attrs={\"class\": [\"newsct_article _article_body\", \"media_end_head_title\"]},\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "\n",
    "docs = loader.load()\n",
    "print(f\"문서의 수: {len(docs)}\")\n",
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0f6eb7",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 문서의 수: 1  (`0.4s`)\n",
    "\n",
    "    ```python\n",
    "    [Document(metadata={'source': 'https://n.news.naver.com/article/437/0000378416'}, page_content=\"\\n출산 직원에게 '1억원' 쏜다…회사의 파격적 저출생 정책\\n\\n\\n[앵커]올해 아이 낳을 계획이 있는 가족이라면 솔깃할 소식입니다. 정부가 저출생 대책으로 매달 주는 부모 급여, 0세 아이는 100만원으로 올렸습니다. 여기에 첫만남이용권, 아동수당까지 더하면 아이 돌까지 1년 동안 1520만원을 받습니다. 지자체도 경쟁하듯 지원에 나섰습니다. 인천시는 새로 태어난 아기, 18살될 때까지 1억원을 주겠다. 광주시도 17살될 때까지 7400만원 주겠다고 했습니다. 선거 때면 나타나서 아이 낳으면 현금 주겠다고 밝힌 사람이 있었죠. 과거에는 표만 노린 '황당 공약'이라는 비판이 따라다녔습니다. 그런데 지금은 출산율이 이보다 더 나쁠 수 없다보니, 이런 현금성 지원을 진지하게 정책화 하는 상황까지 온 겁니다. 게다가 기업들도 뛰어들고 있습니다. 이번에는 출산한 직원에게 단번에 1억원을 주겠다는 회사까지 나타났습니다.이상화 기자가 취재했습니다.[기자]한 그룹사가 오늘 파격적인 저출생 정책을 내놨습니다.2021년 이후 태어난 직원 자녀에 1억원씩, 총 70억원을 지원하고 앞으로도 이 정책을 이어가기로 했습니다.해당 기간에 연년생과 쌍둥이 자녀가 있으면 총 2억원을 받게 됩니다.[오현석/부영그룹 직원 : 아이 키우는 데 금전적으로 많이 힘든 세상이잖아요. 교육이나 생활하는 데 큰 도움이 될 거라 생각합니다.]만약 셋째까지 낳는 경우엔 국민주택을 제공하겠다는 뜻도 밝혔습니다.[이중근/부영그룹 회장 : 3년 이내에 세 아이를 갖는 분이 나올 것이고 따라서 주택을 제공할 수 있는 계기가 될 것으로 생각하고.][조용현/부영그룹 직원 : 와이프가 셋째도 갖고 싶어 했는데 경제적 부담 때문에 부정적이었거든요. (이제) 긍정적으로 생각할 수 있을 것 같습니다.]오늘 행사에서는, 회사가 제공하는 출산장려금은 받는 직원들의 세금 부담을 고려해 정부가 면세해달라는 제안도 나왔습니다.이같은 출산장려책은 점점 확산하는 분위기입니다.법정기간보다 육아휴직을 길게 주거나, 남성 직원의 육아휴직을 의무화한 곳도 있습니다.사내 어린이집을 밤 10시까지 운영하고 셋째를 낳으면 무조건 승진시켜 주기도 합니다.한 회사는 지난해 네쌍둥이를 낳은 직원에 의료비를 지원해 관심을 모았습니다.정부 대신 회사가 나서는 출산장려책이 사회적 분위기를 바꿀 거라는 기대가 커지는 가운데, 여력이 부족한 중소지원이 필요하다는 목소리도 나옵니다.[영상디자인 곽세미]\\n\\t\\t\\n\")]\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e214ed18",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f24ea1",
   "metadata": {},
   "source": [
    "* **`RecursiveCharacterTextSplitter`** = 문서를 지정된 크기의 청크로 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d62e1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "\n",
    "splits = text_splitter.split_documents(docs)\n",
    "len(splits)                                                                     # 3\n",
    "print(f\"분할된 문서의 수: {len(splits)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c240f1",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 분할된 문서의 수: 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c61e07",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9324852d",
   "metadata": {},
   "source": [
    "* **`vectorstore`** (`FAISS` 혹은 `Chroma`): 이러한 청크를 바탕으로 문서의 벡터 표현을 생성함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ae65b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단계 3: 임베딩(Embedding) 생성\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "import warnings\n",
    "\n",
    "# 경고 무시\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# HuggingFace Embeddings 사용\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    model_kwargs={'device': 'cpu'},\n",
    "    encode_kwargs={'normalize_embeddings': True}\n",
    ")\n",
    "\n",
    "print(\"✅ hugging-face 임베딩 모델 로딩 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8522dc",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* ✅ hugging-face 임베딩 모델 로딩 완료!   (`6.2s`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a8d2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 벡터스토어 생성하기\n",
    "vectorstore = FAISS.from_documents(documents=splits, embedding=embeddings)\n",
    "\n",
    "# 뉴스에 포함되어 있는 정보를 검색하고 생성하기\n",
    "retriever = vectorstore.as_retriever()                              # 0.2s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7add3cd2",
   "metadata": {},
   "source": [
    "* **`vectorstore.as_retriever()`** 통해 생성된 검색기 → **`hub.pull`로 가져온 `프롬프트`** + **`LLM`** 으로 새로운 내용 생성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ead203",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"당신은 질문-답변(Question-Answering)을 수행하는 친절한 AI 어시스턴트입니다. 당신의 임무는 주어진 문맥(context) 에서 주어진 질문(question) 에 답하는 것입니다.\n",
    "검색된 다음 문맥(context) 을 사용하여 질문(question) 에 답하세요. 만약, 주어진 문맥(context) 에서 답을 찾을 수 없다면, 답을 모른다면 `주어진 정보에서 질문에 대한 정보를 찾을 수 없습니다` 라고 답하세요.\n",
    "한글로 답변해 주세요. 단, 기술적인 용어나 이름은 번역하지 않고 그대로 사용해 주세요.\n",
    "\n",
    "#Question: \n",
    "{question} \n",
    "\n",
    "#Context: \n",
    "{context} \n",
    "\n",
    "#Answer:\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddb2aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05205bd",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* `print(prompt)` 확인하기\n",
    "\n",
    "    ```bash\n",
    "    input_variables=['context', 'question'] input_types={} partial_variables={} template='당신은 질문-답변(Question-Answering)을 수행하는 친절한 AI 어시스턴트입니다. 당신의 임무는 주어진 문맥(context) 에서 주어진 질문(question) 에 답하는 것입니다.\\n검색된 다음 문맥(context) 을 사용하여 질문(question) 에 답하세요. 만약, 주어진 문맥(context) 에서 답을 찾을 수 없다면, 답을 모른다면 `주어진 정보에서 질문에 대한 정보를 찾을 수 없습니다` 라고 답하세요.\\n한글로 답변해 주세요. 단, 기술적인 용어나 이름은 번역하지 않고 그대로 사용해 주세요.\\n\\n#Question: \\n{question} \\n\\n#Context: \\n{context} \\n\\n#Answer:'\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e4804c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prompt.template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38b8564",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* `print(prompt.template)` → *프롬프트의 내용만 확인하기*\n",
    "\n",
    "    ```markdown\n",
    "    당신은 질문-답변(Question-Answering)을 수행하는 친절한 AI 어시스턴트입니다. 당신의 임무는 주어진 문맥(context) 에서 주어진 질문(question) 에 답하는 것입니다.\n",
    "    검색된 다음 문맥(context) 을 사용하여 질문(question) 에 답하세요. 만약, 주어진 문맥(context) 에서 답을 찾을 수 없다면, 답을 모른다면 `주어진 정보에서 질문에 대한 정보를 찾을 수 없습니다` 라고 답하세요.\n",
    "    한글로 답변해 주세요. 단, 기술적인 용어나 이름은 번역하지 않고 그대로 사용해 주세요.\n",
    "\n",
    "    #Question: \n",
    "    {question} \n",
    "\n",
    "    #Context: \n",
    "    {context} \n",
    "\n",
    "    #Answer:\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf8c0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델(LLM) 생성하기\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# API 키 확인\n",
    "if not os.getenv(\"GOOGLE_API_KEY\"):\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = input(\"Enter your Google API key: \")\n",
    "\n",
    "# LLM 초기화\n",
    "gemini_lc = ChatGoogleGenerativeAI(\n",
    "        model=\"gemini-2.5-flash-lite\",\n",
    "        temperature=0,                                              # temperature = 0으로 설정  \n",
    "        max_output_tokens=4096,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13cba885",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0fb7ce6",
   "metadata": {},
   "source": [
    "* **`Chain` 생성하기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c151f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 체인 생성하기\n",
    "rag_chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | gemini_lc\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a3cf51",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a10a2e",
   "metadata": {},
   "source": [
    "* **`스트리밍 출력 함수`** (프롬프트 템플릿 적용, LLM 사용) → 응답 생성해보기\n",
    "\n",
    "  * `LangChain`의 응답을 스트리밍으로 출력하는 기능\n",
    "  * `LLM`이 답변을 생성하는 동안에도 실시간으로 응답을 출력해 사용자가 답변을 기다리는 시간을 줄여주는 기능 → 사용자 경험을 향상시키기 위해 사용됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d636685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스트리밍 출력 함수\n",
    "def stream_response(question, rag_chain):\n",
    "    # 체인을 실행하고 스트리밍 방식으로 응답 생성\n",
    "    for chunk in rag_chain.stream(question):\n",
    "        print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1068e0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용 예시_1\n",
    "question_1 = \"부영그룹의 출산 장려 정책에 대해 설명해주세요.\"\n",
    "stream_response(question_1, rag_chain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00579885",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 부영그룹은 2021년 이후 태어난 직원 자녀에게 1억원씩 총 70억원을 지원하는 파격적인 출산 장려 정책을 시행하고 있습니다. 또한, 셋째 자녀를 출산하는 직원에게는 국민주택을 제공하겠다는 계획도 밝혔습니다.   (`1.3s`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e04241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용 예시_2\n",
    "question_2 = \"부영그룹은 출산 직원에게 얼마의 지원을 제공하나요?\"\n",
    "stream_response(question_2, rag_chain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4972f93a",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 부영그룹은 2021년 이후 태어난 직원 자녀에게 1억원을 지원합니다. 연년생이나 쌍둥이 자녀의 경우 총 2억원을 받을 수 있으며, 셋째를 낳으면 국민주택을 제공하겠다는 계획도 밝혔습니다.     (`0.8s`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb77f7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용 예시_3\n",
    "question_3 = \"정부의 저출생 대책을 bullet points 형식으로 작성해 주세요.\"\n",
    "stream_response(question_3, rag_chain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a3ced0",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 3번째 질문 (`1.2s`)\n",
    "\n",
    "    ```markdown\n",
    "    정부의 저출생 대책은 다음과 같습니다.\n",
    "\n",
    "    *   매달 부모 급여 지급 (0세 아이는 100만원으로 인상)\n",
    "    *   첫만남이용권 지급\n",
    "    *   아동수당 지급 (아이 돌까지 1년 동안 1520만원 지원)\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7405ba48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용 예시_4\n",
    "question_4 = \"부영그룹의 임직원 숫자는 몇명인가요?\"\n",
    "stream_response(question_4, rag_chain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546d0062",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 주어진 정보에서 질문에 대한 정보를 찾을 수 없습니다   (`0.9s`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5a6766",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99113bb5",
   "metadata": {},
   "source": [
    "* next: ***`03. RAG 의 기능별 다양한 모듈 활용기`***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a4f342",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lc_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
