{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba52bed0",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65001001",
   "metadata": {},
   "source": [
    "* ì¶œì²˜: LangChain ê³µì‹ ë¬¸ì„œ ë˜ëŠ” í•´ë‹¹ êµì¬ëª…\n",
    "* ì›ë³¸ URL: https://smith.langchain.com/hub/teddynote/summary-stuff-documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb2ea90",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb18b49c",
   "metadata": {},
   "source": [
    "### **3. `ë„êµ¬ í˜¸ì¶œ ì—ì´ì „íŠ¸`** *(Tool Calling Agent)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f936725",
   "metadata": {},
   "source": [
    "##### **1) ê°œë…**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6ede17",
   "metadata": {},
   "source": [
    "* ë„êµ¬ í˜¸ì¶œ ì‚¬ìš©ì˜ ì´ì  \n",
    "  * ëª¨ë¸ì´ í•˜ë‚˜ ì´ìƒì˜ **`ë„êµ¬` (tool)** ê°€ **í˜¸ì¶œë˜ì–´ì•¼ í•˜ëŠ” ì‹œê¸°ë¥¼ ê°ì§€í•˜ê³  í•´ë‹¹ ë„êµ¬ì— ì „ë‹¬í•´ì•¼ í•˜ëŠ” ì…ë ¥** ìœ¼ë¡œ ì „ë‹¬ ê°€ëŠ¥\n",
    "  * API í˜¸ì¶œì—ì„œ ë„êµ¬ë¥¼ ì„¤ëª…í•˜ê³  ëª¨ë¸ì´ ì´ëŸ¬í•œ ë„êµ¬ë¥¼ í˜¸ì¶œí•˜ê¸° ìœ„í•œ ì¸ìˆ˜ê°€ í¬í•¨ëœ JSONê³¼ ê°™ì€ êµ¬ì¡°í™”ëœ ê°ì²´ë¥¼ ì¶œë ¥í•˜ë„ë¡ ì§€ëŠ¥ì ìœ¼ë¡œ ì„ íƒ ê°€ëŠ¥\n",
    "\n",
    "* ë„êµ¬ APIì˜ ëª©í‘œ: ì¼ë°˜ í…ìŠ¤íŠ¸ ì™„ì„±ì´ë‚˜ ì±„íŒ… APIë¥¼ ì‚¬ìš©í•˜ì—¬ ìˆ˜í–‰í•  ìˆ˜ ìˆëŠ” ê²ƒë³´ë‹¤ **ë” ì•ˆì •ì ìœ¼ë¡œ ìœ íš¨í•˜ê³  ìœ ìš©í•œ `ë„êµ¬ í˜¸ì¶œ`(tool call)** ì„ ë°˜í™˜í•˜ëŠ” ê²ƒ\n",
    "\n",
    "* êµ¬ì¡°í™”ëœ ì¶œë ¥ì„ ë„êµ¬ í˜¸ì¶œ ì±„íŒ… ëª¨ë¸ì— ì—¬ëŸ¬ ë„êµ¬ë¥¼ ë°”ì¸ë”©í•˜ê³  ëª¨ë¸ì´ í˜¸ì¶œí•  ë„êµ¬ë¥¼ ì„ íƒí•  ìˆ˜ ìˆë‹¤ëŠ” ì‚¬ì‹¤ê³¼ ê²°í•©í•˜ì—¬ ì¿¼ë¦¬ê°€ í•´ê²°ë  ë•Œê¹Œì§€ ë°˜ë³µì ìœ¼ë¡œ ë„êµ¬ë¥¼ í˜¸ì¶œí•˜ê³  ê²°ê³¼ë¥¼ ìˆ˜ì‹ í•˜ëŠ” ì—ì´ì „íŠ¸ë¥¼ ë§Œë“¤ ìˆ˜ ìˆìŒ\n",
    "\n",
    "  * ![agent](../16_Agent/assets/agent-concept.png)\n",
    "\n",
    "  * OpenAIì˜ íŠ¹ì • ë„êµ¬ í˜¸ì¶œ ìŠ¤íƒ€ì¼ì— ë§ê²Œ ì„¤ê³„ëœ OpenAI ë„êµ¬ ì—ì´ì „íŠ¸ ë³´ë‹¤ **`ì¼ë°˜í™”ëœ ë²„ì „`**\n",
    "\n",
    "  * **ì—ì´ì „íŠ¸ `LangChain`ì˜ `ToolCall` ì¸í„°í˜ì´ìŠ¤ë¥¼ ì‚¬ìš©** â†’ **`OpenAI`**, **`Anthropic`**, **`Google Gemini`**, **`Mistral`** ê³¼ ê°™ì€ ë” ê´‘ë²”ìœ„í•œ ê³µê¸‰ì êµ¬í˜„ ì§€ì›\n",
    "\n",
    "  * [`ì°¸ê³  ë§í¬`](https://docs.langchain.com/oss/python/langchain/overview)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716fbfa2",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d763fc98",
   "metadata": {},
   "source": [
    "* **`í™˜ê²½ì„¤ì •`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ca9302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API í‚¤ë¥¼ í™˜ê²½ë³€ìˆ˜ë¡œ ê´€ë¦¬í•˜ê¸° ìœ„í•œ ì„¤ì • íŒŒì¼\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API í‚¤ ì •ë³´ ë¡œë“œ\n",
    "load_dotenv()                           # True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b59d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import Client\n",
    "from langsmith import traceable\n",
    "\n",
    "import os\n",
    "\n",
    "# LangSmith í™˜ê²½ ë³€ìˆ˜ í™•ì¸\n",
    "\n",
    "print(\"\\n--- LangSmith í™˜ê²½ ë³€ìˆ˜ í™•ì¸ ---\")\n",
    "langchain_tracing_v2 = os.getenv('LANGCHAIN_TRACING_V2')\n",
    "langchain_project = os.getenv('LANGCHAIN_PROJECT')\n",
    "langchain_api_key_status = \"ì„¤ì •ë¨\" if os.getenv('LANGCHAIN_API_KEY') else \"ì„¤ì •ë˜ì§€ ì•ŠìŒ\" # API í‚¤ ê°’ì€ ì§ì ‘ ì¶œë ¥í•˜ì§€ ì•ŠìŒ\n",
    "\n",
    "if langchain_tracing_v2 == \"true\" and os.getenv('LANGCHAIN_API_KEY') and langchain_project:\n",
    "    print(f\"âœ… LangSmith ì¶”ì  í™œì„±í™”ë¨ (LANGCHAIN_TRACING_V2='{langchain_tracing_v2}')\")\n",
    "    print(f\"âœ… LangSmith í”„ë¡œì íŠ¸: '{langchain_project}'\")\n",
    "    print(f\"âœ… LangSmith API Key: {langchain_api_key_status}\")\n",
    "    print(\"  -> ì´ì œ LangSmith ëŒ€ì‹œë³´ë“œì—ì„œ ì´ í”„ë¡œì íŠ¸ë¥¼ í™•ì¸í•´ ë³´ì„¸ìš”.\")\n",
    "else:\n",
    "    print(\"âŒ LangSmith ì¶”ì ì´ ì™„ì „íˆ í™œì„±í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë‹¤ìŒì„ í™•ì¸í•˜ì„¸ìš”:\")\n",
    "    if langchain_tracing_v2 != \"true\":\n",
    "        print(f\"  - LANGCHAIN_TRACING_V2ê°€ 'true'ë¡œ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤ (í˜„ì¬: '{langchain_tracing_v2}').\")\n",
    "    if not os.getenv('LANGCHAIN_API_KEY'):\n",
    "        print(\"  - LANGCHAIN_API_KEYê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.\")\n",
    "    if not langchain_project:\n",
    "        print(\"  - LANGCHAIN_PROJECTê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f14d715",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* ì…€ ì¶œë ¥\n",
    "\n",
    "    ```bash\n",
    "    --- LangSmith í™˜ê²½ ë³€ìˆ˜ í™•ì¸ ---\n",
    "    âœ… LangSmith ì¶”ì  í™œì„±í™”ë¨ (LANGCHAIN_TRACING_V2='true')\n",
    "    âœ… LangSmith í”„ë¡œì íŠ¸: 'LangChain-prantice'\n",
    "    âœ… LangSmith API Key: ì„¤ì •ë¨\n",
    "    -> ì´ì œ LangSmith ëŒ€ì‹œë³´ë“œì—ì„œ ì´ í”„ë¡œì íŠ¸ë¥¼ í™•ì¸í•´ ë³´ì„¸ìš”.\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9135f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# ê²½ê³  ë©”ì‹œì§€ ë¬´ì‹œ\n",
    "# ========================================\n",
    "import os\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6225bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# ë£¨íŠ¸ ë””ë ‰í† ë¦¬ë¥¼ Python ê²½ë¡œì— ì¶”ê°€\n",
    "root_dir = Path().absolute().parent\n",
    "sys.path.append(str(root_dir))\n",
    "\n",
    "print(f\"âœ… ë£¨íŠ¸ ë””ë ‰í† ë¦¬ ì¶”ê°€: {root_dir}\")\n",
    "\n",
    "# config import\n",
    "from config import get_llm, get_embeddings\n",
    "from config import gpt_5_nano, gpt_5_mini\n",
    "\n",
    "print(\"âœ… config.py import ì„±ê³µ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed2bfbe",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "- ì‘ë‹µ ì‹œê°„: `5.0s`\n",
    "- âœ… ë£¨íŠ¸ ë””ë ‰í† ë¦¬ ì¶”ê°€: `ë£¨íŠ¸/20250727-langchain-note`\n",
    "- âœ… config.py import ì„±ê³µ!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbd0642",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "# API í‚¤ í™•ì¸\n",
    "if not os.getenv(\"GOOGLE_API_KEY2\"):        \n",
    "    os.environ[\"GOOGLE_API_KEY2\"] = input(\"Enter your Google API key: \")    \n",
    "\n",
    "# LLM ì´ˆê¸°í™”\n",
    "gemini_lc = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\",            \n",
    "    temperature=0,                                              # temperature = 0ìœ¼ë¡œ ì„¤ì •              \n",
    "    max_output_tokens=4096,\n",
    "    )\n",
    "\n",
    "result=gemini_lc.invoke(\"ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ”?\")\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3259c112",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* ì…€ ì¶œë ¥: `1.9s`\n",
    "\n",
    "  ```markdown\n",
    "  ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ” **ì„œìš¸**ì…ë‹ˆë‹¤.\n",
    "  ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548c4008",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13412215",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* `2.0s`\n",
    "\n",
    "* `GoogleNews` ë¼ì´ë¸ŒëŸ¬ë¦¬ ì§ì ‘ ì‚¬ìš© ìœ„í•´ ì„¤ì¹˜ \n",
    "\n",
    "    ```python\n",
    "    %pip install GoogleNews\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d402de6",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* `4.1s`\n",
    "\n",
    "* `langchain-experimental` íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
    "\n",
    "    ```python\n",
    "    %pip install langchain-experimental\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35dfc2ea",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ec4764",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "from typing import List, Dict, Annotated\n",
    "from GoogleNews import GoogleNews \n",
    "from langchain_experimental.utilities import PythonREPL\n",
    "\n",
    "\n",
    "# ë„êµ¬ ìƒì„±\n",
    "@tool\n",
    "def search_news(query: str) -> List[Dict[str, str]]:\n",
    "    \"\"\"Search Google News by input keyword\"\"\"\n",
    "    news_tool = GoogleNews()\n",
    "    \n",
    "    # 1. ê²€ìƒ‰ ì‹¤í–‰\n",
    "    # ë©”ì„œë“œ ì´ë¦„ ë³€ê²½í•˜ê¸°: search_by_keyword -> search\n",
    "    news_tool.search(query)\n",
    "\n",
    "\n",
    "    # 2. ê²°ê³¼ ë°˜í™˜ ë°©ì‹ ë³€ê²½í•˜ê¸°: (search_by_keyword() -> result())\n",
    "    # ERROR: return news_tool.search_by_keyword()[:5]\n",
    "    return news_tool.result()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ee5de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë„êµ¬ ìƒì„±\n",
    "@tool\n",
    "def python_repl_tool(\n",
    "    code:Annotated[str, \"The python code to execute to generate your chart.\"],\n",
    "):\n",
    "    \"\"\"Use this to execute python code. If you want to see the output of a value, you should print it out with `print(...)`. This is visible to the user.\"\"\"\n",
    "    result = \"\"\n",
    "    try:\n",
    "        result = PythonREPL().run(code)\n",
    "    except BaseException as e:\n",
    "        print(f\"Failed to execute. Error: {repr(e)}\")\n",
    "    finally:\n",
    "        return result\n",
    "\n",
    "print(f\"â€ ë„êµ¬ ì´ë¦„: {search_news.name}\")\n",
    "print(f\"â€ ë„êµ¬ ì„¤ëª…: {search_news.description}\")\n",
    "print(f\"â‘¡ ë„êµ¬ ì´ë¦„: {python_repl_tool.name}\")\n",
    "print(f\"â‘¡ ë„êµ¬ ì´ë¦„: {python_repl_tool.description}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d520ac32",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* ì…€ ì¶œë ¥\n",
    "\n",
    "```markdown\n",
    "    â€ ë„êµ¬ ì´ë¦„: search_news\n",
    "    â€ ë„êµ¬ ì„¤ëª…: Search Google News by input keyword\n",
    "    â‘¡ ë„êµ¬ ì´ë¦„: python_repl_tool\n",
    "    â‘¡ ë„êµ¬ ì´ë¦„: Use this to execute python code. If you want to see the output of a value, you should print it out with `print(...)`. This is visible to the user.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf051e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tool ì •ì˜\n",
    "\n",
    "tools = [search_news, python_repl_tool]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbc2b9a",
   "metadata": {},
   "source": [
    "##### **2) `Agent` í”„ë¡¬í”„íŠ¸ ìƒì„±**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1f7cfb",
   "metadata": {},
   "source": [
    "* **`chat_history`**: ì´ì „ ëŒ€í™” ë‚´ìš©ì„ ì €ì¥í•˜ëŠ” ë³€ìˆ˜\n",
    "  * *ë©…í‹°í„´ì„ ì§€ì›í•˜ì§€ ì•ŠëŠ”ë‹¤ë©´, ìƒëµ ê°€ëŠ¥*\n",
    "\n",
    "* **`agent_scratchpad`**: ì—ì´ì „íŠ¸ê°€ ì„ì‹œë¡œ ì €ì¥í•˜ëŠ” ë³€ìˆ˜\n",
    "\n",
    "* **`input`**: ì‚¬ìš©ìì˜ ì…ë ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5566551c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ ìƒì„±\n",
    "# í”„ë¡¬í”„íŠ¸ = ì—ì´ì „íŠ¸ì—ê²Œ ëª¨ë¸ì´ ìˆ˜í–‰í•  ì‘ì—…ì„ ì„¤ëª…í•˜ëŠ” í…ìŠ¤íŠ¸ë¥¼ ì œê³µí•¨\n",
    "# ë„êµ¬ì˜ ì´ë¦„ê³¼ ì—­í• ì„ ì…ë ¥í•´ì•¼ í•¨\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant. \"\n",
    "            \"Make sure to use the `search_news` tool for searching keyword related news.\",\n",
    "        ),\n",
    "        (\"placeholder\", \"{chat_history}\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "    ]\n",
    ")                                               # 0.1s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a2cba8",
   "metadata": {},
   "source": [
    "##### **3) Agent ìƒì„±**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373eb0d9",
   "metadata": {},
   "source": [
    "* `langchainì´ v1.0.5`ë¡œ ì—…ë°ì´íŠ¸ë˜ë©´ì„œ **`Agent` ìƒì„± ë°©ë²•ì´ `ë°”ë€œ`**\n",
    "\n",
    "  * ì„í¬íŠ¸ ë°©ë²• ë°”ë€œ\n",
    "    * `from langchain.agents import create_tool_calling_agent` â†’ **`from langchain.agents import create_agent`**\n",
    "\n",
    "  * **`prompt`** ë³€ìˆ˜ = **ë¬¸ìì—´ë¡œë§Œ ì „ë‹¬í•´ì•¼ í•¨** â†’ ë”°ë¼ì„œ **`í”„ë¡¬í”„íŠ¸ì˜ ë‚´ìš© ì¤‘ ì‹œìŠ¤í…œ ì§€ì‹œì‚¬í•­ë§Œì„ ë¬¸ìì—´ë¡œ ì „ë‹¬`** í•˜ëŠ” ê²ƒì´ ê°€ì¥ ê¹”ë”í•˜ê³  ì˜¬ë°”ë¥¸ ë°©ë²•\n",
    "    * ìœ„ì˜ `prompt` ë³€ìˆ˜ë¥¼ `PromptTemplate` ê·¸ëŒ€ë¡œ ì‚¬ìš©í•´ì„œëŠ” ì•ˆë¨\n",
    "    * **`íƒ€ì… ë¶ˆì¼ì¹˜`**: **`str` (ë¬¸ìì—´)** ê¸°ëŒ€í•˜ê¸° ë•Œë¬¸ â†”ï¸ ë°˜ë©´ì— **`PromptTemplate`** = ë³µì¡í•œ ê°ì²´\n",
    "    * **`ê¸°ëŠ¥ ì¤‘ë³µ`**\n",
    "      * ìœ„ í…œí”Œë¦¿ì— ìˆëŠ” `{agent_scratchpad}`ë‚˜ `{chat_history}` ê°™ì€ í”Œë ˆì´ìŠ¤í™€ë”ë“¤ì€ **`ìƒˆë¡œìš´ create_agent í•¨ìˆ˜`ê°€ ë‚´ë¶€ì ìœ¼ë¡œ ì•Œì•„ì„œ ê´€ë¦¬**\n",
    "      * ì „ì²´ í…œí”Œë¦¿ì„ ë„˜ê¸°ë©´ ì´ ê¸°ëŠ¥ë“¤ì´ ì¶©ëŒí•˜ê±°ë‚˜ ì˜ë„ëŒ€ë¡œ ë™ì‘í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd15c395",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.agents import create_agent\n",
    "\n",
    "# LLM ì •ì˜\n",
    "llm = gemini_lc\n",
    "\n",
    "# ì‹œìŠ¤í…œ ë©”ì‹œì§€ ë‚´ìš©ë§Œ ë¬¸ìì—´ë¡œ ì •ì˜\n",
    "system_instruction = (\n",
    "    \"You are a helpful assistant. \"\n",
    "    \"Make sure to use the `search_news` tool for searching keyword related news.\"\n",
    ")\n",
    "\n",
    "# Agent ìƒì„± (v1.0.5 ê¸°ì¤€)\n",
    "agent = create_agent(\n",
    "    model=llm, \n",
    "    tools=tools,\n",
    "    #system_prompt=system_instruction,\n",
    "    )                          # 0.1s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe79fb5",
   "metadata": {},
   "source": [
    "##### **4) AgentExecutor**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f79d224",
   "metadata": {},
   "source": [
    "* `AgentExecutor` = ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ëŠ” ì—ì´ì „íŠ¸ë¥¼ ì‹¤í–‰í•˜ëŠ” í´ë˜ìŠ¤\n",
    "\n",
    "* `v.1.0.5` ì´í›„ ë²„ì „ë¶€í„°ëŠ” ë ˆê±°ì‹œ êµ¬ì„±ìš”ì†Œë¡œ ë¶„ë¥˜ë˜ì–´ **`langchain` ê¸°ë³¸ íŒ¨í‚¤ì§€ì—ì„œ ì œì™¸ë¨** â†’ **`langchain_classic` íŒ¨í‚¤ì§€ë¡œ ì´ë™í•¨**\n",
    "  * í•´ë‹¹ ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ê¸° ìœ„í•´ì„œëŠ” **`import ê²½ë¡œë¥¼ ìˆ˜ì •í•´ì•¼ í•¨`** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23135db2",
   "metadata": {},
   "source": [
    "* **`ì£¼ìš” ì†ì„±`**\n",
    "\n",
    "  * **`agent`**: ì‹¤í–‰ ë£¨í”„ì˜ ê° ë‹¨ê³„ì—ì„œ ê³„íšì„ ìƒì„±í•˜ê³  í–‰ë™ì„ ê²°ì •í•˜ëŠ” ì—ì´ì „íŠ¸\n",
    "\n",
    "  * **`tools`**: ì—ì´ì „íŠ¸ê°€ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ìœ íš¨í•œ ë„êµ¬ ëª©ë¡\n",
    "\n",
    "  * **`return_intermediate_steps`**: ìµœì¢… ì¶œë ¥ê³¼ í•¨ê»˜ ì—ì´ì „íŠ¸ì˜ ì¤‘ê°„ ë‹¨ê³„ ê²½ë¡œë¥¼ ë°˜í™˜í• ì§€ ì—¬ë¶€\n",
    "\n",
    "  * **`max_iterations`**: ì‹¤í–‰ ë£¨í”„ë¥¼ ì¢…ë£Œí•˜ê¸° ì „ ìµœëŒ€ ë‹¨ê³„ ìˆ˜\n",
    "\n",
    "  * **`max_execution_time`**: ì‹¤í–‰ ë£¨í”„ì— ì†Œìš”ë  ìˆ˜ ìˆëŠ” ìµœëŒ€ ì‹œê°„\n",
    "\n",
    "  * **`early_stopping_method`**: ì—ì´ì „íŠ¸ê°€ AgentFinishë¥¼ ë°˜í™˜í•˜ì§€ ì•Šì„ ë•Œ ì‚¬ìš©í•  ì¡°ê¸° ì¢…ë£Œ ë°©ë²•. (\"force\" or \"generate\")\n",
    "    * **`\"force\"`** = ì‹œê°„ or ë°˜ë³µ ì œí•œì— ë„ë‹¬í•˜ì—¬ ì¤‘ì§€ë˜ì—ˆë‹¤ëŠ” ë¬¸ìì—´ ë°˜í™˜\n",
    "    * **`\"generate\"`** = ì—ì´ì „íŠ¸ì˜ LLM ì²´ì¸ì„ ë§ˆì§€ë§‰ìœ¼ë¡œ í•œ ë²ˆ í˜¸ì¶œí•˜ì—¬ ì´ì „ ë‹¨ê³„ì— ë”°ë¼ ìµœì¢… ë‹µë³€ì„ ìƒì„±\n",
    "\n",
    "  * **`handle_parsing_errors`**\n",
    "    * ì—ì´ì „íŠ¸ì˜ ì¶œë ¥ íŒŒì„œì—ì„œ ë°œìƒí•œ ì˜¤ë¥˜ ì²˜ë¦¬ ë°©ë²•\n",
    "    * `True`, `False`, ë˜ëŠ” `ì˜¤ë¥˜ ì²˜ë¦¬ í•¨ìˆ˜`\n",
    "\n",
    "  * **`trim_intermediate_steps`**\n",
    "    * ì¤‘ê°„ ë‹¨ê³„ë¥¼ íŠ¸ë¦¬ë°í•˜ëŠ” ë°©ë²•\n",
    "    * `-1 trim í•˜ì§€ ì•ŠìŒ` or `íŠ¸ë¦¬ë° í•¨ìˆ˜`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99bb8da6",
   "metadata": {},
   "source": [
    "* **`ì£¼ìš” ë©”ì„œë“œ`**\n",
    "\n",
    "  * **`invoke`**: ì—ì´ì „íŠ¸ ì‹¤í–‰\n",
    "\n",
    "  * **`stream`**: ìµœì¢… ì¶œë ¥ì— ë„ë‹¬í•˜ëŠ” ë° í•„ìš”í•˜ëŠ” ë‹¨ê³„ë¥¼ *ìŠ¤íŠ¸ë¦¬ë°*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d59ad9",
   "metadata": {},
   "source": [
    "* **`ì£¼ìš” ê¸°ëŠ¥`**\n",
    "\n",
    "  * **`ë„êµ¬ ê²€ì¦`**: ì—ì´ì „íŠ¸ì™€ í˜¸í™˜ë˜ëŠ” ë„êµ¬ì¸ì§€ í™•ì¸\n",
    "\n",
    "  * **`ì‹¤í–‰ ì œì–´`**: ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜ ë° ì‹¤í–‰ ì‹œê°„ ì œí•œ ì„¤ì • ê°€ëŠ¥\n",
    "\n",
    "  * **`ì˜¤ë¥˜ ì²˜ë¦¬`**: ì¶œë ¥ íŒŒì‹± ì˜¤ë¥˜ì— ëŒ€í•œ ë‹¤ì–‘í•œ ì²˜ë¦¬ ì˜µì…˜ ì œê³µ\n",
    "\n",
    "  * **`ì¤‘ê°„ ë‹¨ê³„ ê´€ë¦¬`**: ì¤‘ê°„ ë‹¨ê³„ íŠ¸ë¦¬ë° ë° ë°˜í™˜ ì˜µì…˜\n",
    "\n",
    "  * **`ë¹„ë™ê¸° ì§€ì›`**: ë¹„ë™ê¸° ì‹¤í–‰ ë° ìŠ¤íŠ¸ë¦¬ë° ì§€ì›"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a4b9b6",
   "metadata": {},
   "source": [
    "* **`ìµœì í™” íŒ`**\n",
    "\n",
    "  * **`max_iterations`** ì™€ **`max_execution_time`** ì„ ì ì ˆíˆ ì„¤ì •í•˜ì—¬ ì‹¤í–‰ ì‹œê°„ ê´€ë¦¬\n",
    "\n",
    "  * **`trim_intermediate_steps`** ë¥¼ í™œìš©í•˜ì—¬ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì í™”\n",
    "\n",
    "  * ë³µì¡í•œ ì‘ì—…ì˜ ê²½ìš° **`stream`** ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ ë‹¨ê³„ë³„ ê²°ê³¼ ëª¨ë‹ˆí„°ë§"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345d260e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb9e0ad",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* ê¸°ì¡´ êµì¬ ì•ˆë‚´ëœ ì½”ë“œë¡œ ì‹¤í–‰í•˜ê¸° â†’ *`ERROR`* ë°œìƒ \n",
    "\n",
    "    ```python\n",
    "\n",
    "    # ê¸°ì¡´: from langchain.agents import AgentExecutor \n",
    "    # v1.0.5 ë²„ì „ìœ¼ë¡œ ì„í¬íŠ¸í•˜ê¸°\n",
    "    from langchain_classic.agents import AgentExecutor\n",
    "    from langchain_core.messages import HumanMessage\n",
    "\n",
    "    # AgentExecutor ìƒì„±í•˜ê¸°\n",
    "    agent_executor = AgentExecutor(\n",
    "        agent = agent,\n",
    "        tools = tools,\n",
    "        verbose = True,\n",
    "        max_iterations = 10,\n",
    "        #max_execution_time = 10,\n",
    "        recursion_limit = 10,\n",
    "        handle_parsing_errors = True,\n",
    "    )                                           # 3.8s\n",
    "\n",
    "\n",
    "    # AgentExecutor ì‹¤í–‰\n",
    "    result = agent_executor.invoke({\"input\":\"AI íˆ¬ìì™€ ê´€ë ¨ëœ ë‰´ìŠ¤ë¥¼ ê²€ìƒ‰í•´ì£¼ì„¸ìš”.\"})\n",
    "\n",
    "    print(\"Agent ì‹¤í–‰ ê²°ê³¼: \")\n",
    "    print(result[\"output\"])\n",
    "\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc69d62c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee016eec",
   "metadata": {},
   "source": [
    "* **`v.1.0.5`** ë²„ì „ì˜ **`agent`** ê°ì²´ëŠ” ì´ë¯¸ ìŠ¤ìŠ¤ë¡œ ì‹¤í–‰ ê³„íšì„ ì„¸ìš°ê³  ë„êµ¬ë¥¼ í˜¸ì¶œí•˜ëŠ” ëª¨ë“  ê¸°ëŠ¥ì„ ê°–ê³  ìˆìŒ \n",
    "  * ì„í¬íŠ¸ ìˆ˜ì •í•˜ê¸° â†’ `result` ìˆ˜ì •í•´ì„œ ì‹¤í–‰í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193b022e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# ì‹¤í–‰ ì‹œ ì…ë ¥ í˜•ì‹ì´ \"messages\" ë¦¬ìŠ¤íŠ¸ì—¬ì•¼ í•¨\n",
    "result = agent.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"AI íˆ¬ìì™€ ê´€ë ¨ëœ ë‰´ìŠ¤ë¥¼ ê²€ìƒ‰í•´ì£¼ì„¸ìš”.\")]},\n",
    "    # max_iterations ëŒ€ì‹  recursion_limit ì‚¬ìš©\n",
    "    config={\"recursion_limit\": 10}\n",
    ")\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "# result[\"messages\"]ì—ëŠ” ëŒ€í™”ì˜ ëª¨ë“  ì¤‘ê°„ ê³¼ì •(ìƒê°, ë„êµ¬ í˜¸ì¶œ ë“±)ì´ í¬í•¨ë˜ì–´ ìˆìŒ\n",
    "print(\"=== ì‹¤í–‰ ê²°ê³¼ ===\")\n",
    "print(result[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94928a4",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* ì…€ ì¶œë ¥ (`6.1s`)\n",
    "\n",
    "    ```markdown\n",
    "    === ì‹¤í–‰ ê²°ê³¼ ===\n",
    "    AI íˆ¬ìì™€ ê´€ë ¨í•˜ì—¬ ë‹¤ìŒê³¼ ê°™ì€ ë‰´ìŠ¤ë“¤ì„ ì°¾ì•„ì™”ìŠµë‹ˆë‹¤:\n",
    "\n",
    "    *   \"AI Hype Cools, Interest Rates Fall: How the Financial Times Sees the Global Investment Landscape in 2026\" - 2026ë…„ ê¸€ë¡œë²Œ íˆ¬ì ì „ë§ì— ëŒ€í•œ ê¸°ì‚¬ë¡œ, AI íˆ¬ì ë¶ì´ ì‚¬ê·¸ë¼ë“¤ê³  ê¸ˆë¦¬ê°€ í•˜ë½í•˜ëŠ” ì¶”ì„¸ë¥¼ ë‹¤ë£¹ë‹ˆë‹¤.\n",
    "    *   \"2026ë…„ ê³ í™•ì‹  íˆ¬ì ì•„ì´ë””ì–´ - AIì˜ í•µì‹¬ ì—ë„ˆì§€ í™•ë³´: ì„±ì¥ ì ì¬ë ¥ ì¸¡ë©´ì—ì„œëŠ” Eaton, ë°©ì–´ ì¸¡ë©´ì—ì„œëŠ” Quanta\" - AI ê¸°ë°˜ ì—ë„ˆì§€ ìˆ˜ìš”ë¥¼ í™œìš©í•˜ëŠ” Eatonê³¼ Quanta Servicesì— ëŒ€í•œ íˆ¬ì ì•„ì´ë””ì–´ë¥¼ ì œê³µí•©ë‹ˆë‹¤.\n",
    "    *   \"TSMC: AIë¡œ ì¸í•œ ê²½ê¸° ì¹¨ì²´ì—ë„ í”ë“¤ë¦¬ì§€ ì•ŠëŠ”, íƒ„íƒ„í•œ ì¥ê¸° íˆ¬ì ì¢…ëª©\" - TSMCê°€ AI ê´€ë ¨ íˆ¬ì ê°ì†Œì—ë„ ë¶ˆêµ¬í•˜ê³  íšŒë³µë ¥ê³¼ ì„±ì¥ ì ì¬ë ¥ì„ ë³´ì—¬ì£¼ëŠ” ì¥ê¸° íˆ¬ì ì¢…ëª©ì„ì„ ë¶„ì„í•©ë‹ˆë‹¤.\n",
    "    *   \"Ubitus Receives Major METI Investment Grant, Investing JPY 17 Billion to Build Japanâ€™s Top AI GPU Center\" - Ubitusê°€ ì¼ë³¸ ìµœê³ ì˜ AI GPU ì„¼í„° êµ¬ì¶•ì„ ìœ„í•´ ëŒ€ê·œëª¨ íˆ¬ìë¥¼ ìœ ì¹˜í–ˆë‹¤ëŠ” ì†Œì‹ì…ë‹ˆë‹¤.\n",
    "    *   \"ê¹€ë¯¼ ì¹´ì§€ë…¸ ë°°ìš° ì—ì„œ ì„±ê³µí•˜ëŠ” ë°©ë²•: ì „ë¬¸ê°€ë“¤ì˜ ì¡°ì–¸ - ì„±ê³µì„ ìœ„í•œ í•„ìˆ˜ ìš”ì†Œ\" - ì´ ë‰´ìŠ¤ëŠ” AI íˆ¬ìì™€ëŠ” ê´€ë ¨ì´ ì—†ì–´ ë³´ì´ë©°, ì˜¤í”ˆAIì˜ AI ë°ì´í„°ì„¼í„° í”„ë¡œì íŠ¸ íˆ¬ì ìœ ì¹˜ ì–´ë ¤ì›€ì— ëŒ€í•œ ë‚´ìš©ì„ ë‹´ê³  ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "    ì´ ì¤‘ì—ì„œ ë” ìì„¸íˆ ì•Œê³  ì‹¶ì€ ë‰´ìŠ¤ê°€ ìˆìœ¼ì‹ ê°€ìš”?\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6059333b",
   "metadata": {},
   "source": [
    "##### **5) Stream ì¶œë ¥ìœ¼ë¡œ ë‹¨ê³„ë³„ ê²°ê³¼ í™•ì¸**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909a2e06",
   "metadata": {},
   "source": [
    "* AgentExecutorì˜ stream() ë©”ì†Œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ ì—ì´ì „íŠ¸ì˜ ì¤‘ê°„ ë‹¨ê³„ë¥¼ ìŠ¤íŠ¸ë¦¬ë°í•  ê²ƒ\n",
    "\n",
    "* **`stream()`** ì˜ ì¶œë ¥ì€ (Action, Observation) ìŒ ì‚¬ì´ì—ì„œ ë²ˆê°ˆì•„ ë‚˜íƒ€ë‚˜ë©°, ìµœì¢…ì ìœ¼ë¡œ ì—ì´ì „íŠ¸ê°€ ëª©í‘œë¥¼ ë‹¬ì„±í–ˆë‹¤ë©´ ë‹µë³€ìœ¼ë¡œ ë§ˆë¬´ë¦¬ë¨\n",
    "\n",
    "  * â€ `Action` ì¶œë ¥\n",
    "  * â `Observation` ì¶œë ¥\n",
    "  * â‚ `Action` ì¶œë ¥\n",
    "  * âƒ `Observation` ì¶œë ¥\n",
    "  * ... (ëª©í‘œ ë‹¬ì„±ê¹Œì§€ ê³„ì†) ...\n",
    "  * ìµœì¢… ëª©í‘œê°€ ë‹¬ì„±ë˜ë©´ ì—ì´ì „íŠ¸ëŠ” ìµœì¢… ë‹µë³€ì„ ì¶œë ¥í•  ê²ƒ\n",
    "  * â„ `Answer` ì¶œë ¥\n",
    "\n",
    "* ì¶œë ¥ ë‚´ìš© ìš”ì•½\n",
    "\n",
    "  | ì¶œë ¥           | ë‚´ìš©                                                                                     |\n",
    "  |--------------|----------------------------------------------------------------------------------------|\n",
    "  | Action       | * actions: AgentAction ë˜ëŠ” ê·¸ í•˜ìœ„ í´ë˜ìŠ¤<br> * messages: ì•¡ì…˜ í˜¸ì¶œì— í•´ë‹¹í•˜ëŠ” ì±„íŒ… ë©”ì‹œì§€                       |\n",
    "  | Observation  | * steps: í˜„ì¬ ì•¡ì…˜ê³¼ ê·¸ ê´€ì°°ì„ í¬í•¨í•œ ì—ì´ì „íŠ¸ê°€ ì§€ê¸ˆê¹Œì§€ ìˆ˜í–‰í•œ ì‘ì—…ì˜ ê¸°ë¡<br> * messages: í•¨ìˆ˜ í˜¸ì¶œ ê²°ê³¼(ì¦‰, ê´€ì°°)ë¥¼ í¬í•¨í•œ ì±„íŒ… ë©”ì‹œì§€ |\n",
    "  | Final Answer | * output: AgentFinish<br> * messages: ìµœì¢… ì¶œë ¥ì„ í¬í•¨í•œ ì±„íŒ… ë©”ì‹œì§€                                     |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# Agent ë°”ë¡œ ì‹¤í–‰í•˜ê¸°\n",
    "# ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œ\n",
    "result = agent.stream(\n",
    "    {\"messages\": [HumanMessage(content=\"AI íˆ¬ìì™€ ê´€ë ¨ëœ ë‰´ìŠ¤ë¥¼ ê²€ìƒ‰í•´ì£¼ì„¸ìš”.\")]},\n",
    "    # max_iterations ëŒ€ì‹  recursion_limit ì‚¬ìš©\n",
    "    config={\"recursion_limit\": 10}\n",
    ")\n",
    "\n",
    "for step in result:\n",
    "    # ì¤‘ê°„ ë‹¨ê³„ ì¶œë ¥ \n",
    "    print(step)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4595dd67",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* ì…€ ì¶œë ¥ (`2.9s`)\n",
    "\n",
    "    ```bash\n",
    "    {'model': {'messages': [AIMessage(content='', additional_kwargs={'function_call': {'name': 'search_news', 'arguments': '{\"query\": \"AI \\\\ud22c\\\\uc790\"}'}}, response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash-lite', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019b83b8-629f-78f0-bc78-b95f52e94a0d-0', tool_calls=[{'name': 'search_news', 'args': {'query': 'AI íˆ¬ì'}, 'id': '75ad57e6-9a3b-4355-9c66-a92a02dd8393', 'type': 'tool_call'}], invalid_tool_calls=[], usage_metadata={'input_tokens': 126, 'output_tokens': 16, 'total_tokens': 142, 'input_token_details': {'cache_read': 0}})]}}\n",
    "    {'tools': {'messages': [ToolMessage(content=\"[{'title': 'AI Hype Cools, Interest Rates Fall: How the Financial Times Sees the Global Investment Landscape in 2026', 'media': 'kmjournal.net', 'date': '2 days ago', 'datetime': datetime.datetime(2026, 1, 1, 20, 57, 39, 328909), 'desc': 'As the world heads into 2026, the Financial Times says one word defines the global outlook: adjustment. The AI investment boom is losing steam,...', 'link': 'https://www.kmjournal.net/news/articleView.html%3Fidxno%3D6917&ved=2ahUKEwj-gcnCqO-RAxWyd_UHHTAQIZgQxfQBegQICBAC&usg=AOvVaw18S93VZbrpDaD1wQavDMV9', 'img': 'data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=='}, {'title': '2026ë…„ ê³ í™•ì‹  íˆ¬ì ì•„ì´ë””ì–´ - AIì˜ í•µì‹¬ ì—ë„ˆì§€ í™•ë³´: ì„±ì¥ ì ì¬ë ¥ ì¸¡ë©´ì—ì„œëŠ” Eaton, ë°©ì–´ ì¸¡ë©´ì—ì„œëŠ” Quanta', 'media': 'Smartkarma', 'date': '1 week ago', 'datetime': datetime.datetime(2025, 12, 27, 20, 57, 39, 337508), 'desc': 'Eatonê³¼ Quanta ServicesëŠ” AI ê¸°ë°˜ ì—ë„ˆì§€ ìˆ˜ìš”ë¥¼ í™œìš©í•˜ì—¬ ì „ë ¥ë§ í™•ì¥ ë° ë°ì´í„° ì„¼í„° ì „ë ¥ ì‚¬ìš©ì„ í¬ê´„í•¨ìœ¼ë¡œì¨ ë‹¤ê°í™”ëœ ë…¸ì¶œê³¼ íšŒë³µë ¥ì„ í™•ë³´í•©ë‹ˆë‹¤.', 'link': 'https://www.smartkarma.com/ko/insights/2026-high-conviction-idea-capturing-ai-s-energy-backbone-eaton-for-upside-quanta-for-defence&ved=2ahUKEwj-gcnCqO-RAxWyd_UHHTAQIZgQxfQBegQIARAC&usg=AOvVaw0OBD-CAFE1oHB-Qj1EtMXA', 'img': 'data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=='}, {'title': 'TSMC: AIë¡œ ì¸í•œ ê²½ê¸° ì¹¨ì²´ì—ë„ í”ë“¤ë¦¬ì§€ ì•ŠëŠ”, íƒ„íƒ„í•œ ì¥ê¸° íˆ¬ì ì¢…ëª©', 'media': 'Smartkarma', 'date': '2 weeks ago', 'datetime': datetime.datetime(2025, 12, 20, 20, 57, 39, 345095), 'desc': 'ì• í”Œì˜ ì§€ì›ì„ ë°›ì•„ TSMCê°€ 2nm ê³µì •ìœ¼ë¡œ ë°œì „í•œ ê²ƒì€ AI ê´€ë ¨ íˆ¬ì ê°ì†Œë¡œ ì¸í•œ ì ì¬ì  íƒ€ê²©ìœ¼ë¡œë¶€í„° íšŒì‚¬ë¥¼ ë³´í˜¸í•´ ì£¼ë©°, íšŒì‚¬ì˜ íšŒë³µë ¥ê³¼ ì„±ì¥ ì ì¬ë ¥ì„ ë³´ì—¬...', 'link': 'https://www.smartkarma.com/ko/insights/tsmc-a-resilient-long-holding-insulated-from-an-ai-slowdown&ved=2ahUKEwj-gcnCqO-RAxWyd_UHHTAQIZgQxfQBegQIChAC&usg=AOvVaw3SrFSmDsUb1NueH1FFyu36', 'img': 'data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=='}, {'title': 'Ubitus Receives Major METI Investment Grant, Investing JPY 17 Billion to Build Japanâ€™s Top AI GPU Center', 'media': 'ë‰´ìŠ¤ì™€ì´ì–´', 'date': '2 weeks ago', 'datetime': datetime.datetime(2025, 12, 20, 20, 57, 39, 352494), 'desc': 'Ubitus K.K., a global leader in cloud streaming and AI solutions (Headquarters: Shinjuku, Tokyo; CEO: Wesley Kuo), today announced that it has been of.', 'link': 'https://www.newswire.co.kr/newsRead.php%3Fno%3D1025743&ved=2ahUKEwj-gcnCqO-RAxWyd_UHHTAQIZgQxfQBegQIBBAC&usg=AOvVaw0DT_hEHlBhRWWo86MJIOsr', 'img': 'data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=='}, {'title': 'ê¹€ë¯¼ ì¹´ì§€ë…¸ ë°°ìš° ì—ì„œ ì„±ê³µí•˜ëŠ” ë°©ë²•: ì „ë¬¸ê°€ë“¤ì˜ ì¡°ì–¸ - ì„±ê³µì„ ìœ„í•œ í•„ìˆ˜ ìš”ì†Œ', 'media': 'termokonteiner.ru', 'date': '2 weeks ago', 'datetime': datetime.datetime(2025, 12, 20, 20, 57, 39, 359726), 'desc': 'ì˜¤ë¼í´ ë¡œê³  ë¯¸êµ­ ì†Œí”„íŠ¸ì›¨ì–´ ê¸°ì—… ì˜¤ë¼í´ì´ ì˜¤í”ˆAIë¥¼ ìœ„í•´ ê±´ì„¤ ì¤‘ì¸ 100ì–µë‹¬ëŸ¬ ê·œëª¨ì˜ AI ë°ì´í„°ì„¼í„° í”„ë¡œì íŠ¸ê°€ íˆ¬ì ìœ ì¹˜ì— ì–´ë ¤ì›€ì„ ê²ªê³  ìˆë‹¤.', 'link': 'https://www.termokonteiner.ru/%3FGameID%3D2025-11-19/5720.html&ved=2ahUKEwj-gcnCqO-RAxWyd_UHHTAQIZgQxfQBegQIBhAC&usg=AOvVaw0JOrsu8ZKCwZxTHiA2Y9Pp', 'img': 'data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=='}]\", name='search_news', id='a87463c5-cd4b-483a-8e19-9cae120eb87f', tool_call_id='75ad57e6-9a3b-4355-9c66-a92a02dd8393')]}}\n",
    "    {'model': {'messages': [AIMessage(content='AI íˆ¬ìì™€ ê´€ë ¨ëœ ë‰´ìŠ¤ë¥¼ ê²€ìƒ‰í–ˆìŠµë‹ˆë‹¤. 2026ë…„ ê¸€ë¡œë²Œ íˆ¬ì ì „ë§, AI ì—ë„ˆì§€ ìˆ˜ìš” í™œìš©, TSMCì˜ ì¥ê¸° íˆ¬ì ê°€ì¹˜, Ubitusì˜ AI GPU ì„¼í„° êµ¬ì¶• íˆ¬ì, ê·¸ë¦¬ê³  ì˜¤ë¼í´ì˜ AI ë°ì´í„°ì„¼í„° í”„ë¡œì íŠ¸ íˆ¬ì ìœ ì¹˜ ì–´ë ¤ì›€ ë“±ì— ëŒ€í•œ ê¸°ì‚¬ê°€ ìˆìŠµë‹ˆë‹¤.', additional_kwargs={}, response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash-lite', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019b83b8-68ca-77b2-baa6-4d39393c9ea6-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 1578, 'output_tokens': 63, 'total_tokens': 1641, 'input_token_details': {'cache_read': 0}})]}}\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48130c95",
   "metadata": {},
   "source": [
    "##### **6) ì¤‘ê°„ ë‹¨ê³„ ì¶œë ¥ì„ ì‚¬ìš©ì ì •ì˜ í•¨ìˆ˜ë¡œ ì¶œë ¥**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a22e19",
   "metadata": {},
   "source": [
    "* ë‹¤ìŒ 3ê°œì˜ í•¨ìˆ˜ë¥¼ ì •ì˜ â†’ ì¤‘ê°„ ë‹¨ê³„ ì¶œë ¥ì„ ì‚¬ìš©ì ì •ì˜í•˜ê¸°\n",
    "\n",
    "  * **`tool_callback`**: ë„êµ¬ í˜¸ì¶œ ì¶œë ¥ì„ ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜\n",
    "\n",
    "  * **`observation_callback`**: ê´€ì°° (`Observation`) ì¶œë ¥ì„ ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜\n",
    "\n",
    "  * **`result_callback`**: ìµœì¢… ë‹µë³€ ì¶œë ¥ì„ ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba8c155",
   "metadata": {},
   "source": [
    "* ì‚¬ìš©ì ì •ì˜ íŒŒì„œ ì„¤ê³„í•˜ê¸°\n",
    "\n",
    "  * `LangGraph`ê°€ ë°˜í™˜í•˜ëŠ” ìŠ¤íŠ¸ë¦¬ë° `chunk` = `dict`\n",
    "    * ì˜ˆì‹œ:\n",
    "\n",
    "    ```bash\n",
    "    ({'model': ...}, {'tools': ...})\n",
    "    ```\n",
    "\n",
    "  * ì‹¤ì œ í•„ìš”í•œ ê²ƒ = **`AIMessage`ì˜ `content`** ë¿\n",
    "    * â€ **`AIì˜ ë‹µë³€`** = (model ë‹¨ê³„) ê·¸ ë‚´ìš©ì„ ì¶œë ¥í•˜ê¸°\n",
    "    * â **`ë„êµ¬ ì‹¤í–‰ ê²°ê³¼`** = (tools ë‹¨ê³„) â†’ í•„ìš”í•˜ë‹¤ë©´ ì¶œë ¥ or ìƒëµí•˜ê¸° \n",
    "      * ë³´í†µ ìµœì¢… ë‹µë³€ë§Œ ë³´ë ¤ë©´ ìƒëµ \n",
    "      * í˜¹ì€ **`\"ê²€ìƒ‰ ì¤‘...\"`** ê°™ì€ ë©”ì‹œì§€ë§Œ ë„ìš°ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57e46f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage, ToolMessage\n",
    "\n",
    "def parse_agent_stream(stream):\n",
    "    \"\"\"\n",
    "    LangGraph Agentì˜ ìŠ¤íŠ¸ë¦¼ ì¶œë ¥ì„ íŒŒì‹±í•˜ì—¬ ê¹”ë”í•˜ê²Œ ë³´ì—¬ì£¼ëŠ” í•¨ìˆ˜\n",
    "    \"\"\"\n",
    "    for chunk in stream:\n",
    "        # 1. ëª¨ë¸(LLM)ì˜ ì‘ë‹µ ë‹¨ê³„ì¸ ê²½ìš°\n",
    "        if \"model\" in chunk:\n",
    "            model_messages = chunk[\"model\"][\"messages\"]\n",
    "            for message in model_messages:\n",
    "                if isinstance(message, AIMessage):\n",
    "                    # ë„êµ¬ í˜¸ì¶œì´ í¬í•¨ëœ ê²½ìš° (ì•„ì§ ìµœì¢… ë‹µë³€ ì•„ë‹˜)\n",
    "                    if message.tool_calls:\n",
    "                        tool_name = message.tool_calls[0]['name']\n",
    "                        tool_args = message.tool_calls[0]['args']\n",
    "                        print(f\"ğŸ› ï¸ ë„êµ¬ í˜¸ì¶œ: {tool_name} (ì¸ì: {tool_args})\")\n",
    "                    # ìµœì¢… ë‹µë³€ì¸ ê²½ìš° (contentê°€ ìˆëŠ” ê²½ìš°)\n",
    "                    elif message.content:\n",
    "                        print(f\"ğŸ¤– AI ë‹µë³€: {message.content}\")\n",
    "\n",
    "        # 2. ë„êµ¬(Tool) ì‹¤í–‰ ê²°ê³¼ ë‹¨ê³„ì¸ ê²½ìš°\n",
    "        elif \"tools\" in chunk:\n",
    "            tool_messages = chunk[\"tools\"][\"messages\"]\n",
    "            for message in tool_messages:\n",
    "                if isinstance(message, ToolMessage):\n",
    "                    print(f\"âœ… ë„êµ¬ ì‹¤í–‰ ì™„ë£Œ (ê²°ê³¼ ê¸¸ì´: {len(message.content)}ì)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e950fd",
   "metadata": {},
   "source": [
    "* ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ìœ¼ë¡œ Agent ì˜ ì‘ë‹µ ê³¼ì •ì„ í™•ì¸í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì§ˆì˜ì— ëŒ€í•œ ë‹µë³€ì„ ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ì¶œë ¥ ìš”ì²­\n",
    "result = agent.stream(\n",
    "    {\"messages\" : [HumanMessage(content=\"matplotlib ì„ ì‚¬ìš©í•˜ì—¬ pie ì°¨íŠ¸ë¥¼ ê·¸ë¦¬ëŠ” ì½”ë“œë¥¼ ì‘ì„±í•˜ê³  ì‹¤í–‰í•˜ì„¸ìš”.\")]},\n",
    "    config={\"recursion_limit\": 10}\n",
    ")\n",
    "\n",
    "# ì‚¬ìš©ì ì •ì˜ íŒŒì„œ í•¨ìˆ˜ë¡œ ì¶œë ¥í•˜ê¸°\n",
    "# í•¨ìˆ˜ì— ìŠ¤íŠ¸ë¦¼ ê°ì²´ë¥¼ í†µì§¸ë¡œ ì „ë‹¬\n",
    "# (í•¨ìˆ˜ ì•ˆì—ì„œ for ë£¨í”„ë¥¼ ëŒë©´ì„œ í•˜ë‚˜ì”© êº¼ë‚´ ì²˜ë¦¬í•¨)\n",
    "parse_agent_stream(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b757c927",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* ì…€ ì¶œë ¥ (`2.4s`)\n",
    "\n",
    "    ```bash\n",
    "    WARNING:langchain_experimental.utilities.python:Python REPL can execute arbitrary code. Use with caution.\n",
    "    ğŸ› ï¸ ë„êµ¬ í˜¸ì¶œ: python_repl_tool (ì¸ì: {'code': \"\\nimport matplotlib.pyplot as plt\\n\\nlabels = ['A', 'B', 'C', 'D']\\nsizes = [15, 30, 45, 10]\\n\\nfig, ax = plt.subplots()\\nax.pie(sizes, labels=labels, autopct='%1.1f%%')\\nax.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\\n\\nplt.show()\\n\"})\n",
    "    âœ… ë„êµ¬ ì‹¤í–‰ ì™„ë£Œ (ê²°ê³¼ ê¸¸ì´: 51ì)\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29fc4190",
   "metadata": {},
   "source": [
    "* ì‹¤ì œ ê·¸ë˜í”„ê°€ ê·¸ë ¤ì§€ì§€ ì•ŠëŠ” ë¬¸ì œê°€ ë°œìƒ\n",
    "\n",
    "* ì›ì¸ ë¶„ì„\n",
    "  * PythonREPL ë„êµ¬ëŠ” ì½”ë“œë¥¼ ì‹¤í–‰í•˜ê³  í‘œì¤€ ì¶œë ¥(stdout) ê²°ê³¼ë¥¼ ë¬¸ìì—´ë¡œ ë°˜í™˜\n",
    "  * í…ìŠ¤íŠ¸(print ê²°ê³¼ ë“±)ëŠ” ì˜ ë‚˜ì˜¤ì§€ë§Œ, matplotlibìœ¼ë¡œ ê·¸ë¦° ê·¸ë˜í”„ëŠ” ì´ë¯¸ì§€ ë°ì´í„°ì´ë¯€ë¡œ í„°ë¯¸ë„ì´ë‚˜ ì¼ë°˜ì ì¸ í…ìŠ¤íŠ¸ ì¶œë ¥ìœ¼ë¡œëŠ” ë³¼ ìˆ˜ ì—†ìŒ\n",
    "  * PythonREPL ë„êµ¬ëŠ” ë³„ë„ì˜ ê²©ë¦¬ëœ(í˜¹ì€ ë³„ë„ì˜) íŒŒì´ì¬ í”„ë¡œì„¸ìŠ¤ë‚˜ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ì—ì„œ ì‹¤í–‰ë˜ê¸° ë•Œë¬¸ì— plt.show()ë¥¼ í•´ë„ ë…¸íŠ¸ë¶ í™”ë©´ì— ë‚˜íƒ€ë‚˜ì§€ ì•ŠìŒ\n",
    "\n",
    "* í•´ê²° ë°©ë²•: ì—ì´ì „íŠ¸ê°€ ìƒì„±í•œ ì½”ë“œë¥¼ ì§ì ‘ ì‹¤í–‰í•˜ê±°ë‚˜, ê·¸ë˜í”„ ì´ë¯¸ì§€ë¥¼ ì €ì¥í•˜ì—¬ ë³´ì—¬ì£¼ëŠ” ë°©ì‹ìœ¼ë¡œ ë³€ê²½í•´ì•¼ í•¨\n",
    "  * **`ê°€ì¥ ê°„ë‹¨í•˜ê²Œ ê·¸ë˜í”„ë¥¼ í™•ì¸í•˜ëŠ” ë°©ë²•ì€ ì—ì´ì „íŠ¸ê°€ ì‘ì„±í•œ ì½”ë“œë¥¼ ë³µì‚¬í•´ì„œ ë…¸íŠ¸ë¶ ì…€ì—ì„œ ì‹¤í–‰í•˜ëŠ” ê²ƒ`**\n",
    "  * ìë™í™”: **`ì—ì´ì „íŠ¸ê°€ ì½”ë“œë¥¼ ì‹¤í–‰í•œ í›„, ê·¸ ì½”ë“œë¥¼ ì‚¬ìš©ìì—ê²Œ ë³´ì—¬ì£¼ë„ë¡ ìœ ë„`**\n",
    "    * ì´ì „ì˜ ì‚¬ìš©ì ì •ì˜ í•¨ìˆ˜ = ë„êµ¬ì˜ **`í˜¸ì¶œ ì •ë³´(ì¸ì)`** ë§Œ ì¶œë ¥\n",
    "    * **`ì‹¤í–‰ëœ ì½”ë“œë¥¼ ì¶œë ¥í•˜ë„ë¡ ìœ ë„ â†’ ê·¸ë˜í”„ í™•ì¸ ê°€ëŠ¥`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5321983a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage, ToolMessage\n",
    "import json\n",
    "\n",
    "def parse_agent_stream(stream):\n",
    "    \"\"\"\n",
    "    LangGraph Agentì˜ ìŠ¤íŠ¸ë¦¼ ì¶œë ¥ì„ íŒŒì‹±í•˜ì—¬ ê¹”ë”í•˜ê²Œ ë³´ì—¬ì£¼ëŠ” í•¨ìˆ˜\n",
    "    \"\"\"\n",
    "    for chunk in stream:\n",
    "        if \"model\" in chunk:\n",
    "            model_messages = chunk[\"model\"][\"messages\"]\n",
    "            for message in model_messages:\n",
    "                if isinstance(message, AIMessage):\n",
    "                    if message.tool_calls:\n",
    "                        for tool_call in message.tool_calls:\n",
    "                            tool_name = tool_call['name']\n",
    "                            tool_args = tool_call['args']\n",
    "                            \n",
    "                            # tool_argsê°€ ë¬¸ìì—´ì´ë©´ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜ ì‹œë„\n",
    "                            if isinstance(tool_args, str):\n",
    "                                try:\n",
    "                                    tool_args = json.loads(tool_args)\n",
    "                                except json.JSONDecodeError:\n",
    "                                    pass # ë³€í™˜ ì‹¤íŒ¨ ì‹œ ê·¸ëŒ€ë¡œ ë‘ \n",
    "\n",
    "                            # ì½”ë“œ ì‹¤í–‰ ë„êµ¬ì¸ ê²½ìš°\n",
    "                            if isinstance(tool_args, dict) and \"code\" in tool_args:\n",
    "                                print(f\"ğŸ› ï¸ [ì½”ë“œ ìƒì„±]\\n\")\n",
    "                                print(\"```python\")\n",
    "                                print(tool_args['code'])\n",
    "                                print(\"```\")\n",
    "                            else:\n",
    "                                print(f\"ğŸ› ï¸ ë„êµ¬ í˜¸ì¶œ: {tool_name} (ì¸ì: {tool_args})\")\n",
    "                            \n",
    "                    elif message.content:\n",
    "                        print(f\"ğŸ¤– AI ë‹µë³€: {message.content}\")\n",
    "\n",
    "        elif \"tools\" in chunk:\n",
    "            tool_messages = chunk[\"tools\"][\"messages\"]\n",
    "            for message in tool_messages:\n",
    "                if isinstance(message, ToolMessage):\n",
    "                    print(f\"âœ… ì‹¤í–‰ ì™„ë£Œ: {message.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7d9f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìŠ¤íŠ¸ë¦¼ ì‹¤í–‰\n",
    "result_stream = agent.stream(\n",
    "    {\"messages\" : [HumanMessage(content=\"matplotlib ì˜ˆì œ ì½”ë“œ ë³´ì—¬ì£¼ê³ , ì‹¤ì œ íŒŒì´ì°¨íŠ¸ë¥¼ ê·¸ë ¤ì¤˜.\")]},\n",
    "    config={\"recursion_limit\": 10}\n",
    ")\n",
    "\n",
    "parse_agent_stream(result_stream)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ecf23e9",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* ì…€ ì¶œë ¥ (`2.2s`)\n",
    "\n",
    "  * ğŸ› ï¸ [ì½”ë“œ ìƒì„±]\n",
    "\n",
    "    ```python\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    # Pie chart data\n",
    "    labels = ['Apple', 'Banana', 'Cherry', 'Date']\n",
    "    sizes = [15, 30, 45, 10]\n",
    "\n",
    "    # Create pie chart\n",
    "    fig1, ax1 = plt.subplots()\n",
    "    ax1.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=90)\n",
    "    ax1.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    ```\n",
    "  * âœ… ì‹¤í–‰ ì™„ë£Œ: ModuleNotFoundError(\"No module named 'matplotlib'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908a23e8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64726aac",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* ì‚¬ì „ì— `matplotlib` ì„¤ì¹˜ í•„ìš”\n",
    "\n",
    "    ```python\n",
    "    %pip install matplotlib\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9ea986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìŠ¤íŠ¸ë¦¼ ì‹¤í–‰\n",
    "result_stream = agent.stream(  \n",
    "    {\"messages\" : [HumanMessage(content=\"matplotlibì„ ì‚¬ìš©í•˜ì—¬ íŒŒì´ ì°¨íŠ¸ë¥¼ ê·¸ë¦¬ëŠ” ì½”ë“œë¥¼ ì‘ì„±í•˜ê³ , ì§€ê¸ˆ ë°”ë¡œ ì‹¤í–‰í•´ì£¼ì„¸ìš”.\")]},\n",
    "    config={\"recursion_limit\": 10}\n",
    ")\n",
    "\n",
    "parse_agent_stream(result_stream)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7caa5622",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* ì…€ ì¶œë ¥ (`4.4s`)\n",
    "\n",
    "  * ğŸ› ï¸ [ì½”ë“œ ìƒì„±]\n",
    "\n",
    "    ```python\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    # Data for the pie chart\n",
    "    labels = ['A', 'B', 'C', 'D']\n",
    "    sizes = [15, 30, 45, 10]\n",
    "    colors = ['gold', 'yellowgreen', 'lightcoral', 'lightskyblue']\n",
    "    explode = (0.1, 0, 0, 0)  # explode 1st slice\n",
    "\n",
    "    # Plot\n",
    "    plt.pie(sizes, explode=explode, labels=labels, colors=colors,\n",
    "    autopct='%1.1f%%', shadow=True, startangle=140)\n",
    "\n",
    "    plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "    plt.title('My Pie Chart')\n",
    "    plt.show()\n",
    "\n",
    "    ```\n",
    "\n",
    "  * ![output_pie_chart](../16_Agent/assets/03_Agent_output.png)\n",
    "\n",
    "  * âœ… ì‹¤í–‰ ì™„ë£Œ: \n",
    "\n",
    "  * ğŸ¤– AI ë‹µë³€: íŒŒì´ ì°¨íŠ¸ê°€ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤. (ì°¸ê³ : `plt.show()`ëŠ” ìƒˆ ì°½ì— ì°¨íŠ¸ë¥¼ í‘œì‹œí•˜ë¯€ë¡œ, ì›¹ ê¸°ë°˜ í™˜ê²½ì—ì„œëŠ” ì§ì ‘ì ì¸ ì‹œê°ì  ì¶œë ¥ì„ ë³¼ ìˆ˜ ì—†ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d6f948",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09795f13",
   "metadata": {},
   "source": [
    "* next: ***`03. ì—ì´ì „íŠ¸(Agent)` â***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b71fb18",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lc_eval_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
