{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36ae39fe",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064ce159",
   "metadata": {},
   "source": [
    "* 출처: LangChain 공식 문서 또는 해당 교재명\n",
    "* 원본 URL: https://smith.langchain.com/hub/teddynote/summary-stuff-documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0164fdbe",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e402a769",
   "metadata": {},
   "source": [
    "### **`LlamaParser`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da66e2a2",
   "metadata": {},
   "source": [
    "* **`LlamaParse`**\n",
    "  * `LlamaIndex`에서 개발한 문서 파싱 서비스\n",
    "  * **`대규모 언어 모델`(`LLM`)을 위해 특별히 설계됨** \n",
    "\n",
    "<br>\n",
    "\n",
    "* 주요 특징\n",
    "\n",
    "  * **다양한 문서 형식 지원**: **`PDF`, `Word`, `PowerPoint`, `Excel` 등**\n",
    "  * **`자연어 지시`** 를 통한 **`맞춤형 출력 형식`** 제공\n",
    "  * **`복잡한 표`와 `이미지` 추출 기능**\n",
    "  * **`JSON` 모드 지원**\n",
    "  * **`외국어`** 지원\n",
    "\n",
    "<br>\n",
    "\n",
    "* **`독립형 API`로 제공**\n",
    "* **`LlamaCloud` 플랫폼의 일부로도 사용 가능**\n",
    "  * 목표: `문서를 파싱`하고 `정제`하여 **`RAG`** (검색 증강 생성) 등 **`LLM 기반` 애플리케이션의 성능을 향상시키는 것**\n",
    "\n",
    "<br>\n",
    "\n",
    "* **`무료로 하루 1,000페이지` 처리 가능** (유료 플랜을 통해 추가 용량을 확보 가능)\n",
    "\n",
    "<br>\n",
    "\n",
    "* LlamaParse는 `현재 공개 베타 버전`으로 제공 → 지속적으로 기능이 확장되는 중"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d12059",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee5ca88",
   "metadata": {},
   "source": [
    "### **사전 환경 설정**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068ee9fe",
   "metadata": {},
   "source": [
    "* `VS Code` 터미널에 사전 설치할 것\n",
    "\n",
    "```python\n",
    "\n",
    "        pip install llama-index-core llama-parse llama-index-readers-file python-dotenv\n",
    "\n",
    "```\n",
    "\n",
    "* 참고: [**`링크`**](https://cloud.llamaindex.ai)\n",
    "\n",
    "* **`API Key`** 설정: **`.env`** 파일에 **`LLAMA_CLOUD_API_KEY`** 키 설정하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba008ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API KEY를 환경변수로 관리하기 위한 설정 파일\n",
    "import os\n",
    "import nest_asyncio\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API KEY 정보로드\n",
    "load_dotenv()                                       # true\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14da424",
   "metadata": {},
   "source": [
    "* 기본 파서 적용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c9b2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 모듈 임포트\n",
    "from llama_parse import LlamaParse\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "# 파서 설정\n",
    "parser = LlamaParse(\n",
    "    result_type=\"markdown\",              # \"markdown\"과 \"text\" 사용 가능\n",
    "    num_workers=8,                       # worker 수 (기본값: 4)\n",
    "    verbose=True,\n",
    "    language=\"ko\",\n",
    ")\n",
    "\n",
    "# SimpleDirectoryReader를 사용하여 파일 파싱\n",
    "file_extractor = {\".pdf\": parser}\n",
    "\n",
    "# LlamaParse로 파일 파싱\n",
    "documents = SimpleDirectoryReader(\n",
    "    input_files=[\"../06_Document_Loader/data/SPRI_AI_Brief_2023년12월호_F.pdf\"],\n",
    "    file_extractor=file_extractor,\n",
    ").load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebdb4a50",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 셀 출력 (41.8s)\n",
    "\n",
    "    ```markdown\n",
    "    2025-09-16 12:44:10,509 - INFO - HTTP Request: POST https://api.cloud.llamaindex.ai/api/parsing/upload \"HTTP/1.1 200 OK\"\n",
    "    Started parsing the file under job_id d2caa84f-170a-43fe-bf66-2dee8666af8c\n",
    "    2025-09-16 12:44:11,840 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/d2caa84f-170a-43fe-bf66-2dee8666af8c \"HTTP/1.1 200 OK\"\n",
    "    2025-09-16 12:44:14,368 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/d2caa84f-170a-43fe-bf66-2dee8666af8c \"HTTP/1.1 200 OK\"\n",
    "    2025-09-16 12:44:17,768 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/d2caa84f-170a-43fe-bf66-2dee8666af8c \"HTTP/1.1 200 OK\"\n",
    "    2025-09-16 12:44:22,195 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/d2caa84f-170a-43fe-bf66-2dee8666af8c \"HTTP/1.1 200 OK\"\n",
    "    2025-09-16 12:44:27,961 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/d2caa84f-170a-43fe-bf66-2dee8666af8c \"HTTP/1.1 200 OK\"\n",
    "    2025-09-16 12:44:33,661 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/d2caa84f-170a-43fe-bf66-2dee8666af8c \"HTTP/1.1 200 OK\"\n",
    "    2025-09-16 12:44:39,584 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/d2caa84f-170a-43fe-bf66-2dee8666af8c \"HTTP/1.1 200 OK\"\n",
    "    2025-09-16 12:44:45,308 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/d2caa84f-170a-43fe-bf66-2dee8666af8c \"HTTP/1.1 200 OK\"\n",
    "    2025-09-16 12:44:45,848 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/d2caa84f-170a-43fe-bf66-2dee8666af8c/result/markdown \"HTTP/1.1 200 OK\"\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19409df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 로드된 문서 개수 출력\n",
    "\n",
    "print(f\"로드된 문서 개수: {len(documents)}\")            # 로드된 문서 개수: 23"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ecaf80c",
   "metadata": {},
   "source": [
    "* **`LlamaIndex`** → **`LangChain Document`** 로 변환하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42e77d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 랭체인 도큐먼트로 변환\n",
    "docs = [doc.to_langchain_format() for doc in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf6177f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metadata 출력\n",
    "\n",
    "docs[0].metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7864dc69",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 셀 출력\n",
    "\n",
    "    ```python\n",
    "    {'file_path': '../06_Document_Loader/data/SPRI_AI_Brief_2023년12월호_F.pdf',\n",
    "    'file_name': 'SPRI_AI_Brief_2023년12월호_F.pdf',\n",
    "    'file_type': 'application/pdf',\n",
    "    'file_size': 975735,\n",
    "    'creation_date': '2025-09-12',\n",
    "    'last_modified_date': '2025-09-12'}\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45e45e0",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa56ad26",
   "metadata": {},
   "source": [
    "### **`MultiModal Model`로 파싱**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5808ef",
   "metadata": {},
   "source": [
    "* 주요 파라미터\n",
    "\n",
    "  * **`use_vendor_multimodal_model`**\n",
    "    * 멀티모달 모델 사용 여부 지정\n",
    "    * **`True`로 설정 → `외부 벤더의 멀티모달 모델`을 `사용`**\n",
    "\n",
    "  * **`vendor_multimodal_model_name`**\n",
    "    * 사용할 멀티모달 모델의 이름을 지정\n",
    "    * **`gemini-2.5-flash` 사용하기**\n",
    "\n",
    "  * **`vendor_multimodal_api_key`**\n",
    "    * **`멀티모달 모델 API 키` 지정하기 \n",
    "    * 환경 변수(`.env`)에서 `API 키` 가져오기\n",
    "\n",
    "  * **`result_type`**\n",
    "    * **`파싱 결과`의 `형식` 지정하기\n",
    "    * **`markdown`으로 설정** → 결과가 마크다운 형식으로 반환됨\n",
    "\n",
    "  * **`language`**\n",
    "    * 파싱할 문서의 **`언어` 지정**\n",
    "    * **`\"ko\"`로 설정** → 한국어로 처리\n",
    "\n",
    "  * **`skip_diagonal_text`**: 대각선 텍스트를 건너뛸지 여부를 결정\n",
    "\n",
    "  * **`page_separator`**: 페이지 구분자 지정 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4d701d",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = LlamaParse(\n",
    "    use_vendor_multimodal_model=True,\n",
    "    vendor_multimodal_model_name=\"openai-gpt-4o\",\n",
    "    vendor_multimodal_api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    "    result_type=\"markdown\",\n",
    "    language=\"ko\",\n",
    "    # skip_diagonal_text=True,\n",
    "    # page_separator=\"\\n=================\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112ecb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parsing 된 결과\n",
    "parsed_docs = documents.load_data(file_path=\"../06_Document_Loader/data/SPRI_AI_Brief_2023년12월호_F.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8211f163",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 셀 출력\n",
    "\n",
    "    ```markdown\n",
    "    Started parsing the file under job_id c7c29c38-d183-4c66-a9f6-2c14e90da500\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0cd6be6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# langchain 도큐먼트로 변환\n",
    "docs = [doc.to_langchain_format() for doc in parsed_docs]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87934891",
   "metadata": {},
   "source": [
    "* 사용자 정의 인스트럭션 지정 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ac96aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parsing instruction 지정하기\n",
    "parsing_instruction = (\n",
    "    \"You are parsing a brief of AI Report. Please extract tables in markdown format.\"\n",
    ")\n",
    "\n",
    "# LlamaParse 설정\n",
    "parser = LlamaParse(\n",
    "    use_vendor_multimodal_model=True,\n",
    "    vendor_multimodal_model_name=\"openai-gpt-4o-mini\",\n",
    "    vendor_multimodal_api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    "    result_type=\"markdown\",\n",
    "    language=\"ko\",\n",
    "    #parsing_instruction=parsing_instruction,\n",
    "    system_prompt=parsing_instruction,\n",
    ")\n",
    "\n",
    "# parsing 된 결과\n",
    "parsed_docs = parser.load_data(file_path=\"../06_Document_Loader/data/SPRI_AI_Brief_2023년12월호_F.pdf\")\n",
    "\n",
    "# langchain 도큐먼트로 변환\n",
    "docs = [doc.to_langchain_format() for doc in parsed_docs]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51fa0e9a",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 셀 출력\n",
    "\n",
    "    ```markdown\n",
    "    Started parsing the file under job_id b0947ed1-3d8f-4eaa-bf6a-e6a746ff697f\n",
    "\n",
    "    .\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e020f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# markdown 형식으로 추출된 테이블 확인\n",
    "print(docs[-2].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b4183e",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 셀 출력\n",
    "\n",
    "    ```markdown\n",
    "    # Ⅱ. 주요 행사 일정\n",
    "\n",
    "    | 행사명 | 행사 주요 개요 |\n",
    "    | --- | --- |\n",
    "    | CES 2024 | - 미국 소비자기술 협회(CTA)가 주관하는 세계 최대 가전·IT·소비재 전시회로 5G, AR&VR, 디지털헬스, 교통·모빌리티 등 주요 카테고리 중심으로 기업들이 최신의 기술 제품들을 전시\n",
    "    - CTA 사피로 회장은 가장 주목받는 섹터로 AI를 꼽았으며, 모든 산업을 포함한다는 의미에서 '올 인AI on'을 주제로 한 이번 전시에는 500곳 이상의 한국기업 참가 예정\n",
    "\n",
    "    ![CES 2024](https://www.ces.tech/) |\n",
    "    | 기간 | 2024.1.9~12 |\n",
    "    | 장소 | 미국, 라스베가스 |\n",
    "    | 홈페이지 | [https://www.ces.tech/](https://www.ces.tech/) |\n",
    "\n",
    "    | 행사명 | 행사 주요 개요 |\n",
    "    | --- | --- |\n",
    "    | AIMLA 2024 | - 머신러닝 및 응용에 관한 국제 컨퍼런스(AIMLA 2024)는 인공지능 및 머신러닝의 이론, 방법론 및 실용적 접근에 관한 지식과 최신 연구 결과 공유\n",
    "    - 이론 및 실무 측면에서 인공지능, 기계학습의 주요 분야를 논의하고, 함께, 산업계의 연구자와 실무자들에게 해당 분야의 최첨단 개발 소식 공유\n",
    "\n",
    "    ![AIMLA 2024](https://ccnet2024.org/aimla/index) |\n",
    "    | 기간 | 2024.1.27~28 |\n",
    "    | 장소 | 덴마크, 코펜하겐 |\n",
    "    | 홈페이지 | [https://ccnet2024.org/aimla/index](https://ccnet2024.org/aimla/index) |\n",
    "\n",
    "    | 행사명 | 행사 주요 개요 |\n",
    "    | --- | --- |\n",
    "    | AAAI Conference on Artificial Intelligence | - AI 발전 협회 컨퍼런스(AAAI)는 AI 연구를 촉진하고, AI 분야 연구원, 실무자, 과학자, 학술 및 공학자 간 교류의 기회 제공\n",
    "    - 컨퍼런스에서 AI 관련 기술 발표, 특별 트랙, 초청 연사, 워크숍, 튜토리얼, 포스터 세션, 주제 발표, 대회, 전시 프로그램 등 진행\n",
    "\n",
    "    ![AAAI Conference on Artificial Intelligence](https://aaai.org/aaai-conference/) |\n",
    "    | 기간 | 2024.2.20~27 |\n",
    "    | 장소 | 캐나다, 밴쿠버 |\n",
    "    | 홈페이지 | [https://aaai.org/aaai-conference/](https://aaai.org/aaai-conference/) |\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd7180a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc85fca1",
   "metadata": {},
   "source": [
    "* *next: `CH07 텍스트 분할 (Text Splitter)`*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d303dd1",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lc_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
