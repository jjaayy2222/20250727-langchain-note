{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba52bed0",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65001001",
   "metadata": {},
   "source": [
    "* 출처: LangChain 공식 문서 또는 해당 교재명\n",
    "* 원본 URL: https://smith.langchain.com/hub/teddynote/summary-stuff-documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f884510",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb18b49c",
   "metadata": {},
   "source": [
    "### **3. `RunnableLambda`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f936725",
   "metadata": {},
   "source": [
    "#### **1) `RunnableLambda`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad1807f",
   "metadata": {},
   "source": [
    "* **`사용자 정의 함수 실행`** 할 수 있는 기능\n",
    "\n",
    "  * **`RunnableLambda` → `자신만의 함수 정의, 실행 가능`**\n",
    "\n",
    "  * 예시: *데이터 전처리*, *계산*, *외부 API와의 상호 작용* 등"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6638d77",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6bb9c2",
   "metadata": {},
   "source": [
    "#### **2) `사용자 정의 함수 실행하는 방법`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb5960e",
   "metadata": {},
   "source": [
    "* **`주의사항`**\n",
    "\n",
    "  * **`RunnableLambda`** → 사용자 정의 함수를 래핑해서 활용 가능\n",
    "\n",
    "  * **`사용자 정의 함수가 받을 수 있는 인자` = `only 1`**\n",
    "    * *만약, 여러 인수를 받는 함수로 구현하고 싶다면?*\n",
    "    * 단일  입력을 받아들이고 이를 여러 인수로 풀어내는 래퍼를 작성해야 함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d763fc98",
   "metadata": {},
   "source": [
    "* **`환경설정`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ca9302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API 키를 환경변수로 관리하기 위한 설정 파일\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API 키 정보 로드\n",
    "load_dotenv()                           # True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ef86f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import Client\n",
    "from langsmith import traceable\n",
    "\n",
    "import os\n",
    "\n",
    "# LangSmith 환경 변수 확인\n",
    "\n",
    "print(\"\\n--- LangSmith 환경 변수 확인 ---\")\n",
    "langchain_tracing_v2 = os.getenv('LANGCHAIN_TRACING_V2')\n",
    "langchain_project = os.getenv('LANGCHAIN_PROJECT')\n",
    "langchain_api_key_status = \"설정됨\" if os.getenv('LANGCHAIN_API_KEY') else \"설정되지 않음\" # API 키 값은 직접 출력하지 않음\n",
    "\n",
    "if langchain_tracing_v2 == \"true\" and os.getenv('LANGCHAIN_API_KEY') and langchain_project:\n",
    "    print(f\"✅ LangSmith 추적 활성화됨 (LANGCHAIN_TRACING_V2='{langchain_tracing_v2}')\")\n",
    "    print(f\"✅ LangSmith 프로젝트: '{langchain_project}'\")\n",
    "    print(f\"✅ LangSmith API Key: {langchain_api_key_status}\")\n",
    "    print(\"  -> 이제 LangSmith 대시보드에서 이 프로젝트를 확인해 보세요.\")\n",
    "else:\n",
    "    print(\"❌ LangSmith 추적이 완전히 활성화되지 않았습니다. 다음을 확인하세요:\")\n",
    "    if langchain_tracing_v2 != \"true\":\n",
    "        print(f\"  - LANGCHAIN_TRACING_V2가 'true'로 설정되어 있지 않습니다 (현재: '{langchain_tracing_v2}').\")\n",
    "    if not os.getenv('LANGCHAIN_API_KEY'):\n",
    "        print(\"  - LANGCHAIN_API_KEY가 설정되어 있지 않습니다.\")\n",
    "    if not langchain_project:\n",
    "        print(\"  - LANGCHAIN_PROJECT가 설정되어 있지 않습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f14d715",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 셀 출력\n",
    "\n",
    "```bash\n",
    "    --- LangSmith 환경 변수 확인 ---\n",
    "    ✅ LangSmith 추적 활성화됨 (LANGCHAIN_TRACING_V2='true')\n",
    "    ✅ LangSmith 프로젝트: 'LangChain-prantice'\n",
    "    ✅ LangSmith API Key: 설정됨\n",
    "    -> 이제 LangSmith 대시보드에서 이 프로젝트를 확인해 보세요.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403df77a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cf7d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os                                       # 3.6s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트의 길이를 반환하는 함수\n",
    "def length_function(text):  \n",
    "    return len(text)\n",
    "\n",
    "# 두 텍스트의 길이를 곱하는 함수\n",
    "def _multiple_length_function(text1, text2):  \n",
    "    return len(text1) * len(text2)\n",
    "\n",
    "# 2개 인자를 받는 함수로 연결하는 wrapper 함수\n",
    "# 딕셔너리에서 \"text1\"과 \"text2\"의 길이를 곱하는 함수\n",
    "def multiple_length_function(  \n",
    "    _dict,\n",
    "): \n",
    "    return _multiple_length_function(_dict[\"text1\"], _dict[\"text2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798428d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 프롬프트 템플릿 생성\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"what is {a} + {b}?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0999574d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(prompt))             # <class 'langchain_core.prompts.chat.ChatPromptTemplate'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API 키 확인\n",
    "if not os.getenv(\"GOOGLE_API_KEY\"):    \n",
    "    os.environ[\"GOOGLE_API_KEY\"] = input(\"Enter your Google API key: \")\n",
    "    \n",
    "# LLM 초기화\n",
    "gemini_lc = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash-lite\",        \n",
    "    temperature=0,                                              # temperature = 0으로 설정          \n",
    "    max_output_tokens=4096,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4650f18b",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* `LLM` 초기화\n",
    "\n",
    "    ```bash\n",
    "\n",
    "    E0000 00:00:1759973579.086644 1654451 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n",
    "\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 프롬프트와 모델을 연결하여 체인 생성\n",
    "\n",
    "chain1 = prompt | gemini_lc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 체인 구성\n",
    "\n",
    "chain = (\n",
    "    {\n",
    "        \"a\": itemgetter(\"input_1\") | RunnableLambda(length_function),\n",
    "        \"b\": {\"text1\": itemgetter(\"input_1\"), \"text2\": itemgetter(\"input_2\")}\n",
    "        | RunnableLambda(multiple_length_function),\n",
    "    }\n",
    "    | prompt\n",
    "    | gemini_lc\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21778b6d",
   "metadata": {},
   "source": [
    "* **`chain`** 실행 → 결과 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a153d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 주어진 인자들로 체인 실행하기\n",
    "\n",
    "chain.invoke({\"input_1\": \"bar\", \"input_2\": \"gah\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52fb4234",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 주어진 인자들로 체인 실행하기  (`1.3s`)\n",
    "\n",
    "    ```markdown\n",
    "\n",
    "    '3 + 9 = 12'\n",
    "\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd27120",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0aba55",
   "metadata": {},
   "source": [
    "#### **3) `RunnableConfig` 인자로 활용**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7326b18c",
   "metadata": {},
   "source": [
    "* **`RunnableLambda`** → *(선택적으로)* [**`RunnableConfig`**](https://api.python.langchain.com/en/latest/runnables/langchain_core.runnables.config.RunnableConfig.html#langchain_core.runnables.config.RunnableConfig) 수용 가능\n",
    "\n",
    "  * **`콜백`, `태그`, `기타  구성 정보` → `중첩된 실행에 전달 가능`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58dd616",
   "metadata": {},
   "source": [
    "* `gemini` 모델은 `응답`에 `토큰 정보`를 포함\n",
    "\n",
    "  * *`get_openai_callback()` = **`OpenAI`** 전용 방법*\n",
    "\n",
    "  * **`geimini`** 방법\n",
    "    * a. `usage_metadata` 직접 사용해보기\n",
    "    * b. `Custom Callback Handler` 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8784e972",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableLambda, RunnableConfig\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eadc4d69",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* **`a`** 시도 - ***`usage_metadata()`***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb935ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a. 직접 호출 + usage_metadata\n",
    "\n",
    "def parse_or_fix_with_tracking(text: str, config: RunnableConfig):\n",
    "    fixing_prompt = ChatPromptTemplate.from_template(\n",
    "        \"Fix the following text:\\n\\ntext\\n{input}\\n\\nError: {error}\"\n",
    "        \" Don't narrate, just respond with the fixed data.\"\n",
    "    )\n",
    "    \n",
    "    # 토큰 사용량 누적\n",
    "    total_input_tokens = 0\n",
    "    total_output_tokens = 0\n",
    "    \n",
    "    # 최대 3번 시도\n",
    "    for attempt in range(3):\n",
    "        try:\n",
    "            return json.loads(text)\n",
    "        \n",
    "        except Exception as e:\n",
    "            # 프롬프트 생성\n",
    "            messages = fixing_prompt.invoke({\"input\": text, \"error\": e})\n",
    "            \n",
    "            # ✨ LLM 직접 호출 (AIMessage 반환)\n",
    "            ai_message = gemini_lc.invoke(messages, config=config)\n",
    "            \n",
    "            # ✨ 토큰 사용량 추출\n",
    "            usage = ai_message.usage_metadata\n",
    "            total_input_tokens += usage['input_tokens']\n",
    "            total_output_tokens += usage['output_tokens']\n",
    "            \n",
    "            print(f\"\\n--- Attempt {attempt + 1} ---\")\n",
    "            print(f\"Input tokens: {usage['input_tokens']}\")\n",
    "            print(f\"Output tokens: {usage['output_tokens']}\")\n",
    "            print(f\"Total tokens: {usage['total_tokens']}\")\n",
    "            \n",
    "            # 수정된 텍스트\n",
    "            text = ai_message.content\n",
    "            \n",
    "    # 최종 토큰 사용량 출력\n",
    "    print(f\"\\n=== Final Token Usage ===\")\n",
    "    print(f\"Total Input tokens: {total_input_tokens}\")\n",
    "    print(f\"Total Output tokens: {total_output_tokens}\")\n",
    "    print(f\"Total tokens: {total_input_tokens + total_output_tokens}\")\n",
    "    \n",
    "    # 파싱 실패 시 → \"Failed to parse\" 문자열 반환\n",
    "    return \"Failed to parse\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ca75c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a. 실행해보기\n",
    "\n",
    "output = RunnableLambda(parse_or_fix_with_tracking).invoke(\n",
    "    input=\"{foo:: bar}\",\n",
    "    config={\"tags\": [\"my-tag\"]},\n",
    ")\n",
    "\n",
    "print(f\"\\n\\n수정한 결과:\\n{output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0119b7",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* a방법 실행 결과 (`0.8s`)\n",
    "\n",
    "    ```markdown\n",
    "    --- Attempt 1 ---\n",
    "    Input tokens: 50\n",
    "    Output tokens: 6\n",
    "    Total tokens: 56\n",
    "\n",
    "\n",
    "    수정한 결과:\n",
    "    ```\n",
    "    ```python\n",
    "        {'foo': 'bar'}\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00eb3d1c",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* **`b`** 시도 - ***`Custom Callback Handler`***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a60980",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableLambda, RunnableConfig\n",
    "from langchain_core.callbacks import BaseCallbackHandler\n",
    "from typing import Any\n",
    "import json\n",
    "\n",
    "# Custom Callback Handler = 토큰 사용량 추적 핸들러\n",
    "\n",
    "class TokenTrackingHandler(BaseCallbackHandler):\n",
    "    \"\"\"Gemini 토큰 사용량 추적 핸들러\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.total_input_tokens = 0\n",
    "        self.total_output_tokens = 0\n",
    "        self.total_tokens = 0\n",
    "        self.call_count = 0\n",
    "    \n",
    "    def on_llm_end(self, response: Any, **kwargs: Any) -> None:\n",
    "        \"\"\"LLM 호출 완료 시 호출\"\"\"\n",
    "        # Gemini의 usage_metadata 추출\n",
    "        if hasattr(response, 'generations') and response.generations:\n",
    "            generation = response.generations[0][0]\n",
    "            if hasattr(generation, 'message') and hasattr(generation.message, 'usage_metadata'):\n",
    "                usage = generation.message.usage_metadata\n",
    "                \n",
    "                self.total_input_tokens += usage.get('input_tokens', 0)\n",
    "                self.total_output_tokens += usage.get('output_tokens', 0)\n",
    "                self.total_tokens += usage.get('total_tokens', 0)\n",
    "                self.call_count += 1\n",
    "                \n",
    "                print(f\"\\n[Call {self.call_count}] Tokens:\")\n",
    "                print(f\"  Input: {usage.get('input_tokens', 0)}\")\n",
    "                print(f\"  Output: {usage.get('output_tokens', 0)}\")\n",
    "                print(f\"  Total: {usage.get('total_tokens', 0)}\")\n",
    "    \n",
    "    def get_summary(self):\n",
    "        \"\"\"최종 요약\"\"\"\n",
    "        return {\n",
    "            \"total_input_tokens\": self.total_input_tokens,\n",
    "            \"total_output_tokens\": self.total_output_tokens,\n",
    "            \"total_tokens\": self.total_tokens,\n",
    "            \"total_calls\": self.call_count,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse_or_fix 함수\n",
    "\n",
    "def parse_or_fix(text: str, config: RunnableConfig):\n",
    "    fixing_chain = (\n",
    "        ChatPromptTemplate.from_template(\n",
    "            \"Fix the following text:\\n\\ntext\\n{input}\\n\\nError: {error}\"\n",
    "            \" Don't narrate, just respond with the fixed data.\"\n",
    "        )\n",
    "        | gemini_lc\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    \n",
    "    # 최대 3번 시도\n",
    "    for _ in range(3):\n",
    "        try:\n",
    "            return json.loads(text)\n",
    "        \n",
    "        except Exception as e:\n",
    "            # 수정 체인 호출\n",
    "            text = fixing_chain.invoke({\"input\": text, \"error\": e}, config)\n",
    "    \n",
    "    return \"Failed to parse\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b. 실행해보기 - Callback Handler 사용하기\n",
    "\n",
    "token_handler = TokenTrackingHandler()\n",
    "\n",
    "output = RunnableLambda(parse_or_fix).invoke(\n",
    "    input=\"{foo:: bar}\",\n",
    "    config={\n",
    "        \"tags\": [\"my-tag\"],\n",
    "        \"callbacks\": [token_handler],  # ✨ Custom Handler\n",
    "    },\n",
    ")\n",
    "\n",
    "# 최종 결과\n",
    "print(f\"\\n\\n수정한 결과:\\n{output}\")\n",
    "\n",
    "# 토큰 사용량 요약\n",
    "print(\"\\n=== Token Usage Summary ===\")\n",
    "summary = token_handler.get_summary()\n",
    "for key, value in summary.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94f4c5e",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* b 실행 결과 (`1.0s`)\n",
    "\n",
    "    ```markdown\n",
    "    [Call 1] Tokens:\n",
    "      Input: 50\n",
    "      Output: 6\n",
    "      Total: 56\n",
    "\n",
    "\n",
    "    수정한 결과:\n",
    "    ```\n",
    "    ```python\n",
    "        {'foo': 'bar'}\n",
    "    ```\n",
    "\n",
    "    ```markdown\n",
    "    === Token Usage Summary ===\n",
    "    total_input_tokens: 50\n",
    "    total_output_tokens: 6\n",
    "    total_tokens: 56\n",
    "    total_calls: 1\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2d664c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a08b3cd",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 📊  `a` 방법 vs `b` 방법 \n",
    "\n",
    "  | 방법 | 장점 | 단점 | 추천 |\n",
    "  |------|------|------|------|\n",
    "  | **`a` (직접 usage_metadata)** | 간단, 직관적 | Chain 내부 호출 추적 어려움 | ⭐⭐⭐⭐⭐ |\n",
    "  | **`b` (Custom Callback)** | 정교한 추적, 모든 호출 캐치 | 구현 복잡 | ⭐⭐⭐⭐ |\n",
    "\n",
    "<br>\n",
    "\n",
    "* 📊 `OpenAI callback` vs `gemini callback`\n",
    "\n",
    "  * `OpenAI 전용 콜백 함수` 존재\n",
    "  ```python\n",
    "\n",
    "      from langchain.callbacks import get_openai_callback     # ✅\n",
    "\n",
    "  ```\n",
    "\n",
    "  * `gemini` **전용 콜백 함수 존재하지 않음**\n",
    "  ```python\n",
    "\n",
    "      from langchain.callbacks import get_gemini_callback     # ❌ 존재하지 않음\n",
    "\n",
    "  ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b3b031",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7626d2",
   "metadata": {},
   "source": [
    "* next: ***`04. LLM 체인 라우팅 (RunnableLambda, RunnableBranch)`***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f4de16",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lc_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
