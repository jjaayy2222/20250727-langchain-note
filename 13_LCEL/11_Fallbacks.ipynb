{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba52bed0",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65001001",
   "metadata": {},
   "source": [
    "* 출처: LangChain 공식 문서 또는 해당 교재명\n",
    "* 원본 URL: https://smith.langchain.com/hub/teddynote/summary-stuff-documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f884510",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb18b49c",
   "metadata": {},
   "source": [
    "### **11. `폴백`** *(fallback)* **`모델 지정`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f936725",
   "metadata": {},
   "source": [
    "#### **1) `폴백`** *(fallback)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad1807f",
   "metadata": {},
   "source": [
    "* `LLM` 애플리케이션의 문제: 다양한 오류 및 실패\n",
    "\n",
    "  * `LLM API 문제`, `모델 출력 품질 저하`, `다른 통합 관련 이슈` 등"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf76ad8",
   "metadata": {},
   "source": [
    "* **`fallback`** 기능\n",
    "\n",
    "  * `LLM` 문제 처리 및 격리에 활용 가능\n",
    "\n",
    "  * **`LLM` 수준 외 `전체 실행 가능한 수준에 적용할 수 있음`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0221f594",
   "metadata": {},
   "source": [
    "#### **2) `LLM API Error에 대처 방법`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156ab17f",
   "metadata": {},
   "source": [
    "* `fallback` 사용의 가장 일반적인 사례 중 하나 = **`LLM API 오류 처리`**\n",
    "\n",
    "* **`LLM API 요청 실패 원인`**\n",
    "\n",
    "  * `API` 다운\n",
    "\n",
    "  * `속도 제한에 도달`\n",
    "\n",
    "  * 기타 등등\n",
    "\n",
    "* **`중요`**\n",
    "\n",
    "  * **기본적으로 많은 LLM wrapper (*래퍼*) = 오류 포착 및 재시도**\n",
    "\n",
    "  * `fallback` 사용 시 → **`기본 동작 해제 후 사용`해야 함**\n",
    "    * *그렇지 않으면 첫 번째 래퍼가 계속 재시도 → 실패 발생하지 않음*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f40444",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 사전에 `VS Code` 터미널에 설치되어 있는지 확인하기\n",
    "\n",
    "```bash\n",
    "\n",
    "        pip install -qU langchain langchain-openai\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9c68fc",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47256612",
   "metadata": {},
   "source": [
    "#### **3) `RateLimitError` 발생 경우에 대한 모의 테스트**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047df540",
   "metadata": {},
   "source": [
    "* **`환경설정`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbdb0182",
   "metadata": {},
   "source": [
    "* `LLM` 설정\n",
    "\n",
    "  * ➀ `gpt-4o-mini`\n",
    "\n",
    "  * ➁ `gemini-2.5-flash-lite`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f0f975",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "# 2nd OpenAI API key사용해 OpenAI 모델 초기화\n",
    "OPEN_API_KEY = os.getenv(\"OPENAI_API_KEY2\")\n",
    "\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)               # 4.4s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d8aec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os \n",
    "\n",
    "# LLM 초기화\n",
    "# API 키 확인\n",
    "if not os.getenv(\"GOOGLE_API_KEY\"):    \n",
    "    os.environ[\"GOOGLE_API_KEY\"] = input(\"Enter your Google API key: \")\n",
    "    \n",
    "# LLM 생성하기\n",
    "gemini_lc = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash-lite\",\n",
    "    temperature=0,        \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31e0fdc",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* `gemini-2.5-flash-lite` - (`0.7s`)\n",
    "\n",
    "    ```bash\n",
    "\n",
    "    E0000 00:00:1760059917.561864 2692561 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n",
    "\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961e2410",
   "metadata": {},
   "source": [
    "##### **`➀ rate  limit만 설정`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c213445f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unittest.mock import patch\n",
    "\n",
    "import httpx\n",
    "from openai import RateLimitError\n",
    "\n",
    "request = httpx.Request(\"GET\", \"/\")                                 # GET 요청 생성하기\n",
    "\n",
    "# 200 상태 코드와 함께 응답을 생성하기\n",
    "response = httpx.Response(\n",
    "    200, request=request\n",
    ")\n",
    "\n",
    "# 에러메시지 출력하기\n",
    "# \"rate limit\" 메시지와 응답 및 빈 본문을 포함하는 RateLimitError를 생성합니다.\n",
    "error = RateLimitError(\"rate limit\", response=response, body=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65c916b",
   "metadata": {},
   "source": [
    "* **`openai_llm`** 변수 = `OpenAI` 객체 생성\n",
    "\n",
    "* **`max_retries`** 매개변수 **`=` `0`**\n",
    "  * *`API 호출비용 제한 등으로 인한 재시도 방지`*\n",
    "\n",
    "* **`with_fallbacks`** 메서드 사용 → `gemini`를 **`fallback`** `LLM`으로 설정 → `llm` 변수에 할당하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fddcc351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI의 ChatOpenAI 모델을 사용해 openai_llm 객체 생성하기\n",
    "openai_llm = ChatOpenAI(max_retries=0)          # 속도 제한 등으로 인한 재시도 방지하기\n",
    "\n",
    "# Google의 gemini 모델을 사용하여 gemini_llm 객체 생성하기\n",
    "gemini_llm = gemini_lc\n",
    "\n",
    "# openai_llm을 기본으로 사용 → 실패 시 gemini_llm을 대체로 사용하도록 설정\n",
    "llm = openai_llm.with_fallbacks([gemini_llm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cb03c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI LLM → 오류 발생시키기\n",
    "\n",
    "with patch(\"openai.resources.chat.completions.Completions.create\", side_effect=error):\n",
    "    try:\n",
    "        # 질문 OpenAI LLM에 전달하기\n",
    "        print(openai_llm.invoke(\"Why did the chicken cross the road?\"))\n",
    "                                # \"닭이 길을 건넌 이유는 무엇일까요?\"\n",
    "    except RateLimitError:\n",
    "        # 오류 발생 → 오류 메시지 출력\n",
    "        print(\"에러 발생\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b02a62",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* `OpenAI 오류 발생시키기` - (`0.2s`)\n",
    "\n",
    "    ```markdown\n",
    "\n",
    "    에러 발생\n",
    "\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a16e028",
   "metadata": {},
   "source": [
    "##### **`➁ rate  limit(API 호출비용) 제한 오류 → 대체 모델 사용하기`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1011b1a",
   "metadata": {},
   "source": [
    "* `OpenAI API`의 `rate limit` *(비용 제한)* → 오류 발생 → 동작 테스트\n",
    "\n",
    "  * `OpenAI`의 `GPT` 모델 시도 → `ERROR` 발생 → `fallback`모델인 `gemini-2.5-flash-lite`이 대신 추론 수행\n",
    "\n",
    "  * **`with_fallback()` = 대체 모델 설정 → 대체 모델이 성공적 수행 시 `RateLimitError` 발생 ❌**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5306b89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI API 호출 시 에러가 발생하는 경우 gemini로 대체하는 코드\n",
    "\n",
    "with patch(\"openai.resources.chat.completions.Completions.create\", side_effect=error):\n",
    "    try:\n",
    "        # 질문을 언어 모델에 전달 → 응답 출력하기\n",
    "        print(llm.invoke(\"대한민국의 수도는 어디야?\"))              # fallback을 적용한 llm으로 설정\n",
    "\n",
    "    except RateLimitError:\n",
    "        # RateLimitError 발생 → \"에러 발생\" 출력하기\n",
    "        print(\"에러 발생\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50133b7a",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* `fallback`이 적용된 `llm` 사용됨 - (`1.0s`)\n",
    "\n",
    "    ```bash\n",
    "\n",
    "    content='대한민국의 수도는 **서울**입니다.' additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash-lite', 'safety_ratings': []} id='run--e0aa5bc0-791d-4de2-aa86-81cb7d91bb79-0' usage_metadata={'input_tokens': 9, 'output_tokens': 10, 'total_tokens': 19, 'input_token_details': {'cache_read': 0}}\n",
    "\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e22e8e2",
   "metadata": {},
   "source": [
    "##### **`➂ llm.with_fallbacks()`** 설정한 모델 = **일반 `runnable`모델과 동일하게 작동**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d1b38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# 프롬프트 생성\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"질문에 짧고 간결하게 답변해 주세요.\",                          # 시스템 역할 설명\n",
    "        ),\n",
    "        (\"human\", \"{country} 의 수도는 어디입니까?\"),                    # 사용자 질문 템플릿\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b25206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chain 생성\n",
    "chain = prompt | llm  # 프롬프트와 언어 모델을 연결하여 체인 생성\n",
    "# chain = prompt | ChatOpenAI() # 이 코드를 실행하면 \"오류 발생\" 문구가 출력됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165707fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with patch(\"openai.resources.chat.completions.Completions.create\", side_effect=error):\n",
    "    try:\n",
    "        print(chain.invoke({\"country\": \"대한민국\"}))                # 체인을 호출하여 결과 출력\n",
    "    except RateLimitError:                                        # API 비용 제한 오류 처리\n",
    "        print(\"오류 발생\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54799d78",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* **`llm.with_fallback()` → 일반 `runnable` 모델에서 작동** - (`1.2s`)\n",
    "\n",
    "    ```bash\n",
    "\n",
    "    content='서울' additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash-lite', 'safety_ratings': []} id='run--4085cb33-7b87-450e-969a-4870323b9067-0' usage_metadata={'input_tokens': 21, 'output_tokens': 1, 'total_tokens': 22, 'input_token_details': {'cache_read': 0}}\n",
    "\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db380e3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabb20cd",
   "metadata": {},
   "source": [
    "#### **4) `처리해야 할 오류를 구체적으로 명시한 경우`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ddc71cc",
   "metadata": {},
   "source": [
    "* **불필요한 `fallback` 호출을 줄이고, 오류 처리의 효율성을 높일 수 있음**\n",
    "\n",
    "  * 특정 오류를 처리하기 위해 `fallback`이 호출되는 시점을 더 명확하게 지정 가능 → `fallback` 메커니즘이 동작하는 상황을 보다 세밀하게 제어 가능\n",
    "\n",
    "  * *예시: `특정 예외 클래스`, `오류 코드` 지정 → 해당 오류가 발생했을 때만 `fallback` 로직 실행되도록 설정*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154e5a02",
   "metadata": {},
   "source": [
    "* **`exceptions_to_handle`** 파라미터\n",
    "\n",
    "<small>\n",
    "\n",
    "  | 목적                    | 예외 유형 (OpenAI 기준)                       | 설명                                                                            |\n",
    "  |-----------------------|-----------------------------------------|-------------------------------------------------------------------------------|\n",
    "  | `속도 제한` (`Rate Limiting`) | RateLimitError                          | API 호출 횟수가 너무 많아 일시적으로 차단되었을 때, 다른 API로 넘겨서 지연 없이 응답을 받음 / 가장 일반적인 사용 사례 |\n",
    "  | `API 키 오류`              | AuthenticationError                     | API 키가 잘못되었거나 만료되었을 때, 백업 키를 사용하는 다른 LLM으로 전환하여 서비스를 계속함                   |\n",
    "  | `연결`/`서버 오류`              | APIConnectionError, InternalServerError | 네트워크 불안정이나 LLM 제공사 서버의 일시적인 문제로 연결이 끊어졌을 때, 다른 서비스로 넘어가서 안정성을 확보함          |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ec8b86",
   "metadata": {},
   "source": [
    "##### **`➀` 교재와 동일 - `exceptions_to_handle=(KeyboardInterrupt,)`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4830924a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# openai_llm을 기본으로 사용 → 실패 시 gemini_llm을 대체로 사용하도록 설정\n",
    "llm2 = openai_llm.with_fallbacks(\n",
    "    [gemini_llm],                                    # 대체 LLM = gemini\n",
    "    exceptions_to_handle=(KeyboardInterrupt,),       # 예외 처리 대상 지정\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037a77c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chain 생성하기\n",
    "\n",
    "chain2 = prompt | llm2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf650a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with patch(\"openai.resources.chat.completions.Completions.create\", side_effect=error):\n",
    "    try:\n",
    "        # 체인 호출 → 결과 출력해보기\n",
    "        print(chain2.invoke({\"country\": \"대한민국\"}))\n",
    "    except RateLimitError:\n",
    "        # RateLimitError 예외 발생 시 \"오류 발생\" 출력하도록 설정\n",
    "        print(\"오류 발생\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858d5018",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* **`exceptions_to_handle=(KeyboardInterrupt,)`** - (`0.0s`)\n",
    "\n",
    "    ```markdown\n",
    "\n",
    "    오류 발생\n",
    "\n",
    "    ```\n",
    "\n",
    "* \n",
    "  * `exceptions_to_handle` 파라미터에서 `KeyboardInterrupt` 예외가 발생할 경우에만 `fallback`이 구동되도록 설정했기 때문\n",
    "\n",
    "  * `KeyboardInterrupt`를 제외한 모든 예외에서는 `fallback`이 발생하지 않음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09202f6",
   "metadata": {},
   "source": [
    "##### **`➁` API 호출 강제 발생시키기 - `exceptions_to_handle=(APIConnectionError)`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d69186c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import RateLimitError, APIConnectionError \n",
    "from unittest.mock import patch                 # 오류를 강제로 발생시키기 위해 임포트\n",
    "\n",
    "# 예시용 더미 오류 핸들러 함수\n",
    "def error(*args, **kwargs):\n",
    "    # 이 함수가 호출 시 → APIConnectionError를 강제로 발생시킴\n",
    "    raise APIConnectionError(\"네트워크 연결이 일시적으로 불안정합니다. (Mock Error)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619c4d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 프롬프트 생성\n",
    "prompt = ChatPromptTemplate.from_template(\"너는 전문 여행가이드야. {country}에 대해 한 문장으로 설명해줘.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe880c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# openai_llm을 기본으로 사용 → 실패 시 gemini_llm을 대체로 사용하도록 설정\n",
    "llm3 = openai_llm.with_fallbacks(\n",
    "    [gemini_llm],                                                     # 대체 LLM = gemini\n",
    "    exceptions_to_handle=(RateLimitError, APIConnectionError),        # 예외 처리 대상 지정\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce813816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chain 생성하기 - 프롬프트와 LLM을 연결하기\n",
    "\n",
    "chain3 = prompt | llm3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03be11bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Fallback (대체 실행) 테스트 시작 ---\")\n",
    "print(\"OpenAI API 호출이 강제로 APIConnectionError를 발생시킵니다.\")\n",
    "print(\"APIConnectionError는 exceptions_to_handle에 포함되어 있으므로, gemini LLM으로 자동 전환됩니다.\")\n",
    "\n",
    "# 강제로 APIConnectionError를 발생시켜 Fallback을 유도\n",
    "with patch(\"openai.resources.chat.completions.Completions.create\", side_effect=error):\n",
    "    try:\n",
    "        # 체인 호출 → APIConnectionError 발생 → Fallback 작동 = gemini의 응답 출력\n",
    "        print(chain3.invoke({\"country\": \"대한민국\"}))\n",
    "        result = chain3.invoke({\"country\": \"대한민국\"})\n",
    "        print(f\"\\n✅ Fallback 성공! 최종 응답 모델: {result.response_metadata.get('model_name')}\")\n",
    "        print(f\"응답 내용: {result.content}\")\n",
    "    except Exception as e:\n",
    "        # 만약 설정된 예외 외의 다른 예외 발생시 출력\n",
    "        print(f\"\\n❌ 예상치 못한 오류 발생: {type(e).__name__} - {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24300372",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* **`➁` API 호출 강제 발생시키기 / `exceptions_to_handle=(APIConnectionError)`** - (`5.9s`)\n",
    "\n",
    "    ```markdown\n",
    "    --- Fallback (대체 실행) 테스트 시작 ---\n",
    "    OpenAI API 호출이 강제로 APIConnectionError를 발생시킵니다.\n",
    "    APIConnectionError는 exceptions_to_handle에 포함되어 있으므로, gemini LLM으로 자동 전환됩니다.\n",
    "    ```\n",
    "\n",
    "    ```bash\n",
    "    AIMessage(content='저는 대한민국을 \"역동적인 문화와 첨단 기술이 조화를 이루며 끊임없이 발전하는 매력적인 나라\"라고 소개하고 싶습니다.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash-lite', 'safety_ratings': []}, id='run--de866648-5dd5-4608-b8a1-69366a85012e-0', usage_metadata={'input_tokens': 20, 'output_tokens': 33, 'total_tokens': 53, 'input_token_details': {'cache_read': 0}})\n",
    "    ```\n",
    "\n",
    "    ```markdown\n",
    "    ✅ Fallback 성공! 최종 응답 모델: gemini-2.5-flash-lite\n",
    "    응답 내용: 저는 대한민국을 \"역동적인 문화와 첨단 기술이 조화를 이루며 끊임없이 발전하는 매력적인 나라\"라고 소개하고 싶습니다.\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7428a241",
   "metadata": {},
   "source": [
    "##### **`➂` API 키 오류 강제 발생시키기 - `exceptions_to_handle=(AuthenticationError)`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b9dd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AuthenticationError 추가\n",
    "from openai import RateLimitError, APIConnectionError, AuthenticationError \n",
    "from unittest.mock import patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa40c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예시용 더미 오류 핸들러 함수\n",
    "def error(*args, **kwargs):\n",
    "    # 이 함수가 호출 시 → AuthenticationError를 강제로 발생시킴\n",
    "    raise AuthenticationError(\"제공된 API 키가 유효하지 않거나 만료되었습니다. (Mock Error)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d520ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 프롬프트 생성\n",
    "prompt = ChatPromptTemplate.from_template(\"너는 전문 여행가이드야. {country}에 대해 한 문장으로 설명해줘.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f931407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# openai_llm을 기본으로 사용 → 실패 시 gemini_llm을 대체로 사용하도록 설정\n",
    "\n",
    "llm4 = openai_llm.with_fallbacks(\n",
    "    [gemini_llm],                                                     # 대체 LLM = gemini\n",
    "    # 예외 처리 대상 지정에 추가하기\n",
    "    exceptions_to_handle=(RateLimitError, APIConnectionError, AuthenticationError),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d97baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chain 생성하기 - 프롬프트와 LLM을 연결하기\n",
    "\n",
    "chain4 = prompt | llm4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c222d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Fallback (대체 실행) 테스트 시작 ---\")\n",
    "print(\"OpenAI API 호출이 강제로 APIConnectionError를 발생시킵니다.\")\n",
    "print(\"APIConnectionError는 exceptions_to_handle에 포함되어 있으므로, gemini LLM으로 자동 전환됩니다.\")\n",
    "\n",
    "# 강제로 APIConnectionError를 발생시켜 Fallback을 유도\n",
    "with patch(\"openai.resources.chat.completions.Completions.create\", side_effect=error):\n",
    "    try:\n",
    "        # 체인 호출 → APIConnectionError 발생 → Fallback 작동 = gemini의 응답 출력\n",
    "        print(chain4.invoke({\"country\": \"대한민국\"}))\n",
    "        result = chain4.invoke({\"country\": \"대한민국\"})\n",
    "        print(f\"\\n✅ Fallback 성공! 최종 응답 모델: {result.response_metadata.get('model_name')}\")\n",
    "        print(f\"응답 내용: {result.content}\")\n",
    "    except Exception as e:\n",
    "        # 만약 설정된 예외 외의 다른 예외 발생시 출력\n",
    "        print(f\"\\n❌ 예상치 못한 오류 발생: {type(e).__name__} - {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c294291",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* **`➂` API 키 오류 강제 발생시키기 / `exceptions_to_handle=(AuthenticationError)`** - (`1.8s`)\n",
    "\n",
    "    ```markdown\n",
    "    --- Fallback (대체 실행) 테스트 시작 ---\n",
    "    OpenAI API 호출이 강제로 APIConnectionError를 발생시킵니다.\n",
    "    APIConnectionError는 exceptions_to_handle에 포함되어 있으므로, gemini LLM으로 자동 전환됩니다.\n",
    "    ```\n",
    "    ```bash\n",
    "    AIMessage(content='저는 대한민국을 \"역동적인 문화와 첨단 기술이 조화를 이루며 끊임없이 발전하는 매력적인 나라\"라고 소개하고 싶습니다.' additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash-lite', 'safety_ratings': []} id='run--ec43f602-582e-4b59-8707-a3c2f40910c5-0' usage_metadata={'input_tokens': 20, 'output_tokens': 33, 'total_tokens': 53, 'input_token_details': {'cache_read': 0}})\n",
    "    ```\n",
    "\n",
    "    ```markdown\n",
    "    ✅ Fallback 성공! 최종 응답 모델: gemini-2.5-flash-lite\n",
    "    응답 내용: 저는 대한민국을 \"역동적인 문화와 첨단 기술이 조화를 이루며 끊임없이 발전하는 매력적인 나라\"라고 소개하고 싶습니다.\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef913be2",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8f67b5",
   "metadata": {},
   "source": [
    "#### **5) `fallback에 여러 모델을 순차적으로 지정`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83614a2d",
   "metadata": {},
   "source": [
    "* `fallback` 모델 = **`여러 개의 모델 지정 가능` → `순차적으로 시도`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed5228f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "\n",
    "# 프롬프트 생성\n",
    "prompt_template = (\n",
    "    \"질문에 짧고 간결하게 답변해 주세요.\\n\\nQuestion:\\n{question}\\n\\nAnswer:\"\n",
    ")\n",
    "\n",
    "prompt = PromptTemplate.from_template(prompt_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efeb1765",
   "metadata": {},
   "source": [
    "* **2개의 chain 생성 - `오류를 발생하는 chain`, `정상적인 chain`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d75b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 쉽게 오류를 발생시킬 수 있도록 잘못된 모델 이름을 사용 → 체인 생성하기\n",
    "chat_model = ChatOpenAI(model_name=\"gpt-fake\")\n",
    "bad_chain = prompt | chat_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8919cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fallback 체인 생성하기\n",
    "\n",
    "fallback_chain1 = prompt | ChatOpenAI(model=\"gpt-3.6-turbo\")        # 오류\n",
    "fallback_chain2 = prompt | gemini_llm                               # 정상\n",
    "fallback_chain3 = prompt | ChatOpenAI(model=\"gpt-4o-mini\")          # 정상"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ce4332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 두 개의 체인 결합 → 최종 체인 생성하기\n",
    "chain = bad_chain.with_fallbacks(\n",
    "    [fallback_chain1, fallback_chain2, fallback_chain3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac48d1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최종 생성된 체인 호출 → 입력값 전달하기\n",
    "\n",
    "chain.invoke({\"question\": \"대한민국의 수도는 어디야?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb97eb2",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* **`fallback에 여러 모델을 순차적으로 시도`**\n",
    "\n",
    "  * **`fallback2` / `gemini-2.5-flash-lite`** - (`1.6s`)\n",
    "\n",
    "    ```bash\n",
    "\n",
    "    AIMessage(content='서울', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash-lite', 'safety_ratings': []}, id='run--3b29cef3-3972-4e10-a5d1-bed05c0874c6-0', usage_metadata={'input_tokens': 27, 'output_tokens': 1, 'total_tokens': 28, 'input_token_details': {'cache_read': 0}})\n",
    "\n",
    "    ```\n",
    "\n",
    "<br>\n",
    "\n",
    "* \n",
    "  * **`fallback3` / `gpt-4o-mini`** - (`5.9s`)\n",
    "\n",
    "    ```bash\n",
    "\n",
    "    AIMessage(content='서울입니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 3, 'prompt_tokens': 33, 'total_tokens': 36, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-COx8AQOOuy3Qd4eZNwXrCVnjrEwOt', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--43b31421-11c5-467e-af63-7123a0ce3440-0', usage_metadata={'input_tokens': 33, 'output_tokens': 3, 'total_tokens': 36, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})\n",
    "\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403df77a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7626d2",
   "metadata": {},
   "source": [
    "* next: ***`CH14. 체인 (Chains)`***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f4de16",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lc_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
