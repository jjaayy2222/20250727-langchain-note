{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba52bed0",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65001001",
   "metadata": {},
   "source": [
    "* 출처: LangChain 공식 문서 또는 해당 교재명\n",
    "* 원본 URL: https://smith.langchain.com/hub/teddynote/summary-stuff-documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f884510",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb18b49c",
   "metadata": {},
   "source": [
    "### **2. `Runnable 구조`(그래프) `검토`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f936725",
   "metadata": {},
   "source": [
    "#### **1) `Runnables 구조 검토`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad1807f",
   "metadata": {},
   "source": [
    "* **`Runnable`** 생성 후 → 검사 → 어떤 일이 일어나는지 과정을 파악할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6638d77",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d763fc98",
   "metadata": {},
   "source": [
    "* **`환경설정`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ca9302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API 키를 환경변수로 관리하기 위한 설정 파일\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API 키 정보 로드\n",
    "load_dotenv()                           # True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ef86f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import Client\n",
    "from langsmith import traceable\n",
    "\n",
    "import os\n",
    "\n",
    "# LangSmith 환경 변수 확인\n",
    "\n",
    "print(\"\\n--- LangSmith 환경 변수 확인 ---\")\n",
    "langchain_tracing_v2 = os.getenv('LANGCHAIN_TRACING_V2')\n",
    "langchain_project = os.getenv('LANGCHAIN_PROJECT')\n",
    "langchain_api_key_status = \"설정됨\" if os.getenv('LANGCHAIN_API_KEY') else \"설정되지 않음\" # API 키 값은 직접 출력하지 않음\n",
    "\n",
    "if langchain_tracing_v2 == \"true\" and os.getenv('LANGCHAIN_API_KEY') and langchain_project:\n",
    "    print(f\"✅ LangSmith 추적 활성화됨 (LANGCHAIN_TRACING_V2='{langchain_tracing_v2}')\")\n",
    "    print(f\"✅ LangSmith 프로젝트: '{langchain_project}'\")\n",
    "    print(f\"✅ LangSmith API Key: {langchain_api_key_status}\")\n",
    "    print(\"  -> 이제 LangSmith 대시보드에서 이 프로젝트를 확인해 보세요.\")\n",
    "else:\n",
    "    print(\"❌ LangSmith 추적이 완전히 활성화되지 않았습니다. 다음을 확인하세요:\")\n",
    "    if langchain_tracing_v2 != \"true\":\n",
    "        print(f\"  - LANGCHAIN_TRACING_V2가 'true'로 설정되어 있지 않습니다 (현재: '{langchain_tracing_v2}').\")\n",
    "    if not os.getenv('LANGCHAIN_API_KEY'):\n",
    "        print(\"  - LANGCHAIN_API_KEY가 설정되어 있지 않습니다.\")\n",
    "    if not langchain_project:\n",
    "        print(\"  - LANGCHAIN_PROJECT가 설정되어 있지 않습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f14d715",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 셀 출력\n",
    "\n",
    "    ```bash\n",
    "    --- LangSmith 환경 변수 확인 ---\n",
    "    ✅ LangSmith 추적 활성화됨 (LANGCHAIN_TRACING_V2='true')\n",
    "    ✅ LangSmith 프로젝트: 'LangChain-prantice'\n",
    "    ✅ LangSmith API Key: 설정됨\n",
    "    -> 이제 LangSmith 대시보드에서 이 프로젝트를 확인해 보세요.\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba61979",
   "metadata": {},
   "source": [
    "* 사전에 `VS Code` 터미널에 설치할 것\n",
    "\n",
    "```bash\n",
    "\n",
    "    pip install -qU faiss-cpu tiktoken\n",
    "\n",
    "    # 그래프를 그리기 위한 라이브러러리 설치\n",
    "    pip install -qU grandalf  \n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403df77a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3163867",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import warnings                                     # 5.4s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6ab348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임베딩(Embedding) 생성\n",
    "\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "import warnings                                                     # 경고 무시\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")                                   # HuggingFace Embeddings 사용\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\",    \n",
    "    model_kwargs={'device': 'cpu'},    \\\n",
    "    encode_kwargs={'normalize_embeddings': True})\n",
    "\n",
    "print(\"✅ hugging-face 임베딩 모델 로딩 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d770c3f",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* ✅ hugging-face 임베딩 모델 로딩 완료!  (`6.8s`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61598f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API 키 확인\n",
    "if not os.getenv(\"GOOGLE_API_KEY\"):    \n",
    "    os.environ[\"GOOGLE_API_KEY\"] = input(\"Enter your Google API key: \")\n",
    "    \n",
    "# LLM 초기화\n",
    "gemini_lc = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash-lite\",        \n",
    "    temperature=0,                                              # temperature = 0으로 설정          \n",
    "    max_output_tokens=4096,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e119ed",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* `gemini-2.5-flash-lite`로 `LLM` 생성하기\n",
    "\n",
    "    ```bash\n",
    "\n",
    "    E0000 00:00:1759826376.951511 2658484 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n",
    "\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5500949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트로부터 FAISS 벡터 저장소를 생성함\n",
    "\n",
    "vectorstore = FAISS.from_texts(\n",
    "    [\"Alice is an AI engineer who loves programming!\"],\n",
    "    embedding=embeddings\n",
    ")                                               # 0.1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495a0bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 벡터 저장소를 검색기로 사용하기\n",
    "\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cbfe20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 템플릿 정의하기\n",
    "\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}  \n",
    "\n",
    "Question: {question}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2ed114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 템플릿으로부터 채팅 프롬프트 생성하기\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4c892b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(prompt))                 # <class 'langchain.prompts.chat.ChatPromptTemplate'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4137cd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM 모델 초기화\n",
    "\n",
    "gemini_lc = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash-lite\",        \n",
    "    temperature=0,                                              # temperature = 0으로 설정          \n",
    "    max_output_tokens=4096,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d44c06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검색 체인 구성\n",
    "\n",
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | gemini_lc\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8691984f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b570aba",
   "metadata": {},
   "source": [
    "#### **2) `그래프 구성 확인`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234ad469",
   "metadata": {},
   "source": [
    "* **`chain.get_graph()`** 메서드 → 그래프 구성 확인\n",
    "\n",
    "  * 체인의 각 노드, 노으 간의 연결을 나타내는 그래프 객체 반환\n",
    "\n",
    "    * **그래프의 `노드` = 체인의 `각 단계`**\n",
    "\n",
    "    * **그래프의 `엣지` = 단계 간의 `데이터의 흐름`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628f5cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 체인의 그래프에서 노드 가져오기\n",
    "\n",
    "chain.get_graph().nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c916e3",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* `chain.get_graph().nodes`  (`0.0s`)\n",
    "\n",
    "    ```python\n",
    "\n",
    "    {'3a47829b6af64089ae0efacf91792810': Node(id='3a47829b6af64089ae0efacf91792810', name='Parallel<context,question>Input', data=<class 'langchain_core.runnables.base.RunnableParallel<context,question>Input'>, metadata=None),\n",
    "    '6bfd7625e89c4fd9a21a310536d3381c': Node(id='6bfd7625e89c4fd9a21a310536d3381c', name='Parallel<context,question>Output', data=<class 'langchain_core.utils.pydantic.RunnableParallel<context,question>Output'>, metadata=None),\n",
    "    '4a920571229044cdbea3a45f13bd369c': Node(id='4a920571229044cdbea3a45f13bd369c', name='VectorStoreRetriever', data=VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x137832ba0>, search_kwargs={}), metadata=None),\n",
    "    'ccac6fe387d14ce6943ee0354406e9c9': Node(id='ccac6fe387d14ce6943ee0354406e9c9', name='Passthrough', data=RunnablePassthrough(), metadata=None),\n",
    "    'dd89b2c15667467baf81ea6ddbf56299': Node(id='dd89b2c15667467baf81ea6ddbf56299', name='ChatPromptTemplate', data=ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template='Answer the question based only on the following context:\\n{context}  \\n\\nQuestion: {question}'), additional_kwargs={})]), metadata=None),\n",
    "    'fdb22a5260b143a19fadc21d59e003f8': Node(id='fdb22a5260b143a19fadc21d59e003f8', name='ChatGoogleGenerativeAI', data=ChatGoogleGenerativeAI(model='models/gemini-2.5-flash-lite', google_api_key=SecretStr('**********'), temperature=0.0, max_output_tokens=4096, client=<google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x1378a9810>, default_metadata=(), model_kwargs={}), metadata=None),\n",
    "    'c9e4cf780d974908a8fbd1caf38795ed': Node(id='c9e4cf780d974908a8fbd1caf38795ed', name='StrOutputParser', data=StrOutputParser(), metadata=None),\n",
    "    '5e11b2ded7ac43f4963333530b9f2d2d': Node(id='5e11b2ded7ac43f4963333530b9f2d2d', name='StrOutputParserOutput', data=<class 'langchain_core.output_parsers.string.StrOutputParserOutput'>, metadata=None)}\n",
    "\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee303db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 체인의 그래프에서 엣지 가져오기\n",
    "\n",
    "chain.get_graph().edges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3f7365",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* `chain.get_graph().edges` -  (`0.0s`)\n",
    "\n",
    "    ```python\n",
    "\n",
    "    [Edge(source='28d3448e94f64949810466ae33b24bb5', target='6f1d4b98c2c2429fbb175f8c4c31f611', data=None, conditional=False),\n",
    "    Edge(source='6f1d4b98c2c2429fbb175f8c4c31f611', target='d9c48cd636524d6cba07aa83a3c4a45a', data=None, conditional=False),\n",
    "    Edge(source='28d3448e94f64949810466ae33b24bb5', target='4022fd2fd5de4e04b442f42ec1bd248a', data=None, conditional=False),\n",
    "    Edge(source='4022fd2fd5de4e04b442f42ec1bd248a', target='d9c48cd636524d6cba07aa83a3c4a45a', data=None, conditional=False),\n",
    "    Edge(source='d9c48cd636524d6cba07aa83a3c4a45a', target='22e7826d3a6845a4b42daae54f1db225', data=None, conditional=False),\n",
    "    Edge(source='22e7826d3a6845a4b42daae54f1db225', target='4119523b2bf54e56b1c64001057a0ad7', data=None, conditional=False),\n",
    "    Edge(source='3672bd85a2774a7bb16aaad83f973d1c', target='73e690c3e20c431295d9ae503ca16db5', data=None, conditional=False),\n",
    "    Edge(source='4119523b2bf54e56b1c64001057a0ad7', target='3672bd85a2774a7bb16aaad83f973d1c', data=None, conditional=False)]\n",
    "\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a15342a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f315315",
   "metadata": {},
   "source": [
    "#### **4) `그래프 출력`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5cb95f5",
   "metadata": {},
   "source": [
    "* 숫자 → 이해하기 쉬운 형태 = **`그래프`** 로 확인해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbca9876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 체인의 그래프를 ASCII 형식으로 출력해보기\n",
    "\n",
    "chain.get_graph().print_ascii()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859b00a7",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* `chain.get_graph().print_ascii()` - (`0.0s`)\n",
    "\n",
    "    ```markdown\n",
    "\n",
    "    +---------------------------------+         \n",
    "                | Parallel<context,question>Input |         \n",
    "                +---------------------------------+         \n",
    "                        **               ***                \n",
    "                    ***                    ***             \n",
    "                **                          **           \n",
    "    +----------------------+               +-------------+  \n",
    "    | VectorStoreRetriever |               | Passthrough |  \n",
    "    +----------------------+               +-------------+  \n",
    "                        **               ***                \n",
    "                        ***         ***                   \n",
    "                            **     **                      \n",
    "            +----------------------------------+         \n",
    "            | Parallel<context,question>Output |         \n",
    "            +----------------------------------+         \n",
    "                                *                          \n",
    "                                *                          \n",
    "                                *                          \n",
    "                    +--------------------+                \n",
    "                    | ChatPromptTemplate |                \n",
    "                    +--------------------+                \n",
    "                                *                          \n",
    "                                *                          \n",
    "                                *                          \n",
    "                    +------------------------+              \n",
    "                    | ChatGoogleGenerativeAI |              \n",
    "                    +------------------------+              \n",
    "                                *                          \n",
    "                                *                          \n",
    "                                *                          \n",
    "                        +-----------------+                 \n",
    "                        | StrOutputParser |                 \n",
    "                        +-----------------+                 \n",
    "                                *                          \n",
    "                                *                          \n",
    "                                *                          \n",
    "                    +-----------------------+              \n",
    "                    | StrOutputParserOutput |              \n",
    "                    +-----------------------+\n",
    "\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e72aef",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3594a512",
   "metadata": {},
   "source": [
    "#### **5) `프롬프트 가져오기`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e3a5dd",
   "metadata": {},
   "source": [
    "* **`chain.get_prompt()`** = 체인에서 사용되는 프롬프트 객체의 **`리스트`** 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 체인에서 사용되는 프롬프트 가져오기\n",
    "\n",
    "chain.get_prompts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bfbc95",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* `chain.get_prompts()` - (`0.0s`)\n",
    "\n",
    "    ```python\n",
    "\n",
    "    [ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template='Answer the question based only on the following context:\\n{context}  \\n\\nQuestion: {question}'), additional_kwargs={})])]\n",
    "\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b3b031",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7626d2",
   "metadata": {},
   "source": [
    "* next: ***`03. RunnableLambda`***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f4de16",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lc_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
