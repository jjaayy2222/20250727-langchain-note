{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba52bed0",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65001001",
   "metadata": {},
   "source": [
    "* 출처: LangChain 공식 문서 또는 해당 교재명\n",
    "* 원본 URL: https://smith.langchain.com/hub/teddynote/summary-stuff-documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb2ea90",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6662ac",
   "metadata": {},
   "source": [
    "## **`CH13.` `LangChain Expression Language`** *(LCEL)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a0d6f0",
   "metadata": {},
   "source": [
    "* **`LangChain Expression Language`** *(LCEL)*\n",
    "\n",
    "  * `LangChain` 라이브러리에서 제공하는 선언적 방식의 인터페이스\n",
    "  * 복잡한 **`LLM`** (`Large Language Model`) 애플리케이션을 구축하고 실행하기 위한 도구\n",
    "  * `LLM`, `프롬프트`, `검색기`, `메모리` 등 `다양한 컴포넌트`를 `조합`하여 강력하고 유연한 `AI 시스템`을 만들 수 있게 해줌"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80cc512",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587082c6",
   "metadata": {},
   "source": [
    "* **`주요 특징`**\n",
    "\n",
    "  * **`선언적 구문`**: 복잡한 로직 간결 → 읽기 쉬운 방식으로 표현 가능\n",
    "\n",
    "  * **`모듈성`**: 다양한 컴포넌트 → 쉽게 조합, 재사용 가능\n",
    "\n",
    "  * **`유연성`**: 다양한 유형의 LLM 애플리케이션 구축 가능\n",
    "\n",
    "  * **`확장성`**: 사용자 정의 컴포넌트 쉽게 통합 가능\n",
    "\n",
    "  * **`최적화`**: 실행 시 자동으로 최적화 수행"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54e6604",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d69862c",
   "metadata": {},
   "source": [
    "* **`기본 구성 요소`**\n",
    "\n",
    "  * **`Runnable`**: 모든 `LCEL` 컴포넌트의 기본 클래스\n",
    "\n",
    "  * **`Chain`**: 여러 `Runnable`을 순차적으로 실행\n",
    "\n",
    "  * **`RunnableMap`**: 여러 `Runnable`을 병렬로 실행\n",
    "\n",
    "  * **`RunnableSequence`**: `Runnable`의 시쿼스 정의\n",
    "\n",
    "  * **`RunnableLambda`**: 사용자 정의 함수 = `Runnable`로 래핑"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84487e3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0598a09b",
   "metadata": {},
   "source": [
    "* **`사용 예시`**\n",
    "\n",
    "  * `LCEL`을 사용한 간단한 예시\n",
    "    * *프롬프트, 모델, 출력 파서를 파이프라인으로 연결하여 간단한 체인으로 만들고 있음*\n",
    "\n",
    "    ```python\n",
    "\n",
    "        from langchain.chat_models import ChatOpenAI\n",
    "        from langchain.prompts import ChatPromptTemplate\n",
    "        from langchain.schema.output_parser import StrOutputParser\n",
    "\n",
    "        prompt = ChatPromptTemplate.from_template(\"다음의 주제에 대해서 설명해줘: {topic}\")\n",
    "        model = ChatOpenAI()\n",
    "        output_parser = StrOutputParser()\n",
    "\n",
    "        chain = prompt | model | output_parser\n",
    "\n",
    "        result = chain.invoke({\"topic\": \"LangChain\"})\n",
    "        print(result)\n",
    "\n",
    "    ``` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **`고급 기능`**\n",
    "\n",
    "  * **`병렬 처리`**: `Runnable` → 여러 작업을 동시에 실행 가능\n",
    "\n",
    "  * **`조건부 실행`**: `RunnableBranch` → 조건에 따라 다른 경로로 실행 가능\n",
    "\n",
    "  * **`재시도 및 폴백`**: 실패 시 자동으로 재시도 or 대체 경로로 실행 가능\n",
    "\n",
    "  * **`스트리밍`**: 대규모 데이터를 효율적으로 처리 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464c87d1",
   "metadata": {},
   "source": [
    "* **`장단점`**\n",
    "\n",
    "  * **`장점`**\n",
    "\n",
    "    * **`코드 가독성`**: 복잡한 로직 → 명확, 간결하게 표현 가능\n",
    "\n",
    "    * **`유지보수성`**: 모듈화된 구조 → 유지보수 용이\n",
    "\n",
    "    * **`성능`**: 자동 최적화 → 효율적 실행 가능\n",
    "\n",
    "    * **`확장성`**: 새로운 컴포넌트 → 쉽게 추가 및 통합 가능 \n",
    "\n",
    "<br>\n",
    "\n",
    "* \n",
    "  * **`단점`**\n",
    "\n",
    "    * **`학습 곡선`**: 새로운 패러다임에 익숙해지는 데 시간이 필요할 수 있음\n",
    "\n",
    "    * **`디버깅`**: 복잡한 체인의 경우 디버깅이 어려울 수 있음\n",
    "\n",
    "    * **`성능 오버헤드`**: 매우 간단한 작업의 경우 오버헤드가 발생할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ed0d50",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128871af",
   "metadata": {},
   "source": [
    "* **`활용 사례`**\n",
    "\n",
    "  * `LCEL`은 다음과 같은 다양한 `LLM` 애플리케이션 구축에 활용 가능 \n",
    "\n",
    "    * 대화형 AI 시스템\n",
    "\n",
    "    * 문서 요약 및 분석 도구\n",
    "\n",
    "    * 질의응답 시스템\n",
    "\n",
    "    * 데이터 추출 및 변환 파이프라인\n",
    "\n",
    "    * 다국어 번역 서비스\n",
    "\n",
    "<br>\n",
    "\n",
    "* \n",
    "  * `LLM` 애플리케이션 개발을 위한 강력하고 유연한 도구\n",
    "      * 선언적 구문 + 모듈성 → 복잡한 AI 시스템을 효율적으로 구축 → LangChain 생태계의 핵심 요소\n",
    "      * 지속적 발전 → `LCEL` - AI 개발자들에게 더욱 중요한 도구가 될 것"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f884510",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb18b49c",
   "metadata": {},
   "source": [
    "### **1. `RunnablePassthrough`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f936725",
   "metadata": {},
   "source": [
    "#### **1) `RunnablePassthrough`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6ede17",
   "metadata": {},
   "source": [
    "* `RunnalbePassthrough`\n",
    "  * 데이터 전달하는 역할\n",
    "  * **`invoke()` 메서드 → 입력 데이터를 그대로 반환**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4dc7ca",
   "metadata": {},
   "source": [
    "* 유용하게 활용되는 경우\n",
    "\n",
    "  * 데이터를 변환 or 수정할 필요가 없는 경우\n",
    "\n",
    "  * 파이프라인의 특정 단계를 뛰어건너야 하는 경우\n",
    "\n",
    "  * 디버깅 or 테스트 목적으로 데이터 흐름을 모니터링 해야 하는 경우"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270855d6",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad1807f",
   "metadata": {},
   "source": [
    "* **`Runnable` 인터페이스 구현 → 다른 `Runnable` 객체와 함께 파이프라인에서 사용 가능**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6638d77",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d763fc98",
   "metadata": {},
   "source": [
    "* **`환경설정`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ca9302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API 키를 환경변수로 관리하기 위한 설정 파일\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API 키 정보 로드\n",
    "load_dotenv()                           # True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ef86f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import Client\n",
    "from langsmith import traceable\n",
    "\n",
    "import os\n",
    "\n",
    "# LangSmith 환경 변수 확인\n",
    "\n",
    "print(\"\\n--- LangSmith 환경 변수 확인 ---\")\n",
    "langchain_tracing_v2 = os.getenv('LANGCHAIN_TRACING_V2')\n",
    "langchain_project = os.getenv('LANGCHAIN_PROJECT')\n",
    "langchain_api_key_status = \"설정됨\" if os.getenv('LANGCHAIN_API_KEY') else \"설정되지 않음\" # API 키 값은 직접 출력하지 않음\n",
    "\n",
    "if langchain_tracing_v2 == \"true\" and os.getenv('LANGCHAIN_API_KEY') and langchain_project:\n",
    "    print(f\"✅ LangSmith 추적 활성화됨 (LANGCHAIN_TRACING_V2='{langchain_tracing_v2}')\")\n",
    "    print(f\"✅ LangSmith 프로젝트: '{langchain_project}'\")\n",
    "    print(f\"✅ LangSmith API Key: {langchain_api_key_status}\")\n",
    "    print(\"  -> 이제 LangSmith 대시보드에서 이 프로젝트를 확인해 보세요.\")\n",
    "else:\n",
    "    print(\"❌ LangSmith 추적이 완전히 활성화되지 않았습니다. 다음을 확인하세요:\")\n",
    "    if langchain_tracing_v2 != \"true\":\n",
    "        print(f\"  - LANGCHAIN_TRACING_V2가 'true'로 설정되어 있지 않습니다 (현재: '{langchain_tracing_v2}').\")\n",
    "    if not os.getenv('LANGCHAIN_API_KEY'):\n",
    "        print(\"  - LANGCHAIN_API_KEY가 설정되어 있지 않습니다.\")\n",
    "    if not langchain_project:\n",
    "        print(\"  - LANGCHAIN_PROJECT가 설정되어 있지 않습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f14d715",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 셀 출력\n",
    "\n",
    "    ```bash\n",
    "    --- LangSmith 환경 변수 확인 ---\n",
    "    ✅ LangSmith 추적 활성화됨 (LANGCHAIN_TRACING_V2='true')\n",
    "    ✅ LangSmith 프로젝트: 'LangChain-prantice'\n",
    "    ✅ LangSmith API Key: 설정됨\n",
    "    -> 이제 LangSmith 대시보드에서 이 프로젝트를 확인해 보세요.\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403df77a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386e9802",
   "metadata": {},
   "source": [
    "#### **2) `데이터 전달하기`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94584204",
   "metadata": {},
   "source": [
    "* **`RunnablePassthrough`** = **`입력을 변경하지 않고 그대로 전달`** = **`추가 키를 더해서 전달 가능`**\n",
    "\n",
    "  * 일반적으로 **`RunnableParallel`** 과 함께 사용 →  데이터를 맵의 새로운 키에 할당하는 데 활용\n",
    "\n",
    "  * **`RunnablePassthrough()`** 단독으로 호출 → **`단순히 입력을 그대로 반환`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63bbe76d",
   "metadata": {},
   "source": [
    "* **`RunnablePassthrough.assign(...)`** = **`assign 함수에 전달된 추가 인자 더하기`**\n",
    "\n",
    "  * **`Runnable`** 클래스 사용 → **`병렬로 실행 가능한 작업 정의`**\n",
    "\n",
    "  * **`passed`** 속성: `RunnablePassthrough` 인스턴스 할당 → 입력을 그대로 반환하도록 설정\n",
    "\n",
    "  * **`extra`** 속성: `RunnablePassthrough.assign(...)` 메서드 사용 → 입력의 `num` 값에 `3`을 곱한 결과를 `mult`키에 할당하는 작업 정의\n",
    "\n",
    "  * **`modified`** 속성: 람다 함수 사용 → 입력의 `num` 값에 `1`을 더한 결과를 더하는 작업 정의\n",
    "\n",
    "  * **`runnable.invoke()`** 메서드 호출 → **`{ \"num\" : 1 }`** 입력 → **`병렬 작업 실행`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed94b331",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "\n",
    "runnable = RunnableParallel(\n",
    "    passed=RunnablePassthrough(),                                           # 전달된 입력을 그대로 반환하는 Runnable 설정\n",
    "    extra=RunnablePassthrough.assign(mult=lambda x: x[\"num\"] * 3),          # 입력의 \"num\" 값에 3을 곱한 결과를 반환하는 Runnable 설정\n",
    "    modified=lambda x: x[\"num\"] + 1,                                        # 입력의 \"num\" 값에 1을 더한 결과를 반환하는 Runnable 설정\n",
    ")\n",
    "\n",
    "# {\"num\": 1}을 입력으로 Runnable 실행하기\n",
    "runnable.invoke({\"num\": 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c231e657",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 셀 출력  (`0.3s`)\n",
    "\n",
    "    ```python\n",
    "\n",
    "    {'passed': {'num': 1}, 'extra': {'num': 1, 'mult': 3}, 'modified': 2}\n",
    "\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e42867",
   "metadata": {},
   "source": [
    "* `passed` = **`RunnablePassthrough()`** 와 함께 호출 → **단순히 `{ 'num' : 1 }` 을 전달함**\n",
    "\n",
    "* `extra` = **`RunnablePassthrough.assign(mult=lambda x: x[\"num\"] * 3)`** 와 함께 호출 → **단순히 `{ 'num' : 1 }` 을 전달함**\n",
    "\n",
    "* `combined` = **`RunnablePassthrough.assign(mult=lambda x: x[\"num\"] * 3)`** 와 함께 호출 → **단순히 `{ 'num' : 1 }` 을 전달함**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2adafe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = RunnablePassthrough.assign(mult=lambda x: x[\"num\"] * 3)\n",
    "\n",
    "r.invoke({\"num\": 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddebba95",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 셀 출력 \n",
    "\n",
    "    ```python\n",
    "\n",
    "    {'num': 1, 'mult': 3}\n",
    "\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009251c4",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a60797e",
   "metadata": {},
   "source": [
    "#### **3) `검색기 예제`** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3d3741",
   "metadata": {},
   "source": [
    "* **`RunnablePassthrough` 사용하는 예제** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3163867",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import warnings                                     # 5.4s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6ab348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임베딩(Embedding) 생성\n",
    "\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "import warnings                                                     # 경고 무시\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")                                   # HuggingFace Embeddings 사용\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\",    \n",
    "    model_kwargs={'device': 'cpu'},    \\\n",
    "    encode_kwargs={'normalize_embeddings': True})\n",
    "\n",
    "print(\"✅ hugging-face 임베딩 모델 로딩 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d770c3f",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* ✅ hugging-face 임베딩 모델 로딩 완료!  (`8.8s`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61598f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API 키 확인\n",
    "if not os.getenv(\"GOOGLE_API_KEY\"):    \n",
    "    os.environ[\"GOOGLE_API_KEY\"] = input(\"Enter your Google API key: \")\n",
    "    \n",
    "# LLM 초기화\n",
    "gemini_lc = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash-lite\",        \n",
    "    temperature=0,                                              # temperature = 0으로 설정          \n",
    "    max_output_tokens=4096,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e119ed",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* `gemini-2.5-flash-lite`로 `LLM` 생성하기\n",
    "\n",
    "    ```bash\n",
    "\n",
    "    E0000 00:00:1759825336.333701 2593718 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n",
    "\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5500949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트로부터 FAISS 벡터 저장소를 생성함\n",
    "\n",
    "vectorstore = FAISS.from_texts(\n",
    "    [\n",
    "        \"A는 랭체인 주식회사에서 근무를 하였습니다.\",\n",
    "        \"B는 A와 같은 회사에서 근무하였습니다.\",\n",
    "        \"A의 직업은 개발자입니다.\",\n",
    "        \"B의 직업은 디자이너입니다.\",\n",
    "    ],\n",
    "    embedding=embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495a0bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 벡터 저장소를 검색기로 사용하기\n",
    "\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cbfe20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 템플릿 정의하기\n",
    "\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 템플릿으로부터 채팅 프롬프트 생성하기\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(prompt))                 # <class 'langchain.prompts.chat.ChatPromptTemplate'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM 모델 초기화\n",
    "\n",
    "gemini_lc = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash-lite\",        \n",
    "    temperature=0,                                              # temperature = 0으로 설정          \n",
    "    max_output_tokens=4096,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문서를 포맷팅하는 함수\n",
    "def format_docs(docs):\n",
    "    return \"\\n\".join([doc.page_content for doc in docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검색 체인 구성\n",
    "\n",
    "retrieval_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | gemini_lc\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2736d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검색 체인을 실행하여 질문에 대한 답변을 얻기\n",
    "\n",
    "retrieval_chain.invoke(\"A의 직업은 무엇입니까?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e8c8ef",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* `query_1` (\"A의 직업은 무엇입니까?\") - (`1.2s`)\n",
    "\n",
    "\n",
    "    ```markdown\n",
    "\n",
    "    '개발자'\n",
    "\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957a8a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검색 체인을 실행하여 질문에 대한 답변을 얻기\n",
    "\n",
    "retrieval_chain.invoke(\"B의 직업은 무엇입니까?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2370d3",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* `query_2`(\"B의 직업은 무엇입니까?\") - (`0.7s`)\n",
    "\n",
    "\n",
    "    ```markdown\n",
    "\n",
    "    'B의 직업은 디자이너입니다.'\n",
    "\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180f8ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검색 체인을 실행하여 질문에 대한 답변을 얻기\n",
    "\n",
    "retrieval_chain.invoke(\"A의 직장은 어디입니까?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ecfada",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* `query_3` (\"A의 직장은 어디입니까?\") - (`0.7s`)\n",
    "\n",
    "    ```markdown\n",
    "\n",
    "    '랭체인 주식회사'\n",
    "\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4354501f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검색 체인을 실행하여 질문에 대한 답변을 얻기\n",
    "\n",
    "retrieval_chain.invoke(\"B의 직장은 어디입니까?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9432246a",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* `query_4` (\"B의 직장은 어디입니까?\") - (`0.8s`)\n",
    "\n",
    "    ```markdown\n",
    "\n",
    "    '랭체인 주식회사'\n",
    "\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b3b031",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7626d2",
   "metadata": {},
   "source": [
    "* next: ***`02. Runnable 구조(그래프) 검토`***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f4de16",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lc_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
