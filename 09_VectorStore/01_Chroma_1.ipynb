{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf989cca",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5587735",
   "metadata": {},
   "source": [
    "* 출처: LangChain 공식 문서 또는 해당 교재명\n",
    "* 원본 URL: https://smith.langchain.com/hub/teddynote/summary-stuff-documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48fe9ecc",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827aa7b4",
   "metadata": {},
   "source": [
    "## **`CH09 벡터저장소 (VectorStore)`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d118df",
   "metadata": {},
   "source": [
    "* 벡터스토어 저장 단계 = **`RAG`** 의 **`4번째 단계`**\n",
    "\n",
    "  * 이전 단계에서 **`생성된 임베딩 벡터들을 효율적으로 저장하고 관리하는` 과정**\n",
    "  * 향후 **`검색 과정에서 벡터들을 빠르게 조회`하고, `관련 문서를 신속하게 찾아내는 데 필수적`** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f40ca9",
   "metadata": {},
   "source": [
    "* 벡터스토어 저장의 **`필요성`**\n",
    "\n",
    "  * **`빠른 검색 속도`**: 임베딩 벡터들을 효과적으로 저장 • 색인화 → 대량의 데이터 중에서 **`관련된 정보를 빠르게 검색` 가능**\n",
    "\n",
    "  * **`스케일러빌리티`**\n",
    "\n",
    "    * **데이터 지속적으로 증가 → `수용할 수 있는 충분한 스케일러빌리티 제공`해야 함**\n",
    "\n",
    "    * 효율적인 저장 구조 → **`데이터베이스의 확장성 보장`, `시스템의 성능 저하 없이 대규모 데이터 관리 가능`**\n",
    "\n",
    "  * **`의미 검색 (Semantic Search)` 지원** **→ `사용자의 질문과 의미상으로 유사한 단락 조회 O` → 벡터스토어 지원 가능한 기능**\n",
    "\n",
    "    * 텍스트 자체가 저장되는 DB: `키워드 기반 검색`에 의존해야 하는 한계성 O\n",
    "\n",
    "    * **`벡터스토이`: 의미적으로 유사한 단락 검색 가능**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ff7281",
   "metadata": {},
   "source": [
    "* 예시: `Q. \"모바일 디바이스 상에서 동작하는 인공지능 기술을 소개한 기업명은?\"`\n",
    "\n",
    "  ![사용자 질문](../09_VectorStore/images/qustion_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22af638b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85837f5",
   "metadata": {},
   "source": [
    "* **`벡터스토어 중요성`**\n",
    "\n",
    "  * 벡터스토어의 저장 단계 = **`RAG 시스템의 검색 기능과 직접적으로 연결`됨**\n",
    "\n",
    "  * 전체 시스템의 **`응답 시간과 정확성에 큰 영향`** 미침\n",
    "\n",
    "    * **→ 데이터 관리 용이 → 필요 시 즉시 접근 가능 → 사용자에게 신속하고 정확한 정보 제공 가능**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa79166",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507003e2",
   "metadata": {},
   "source": [
    "### **`코드`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aaf2d75",
   "metadata": {},
   "source": [
    "* 코드 예시\n",
    "\n",
    "```python\n",
    "\n",
    "        from langchain_community.vectorstores import FAISS\n",
    "\n",
    "        # 단계 4: DB 생성(Create DB) 및 저장\n",
    "        # 벡터스토어 생성하기\n",
    "        vectorstore = FAISS.from_documents(documents=documents, embedding=embeddings)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00db166b",
   "metadata": {},
   "source": [
    "### **`참고`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3faed0fd",
   "metadata": {},
   "source": [
    "* *[**`Embedding`**](https://wikidocs.net/234013)*\n",
    "\n",
    "* *[**`LangChain VectorStores`**](https://python.langchain.com/v0.1/docs/modules/data_connection/vectorstores/)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eaf4fcb",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e46434a",
   "metadata": {},
   "source": [
    "### **1. `Chroma`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2724843",
   "metadata": {},
   "source": [
    "* **`Chroma`**\n",
    "  * 개발자의 생산성과 행복에 초점을 맞춘 AI 네이티브 오픈 소스 벡터 데이터베이스\n",
    "  * `Apahche 2.0`에 따른 라이이선스 부여"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5985ef3c",
   "metadata": {},
   "source": [
    "* 참고 링크\n",
    "\n",
    "  * [Chroma LancChain 문서](https://python.langchain.com/v0.2/docs/integrations/vectorstores/chroma/)\n",
    "  * [Chroma 공식 문서](https://docs.trychroma.com/docs/overview/getting-started)\n",
    "  * [LangChain 지원 VectorStore 리스트](https://python.langchain.com/v0.2/docs/integrations/vectorstores/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d5a301",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8748488",
   "metadata": {},
   "source": [
    "#### **1) `설정`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642a1105",
   "metadata": {},
   "source": [
    "* **먼저 `langchain-openai` 설치 → `필요한 환경 변수`를 `설정`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b37773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API 키를 환경변수로 관리하기 위한 설정 파일\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API 키 정보 로드\n",
    "load_dotenv()                               # True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b64773",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import Client\n",
    "from langsmith import traceable         # @traceable 데코레이터 사용 시\n",
    "\n",
    "import os\n",
    "\n",
    "# LangSmith 환경 변수 확인\n",
    "\n",
    "print(\"\\n--- LangSmith 환경 변수 확인 ---\")\n",
    "langchain_tracing_v2 = os.getenv('LANGCHAIN_TRACING_V2')\n",
    "langchain_project = os.getenv('LANGCHAIN_PROJECT')\n",
    "langchain_api_key_status = \"설정됨\" if os.getenv('LANGCHAIN_API_KEY') else \"설정되지 않음\" # API 키 값은 직접 출력하지 않음\n",
    "\n",
    "if langchain_tracing_v2 == \"true\" and os.getenv('LANGCHAIN_API_KEY') and langchain_project:\n",
    "    print(f\"✅ LangSmith 추적 활성화됨 (LANGCHAIN_TRACING_V2='{langchain_tracing_v2}')\")\n",
    "    print(f\"✅ LangSmith 프로젝트: '{langchain_project}'\")\n",
    "    print(f\"✅ LangSmith API Key: {langchain_api_key_status}\")\n",
    "    print(\"  -> 이제 LangSmith 대시보드에서 이 프로젝트를 확인해 보세요.\")\n",
    "else:\n",
    "    print(\"❌ LangSmith 추적이 완전히 활성화되지 않았습니다. 다음을 확인하세요:\")\n",
    "    if langchain_tracing_v2 != \"true\":\n",
    "        print(f\"  - LANGCHAIN_TRACING_V2가 'true'로 설정되어 있지 않습니다 (현재: '{langchain_tracing_v2}').\")\n",
    "    if not os.getenv('LANGCHAIN_API_KEY'):\n",
    "        print(\"  - LANGCHAIN_API_KEY가 설정되어 있지 않습니다.\")\n",
    "    if not langchain_project:\n",
    "        print(\"  - LANGCHAIN_PROJECT가 설정되어 있지 않습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ecadfe5",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 셀 출력\n",
    "\n",
    "    ```markdown\n",
    "    --- LangSmith 환경 변수 확인 ---\n",
    "    ✅ LangSmith 추적 활성화됨 (LANGCHAIN_TRACING_V2='true')\n",
    "    ✅ LangSmith 프로젝트: 'LangChain-prantice'\n",
    "    ✅ LangSmith API Key: 설정됨\n",
    "    -> 이제 LangSmith 대시보드에서 이 프로젝트를 확인해 보세요.\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf86c0a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbcab931",
   "metadata": {},
   "source": [
    "* 샘플 데이터셋 로드하기\n",
    "\n",
    "  * *오류 생길 경우*: 사전에 `VS Code` 터미널에 설치할 것 \n",
    "    ```bash\n",
    "\n",
    "        pip install langchain-chroma\n",
    "        \n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e17313e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "# 텍스트 분할\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=600, chunk_overlap=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4db62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트 파일을 load → List[Document] 형태로 변환\n",
    "loader1 = TextLoader(\"../09_VectorStore/data/nlp-keywords.txt\")\n",
    "loader2 = TextLoader(\"../09_VectorStore/data/finance-keywords.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d246da",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(loader1))    # <class 'langchain_community.document_loaders.text.TextLoader'>\n",
    "print(type(loader2))    # <class 'langchain_community.document_loaders.text.TextLoader'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73978f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문서 분할\n",
    "split_doc1 = loader1.load_and_split(text_splitter)\n",
    "split_doc2 = loader2.load_and_split(text_splitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bc5930",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(split_doc1))     # <class 'list'>\n",
    "print(type(split_doc2))     # <class 'list'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7185cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문서 개수 확인\n",
    "\n",
    "print(f\"첫번째 문서의 개수: {len(split_doc1)}\")\n",
    "print(\"\\n\", \"=\"*25, \"\\n\")\n",
    "print(f\"두번째 문서의 개수: {len(split_doc2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8200a4",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 셀 출력\n",
    "\n",
    "    ```markdown\n",
    "    첫번째 문서의 개수: 11\n",
    "\n",
    "    ========================= \n",
    "\n",
    "    두번째 문서의 개수: 6\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7506e4f9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c371c9",
   "metadata": {},
   "source": [
    "#### **2) `VectorStore` 생성**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a458cb",
   "metadata": {},
   "source": [
    "* **`벡터 저장소 생성` (`from_documents`)**: 문서 리스트 → 벡터 저장소 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02395532",
   "metadata": {},
   "source": [
    "* **`매개변수`**\n",
    "\n",
    "  * `documents` (List[Document]): 벡터 저장소에 추가할 문서 리스트\n",
    "  * `embedding` (Optional[Embeddings]): 임베딩 함수. 기본값은 None\n",
    "  * `ids` (Optional[List[str]]): 문서 ID 리스트. 기본값은 None\n",
    "  * `collection_name` (str): 생성할 컬렉션 이름.\n",
    "  * `persist_directory` (Optional[str]): 컬렉션을 저장할 디렉토리. 기본값은 None\n",
    "  * `client_settings` (Optional[chromadb.config.Settings]): Chroma 클라이언트 설정\n",
    "  * `client` (Optional[chromadb.Client]): Chroma 클라이언트 인스턴스\n",
    "  * `collection_metadata` (Optional[Dict]): 컬렉션 구성 정보. 기본값은 None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc12feb6",
   "metadata": {},
   "source": [
    "* **`참고`**\n",
    "\n",
    "  * **`persist_directory`**\n",
    "    * 지정 시 컬렉션이 해당 디력토리에 저장\n",
    "    * 지정되지 않으면 데이터는 메모리에 임시로 저장됨\n",
    "\n",
    "  * **`from_texts`**: 내부적으로 해당 메서드 호출 → 벡터 자장소 생성\n",
    "\n",
    "  * 문서\n",
    "    * **`page_content`** = text\n",
    "    * **`metadata`** = metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a2981a",
   "metadata": {},
   "source": [
    "* **`반환값`**\n",
    "  * `Chroma`\n",
    "    * 생성된 Chroma 벡터 자장소 인스턴스의 **`documents` 매개변수로 `Document` 리스트 전달**\n",
    "    * `embedding`에 활용할 임베딩 모델 지정\n",
    "    * `namespace`의 역할을 하는 **`collection_name`지정 가능**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "195db571",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# API 키 확인\n",
    "if not os.getenv(\"GOOGLE_API_KEY\"):\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = input(\"Enter your Google API key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1d0902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gemini 임베딩 모델 생성 (task_type 명시)\n",
    "embeddings = GoogleGenerativeAIEmbeddings(\n",
    "    model=\"models/gemini-embedding-001\",\n",
    "    task_type=\"retrieval_document\",\n",
    "    google_api_key=os.getenv(\"GOOGLE_API_KEY\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d94ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DB 생성 (3.1s 소요)\n",
    "\n",
    "db = Chroma.from_documents(\n",
    "    documents=split_doc1,               # 문서 리스트 전달\n",
    "    embedding=embeddings,               # 임베딩 모델 지정\n",
    "    collection_name=\"my_db\"             # 생성할 컬렉션 이름 설정 \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67aa5003",
   "metadata": {},
   "source": [
    "* `persist_directory` 지정 시 → `disk`에 파일 형태로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5fcf0c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장할 경로 지정\n",
    "DB_PATH = \"../09_VectorStore/chroma_db/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "95308242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문서를 디스크에 저장하기 \n",
    "# 저장시 persist_directory에 저장할 경로 지정하기\n",
    "persist_db = Chroma.from_documents(\n",
    "    split_doc1, embeddings, persist_directory=DB_PATH, collection_name=\"my_db\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99bbeb5",
   "metadata": {},
   "source": [
    "* `DB_PATH`에 저장된 데이터 로드해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "54cb4521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디스크에서 문서 로드하기\n",
    "\n",
    "persist_db = Chroma(\n",
    "    persist_directory=DB_PATH,\n",
    "    embedding_function=embeddings,\n",
    "    collection_name=\"my_db\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb4ec54",
   "metadata": {},
   "source": [
    "* 불러온 `VectorStore`에서 저장된 데이터 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def96073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장된 데이터 확인\n",
    "\n",
    "persist_db.get()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58236fea",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 셀 출력\n",
    "\n",
    "  ```python\n",
    "  {'ids': ['e2bcb7fd-40bf-4e86-8eeb-0b195ca8da5d',\n",
    "    '614593b7-71fb-42e4-a954-e967f460c2e5',\n",
    "    '15e1303c-c7dc-4872-a826-392223220c0a',\n",
    "    '9e2d6752-2210-42c0-a2e1-0667f9b971ee',\n",
    "    '38a6d754-0ee0-4aff-843f-f62a03663e18',\n",
    "    'cea859e8-2584-4930-b82f-64abdf973757',\n",
    "    '9aa2bf6a-bb4c-4160-b886-f6989dabd265',\n",
    "    '9f805e9b-edc4-462e-871f-a627bd98f4d3',\n",
    "    '1c057883-26c0-4b59-906e-0c55091716b7',\n",
    "    '5706ef24-0425-4483-8578-cc7b26138b70',\n",
    "    '977bf0ba-3bef-4029-a501-b9c0fedbf5e2'],\n",
    "  'embeddings': None,\n",
    "  'documents': ['Semantic Search\\n\\n정의: 의미론적 검색은 사용자의 질의를 단순한 키워드 매칭을 넘어서 그 의미를 파악하여 관련된 결과를 반환하는 검색 방식입니다.\\n예시: 사용자가 \"태양계 행성\"이라고 검색하면, \"목성\", \"화성\" 등과 같이 관련된 행성에 대한 정보를 반환합니다.\\n연관키워드: 자연어 처리, 검색 알고리즘, 데이터 마이닝\\n\\nEmbedding\\n\\n정의: 임베딩은 단어나 문장 같은 텍스트 데이터를 저차원의 연속적인 벡터로 변환하는 과정입니다. 이를 통해 컴퓨터가 텍스트를 이해하고 처리할 수 있게 합니다.\\n예시: \"사과\"라는 단어를 [0.65, -0.23, 0.17]과 같은 벡터로 표현합니다.\\n연관키워드: 자연어 처리, 벡터화, 딥러닝\\n\\nToken\\n\\n정의: 토큰은 텍스트를 더 작은 단위로 분할하는 것을 의미합니다. 이는 일반적으로 단어, 문장, 또는 구절일 수 있습니다.\\n예시: 문장 \"나는 학교에 간다\"를 \"나는\", \"학교에\", \"간다\"로 분할합니다.\\n연관키워드: 토큰화, 자연어 처리, 구문 분석\\n\\nTokenizer',\n",
    "    '정의: 토크나이저는 텍스트 데이터를 토큰으로 분할하는 도구입니다. 이는 자연어 처리에서 데이터를 전처리하는 데 사용됩니다.\\n예시: \"I love programming.\"이라는 문장을 [\"I\", \"love\", \"programming\", \".\"]으로 분할합니다.\\n연관키워드: 토큰화, 자연어 처리, 구문 분석\\n\\nVectorStore\\n\\n정의: 벡터스토어는 벡터 형식으로 변환된 데이터를 저장하는 시스템입니다. 이는 검색, 분류 및 기타 데이터 분석 작업에 사용됩니다.\\n예시: 단어 임베딩 벡터들을 데이터베이스에 저장하여 빠르게 접근할 수 있습니다.\\n연관키워드: 임베딩, 데이터베이스, 벡터화\\n\\nSQL\\n\\n정의: SQL(Structured Query Language)은 데이터베이스에서 데이터를 관리하기 위한 프로그래밍 언어입니다. 데이터 조회, 수정, 삽입, 삭제 등 다양한 작업을 수행할 수 있습니다.\\n예시: SELECT * FROM users WHERE age > 18;은 18세 이상의 사용자 정보를 조회합니다.\\n연관키워드: 데이터베이스, 쿼리, 데이터 관리\\n\\nCSV',\n",
    "    '정의: CSV(Comma-Separated Values)는 데이터를 저장하는 파일 형식으로, 각 데이터 값은 쉼표로 구분됩니다. 표 형태의 데이터를 간단하게 저장하고 교환할 때 사용됩니다.\\n예시: 이름, 나이, 직업이라는 헤더를 가진 CSV 파일에는 홍길동, 30, 개발자와 같은 데이터가 포함될 수 있습니다.\\n연관키워드: 데이터 형식, 파일 처리, 데이터 교환\\n\\nJSON\\n\\n정의: JSON(JavaScript Object Notation)은 경량의 데이터 교환 형식으로, 사람과 기계 모두에게 읽기 쉬운 텍스트를 사용하여 데이터 객체를 표현합니다.\\n예시: {\"이름\": \"홍길동\", \"나이\": 30, \"직업\": \"개발자\"}는 JSON 형식의 데이터입니다.\\n연관키워드: 데이터 교환, 웹 개발, API\\n\\nTransformer\\n\\n정의: 트랜스포머는 자연어 처리에서 사용되는 딥러닝 모델의 한 유형으로, 주로 번역, 요약, 텍스트 생성 등에 사용됩니다. 이는 Attention 메커니즘을 기반으로 합니다.\\n예시: 구글 번역기는 트랜스포머 모델을 사용하여 다양한 언어 간의 번역을 수행합니다.\\n연관키워드: 딥러닝, 자연어 처리, Attention\\n\\nHuggingFace',\n",
    "    '정의: HuggingFace는 자연어 처리를 위한 다양한 사전 훈련된 모델과 도구를 제공하는 라이브러리입니다. 이는 연구자와 개발자들이 쉽게 NLP 작업을 수행할 수 있도록 돕습니다.\\n예시: HuggingFace의 Transformers 라이브러리를 사용하여 감정 분석, 텍스트 생성 등의 작업을 수행할 수 있습니다.\\n연관키워드: 자연어 처리, 딥러닝, 라이브러리\\n\\nDigital Transformation\\n\\n정의: 디지털 변환은 기술을 활용하여 기업의 서비스, 문화, 운영을 혁신하는 과정입니다. 이는 비즈니스 모델을 개선하고 디지털 기술을 통해 경쟁력을 높이는 데 중점을 둡니다.\\n예시: 기업이 클라우드 컴퓨팅을 도입하여 데이터 저장과 처리를 혁신하는 것은 디지털 변환의 예입니다.\\n연관키워드: 혁신, 기술, 비즈니스 모델\\n\\nCrawling\\n\\n정의: 크롤링은 자동화된 방식으로 웹 페이지를 방문하여 데이터를 수집하는 과정입니다. 이는 검색 엔진 최적화나 데이터 분석에 자주 사용됩니다.\\n예시: 구글 검색 엔진이 인터넷 상의 웹사이트를 방문하여 콘텐츠를 수집하고 인덱싱하는 것이 크롤링입니다.\\n연관키워드: 데이터 수집, 웹 스크래핑, 검색 엔진\\n\\nWord2Vec',\n",
    "    '정의: Word2Vec은 단어를 벡터 공간에 매핑하여 단어 간의 의미적 관계를 나타내는 자연어 처리 기술입니다. 이는 단어의 문맥적 유사성을 기반으로 벡터를 생성합니다.\\n예시: Word2Vec 모델에서 \"왕\"과 \"여왕\"은 서로 가까운 위치에 벡터로 표현됩니다.\\n연관키워드: 자연어 처리, 임베딩, 의미론적 유사성\\nLLM (Large Language Model)\\n\\n정의: LLM은 대규모의 텍스트 데이터로 훈련된 큰 규모의 언어 모델을 의미합니다. 이러한 모델은 다양한 자연어 이해 및 생성 작업에 사용됩니다.\\n예시: OpenAI의 GPT 시리즈는 대표적인 대규모 언어 모델입니다.\\n연관키워드: 자연어 처리, 딥러닝, 텍스트 생성\\n\\nFAISS (Facebook AI Similarity Search)\\n\\n정의: FAISS는 페이스북에서 개발한 고속 유사성 검색 라이브러리로, 특히 대규모 벡터 집합에서 유사 벡터를 효과적으로 검색할 수 있도록 설계되었습니다.\\n예시: 수백만 개의 이미지 벡터 중에서 비슷한 이미지를 빠르게 찾는 데 FAISS가 사용될 수 있습니다.\\n연관키워드: 벡터 검색, 머신러닝, 데이터베이스 최적화\\n\\nOpen Source',\n",
    "    '정의: 오픈 소스는 소스 코드가 공개되어 누구나 자유롭게 사용, 수정, 배포할 수 있는 소프트웨어를 의미합니다. 이는 협업과 혁신을 촉진하는 데 중요한 역할을 합니다.\\n예시: 리눅스 운영 체제는 대표적인 오픈 소스 프로젝트입니다.\\n연관키워드: 소프트웨어 개발, 커뮤니티, 기술 협업\\n\\nStructured Data\\n\\n정의: 구조화된 데이터는 정해진 형식이나 스키마에 따라 조직된 데이터입니다. 이는 데이터베이스, 스프레드시트 등에서 쉽게 검색하고 분석할 수 있습니다.\\n예시: 관계형 데이터베이스에 저장된 고객 정보 테이블은 구조화된 데이터의 예입니다.\\n연관키워드: 데이터베이스, 데이터 분석, 데이터 모델링\\n\\nParser\\n\\n정의: 파서는 주어진 데이터(문자열, 파일 등)를 분석하여 구조화된 형태로 변환하는 도구입니다. 이는 프로그래밍 언어의 구문 분석이나 파일 데이터 처리에 사용됩니다.\\n예시: HTML 문서를 구문 분석하여 웹 페이지의 DOM 구조를 생성하는 것은 파싱의 한 예입니다.\\n연관키워드: 구문 분석, 컴파일러, 데이터 처리\\n\\nTF-IDF (Term Frequency-Inverse Document Frequency)',\n",
    "    '정의: TF-IDF는 문서 내에서 단어의 중요도를 평가하는 데 사용되는 통계적 척도입니다. 이는 문서 내 단어의 빈도와 전체 문서 집합에서 그 단어의 희소성을 고려합니다.\\n예시: 많은 문서에서 자주 등장하지 않는 단어는 높은 TF-IDF 값을 가집니다.\\n연관키워드: 자연어 처리, 정보 검색, 데이터 마이닝\\n\\nDeep Learning\\n\\n정의: 딥러닝은 인공신경망을 이용하여 복잡한 문제를 해결하는 머신러닝의 한 분야입니다. 이는 데이터에서 고수준의 표현을 학습하는 데 중점을 둡니다.\\n예시: 이미지 인식, 음성 인식, 자연어 처리 등에서 딥러닝 모델이 활용됩니다.\\n연관키워드: 인공신경망, 머신러닝, 데이터 분석\\n\\nSchema\\n\\n정의: 스키마는 데이터베이스나 파일의 구조를 정의하는 것으로, 데이터가 어떻게 저장되고 조직되는지에 대한 청사진을 제공합니다.\\n예시: 관계형 데이터베이스의 테이블 스키마는 열 이름, 데이터 타입, 키 제약 조건 등을 정의합니다.\\n연관키워드: 데이터베이스, 데이터 모델링, 데이터 관리\\n\\nDataFrame',\n",
    "    \"정의: DataFrame은 행과 열로 이루어진 테이블 형태의 데이터 구조로, 주로 데이터 분석 및 처리에 사용됩니다.\\n예시: 판다스 라이브러리에서 DataFrame은 다양한 데이터 타입의 열을 가질 수 있으며, 데이터 조작과 분석을 용이하게 합니다.\\n연관키워드: 데이터 분석, 판다스, 데이터 처리\\n\\nAttention 메커니즘\\n\\n정의: Attention 메커니즘은 딥러닝에서 중요한 정보에 더 많은 '주의'를 기울이도록 하는 기법입니다. 이는 주로 시퀀스 데이터(예: 텍스트, 시계열 데이터)에서 사용됩니다.\\n예시: 번역 모델에서 Attention 메커니즘은 입력 문장의 중요한 부분에 더 집중하여 정확한 번역을 생성합니다.\\n연관키워드: 딥러닝, 자연어 처리, 시퀀스 모델링\\n\\n판다스 (Pandas)\\n\\n정의: 판다스는 파이썬 프로그래밍 언어를 위한 데이터 분석 및 조작 도구를 제공하는 라이브러리입니다. 이는 데이터 분석 작업을 효율적으로 수행할 수 있게 합니다.\\n예시: 판다스를 사용하여 CSV 파일을 읽고, 데이터를 정제하며, 다양한 분석을 수행할 수 있습니다.\\n연관키워드: 데이터 분석, 파이썬, 데이터 처리\",\n",
    "    'GPT (Generative Pretrained Transformer)\\n\\n정의: GPT는 대규모의 데이터셋으로 사전 훈련된 생성적 언어 모델로, 다양한 텍스트 기반 작업에 활용됩니다. 이는 입력된 텍스트에 기반하여 자연스러운 언어를 생성할 수 있습니다.\\n예시: 사용자가 제공한 질문에 대해 자세한 답변을 생성하는 챗봇은 GPT 모델을 사용할 수 있습니다.\\n연관키워드: 자연어 처리, 텍스트 생성, 딥러닝\\n\\nInstructGPT\\n\\n정의: InstructGPT는 사용자의 지시에 따라 특정한 작업을 수행하기 위해 최적화된 GPT 모델입니다. 이 모델은 보다 정확하고 관련성 높은 결과를 생성하도록 설계되었습니다.\\n예시: 사용자가 \"이메일 초안 작성\"과 같은 특정 지시를 제공하면, InstructGPT는 관련 내용을 기반으로 이메일을 작성합니다.\\n연관키워드: 인공지능, 자연어 이해, 명령 기반 처리\\n\\nKeyword Search',\n",
    "    '정의: 키워드 검색은 사용자가 입력한 키워드를 기반으로 정보를 찾는 과정입니다. 이는 대부분의 검색 엔진과 데이터베이스 시스템에서 기본적인 검색 방식으로 사용됩니다.\\n예시: 사용자가 \"커피숍 서울\"이라고 검색하면, 관련된 커피숍 목록을 반환합니다.\\n연관키워드: 검색 엔진, 데이터 검색, 정보 검색\\n\\nPage Rank\\n\\n정의: 페이지 랭크는 웹 페이지의 중요도를 평가하는 알고리즘으로, 주로 검색 엔진 결과의 순위를 결정하는 데 사용됩니다. 이는 웹 페이지 간의 링크 구조를 분석하여 평가합니다.\\n예시: 구글 검색 엔진은 페이지 랭크 알고리즘을 사용하여 검색 결과의 순위를 정합니다.\\n연관키워드: 검색 엔진 최적화, 웹 분석, 링크 분석\\n\\n데이터 마이닝\\n\\n정의: 데이터 마이닝은 대량의 데이터에서 유용한 정보를 발굴하는 과정입니다. 이는 통계, 머신러닝, 패턴 인식 등의 기술을 활용합니다.\\n예시: 소매업체가 고객 구매 데이터를 분석하여 판매 전략을 수립하는 것은 데이터 마이닝의 예입니다.\\n연관키워드: 빅데이터, 패턴 인식, 예측 분석\\n\\n멀티모달 (Multimodal)',\n",
    "    '정의: 멀티모달은 여러 종류의 데이터 모드(예: 텍스트, 이미지, 소리 등)를 결합하여 처리하는 기술입니다. 이는 서로 다른 형식의 데이터 간의 상호 작용을 통해 보다 풍부하고 정확한 정보를 추출하거나 예측하는 데 사용됩니다.\\n예시: 이미지와 설명 텍스트를 함께 분석하여 더 정확한 이미지 분류를 수행하는 시스템은 멀티모달 기술의 예입니다.\\n연관키워드: 데이터 융합, 인공지능, 딥러닝'],\n",
    "  'uris': None,\n",
    "  'included': ['metadatas', 'documents'],\n",
    "  'data': None,\n",
    "  'metadatas': [{'source': '../09_VectorStore/data/nlp-keywords.txt'},\n",
    "    {'source': '../09_VectorStore/data/nlp-keywords.txt'},\n",
    "    {'source': '../09_VectorStore/data/nlp-keywords.txt'},\n",
    "    {'source': '../09_VectorStore/data/nlp-keywords.txt'},\n",
    "    {'source': '../09_VectorStore/data/nlp-keywords.txt'},\n",
    "    {'source': '../09_VectorStore/data/nlp-keywords.txt'},\n",
    "    {'source': '../09_VectorStore/data/nlp-keywords.txt'},\n",
    "    {'source': '../09_VectorStore/data/nlp-keywords.txt'},\n",
    "    {'source': '../09_VectorStore/data/nlp-keywords.txt'},\n",
    "    {'source': '../09_VectorStore/data/nlp-keywords.txt'},\n",
    "    {'source': '../09_VectorStore/data/nlp-keywords.txt'}]}\n",
    "  ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b350e153",
   "metadata": {},
   "source": [
    "* `collection_name`을 다르게 지정할 경우: 아무런 결과 얻지 못함 (저장된 데이터가 없으므로)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "52016015",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [],\n",
       " 'embeddings': None,\n",
       " 'documents': [],\n",
       " 'uris': None,\n",
       " 'included': ['metadatas', 'documents'],\n",
       " 'data': None,\n",
       " 'metadatas': []}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 디스크에서 문서 로드하기\n",
    "\n",
    "persist_db2 = Chroma(\n",
    "    persist_directory=DB_PATH,\n",
    "    embedding_function=embeddings,\n",
    "    collection_name=\"my_db2\",\n",
    ")\n",
    "\n",
    "# 저장된 데이터 확인해보기\n",
    "persist_db2.get()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27f69f3",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 셀 출력\n",
    "\n",
    "    ```python\n",
    "    {'ids': [],\n",
    "    'embeddings': None,\n",
    "    'documents': [],\n",
    "    'uris': None,\n",
    "    'included': ['metadatas', 'documents'],\n",
    "    'data': None,\n",
    "    'metadatas': []}\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef80ed2",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8beeb0c",
   "metadata": {},
   "source": [
    "* **`벡터 저장소 생성` ➁**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1e6232",
   "metadata": {},
   "source": [
    "* **`참고`**\n",
    "  * **`ids`: 미제공 → `UUID` 자동 생성**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433d1e88",
   "metadata": {},
   "source": [
    "* **`반환값`**\n",
    "  * 생성된 벡터 저장소 인스턴스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5fd7f8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문자열 리스트로 생성\n",
    "db2 = Chroma.from_texts(\n",
    "    [\"안녕하세요. 정말 반갑습니다.\", \"제 이름은 앨리스입니다.\"],\n",
    "    embedding=embeddings,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0261790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 조회해보기\n",
    "db2.get()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100bec7f",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 셀 출력\n",
    "\n",
    "    ```python\n",
    "    {'ids': ['78f79150-0676-4bf1-a434-31d2e84a12ba',\n",
    "    '2af7b3f8-94bd-46c3-b6e7-8ce90797e97c'],\n",
    "    'embeddings': None,\n",
    "    'documents': ['안녕하세요. 정말 반갑습니다.', '제 이름은 앨리스입니다.'],\n",
    "    'uris': None,\n",
    "    'included': ['metadatas', 'documents'],\n",
    "    'data': None,\n",
    "    'metadatas': [None, None]}\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23f166a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa64493e",
   "metadata": {},
   "source": [
    "#### **3) `유사도 검색`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0162ecc4",
   "metadata": {},
   "source": [
    "* **`similarity_search` 메서드**\n",
    "\n",
    "  * `Chroma` 데이터베이스에서 유사도 검색 수행\n",
    "  * 주어진 `쿼리와 가장 유사한 문서`들을 반환"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9793915",
   "metadata": {},
   "source": [
    "* **`매개변수`**\n",
    "\n",
    "  * **`query`** (`str`): 검색할 쿼리 텍스트\n",
    "  * **`k`** (`int`, `선택적`): 반환할 결과의 수 (**`기본값 = 4`**)\n",
    "  * **`filter`** (`Dict[str, str]`, `선택적`): **메타데이터로 필터링** (기본값 = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e4d3f1",
   "metadata": {},
   "source": [
    "* **`참고`**\n",
    "  * **`k`값 조절**: 원하는 수의 결과 얻을 수 있음\n",
    "  * **`filter` 사용**: `특정 메타데이터 조건에 맞는 문서만 검색` 가능\n",
    "\n",
    "  * 이 메서드는 **`점수 정보없이 문서만 반환함`** \n",
    "  * **점수 정보도 필요한 경우: `similarity_search_with_score` 직접 사용**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fada16",
   "metadata": {},
   "source": [
    "* **`반환값`**: `List [Document]` = 쿼리 텍스트와 **`가장 유사한 문서의 리스트`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793088bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "db.similarity_search(\"TF IDF 에 대하여 알려줘\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834f664c",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 셀 출력 (0.6s)\n",
    "\n",
    "    ```python\n",
    "\n",
    "    [Document(id='57005c56-b9a8-4d48-9dd1-c8e093be0bac', metadata={'source': '../09_VectorStore/data/nlp-keywords.txt'}, page_content='정의: TF-IDF는 문서 내에서 단어의 중요도를 평가하는 데 사용되는 통계적 척도입니다. 이는 문서 내 단어의 빈도와 전체 문서 집합에서 그 단어의 희소성을 고려합니다.\\n예시: 많은 문서에서 자주 등장하지 않는 단어는 높은 TF-IDF 값을 가집니다.\\n연관키워드: 자연어 처리, 정보 검색, 데이터 마이닝\\n\\nDeep Learning\\n\\n정의: 딥러닝은 인공신경망을 이용하여 복잡한 문제를 해결하는 머신러닝의 한 분야입니다. 이는 데이터에서 고수준의 표현을 학습하는 데 중점을 둡니다.\\n예시: 이미지 인식, 음성 인식, 자연어 처리 등에서 딥러닝 모델이 활용됩니다.\\n연관키워드: 인공신경망, 머신러닝, 데이터 분석\\n\\nSchema\\n\\n정의: 스키마는 데이터베이스나 파일의 구조를 정의하는 것으로, 데이터가 어떻게 저장되고 조직되는지에 대한 청사진을 제공합니다.\\n예시: 관계형 데이터베이스의 테이블 스키마는 열 이름, 데이터 타입, 키 제약 조건 등을 정의합니다.\\n연관키워드: 데이터베이스, 데이터 모델링, 데이터 관리\\n\\nDataFrame'),\n",
    "    Document(id='213aac84-a1cd-401d-94f5-fd0f1236bdb6', metadata={'source': '../09_VectorStore/data/nlp-keywords.txt'}, page_content='Semantic Search\\n\\n정의: 의미론적 검색은 사용자의 질의를 단순한 키워드 매칭을 넘어서 그 의미를 파악하여 관련된 결과를 반환하는 검색 방식입니다.\\n예시: 사용자가 \"태양계 행성\"이라고 검색하면, \"목성\", \"화성\" 등과 같이 관련된 행성에 대한 정보를 반환합니다.\\n연관키워드: 자연어 처리, 검색 알고리즘, 데이터 마이닝\\n\\nEmbedding\\n\\n정의: 임베딩은 단어나 문장 같은 텍스트 데이터를 저차원의 연속적인 벡터로 변환하는 과정입니다. 이를 통해 컴퓨터가 텍스트를 이해하고 처리할 수 있게 합니다.\\n예시: \"사과\"라는 단어를 [0.65, -0.23, 0.17]과 같은 벡터로 표현합니다.\\n연관키워드: 자연어 처리, 벡터화, 딥러닝\\n\\nToken\\n\\n정의: 토큰은 텍스트를 더 작은 단위로 분할하는 것을 의미합니다. 이는 일반적으로 단어, 문장, 또는 구절일 수 있습니다.\\n예시: 문장 \"나는 학교에 간다\"를 \"나는\", \"학교에\", \"간다\"로 분할합니다.\\n연관키워드: 토큰화, 자연어 처리, 구문 분석\\n\\nTokenizer'),\n",
    "    Document(id='adb0e0c1-7787-4c8a-92fc-18ee6089d482', metadata={'source': '../09_VectorStore/data/nlp-keywords.txt'}, page_content='정의: 오픈 소스는 소스 코드가 공개되어 누구나 자유롭게 사용, 수정, 배포할 수 있는 소프트웨어를 의미합니다. 이는 협업과 혁신을 촉진하는 데 중요한 역할을 합니다.\\n예시: 리눅스 운영 체제는 대표적인 오픈 소스 프로젝트입니다.\\n연관키워드: 소프트웨어 개발, 커뮤니티, 기술 협업\\n\\nStructured Data\\n\\n정의: 구조화된 데이터는 정해진 형식이나 스키마에 따라 조직된 데이터입니다. 이는 데이터베이스, 스프레드시트 등에서 쉽게 검색하고 분석할 수 있습니다.\\n예시: 관계형 데이터베이스에 저장된 고객 정보 테이블은 구조화된 데이터의 예입니다.\\n연관키워드: 데이터베이스, 데이터 분석, 데이터 모델링\\n\\nParser\\n\\n정의: 파서는 주어진 데이터(문자열, 파일 등)를 분석하여 구조화된 형태로 변환하는 도구입니다. 이는 프로그래밍 언어의 구문 분석이나 파일 데이터 처리에 사용됩니다.\\n예시: HTML 문서를 구문 분석하여 웹 페이지의 DOM 구조를 생성하는 것은 파싱의 한 예입니다.\\n연관키워드: 구문 분석, 컴파일러, 데이터 처리\\n\\nTF-IDF (Term Frequency-Inverse Document Frequency)'),\n",
    "    Document(id='d464f668-71ee-40a7-af5a-52de76c525f0', metadata={'source': '../09_VectorStore/data/nlp-keywords.txt'}, page_content='정의: 키워드 검색은 사용자가 입력한 키워드를 기반으로 정보를 찾는 과정입니다. 이는 대부분의 검색 엔진과 데이터베이스 시스템에서 기본적인 검색 방식으로 사용됩니다.\\n예시: 사용자가 \"커피숍 서울\"이라고 검색하면, 관련된 커피숍 목록을 반환합니다.\\n연관키워드: 검색 엔진, 데이터 검색, 정보 검색\\n\\nPage Rank\\n\\n정의: 페이지 랭크는 웹 페이지의 중요도를 평가하는 알고리즘으로, 주로 검색 엔진 결과의 순위를 결정하는 데 사용됩니다. 이는 웹 페이지 간의 링크 구조를 분석하여 평가합니다.\\n예시: 구글 검색 엔진은 페이지 랭크 알고리즘을 사용하여 검색 결과의 순위를 정합니다.\\n연관키워드: 검색 엔진 최적화, 웹 분석, 링크 분석\\n\\n데이터 마이닝\\n\\n정의: 데이터 마이닝은 대량의 데이터에서 유용한 정보를 발굴하는 과정입니다. 이는 통계, 머신러닝, 패턴 인식 등의 기술을 활용합니다.\\n예시: 소매업체가 고객 구매 데이터를 분석하여 판매 전략을 수립하는 것은 데이터 마이닝의 예입니다.\\n연관키워드: 빅데이터, 패턴 인식, 예측 분석\\n\\n멀티모달 (Multimodal)')]\n",
    "\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0493b88c",
   "metadata": {},
   "source": [
    "* **`k`값에 따라 검색 결과의 개수 지정 가능**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad65609",
   "metadata": {},
   "outputs": [],
   "source": [
    "db.similarity_search(\"TF IDF 에 대하여 알려줘\", k=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a383e4d",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 셀 출력 (0.4s)(2개만 검색)\n",
    "\n",
    "    ```python\n",
    "\n",
    "    [Document(id='57005c56-b9a8-4d48-9dd1-c8e093be0bac', metadata={'source': '../09_VectorStore/data/nlp-keywords.txt'}, page_content='정의: TF-IDF는 문서 내에서 단어의 중요도를 평가하는 데 사용되는 통계적 척도입니다. 이는 문서 내 단어의 빈도와 전체 문서 집합에서 그 단어의 희소성을 고려합니다.\\n예시: 많은 문서에서 자주 등장하지 않는 단어는 높은 TF-IDF 값을 가집니다.\\n연관키워드: 자연어 처리, 정보 검색, 데이터 마이닝\\n\\nDeep Learning\\n\\n정의: 딥러닝은 인공신경망을 이용하여 복잡한 문제를 해결하는 머신러닝의 한 분야입니다. 이는 데이터에서 고수준의 표현을 학습하는 데 중점을 둡니다.\\n예시: 이미지 인식, 음성 인식, 자연어 처리 등에서 딥러닝 모델이 활용됩니다.\\n연관키워드: 인공신경망, 머신러닝, 데이터 분석\\n\\nSchema\\n\\n정의: 스키마는 데이터베이스나 파일의 구조를 정의하는 것으로, 데이터가 어떻게 저장되고 조직되는지에 대한 청사진을 제공합니다.\\n예시: 관계형 데이터베이스의 테이블 스키마는 열 이름, 데이터 타입, 키 제약 조건 등을 정의합니다.\\n연관키워드: 데이터베이스, 데이터 모델링, 데이터 관리\\n\\nDataFrame'),\n",
    "    Document(id='213aac84-a1cd-401d-94f5-fd0f1236bdb6', metadata={'source': '../09_VectorStore/data/nlp-keywords.txt'}, page_content='Semantic Search\\n\\n정의: 의미론적 검색은 사용자의 질의를 단순한 키워드 매칭을 넘어서 그 의미를 파악하여 관련된 결과를 반환하는 검색 방식입니다.\\n예시: 사용자가 \"태양계 행성\"이라고 검색하면, \"목성\", \"화성\" 등과 같이 관련된 행성에 대한 정보를 반환합니다.\\n연관키워드: 자연어 처리, 검색 알고리즘, 데이터 마이닝\\n\\nEmbedding\\n\\n정의: 임베딩은 단어나 문장 같은 텍스트 데이터를 저차원의 연속적인 벡터로 변환하는 과정입니다. 이를 통해 컴퓨터가 텍스트를 이해하고 처리할 수 있게 합니다.\\n예시: \"사과\"라는 단어를 [0.65, -0.23, 0.17]과 같은 벡터로 표현합니다.\\n연관키워드: 자연어 처리, 벡터화, 딥러닝\\n\\nToken\\n\\n정의: 토큰은 텍스트를 더 작은 단위로 분할하는 것을 의미합니다. 이는 일반적으로 단어, 문장, 또는 구절일 수 있습니다.\\n예시: 문장 \"나는 학교에 간다\"를 \"나는\", \"학교에\", \"간다\"로 분할합니다.\\n연관키워드: 토큰화, 자연어 처리, 구문 분석\\n\\nTokenizer')]\n",
    "\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1781a821",
   "metadata": {},
   "source": [
    "* **`filter`에 `metadata`정보를 활용해 검색 결과 필터링해보기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c30f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter 사용\n",
    "\n",
    "db.similarity_search(\n",
    "    \"TF IDF 에 대하여 알려줘\",                              # query = 검색 쿼리 텍스트 \n",
    "    filter={\"source\": \"../09_VectorStore/data/nlp-keywords.txt\"},         # metadata로 필터링\n",
    "    k=2                                                 # k = 검색 결과 개수 지정\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6e4cf2",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 셀 출력 (0.3s) (metadata 필터링까지 적용)\n",
    "\n",
    "    ```python\n",
    "\n",
    "    [Document(id='57005c56-b9a8-4d48-9dd1-c8e093be0bac', metadata={'source': '../09_VectorStore/data/nlp-keywords.txt'}, page_content='정의: TF-IDF는 문서 내에서 단어의 중요도를 평가하는 데 사용되는 통계적 척도입니다. 이는 문서 내 단어의 빈도와 전체 문서 집합에서 그 단어의 희소성을 고려합니다.\\n예시: 많은 문서에서 자주 등장하지 않는 단어는 높은 TF-IDF 값을 가집니다.\\n연관키워드: 자연어 처리, 정보 검색, 데이터 마이닝\\n\\nDeep Learning\\n\\n정의: 딥러닝은 인공신경망을 이용하여 복잡한 문제를 해결하는 머신러닝의 한 분야입니다. 이는 데이터에서 고수준의 표현을 학습하는 데 중점을 둡니다.\\n예시: 이미지 인식, 음성 인식, 자연어 처리 등에서 딥러닝 모델이 활용됩니다.\\n연관키워드: 인공신경망, 머신러닝, 데이터 분석\\n\\nSchema\\n\\n정의: 스키마는 데이터베이스나 파일의 구조를 정의하는 것으로, 데이터가 어떻게 저장되고 조직되는지에 대한 청사진을 제공합니다.\\n예시: 관계형 데이터베이스의 테이블 스키마는 열 이름, 데이터 타입, 키 제약 조건 등을 정의합니다.\\n연관키워드: 데이터베이스, 데이터 모델링, 데이터 관리\\n\\nDataFrame'),\n",
    "    Document(id='213aac84-a1cd-401d-94f5-fd0f1236bdb6', metadata={'source': '../09_VectorStore/data/nlp-keywords.txt'}, page_content='Semantic Search\\n\\n정의: 의미론적 검색은 사용자의 질의를 단순한 키워드 매칭을 넘어서 그 의미를 파악하여 관련된 결과를 반환하는 검색 방식입니다.\\n예시: 사용자가 \"태양계 행성\"이라고 검색하면, \"목성\", \"화성\" 등과 같이 관련된 행성에 대한 정보를 반환합니다.\\n연관키워드: 자연어 처리, 검색 알고리즘, 데이터 마이닝\\n\\nEmbedding\\n\\n정의: 임베딩은 단어나 문장 같은 텍스트 데이터를 저차원의 연속적인 벡터로 변환하는 과정입니다. 이를 통해 컴퓨터가 텍스트를 이해하고 처리할 수 있게 합니다.\\n예시: \"사과\"라는 단어를 [0.65, -0.23, 0.17]과 같은 벡터로 표현합니다.\\n연관키워드: 자연어 처리, 벡터화, 딥러닝\\n\\nToken\\n\\n정의: 토큰은 텍스트를 더 작은 단위로 분할하는 것을 의미합니다. 이는 일반적으로 단어, 문장, 또는 구절일 수 있습니다.\\n예시: 문장 \"나는 학교에 간다\"를 \"나는\", \"학교에\", \"간다\"로 분할합니다.\\n연관키워드: 토큰화, 자연어 처리, 구문 분석\\n\\nTokenizer')]\n",
    "\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b420feab",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9387f399",
   "metadata": {},
   "source": [
    "* `filter`에서 다른 `source`를 사용해 검색한 결과 확인해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d576a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter 사용\n",
    "\n",
    "db.similarity_search(\n",
    "    \"TF IDF 에 대하여 알려줘\", \n",
    "    filter={\"source\": \"../09_VectorStore/data/finance-keywords.txt\"}, # 다른 텍스트 문서\n",
    "    k=2\n",
    ")                                                                     # []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28405f9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f18aa81",
   "metadata": {},
   "source": [
    "#### **4) `벡터 저장소에 문서 추가해보기`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc27e0b",
   "metadata": {},
   "source": [
    "* **`add_documents` 메서드: 벡터 저자소에 문서를 추가 or 업데이트**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8563143e",
   "metadata": {},
   "source": [
    "* **`매개변수`**\n",
    "  * **`documents`** (`List [Document]`): 벡터 저장소에 추가할 문서 리스트\n",
    "  * **`kwargs`**: 추가 키워드 인자\n",
    "  * **`ids`**: 문서 `ID` 리스트 **→ 제공할 경우 문서의 `ID`보다 우선시됨**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97115685",
   "metadata": {},
   "source": [
    "* **`참고`**\n",
    "\n",
    "  * **`add_texts` 메서드 구현되어 있어야 함**\n",
    "\n",
    "  * 문서\n",
    "    * **`page_content`** = `text`\n",
    "    * **`metadata`** = `metadata`\n",
    "\n",
    "  * 문서의 **`ID`**\n",
    "    * 문서의 `ID`가 사용되는 경우: **문서에 `ID`가 있고, `kwargs`에 `ID`가 제공되지 않는 경우**\n",
    "    * **`kwargs`의 `ID`와 문서의 수가 일치하지 않는 경우 `ValueError` 발생**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1acd98",
   "metadata": {},
   "source": [
    "* **`예외`**\n",
    "  * **`NotImplementedError`**: `add_texts` 메서드가 구현되지 않은 경우 발생"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a55a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "# page_content, metadata, id 지정\n",
    "db.add_documents(\n",
    "    [\n",
    "        Document(\n",
    "            page_content=\"안녕하세요! 이번엔 도큐먼트를 새로 추가해 볼께요\",\n",
    "            metadata={\"source\": \"mydata.txt\"},\n",
    "            id=\"1\",\n",
    "        )\n",
    "    ]\n",
    ")                                                       # ['1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2567c88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# id=1 로 문서 조회\n",
    "\n",
    "db.get(\"1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9f79ce",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 셀 출력 (0.1s)\n",
    "\n",
    "    ```python\n",
    "\n",
    "    {'ids': ['1'],\n",
    "    'embeddings': None,\n",
    "    'documents': ['안녕하세요! 이번엔 도큐먼트를 새로 추가해 볼께요'],\n",
    "    'uris': None,\n",
    "    'included': ['metadatas', 'documents'],\n",
    "    'data': None,\n",
    "    'metadatas': [{'source': 'mydata.txt'}]}\n",
    "\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3852eec7",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cbe52c5",
   "metadata": {},
   "source": [
    "* **`add_texts` 메서드 = 텍스트 임베딩, 벡터 저장소에 추가**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2a9fdc",
   "metadata": {},
   "source": [
    "* **`매개변수`**\n",
    "  * **`text`** (`Iterable` [`str`]): 벡터 저장소에 추가할 텍스트 리스트\n",
    "  * **`metadates`** (`Optional` [`List`[`dict`]]): 메타데이터 리스트 (*기본값 = None*)\n",
    "  * **`ids`** (`Optional`[`List`[`str`]]): 문서 `ID` 리스트 (*기본값 = None*)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b28553d",
   "metadata": {},
   "source": [
    "* **`참고`**\n",
    "\n",
    "  * `ids` 미제공시: **`UUID` 사용 → 자동 생성**\n",
    "\n",
    "  * **임베딩 함수 설정 시 텍스트를 임베딩함**\n",
    "\n",
    "  * **`메타데이터 제공된 경우`**:\n",
    "    * **`분리 처리`**: 메타데이터가 있는 텍스트, 없는 텍스트\n",
    "    * 메타데이터가 없는 텍스트의 경우 = **`빈 딕셔너리`**\n",
    "\n",
    "  * 컬렉션에 `upsert` 수행 → `텍스트`, `임베딩`, `메타데이터` 추가"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fa82bb",
   "metadata": {},
   "source": [
    "* **`반환값`**: `List [str]` = 추가된 텍스트의 `ID` 리스트"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b003da",
   "metadata": {},
   "source": [
    "* **`에외`**\n",
    "\n",
    "  * **`ValueError`**: 복잡한 메타데이터로 인한 오류 발생시\n",
    "\n",
    "    * 필터링 방법 안내 메시지와 함께 발생 기존 아이디에 추가하는 경우 `upsert`가 수행\n",
    "    * 기존의 문서는 대체됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492615f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '2']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 신규 데이터 추가 \n",
    "# 이때 기존의 id=1 의 데이터는 덮어씀\n",
    "\n",
    "db.add_texts(\n",
    "    [\"이전에 추가한 Document 를 덮어쓰겠습니다.\", \"덮어쓴 결과가 어떤가요?\"],\n",
    "    metadatas=[{\"source\": \"mydata.txt\"}, {\"source\": \"mydata.txt\"}],\n",
    "    ids=[\"1\", \"2\"],\n",
    ")                                                     # ['1', '2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f5bcaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# id=1 조회\n",
    "\n",
    "db.get([\"1\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1c9874",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 셀 출력\n",
    "\n",
    "    ```python\n",
    "\n",
    "    {'ids': ['1'],\n",
    "    'embeddings': None,\n",
    "    'documents': ['이전에 추가한 Document 를 덮어쓰겠습니다.'],\n",
    "    'uris': None,\n",
    "    'included': ['metadatas', 'documents'],\n",
    "    'data': None,\n",
    "    'metadatas': [{'source': 'mydata.txt'}]}\n",
    "\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351c63f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# id=2 조회\n",
    "\n",
    "db.get([\"2\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441dd9c7",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 셀 출력\n",
    "\n",
    "    ```python\n",
    "\n",
    "    {'ids': ['2'],\n",
    "    'embeddings': None,\n",
    "    'documents': ['덮어쓴 결과가 어떤가요?'],\n",
    "    'uris': None,\n",
    "    'included': ['metadatas', 'documents'],\n",
    "    'data': None,\n",
    "    'metadatas': [{'source': 'mydata.txt'}]}\n",
    "\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8501ca96",
   "metadata": {},
   "source": [
    "* id=1, id=2 조회한 결과 \n",
    "\n",
    "    |             | 코드          | 결과                                                                                                                                                                                                                    |\n",
    "    |-------------|-------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "    | id=1로 문서 조회 | db.get(\"1\") | {'ids': ['1'],<br> 'embeddings': None,<br> 'documents': ['안녕하세요! 이번엔 도큐먼트를 새로 추가해 볼께요'],<br> 'uris': None,<br> 'included': ['metadatas', 'documents'],<br> 'data': None,<br> 'metadatas': [{'source': 'mydata.txt'}]} |\n",
    "    | id=2로 문서 조회 | db.get(\"2\") | {'ids': ['2'],<br> 'embeddings': None,<br> 'documents': ['덮어쓴 결과가 어떤가요?'],<br> 'uris': None,<br> 'included': ['metadatas', 'documents'],<br> 'data': None,<br> 'metadatas': [{'source': 'mydata.txt'}]}               |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b43d5f9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d279bfa",
   "metadata": {},
   "source": [
    "#### **5) `벡터 저장소에서 문서 삭제`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3c7ebb",
   "metadata": {},
   "source": [
    "* **`delete` 메서드**: 벡터 저장소에서 지정된 `ID`의 문서 삭제"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87eb27d",
   "metadata": {},
   "source": [
    "* **`매개변수`**\n",
    "\n",
    "  * **`ids`** (`Optional` [`List` [`str`]]): 삭제할 문서의 `ID` 리스트 (*기본값 = None*)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c304c65",
   "metadata": {},
   "source": [
    "* **`참고`**\n",
    "\n",
    "  * 해당 메서드는 내부적으로 컬렉션의 **`delete` 메서드 호출**\n",
    "\n",
    "  * **`ids = None` → 아무 작업도 수행하지 않음**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e1d3d5",
   "metadata": {},
   "source": [
    "* **`반환값` = `None`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1bb5eb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# id=1 삭제\n",
    "\n",
    "db.delete(ids=[\"1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5e1242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문서 조회\n",
    "\n",
    "db.get([\"1\", \"2\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e8b5a8",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 셀 출력 (`id=1`의 값이 삭제된 것을 확인할 수 있음)\n",
    "\n",
    "    ```python\n",
    "\n",
    "    {'ids': ['2'],\n",
    "    'embeddings': None,\n",
    "    'documents': ['덮어쓴 결과가 어떤가요?'],\n",
    "    'uris': None,\n",
    "    'included': ['metadatas', 'documents'],\n",
    "    'data': None,\n",
    "    'metadatas': [{'source': 'mydata.txt'}]}\n",
    "\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f4f255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# where 조건으로 metadata 조회\n",
    "\n",
    "db.get(where={\"source\": \"mydata.txt\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf5003d",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 셀 출력\n",
    "\n",
    "    ```python\n",
    "\n",
    "    {'ids': ['2'],\n",
    "    'embeddings': None,\n",
    "    'documents': ['덮어쓴 결과가 어떤가요?'],\n",
    "    'uris': None,\n",
    "    'included': ['metadatas', 'documents'],\n",
    "    'data': None,\n",
    "    'metadatas': [{'source': 'mydata.txt'}]}\n",
    "\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bbef8ab",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ed510e",
   "metadata": {},
   "source": [
    "#### **6) `초기화` (`reset_colllection`)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91595203",
   "metadata": {},
   "source": [
    "* **`reset_colltion` 메스드 = 벡터 저장소의 컬렉션 초기화**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "148e6678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 컬렉션 초기화\n",
    "\n",
    "db.reset_collection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d2861aa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [],\n",
       " 'embeddings': None,\n",
       " 'documents': [],\n",
       " 'uris': None,\n",
       " 'included': ['metadatas', 'documents'],\n",
       " 'data': None,\n",
       " 'metadatas': []}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 초기화 후 문서 조회\n",
    "\n",
    "db.get()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97be31b",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 셀 출력 (아무것도 검색되지 않음)\n",
    "\n",
    "    ```python\n",
    "\n",
    "    {'ids': [],\n",
    "    'embeddings': None,\n",
    "    'documents': [],\n",
    "    'uris': None,\n",
    "    'included': ['metadatas', 'documents'],\n",
    "    'data': None,\n",
    "    'metadatas': []}\n",
    "\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704c0261",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971c3d2e",
   "metadata": {},
   "source": [
    "#### **7) `벡터저장소를 검색기(Retriever)로 변환`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012e1dc2",
   "metadata": {},
   "source": [
    "* **`as_retriever` 메서드 = 벡터 자장소를 기반으로 `VectorStoreRetriever` 생성**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6d6212",
   "metadata": {},
   "source": [
    "* **`매개변수`**\n",
    "\n",
    "    * **`kwargs`**: 검색 함수에 전달할 **`키워드 인자`**\n",
    "\n",
    "    * **`search_type`** (`Optional` [`str`]): 검색 유형\n",
    "      * **`similarity`**\n",
    "      * **`mmr`**\n",
    "      * **`similarity_score_threshold`**\n",
    "\n",
    "    * **`search_kwargs`** (`Optional`[`Dict`]): 검색 함수에 전달할 추가 인자\n",
    "      * **`k`**: 반환할 문서 수 *(**`기본값 = 4`**)*\n",
    "      * **`score_threshold`**: 최고 유사도 임계값\n",
    "      * **`fetch_k`**: `MMR` 알고리즘에 전달할 문서 수 *(**`기본값 = 20`**)*\n",
    "      * **`lambda_mult`**: `MMR` 결과의 다양성 조절 *(**`0~1, 기본값 = 0.5`**)*\n",
    "      * **`filter`**: 문서 메타데이터 필터링"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b027c79",
   "metadata": {},
   "source": [
    "* **`반환값`**: **`VectorStoreRetriever`** = 벡터 저장소 기반 검색기 인스턴스 `DB` 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f198048f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DB 생성 (1.4s 소요)\n",
    "\n",
    "db = Chroma.from_documents(\n",
    "    documents=split_doc1 + split_doc2,\n",
    "    embedding=embeddings,\n",
    "    collection_name=\"nlp\",\n",
    ")       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1877340",
   "metadata": {},
   "source": [
    "* 기본 값으로 설정된 4개의 문서를 유사도 검색을 수행해서 조회해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8847b905",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db.as_retriever()\n",
    "retriever.invoke(\"Word2Vec 에 대하여 알려줘\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f24d1b",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 셀 출력 (기본 값으로 설정된 4개의 문서를 유사도 검색으로 조회)\n",
    "\n",
    "    ```python\n",
    "\n",
    "    [Document(id='9174a219-9bba-41d6-a08c-9c2fe712d441', metadata={'source': '../09_VectorStore/data/nlp-keywords.txt'}, page_content='정의: Word2Vec은 단어를 벡터 공간에 매핑하여 단어 간의 의미적 관계를 나타내는 자연어 처리 기술입니다. 이는 단어의 문맥적 유사성을 기반으로 벡터를 생성합니다.\\n예시: Word2Vec 모델에서 \"왕\"과 \"여왕\"은 서로 가까운 위치에 벡터로 표현됩니다.\\n연관키워드: 자연어 처리, 임베딩, 의미론적 유사성\\nLLM (Large Language Model)\\n\\n정의: LLM은 대규모의 텍스트 데이터로 훈련된 큰 규모의 언어 모델을 의미합니다. 이러한 모델은 다양한 자연어 이해 및 생성 작업에 사용됩니다.\\n예시: OpenAI의 GPT 시리즈는 대표적인 대규모 언어 모델입니다.\\n연관키워드: 자연어 처리, 딥러닝, 텍스트 생성\\n\\nFAISS (Facebook AI Similarity Search)\\n\\n정의: FAISS는 페이스북에서 개발한 고속 유사성 검색 라이브러리로, 특히 대규모 벡터 집합에서 유사 벡터를 효과적으로 검색할 수 있도록 설계되었습니다.\\n예시: 수백만 개의 이미지 벡터 중에서 비슷한 이미지를 빠르게 찾는 데 FAISS가 사용될 수 있습니다.\\n연관키워드: 벡터 검색, 머신러닝, 데이터베이스 최적화\\n\\nOpen Source'),\n",
    "    Document(id='ec2f75fb-88fd-4936-b929-40ed4bdea955', metadata={'source': '../09_VectorStore/data/nlp-keywords.txt'}, page_content='Semantic Search\\n\\n정의: 의미론적 검색은 사용자의 질의를 단순한 키워드 매칭을 넘어서 그 의미를 파악하여 관련된 결과를 반환하는 검색 방식입니다.\\n예시: 사용자가 \"태양계 행성\"이라고 검색하면, \"목성\", \"화성\" 등과 같이 관련된 행성에 대한 정보를 반환합니다.\\n연관키워드: 자연어 처리, 검색 알고리즘, 데이터 마이닝\\n\\nEmbedding\\n\\n정의: 임베딩은 단어나 문장 같은 텍스트 데이터를 저차원의 연속적인 벡터로 변환하는 과정입니다. 이를 통해 컴퓨터가 텍스트를 이해하고 처리할 수 있게 합니다.\\n예시: \"사과\"라는 단어를 [0.65, -0.23, 0.17]과 같은 벡터로 표현합니다.\\n연관키워드: 자연어 처리, 벡터화, 딥러닝\\n\\nToken\\n\\n정의: 토큰은 텍스트를 더 작은 단위로 분할하는 것을 의미합니다. 이는 일반적으로 단어, 문장, 또는 구절일 수 있습니다.\\n예시: 문장 \"나는 학교에 간다\"를 \"나는\", \"학교에\", \"간다\"로 분할합니다.\\n연관키워드: 토큰화, 자연어 처리, 구문 분석\\n\\nTokenizer'),\n",
    "    Document(id='0762048e-c63b-4f3c-bf0c-2ca289c6f959', metadata={'source': '../09_VectorStore/data/nlp-keywords.txt'}, page_content='GPT (Generative Pretrained Transformer)\\n\\n정의: GPT는 대규모의 데이터셋으로 사전 훈련된 생성적 언어 모델로, 다양한 텍스트 기반 작업에 활용됩니다. 이는 입력된 텍스트에 기반하여 자연스러운 언어를 생성할 수 있습니다.\\n예시: 사용자가 제공한 질문에 대해 자세한 답변을 생성하는 챗봇은 GPT 모델을 사용할 수 있습니다.\\n연관키워드: 자연어 처리, 텍스트 생성, 딥러닝\\n\\nInstructGPT\\n\\n정의: InstructGPT는 사용자의 지시에 따라 특정한 작업을 수행하기 위해 최적화된 GPT 모델입니다. 이 모델은 보다 정확하고 관련성 높은 결과를 생성하도록 설계되었습니다.\\n예시: 사용자가 \"이메일 초안 작성\"과 같은 특정 지시를 제공하면, InstructGPT는 관련 내용을 기반으로 이메일을 작성합니다.\\n연관키워드: 인공지능, 자연어 이해, 명령 기반 처리\\n\\nKeyword Search'),\n",
    "    Document(id='b05272b0-7f0d-4917-9672-2bc53a6d1b6f', metadata={'source': '../09_VectorStore/data/nlp-keywords.txt'}, page_content='정의: HuggingFace는 자연어 처리를 위한 다양한 사전 훈련된 모델과 도구를 제공하는 라이브러리입니다. 이는 연구자와 개발자들이 쉽게 NLP 작업을 수행할 수 있도록 돕습니다.\\n예시: HuggingFace의 Transformers 라이브러리를 사용하여 감정 분석, 텍스트 생성 등의 작업을 수행할 수 있습니다.\\n연관키워드: 자연어 처리, 딥러닝, 라이브러리\\n\\nDigital Transformation\\n\\n정의: 디지털 변환은 기술을 활용하여 기업의 서비스, 문화, 운영을 혁신하는 과정입니다. 이는 비즈니스 모델을 개선하고 디지털 기술을 통해 경쟁력을 높이는 데 중점을 둡니다.\\n예시: 기업이 클라우드 컴퓨팅을 도입하여 데이터 저장과 처리를 혁신하는 것은 디지털 변환의 예입니다.\\n연관키워드: 혁신, 기술, 비즈니스 모델\\n\\nCrawling\\n\\n정의: 크롤링은 자동화된 방식으로 웹 페이지를 방문하여 데이터를 수집하는 과정입니다. 이는 검색 엔진 최적화나 데이터 분석에 자주 사용됩니다.\\n예시: 구글 검색 엔진이 인터넷 상의 웹사이트를 방문하여 콘텐츠를 수집하고 인덱싱하는 것이 크롤링입니다.\\n연관키워드: 데이터 수집, 웹 스크래핑, 검색 엔진\\n\\nWord2Vec')]\n",
    "\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c6317e",
   "metadata": {},
   "source": [
    "* 다양성이 높은 더 많은 문서 검색해보기\n",
    "\n",
    "  * **`k`**: 반환할 문서 수 *(**`기본값 = 4`**)*\n",
    "  * **`fetch_k`**: `MMR` 알고리즘에 전달할 문서 수 *(**`기본값 = 20`**)*\n",
    "  * **`lambda_mult`**: `MMR` 결과의 다양성 조절 *(**`0~1, 기본값 = 0.5`**)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fbc61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db.as_retriever(\n",
    "    search_type=\"mmr\",                              # 검색 유형\n",
    "    search_kwargs={\"k\": 6,                          # 반환할 문서 수\n",
    "                    \"lambda_mult\": 0.25,            # 결과의 다양성 조절\n",
    "                    \"fetch_k\": 10}                  # MMR 알고리즘에 전달할 문서 수\n",
    ")\n",
    "retriever.invoke(\"Word2Vec 에 대하여 알려줘\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f646092",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 셀 출력\n",
    "\n",
    "    ```python\n",
    "\n",
    "    [Document(id='9174a219-9bba-41d6-a08c-9c2fe712d441', metadata={'source': '../09_VectorStore/data/nlp-keywords.txt'}, page_content='정의: Word2Vec은 단어를 벡터 공간에 매핑하여 단어 간의 의미적 관계를 나타내는 자연어 처리 기술입니다. 이는 단어의 문맥적 유사성을 기반으로 벡터를 생성합니다.\\n예시: Word2Vec 모델에서 \"왕\"과 \"여왕\"은 서로 가까운 위치에 벡터로 표현됩니다.\\n연관키워드: 자연어 처리, 임베딩, 의미론적 유사성\\nLLM (Large Language Model)\\n\\n정의: LLM은 대규모의 텍스트 데이터로 훈련된 큰 규모의 언어 모델을 의미합니다. 이러한 모델은 다양한 자연어 이해 및 생성 작업에 사용됩니다.\\n예시: OpenAI의 GPT 시리즈는 대표적인 대규모 언어 모델입니다.\\n연관키워드: 자연어 처리, 딥러닝, 텍스트 생성\\n\\nFAISS (Facebook AI Similarity Search)\\n\\n정의: FAISS는 페이스북에서 개발한 고속 유사성 검색 라이브러리로, 특히 대규모 벡터 집합에서 유사 벡터를 효과적으로 검색할 수 있도록 설계되었습니다.\\n예시: 수백만 개의 이미지 벡터 중에서 비슷한 이미지를 빠르게 찾는 데 FAISS가 사용될 수 있습니다.\\n연관키워드: 벡터 검색, 머신러닝, 데이터베이스 최적화\\n\\nOpen Source'),\n",
    "    Document(id='0762048e-c63b-4f3c-bf0c-2ca289c6f959', metadata={'source': '../09_VectorStore/data/nlp-keywords.txt'}, page_content='GPT (Generative Pretrained Transformer)\\n\\n정의: GPT는 대규모의 데이터셋으로 사전 훈련된 생성적 언어 모델로, 다양한 텍스트 기반 작업에 활용됩니다. 이는 입력된 텍스트에 기반하여 자연스러운 언어를 생성할 수 있습니다.\\n예시: 사용자가 제공한 질문에 대해 자세한 답변을 생성하는 챗봇은 GPT 모델을 사용할 수 있습니다.\\n연관키워드: 자연어 처리, 텍스트 생성, 딥러닝\\n\\nInstructGPT\\n\\n정의: InstructGPT는 사용자의 지시에 따라 특정한 작업을 수행하기 위해 최적화된 GPT 모델입니다. 이 모델은 보다 정확하고 관련성 높은 결과를 생성하도록 설계되었습니다.\\n예시: 사용자가 \"이메일 초안 작성\"과 같은 특정 지시를 제공하면, InstructGPT는 관련 내용을 기반으로 이메일을 작성합니다.\\n연관키워드: 인공지능, 자연어 이해, 명령 기반 처리\\n\\nKeyword Search'),\n",
    "    Document(id='b05272b0-7f0d-4917-9672-2bc53a6d1b6f', metadata={'source': '../09_VectorStore/data/nlp-keywords.txt'}, page_content='정의: HuggingFace는 자연어 처리를 위한 다양한 사전 훈련된 모델과 도구를 제공하는 라이브러리입니다. 이는 연구자와 개발자들이 쉽게 NLP 작업을 수행할 수 있도록 돕습니다.\\n예시: HuggingFace의 Transformers 라이브러리를 사용하여 감정 분석, 텍스트 생성 등의 작업을 수행할 수 있습니다.\\n연관키워드: 자연어 처리, 딥러닝, 라이브러리\\n\\nDigital Transformation\\n\\n정의: 디지털 변환은 기술을 활용하여 기업의 서비스, 문화, 운영을 혁신하는 과정입니다. 이는 비즈니스 모델을 개선하고 디지털 기술을 통해 경쟁력을 높이는 데 중점을 둡니다.\\n예시: 기업이 클라우드 컴퓨팅을 도입하여 데이터 저장과 처리를 혁신하는 것은 디지털 변환의 예입니다.\\n연관키워드: 혁신, 기술, 비즈니스 모델\\n\\nCrawling\\n\\n정의: 크롤링은 자동화된 방식으로 웹 페이지를 방문하여 데이터를 수집하는 과정입니다. 이는 검색 엔진 최적화나 데이터 분석에 자주 사용됩니다.\\n예시: 구글 검색 엔진이 인터넷 상의 웹사이트를 방문하여 콘텐츠를 수집하고 인덱싱하는 것이 크롤링입니다.\\n연관키워드: 데이터 수집, 웹 스크래핑, 검색 엔진\\n\\nWord2Vec'),\n",
    "    Document(id='1642794d-38de-4bde-a521-3b9606e768dd', metadata={'source': '../09_VectorStore/data/nlp-keywords.txt'}, page_content='정의: 키워드 검색은 사용자가 입력한 키워드를 기반으로 정보를 찾는 과정입니다. 이는 대부분의 검색 엔진과 데이터베이스 시스템에서 기본적인 검색 방식으로 사용됩니다.\\n예시: 사용자가 \"커피숍 서울\"이라고 검색하면, 관련된 커피숍 목록을 반환합니다.\\n연관키워드: 검색 엔진, 데이터 검색, 정보 검색\\n\\nPage Rank\\n\\n정의: 페이지 랭크는 웹 페이지의 중요도를 평가하는 알고리즘으로, 주로 검색 엔진 결과의 순위를 결정하는 데 사용됩니다. 이는 웹 페이지 간의 링크 구조를 분석하여 평가합니다.\\n예시: 구글 검색 엔진은 페이지 랭크 알고리즘을 사용하여 검색 결과의 순위를 정합니다.\\n연관키워드: 검색 엔진 최적화, 웹 분석, 링크 분석\\n\\n데이터 마이닝\\n\\n정의: 데이터 마이닝은 대량의 데이터에서 유용한 정보를 발굴하는 과정입니다. 이는 통계, 머신러닝, 패턴 인식 등의 기술을 활용합니다.\\n예시: 소매업체가 고객 구매 데이터를 분석하여 판매 전략을 수립하는 것은 데이터 마이닝의 예입니다.\\n연관키워드: 빅데이터, 패턴 인식, 예측 분석\\n\\n멀티모달 (Multimodal)'),\n",
    "    Document(id='1695c7d3-65e5-4b66-b9c4-a786e1a33787', metadata={'source': '../09_VectorStore/data/nlp-keywords.txt'}, page_content='정의: 토크나이저는 텍스트 데이터를 토큰으로 분할하는 도구입니다. 이는 자연어 처리에서 데이터를 전처리하는 데 사용됩니다.\\n예시: \"I love programming.\"이라는 문장을 [\"I\", \"love\", \"programming\", \".\"]으로 분할합니다.\\n연관키워드: 토큰화, 자연어 처리, 구문 분석\\n\\nVectorStore\\n\\n정의: 벡터스토어는 벡터 형식으로 변환된 데이터를 저장하는 시스템입니다. 이는 검색, 분류 및 기타 데이터 분석 작업에 사용됩니다.\\n예시: 단어 임베딩 벡터들을 데이터베이스에 저장하여 빠르게 접근할 수 있습니다.\\n연관키워드: 임베딩, 데이터베이스, 벡터화\\n\\nSQL\\n\\n정의: SQL(Structured Query Language)은 데이터베이스에서 데이터를 관리하기 위한 프로그래밍 언어입니다. 데이터 조회, 수정, 삽입, 삭제 등 다양한 작업을 수행할 수 있습니다.\\n예시: SELECT * FROM users WHERE age > 18;은 18세 이상의 사용자 정보를 조회합니다.\\n연관키워드: 데이터베이스, 쿼리, 데이터 관리\\n\\nCSV'),\n",
    "    Document(id='1bc73306-0be6-4c34-8ce2-090d73fd04bb', metadata={'source': '../09_VectorStore/data/nlp-keywords.txt'}, page_content=\"정의: DataFrame은 행과 열로 이루어진 테이블 형태의 데이터 구조로, 주로 데이터 분석 및 처리에 사용됩니다.\\n예시: 판다스 라이브러리에서 DataFrame은 다양한 데이터 타입의 열을 가질 수 있으며, 데이터 조작과 분석을 용이하게 합니다.\\n연관키워드: 데이터 분석, 판다스, 데이터 처리\\n\\nAttention 메커니즘\\n\\n정의: Attention 메커니즘은 딥러닝에서 중요한 정보에 더 많은 '주의'를 기울이도록 하는 기법입니다. 이는 주로 시퀀스 데이터(예: 텍스트, 시계열 데이터)에서 사용됩니다.\\n예시: 번역 모델에서 Attention 메커니즘은 입력 문장의 중요한 부분에 더 집중하여 정확한 번역을 생성합니다.\\n연관키워드: 딥러닝, 자연어 처리, 시퀀스 모델링\\n\\n판다스 (Pandas)\\n\\n정의: 판다스는 파이썬 프로그래밍 언어를 위한 데이터 분석 및 조작 도구를 제공하는 라이브러리입니다. 이는 데이터 분석 작업을 효율적으로 수행할 수 있게 합니다.\\n예시: 판다스를 사용하여 CSV 파일을 읽고, 데이터를 정제하며, 다양한 분석을 수행할 수 있습니다.\\n연관키워드: 데이터 분석, 파이썬, 데이터 처리\")]\n",
    "\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7051d35",
   "metadata": {},
   "source": [
    "* `MMR` 알고리즘을 위해 더 많은 문서를 가져오되 **`상위 2개만 반환`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7641db53",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db.as_retriever(\n",
    "    search_type=\"mmr\", \n",
    "    search_kwargs={\n",
    "        \"k\": 2,                                     # 상위 2개만 반환\n",
    "        \"fetch_k\": 10})\n",
    "\n",
    "retriever.invoke(\"Word2Vec 에 대하여 알려줘\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c513475b",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 셀 출력 (상위 2개만 가져오도록 출력)\n",
    "\n",
    "    ```python\n",
    "\n",
    "    [Document(id='9174a219-9bba-41d6-a08c-9c2fe712d441', metadata={'source': '../09_VectorStore/data/nlp-keywords.txt'}, page_content='정의: Word2Vec은 단어를 벡터 공간에 매핑하여 단어 간의 의미적 관계를 나타내는 자연어 처리 기술입니다. 이는 단어의 문맥적 유사성을 기반으로 벡터를 생성합니다.\\n예시: Word2Vec 모델에서 \"왕\"과 \"여왕\"은 서로 가까운 위치에 벡터로 표현됩니다.\\n연관키워드: 자연어 처리, 임베딩, 의미론적 유사성\\nLLM (Large Language Model)\\n\\n정의: LLM은 대규모의 텍스트 데이터로 훈련된 큰 규모의 언어 모델을 의미합니다. 이러한 모델은 다양한 자연어 이해 및 생성 작업에 사용됩니다.\\n예시: OpenAI의 GPT 시리즈는 대표적인 대규모 언어 모델입니다.\\n연관키워드: 자연어 처리, 딥러닝, 텍스트 생성\\n\\nFAISS (Facebook AI Similarity Search)\\n\\n정의: FAISS는 페이스북에서 개발한 고속 유사성 검색 라이브러리로, 특히 대규모 벡터 집합에서 유사 벡터를 효과적으로 검색할 수 있도록 설계되었습니다.\\n예시: 수백만 개의 이미지 벡터 중에서 비슷한 이미지를 빠르게 찾는 데 FAISS가 사용될 수 있습니다.\\n연관키워드: 벡터 검색, 머신러닝, 데이터베이스 최적화\\n\\nOpen Source'),\n",
    "    Document(id='0762048e-c63b-4f3c-bf0c-2ca289c6f959', metadata={'source': '../09_VectorStore/data/nlp-keywords.txt'}, page_content='GPT (Generative Pretrained Transformer)\\n\\n정의: GPT는 대규모의 데이터셋으로 사전 훈련된 생성적 언어 모델로, 다양한 텍스트 기반 작업에 활용됩니다. 이는 입력된 텍스트에 기반하여 자연스러운 언어를 생성할 수 있습니다.\\n예시: 사용자가 제공한 질문에 대해 자세한 답변을 생성하는 챗봇은 GPT 모델을 사용할 수 있습니다.\\n연관키워드: 자연어 처리, 텍스트 생성, 딥러닝\\n\\nInstructGPT\\n\\n정의: InstructGPT는 사용자의 지시에 따라 특정한 작업을 수행하기 위해 최적화된 GPT 모델입니다. 이 모델은 보다 정확하고 관련성 높은 결과를 생성하도록 설계되었습니다.\\n예시: 사용자가 \"이메일 초안 작성\"과 같은 특정 지시를 제공하면, InstructGPT는 관련 내용을 기반으로 이메일을 작성합니다.\\n연관키워드: 인공지능, 자연어 이해, 명령 기반 처리\\n\\nKeyword Search')]\n",
    "\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a927ac",
   "metadata": {},
   "source": [
    "* 특정 임계값 이상의 유사도를 가진 문서만 검색해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67cd062",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db.as_retriever(\n",
    "    search_type=\"similarity_score_threshold\",               # 검색 유형 설정하기\n",
    "    search_kwargs={\"score_threshold\": 0.8}                  # 유사도 임계값 설정하기\n",
    ")\n",
    "\n",
    "# 출력해보기\n",
    "retriever.invoke(\"Word2Vec 에 대하여 알려줘\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b76800c",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 셀 출력 (특정 임계값 이상의 `유사도`를 가진 문서만 검색)\n",
    "\n",
    "    ```python\n",
    "\n",
    "    [Document(id='9174a219-9bba-41d6-a08c-9c2fe712d441', metadata={'source': '../09_VectorStore/data/nlp-keywords.txt'}, page_content='정의: Word2Vec은 단어를 벡터 공간에 매핑하여 단어 간의 의미적 관계를 나타내는 자연어 처리 기술입니다. 이는 단어의 문맥적 유사성을 기반으로 벡터를 생성합니다.\\n예시: Word2Vec 모델에서 \"왕\"과 \"여왕\"은 서로 가까운 위치에 벡터로 표현됩니다.\\n연관키워드: 자연어 처리, 임베딩, 의미론적 유사성\\nLLM (Large Language Model)\\n\\n정의: LLM은 대규모의 텍스트 데이터로 훈련된 큰 규모의 언어 모델을 의미합니다. 이러한 모델은 다양한 자연어 이해 및 생성 작업에 사용됩니다.\\n예시: OpenAI의 GPT 시리즈는 대표적인 대규모 언어 모델입니다.\\n연관키워드: 자연어 처리, 딥러닝, 텍스트 생성\\n\\nFAISS (Facebook AI Similarity Search)\\n\\n정의: FAISS는 페이스북에서 개발한 고속 유사성 검색 라이브러리로, 특히 대규모 벡터 집합에서 유사 벡터를 효과적으로 검색할 수 있도록 설계되었습니다.\\n예시: 수백만 개의 이미지 벡터 중에서 비슷한 이미지를 빠르게 찾는 데 FAISS가 사용될 수 있습니다.\\n연관키워드: 벡터 검색, 머신러닝, 데이터베이스 최적화\\n\\nOpen Source')]\n",
    "\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48cd547d",
   "metadata": {},
   "source": [
    "* 가장 유시한 단일 문서만 검색해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb35eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db.as_retriever(search_kwargs={\"k\": 1})         # 유사도가 높은 문서 1개만 반환하기\n",
    "\n",
    "retriever.invoke(\"Word2Vec 에 대하여 알려줘\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d064fe",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 셀 출력\n",
    "\n",
    "    ```python\n",
    "\n",
    "    [Document(id='9174a219-9bba-41d6-a08c-9c2fe712d441', metadata={'source': '../09_VectorStore/data/nlp-keywords.txt'}, page_content='정의: Word2Vec은 단어를 벡터 공간에 매핑하여 단어 간의 의미적 관계를 나타내는 자연어 처리 기술입니다. 이는 단어의 문맥적 유사성을 기반으로 벡터를 생성합니다.\\n예시: Word2Vec 모델에서 \"왕\"과 \"여왕\"은 서로 가까운 위치에 벡터로 표현됩니다.\\n연관키워드: 자연어 처리, 임베딩, 의미론적 유사성\\nLLM (Large Language Model)\\n\\n정의: LLM은 대규모의 텍스트 데이터로 훈련된 큰 규모의 언어 모델을 의미합니다. 이러한 모델은 다양한 자연어 이해 및 생성 작업에 사용됩니다.\\n예시: OpenAI의 GPT 시리즈는 대표적인 대규모 언어 모델입니다.\\n연관키워드: 자연어 처리, 딥러닝, 텍스트 생성\\n\\nFAISS (Facebook AI Similarity Search)\\n\\n정의: FAISS는 페이스북에서 개발한 고속 유사성 검색 라이브러리로, 특히 대규모 벡터 집합에서 유사 벡터를 효과적으로 검색할 수 있도록 설계되었습니다.\\n예시: 수백만 개의 이미지 벡터 중에서 비슷한 이미지를 빠르게 찾는 데 FAISS가 사용될 수 있습니다.\\n연관키워드: 벡터 검색, 머신러닝, 데이터베이스 최적화\\n\\nOpen Source')]\n",
    "\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba75c133",
   "metadata": {},
   "source": [
    "* 특정 메타데이터 필터 적용해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b12b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db.as_retriever(\n",
    "    search_kwargs={\n",
    "        \"filter\": {\"source\": \"../09_VectorStore/data/finance-keywords.txt\"}, \n",
    "        \"k\": 2}\n",
    ")\n",
    "\n",
    "retriever.invoke(\"ESG 에 대하여 알려줘\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d3672c",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 셀 출력\n",
    "\n",
    "    ```python\n",
    "\n",
    "    [Document(id='135ddd04-f01c-4374-8888-aef61c932bad', metadata={'source': '../09_VectorStore/data/finance-keywords.txt'}, page_content='정의: ESG는 기업의 환경, 사회, 지배구조 측면을 고려하는 투자 접근 방식입니다.\\n예시: S&P 500 ESG 지수는 우수한 ESG 성과를 보이는 기업들로 구성된 지수입니다.\\n연관키워드: 지속가능 투자, 기업의 사회적 책임, 윤리 경영\\n\\nStock Buyback\\n\\n정의: 자사주 매입은 기업이 자사의 주식을 시장에서 다시 사들이는 것을 말합니다.\\n예시: 애플은 S&P 500 기업 중 가장 큰 규모의 자사주 매입 프로그램을 운영하고 있습니다.\\n연관키워드: 주주 가치, 자본 관리, 주가 부양\\n\\nCyclical Stocks\\n\\n정의: 경기순환주는 경제 상황에 따라 실적이 크게 변동하는 기업의 주식을 말합니다.\\n예시: 포드, 제너럴 모터스와 같은 자동차 기업들은 S&P 500에 포함된 대표적인 경기순환주입니다.\\n연관키워드: 경제 사이클, 섹터 분석, 투자 타이밍\\n\\nDefensive Stocks\\n\\n정의: 방어주는 경기 변동에 상관없이 안정적인 실적을 보이는 기업의 주식을 의미합니다.\\n예시: 프록터앤갬블, 존슨앤존슨과 같은 생활필수품 기업들은 S&P 500 내 대표적인 방어주로 꼽힙니다.\\n연관키워드: 안정적 수익, 저변동성, 리스크 관리'),\n",
    "    Document(id='cca43bd4-0754-426c-97d9-d16c02e8ffce', metadata={'source': '../09_VectorStore/data/finance-keywords.txt'}, page_content='정의: 주식 리서치는 기업의 재무 상태, 사업 모델, 경쟁력 등을 분석하여 투자 의사 결정을 돕는 활동입니다.\\n예시: 골드만삭스의 애널리스트들이 S&P 500 기업들에 대한 분기별 실적 전망을 발표했습니다.\\n연관키워드: 투자 분석, 기업 가치평가, 시장 전망\\n\\nCorporate Governance\\n\\n정의: 기업 지배구조는 기업의 경영과 통제에 관한 시스템과 프로세스를 의미합니다.\\n예시: S&P 500 기업들 중 이사회의 다양성을 높이는 기업들이 증가하고 있습니다.\\n연관키워드: 주주 권리, ESG, 기업 윤리\\n\\nMergers and Acquisitions (M&A)\\n\\n정의: 인수합병은 기업들이 다른 기업을 사거나 합치는 과정을 말합니다.\\n예시: 마이크로소프트가 액티비전 블리자드를 인수하면서 S&P 500 내 게임 산업의 판도가 변화했습니다.\\n연관키워드: 기업 전략, 시너지 효과, 기업 가치\\n\\nESG (Environmental, Social, and Governance)')]\n",
    "\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe4a46b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9480ef",
   "metadata": {},
   "source": [
    "* *next: **`멀티모달 이용해보기`***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c888d3dc",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lc_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
