{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c6c0226",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e416518f",
   "metadata": {},
   "source": [
    "* 출처: LangChain 공식 문서 또는 해당 교재명\n",
    "* 원본 URL: https://smith.langchain.com/hub/teddynote/summary-stuff-documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6793a387",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a8e3a7",
   "metadata": {},
   "source": [
    "## **직렬화(`Serialization`)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f17f9d9",
   "metadata": {},
   "source": [
    "### **`직렬화`란?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44531b6d",
   "metadata": {},
   "source": [
    "#### **정의**\n",
    "\n",
    "* 모델을 `저장 가능한 형식`으로 `변환`하는 과정\n",
    "\n",
    "* 모델 직렬화\n",
    "  * `AI 개발` 및 `배포 과정`에서 `중요한 단계`\n",
    "  * `효율적인 모델 관리`와 `재사용`을 가능하게 함\n",
    "\n",
    "#### **목적**\n",
    "\n",
    "* 모델 **재사용** (재훈련 없이)\n",
    "* 모델 **배포 및 공유 용이**\n",
    "* **계산 리소스 절약**\n",
    "\n",
    "#### **장점**\n",
    "\n",
    "* **`빠른` 모델 로딩**\n",
    "* **`버전 관리` 가능**\n",
    "* **`다양한 환경`에서 사용 가능**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8670efd",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3527b3",
   "metadata": {},
   "source": [
    "* `is_lc_serializable 클래스 메서드` → **`LangChain` 클래스가 직렬화 가능한지 확인**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be4975fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 환경변수 처리 및 클라어트 생성\n",
    "from langsmith import Client\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "import os\n",
    "import json\n",
    "\n",
    "# 클라이언트 생성 \n",
    "api_key = os.getenv(\"LANGSMITH_API_KEY\")\n",
    "client = Client(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1815f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangSmith 추적 설정하기 (https:smith.langchin.com)\n",
    "# LangSmith 추적을 위한 라이브러리 임포트\n",
    "from langsmith import traceable                                                             # @traceable 데코레이터 사용 시\n",
    "\n",
    "# LangSmith 환경 변수 확인\n",
    "\n",
    "print(\"\\n--- LangSmith 환경 변수 확인 ---\")\n",
    "langchain_tracing_v2 = os.getenv('LANGCHAIN_TRACING_V2')\n",
    "langchain_project = os.getenv('LANGCHAIN_PROJECT')\n",
    "langchain_api_key_status = \"설정됨\" if os.getenv('LANGCHAIN_API_KEY') else \"설정되지 않음\"      # API 키 값은 직접 출력하지 않음\n",
    "org = \"설정됨\" if os.getenv('LANGCHAIN_ORGANIZATION') else \"설정되지 않음\"                     # 직접 출력하지 않음\n",
    "\n",
    "if langchain_tracing_v2 == \"true\" and os.getenv('LANGCHAIN_API_KEY') and langchain_project:\n",
    "    print(f\"✅ LangSmith 추적 활성화됨 (LANGCHAIN_TRACING_V2='{langchain_tracing_v2}')\")\n",
    "    print(f\"✅ LangSmith 프로젝트: '{langchain_project}'\")\n",
    "    print(f\"✅ LangSmith API Key: {langchain_api_key_status}\")\n",
    "    print(\"  -> 이제 LangSmith 대시보드에서 이 프로젝트를 확인해 보세요.\")\n",
    "else:\n",
    "    print(\"❌ LangSmith 추적이 완전히 활성화되지 않았습니다. 다음을 확인하세요:\")\n",
    "    if langchain_tracing_v2 != \"true\":\n",
    "        print(f\"  - LANGCHAIN_TRACING_V2가 'true'로 설정되어 있지 않습니다 (현재: '{langchain_tracing_v2}').\")\n",
    "    if not os.getenv('LANGCHAIN_API_KEY'):\n",
    "        print(\"  - LANGCHAIN_API_KEY가 설정되어 있지 않습니다.\")\n",
    "    if not langchain_project:\n",
    "        print(\"  - LANGCHAIN_PROJECT가 설정되어 있지 않습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb5b9e0",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 셀 출력\n",
    "\n",
    "    ```markdown\n",
    "    --- LangSmith 환경 변수 확인 ---\n",
    "    ✅ LangSmith 추적 활성화됨 (LANGCHAIN_TRACING_V2='true')\n",
    "    ✅ LangSmith 프로젝트: 'LangChain-prantice'\n",
    "    ✅ LangSmith API Key: 설정됨\n",
    "    -> 이제 LangSmith 대시보드에서 이 프로젝트를 확인해 보세요.\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49cf2c22",
   "metadata": {},
   "source": [
    "* **`모델` 생성**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f37855f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM 초기화\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "gemini_lc = ChatGoogleGenerativeAI(\n",
    "        model=\"gemini-2.5-flash-lite\",\n",
    "        #temperature=0.7,                                    \n",
    "        max_output_tokens=4096,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aca90b1",
   "metadata": {},
   "source": [
    "* **`프롬프트` 생성**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "393a3e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 프롬프트 생성\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"{fruit}의 색상이 무엇입니까?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f0ef0e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ddd72df",
   "metadata": {},
   "source": [
    "* **`클래스(class)` 직렬화 가능 여부 확인하기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f72987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 직렬화 가능한지 체크하기\n",
    "\n",
    "print(f\"ChatGoogleGenerativeAI: {ChatGoogleGenerativeAI.is_lc_serializable()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a27a1c",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 셀 출력\n",
    "\n",
    "    ```markdown\n",
    "    ChatGoogleGenerativeAI: True\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c24e8b",
   "metadata": {},
   "source": [
    "* **`LLM 객체` 직렬화 가능 여부 확인하기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc937cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 교재와 동일하게 온도를 0으로 맞춰 초기화하기\n",
    "\n",
    "gemini_lc = ChatGoogleGenerativeAI(\n",
    "        model=\"gemini-2.5-flash-lite\",\n",
    "        temperature=0,                          # 교재와 동일한 조건        \n",
    "        max_output_tokens=4096,\n",
    "    )\n",
    "\n",
    "# 직렬화 가능 여부 체크하기\n",
    "print(f\"ChatGoogleGenerativeAI:{gemini_lc.is_lc_serializable()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21773655",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 셀 출력\n",
    "\n",
    "    ```markdown\n",
    "    ChatGoogleGenerativeAI:True\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79e4570",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189da509",
   "metadata": {},
   "source": [
    "* **`체인` 생성**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45ea9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 체인 생성\n",
    "chain = prompt | gemini_lc\n",
    "\n",
    "# 직렬화 가능 여부 체크하기\n",
    "chain.is_lc_serializable()                      # True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb35a4d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a91324",
   "metadata": {},
   "source": [
    "### **체인(`Chain`) 직렬화(`dumps`, `dumpd`)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e02c94",
   "metadata": {},
   "source": [
    "#### **개요**\n",
    "\n",
    "* 체인 직렬화: `직렬화 가능한 모든 객체`를 **`딕셔너리`** 또는 **`JSON 문자열`** 로 변환하는 과정을 의미"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7da297",
   "metadata": {},
   "source": [
    "#### **직렬화 방법**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d062f1",
   "metadata": {},
   "source": [
    "* 객체의 속성 및 데이터를 `키-값 쌍`으로 저장하여 `딕셔너리 형태`로 변환\n",
    "\n",
    "  * 객체를 `쉽게 저장`하고 `전송`할 수 있게 함\n",
    "  * `다양한 환경`에서 `객체`를 `재구성 가능`\n",
    "\n",
    "<br>\n",
    "\n",
    "* 참고\n",
    "\n",
    "  * **`dumps`**: 객체를 `JSON 문자열`로 직렬화\n",
    "  * **`dumpd`**: 객체를 `딕셔너리`로 직렬화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025b3d8b",
   "metadata": {},
   "source": [
    "#### **1) `dumpd` 사용해서 직렬화하기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9edad396",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.load import dumpd, dumps\n",
    "\n",
    "dumpd_chain = dumpd(chain)\n",
    "dumpd_chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34e3a52",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 셀 출력\n",
    "\n",
    "    ```python\n",
    "    {'lc': 1,\n",
    "    'type': 'constructor',\n",
    "    'id': ['langchain', 'schema', 'runnable', 'RunnableSequence'],\n",
    "    'kwargs': {'first': {'lc': 1,\n",
    "    'type': 'constructor',\n",
    "    'id': ['langchain', 'prompts', 'prompt', 'PromptTemplate'],\n",
    "    'kwargs': {'input_variables': ['fruit'],\n",
    "        'template': '{fruit}의 색상이 무엇입니까?',\n",
    "        'template_format': 'f-string'},\n",
    "    'name': 'PromptTemplate'},\n",
    "    'last': {'lc': 1,\n",
    "    'type': 'constructor',\n",
    "    'id': ['langchain_google_genai', 'chat_models', 'ChatGoogleGenerativeAI'],\n",
    "    'kwargs': {'model': 'models/gemini-2.5-flash-lite',\n",
    "        'google_api_key': {'lc': 1, 'type': 'secret', 'id': ['GOOGLE_API_KEY']},\n",
    "        'temperature': 0.0,\n",
    "        'max_output_tokens': 4096,\n",
    "        'n': 1,\n",
    "        'max_retries': 6,\n",
    "        'default_metadata': []},\n",
    "    'name': 'ChatGoogleGenerativeAI'}},\n",
    "    'name': 'RunnableSequence'}\n",
    "    111"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be67a8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 직렬화된 체인 타입 확인하기\n",
    "\n",
    "type(dumpd_chain)                       # dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f4b9ec",
   "metadata": {},
   "source": [
    "#### **2) `dumps` 사용해서 직렬화하기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c2cee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dumps 함수를 사용 → 직렬화된 체인 확인해보기\n",
    "\n",
    "dumps_chain = dumps(chain)\n",
    "\n",
    "dumps_chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed6b7aa",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 셀 출력\n",
    "\n",
    "    ```json\n",
    "    '{\"lc\": 1, \"type\": \"constructor\", \"id\": [\"langchain\", \"schema\", \"runnable\", \"RunnableSequence\"], \"kwargs\": {\"first\": {\"lc\": 1, \"type\": \"constructor\", \"id\": [\"langchain\", \"prompts\", \"prompt\", \"PromptTemplate\"], \"kwargs\": {\"input_variables\": [\"fruit\"], \"template\": \"{fruit}\\\\uc758 \\\\uc0c9\\\\uc0c1\\\\uc774 \\\\ubb34\\\\uc5c7\\\\uc785\\\\ub2c8\\\\uae4c?\", \"template_format\": \"f-string\"}, \"name\": \"PromptTemplate\"}, \"last\": {\"lc\": 1, \"type\": \"constructor\", \"id\": [\"langchain_google_genai\", \"chat_models\", \"ChatGoogleGenerativeAI\"], \"kwargs\": {\"model\": \"models/gemini-2.5-flash-lite\", \"google_api_key\": {\"lc\": 1, \"type\": \"secret\", \"id\": [\"GOOGLE_API_KEY\"]}, \"temperature\": 0.0, \"max_output_tokens\": 4096, \"n\": 1, \"max_retries\": 6, \"default_metadata\": []}, \"name\": \"ChatGoogleGenerativeAI\"}}, \"name\": \"RunnableSequence\"}'\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 직렬화된 체인의 타입 확인하기\n",
    "\n",
    "type(dumps_chain)                           # str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40fe25b4",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06255d09",
   "metadata": {},
   "source": [
    "### **`Pickle` 파일**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe5c055",
   "metadata": {},
   "source": [
    "#### **개요**\n",
    "\n",
    "* `Pickle` 파일 = `Python 객체`를 `바이너리 형태`로 `직렬화`하는 `포맷`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b7813c",
   "metadata": {},
   "source": [
    "#### **특징**\n",
    "\n",
    "* **개요**\n",
    "  * Python 객체를 바이너리 형태로 직렬화하는 포맷\n",
    "  * `효율적인 모델 관리`와 `재사용`을 가능하게 함\n",
    "\n",
    "    ---\n",
    "\n",
    "* 특징\n",
    "\n",
    "  * **`Python 전용`** (다른 언어와 호환 불가)\n",
    "  * 대부분의 `Python 데이터 타입` 지원 (`리스트`, `딕셔너리`, `클래스` 등)\n",
    "  * `객체의 상태`와 `구조`를 그대로 보존\n",
    "\n",
    "    ---\n",
    "\n",
    "* 장점\n",
    "\n",
    "  * `효율적`인 `저장` 및 `전송`\n",
    "  * `복잡한 객체 구조 유지`\n",
    "  * **빠른 `직렬화/역직렬화` 속도**\n",
    "\n",
    "    ---\n",
    "\n",
    "* 단점\n",
    "\n",
    "  * **보안 위험** (`신뢰할 수 없는 데이터 역직렬화 시 주의 필요`)\n",
    "  * **사람이 읽을 수 없는 `바이너리 형식`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad773ab7",
   "metadata": {},
   "source": [
    "#### **주요 용도**\n",
    "\n",
    "* 객체 `캐싱`\n",
    "* 머신러닝 `모델 저장`\n",
    "* 프로그램 `상태 저장` 및 `복원`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61360533",
   "metadata": {},
   "source": [
    "#### **사용법**\n",
    "\n",
    "* **`pickle.dump()`**: 객체를 `파일`에 `저장`\n",
    "\n",
    "* **`pickle.load()`**: `파일`에서 `객체` `로드`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51190b9b",
   "metadata": {},
   "source": [
    "#### **1) `Pickle` 파일로 저장하기**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b69c11",
   "metadata": {},
   "source": [
    "* `Pickle` 파일로 저장하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fff2016",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# fuit_chain.pkl 파일로 직렬화된 체인 저장하기\n",
    "with open(\"fruit_chain.pkl\", \"wb\") as f:\n",
    "    pickle.dump(dumpd_chain, f)                             # 04_Model/fruit_chain.pkl 생성됨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119c5d38",
   "metadata": {},
   "source": [
    "* `JSON` 형식으로도 저장해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db78b39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"fruit_chain.json\", \"w\") as fp:\n",
    "    json.dump(dumpd_chain, fp)\n",
    "                                                            # 04_Model/fruit_chain.json 셍성됨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41765e6a",
   "metadata": {},
   "source": [
    "#### **2) `load`: 저장한 모델 불러오기**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e40224",
   "metadata": {},
   "source": [
    "* 먼저, 이전에 저장한 `pickle` 형식 파일 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e266f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# pickle 파일 로드\n",
    "with open(\"fruit_chain.pkl\", \"rb\") as f:\n",
    "    loaded_chain = pickle.load(f)                           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa4cb98",
   "metadata": {},
   "source": [
    "* 로드한 `JSON`파일을 `load`메서드로 로드하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3a6ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.load import load\n",
    "\n",
    "# 체인 로드하기\n",
    "chain_from_file = load(loaded_chain)\n",
    "\n",
    "# 체인 실행하기\n",
    "print(chain_from_file.invoke({\"fruit\": \"사과\"})) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a903d769",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 셀 출력 (1.1s)\n",
    "\n",
    "    ```markdown\n",
    "    /var/folders/h3/l7wnkv352kqftv0t8ctl2ld40000gn/T/ipykernel_3877/1712892737.py:4: LangChainBetaWarning: The function `load` is in beta. It is actively being worked on, so the API may change.\n",
    "    ```\n",
    "\n",
    "    ```python\n",
    "    chain_from_file = load(loaded_chain)\n",
    "    ```\n",
    "\n",
    "    ```python\n",
    "    content='사과는 일반적으로 **빨간색**입니다.\\n\\n하지만 사과의 품종에 따라 **초록색**, **노란색**, 또는 이 색들이 섞인 **붉은색과 초록색이 섞인 색** 등 다양한 색깔을 띨 수 있습니다.' additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash-lite', 'safety_ratings': []} id='run--5a09635a-b028-4167-abbb-831462ada1f1-0' usage_metadata={'input_tokens': 9, 'output_tokens': 61, 'total_tokens': 70, 'input_token_details': {'cache_read': 0}}\n",
    "    ```\n",
    "\n",
    "<br>\n",
    "\n",
    "  ---\n",
    "\n",
    "<br>\n",
    "\n",
    "* 셀 출력 해석하기\n",
    "\n",
    "  * ➀ 경고 메시지\n",
    "  \n",
    "    * `a. 경고 메시지_1`\n",
    "  \n",
    "      ```markdown\n",
    "      /var/folders/h3/l7wnkv352kqftv0t8ctl2ld40000gn/T/ipykernel_3877/1712892737.py:4: LangChainBetaWarning: \n",
    "      ```\n",
    "    \n",
    "    * `LangChainBetaWarning`은 **현재 사용 중인 load 함수가 베타 버전이라, API(인터페이스)가 변경될 수 있다** 는 의미\n",
    "    * 즉, 이 기능은 아직 개발 중이라는 뜻 → 그래서 나중에 바뀔 수도 있다는 경고 출력한 것임\n",
    "\n",
    "    * `b. 경고 메시지_2`\n",
    "  \n",
    "      ```markdown\n",
    "        The function `load` is in beta. It is actively being worked on, so the API may change.\n",
    "      ```\n",
    "\n",
    "    * 아까 설명한 경고 메시지의 자세한 내용\n",
    "    * **현재 load 함수는 베타(시험) 버전이기 때문에, 계속해서 작업이 이루어지고 있고, 나중에 함수 사용법이나 결과가 바뀔 수 있다**\n",
    "\n",
    "    <br>\n",
    "\n",
    "    ---\n",
    "\n",
    "    <br>\n",
    "\n",
    "  * ➁ `load` 함수 호출 = `loaded_chain 객체 로드\n",
    "  \n",
    "    ```python\n",
    "    chain_from_file = load(loaded_chain)\n",
    "    ```\n",
    "\n",
    "    * 실제로 코드에서 `load 함수`를 호출해서 `loaded_chain 객체`를 `로드`하는 부분\n",
    "    * `chain_from_file` 변수 = `load 함수가 반환하는 값`을 `저장`하는 역할\n",
    "\n",
    "    <br>\n",
    "\n",
    "    ---\n",
    "\n",
    "    <br>\n",
    "\n",
    "  * ➂ `content` 내용\n",
    "  \n",
    "    * `a. chain_from_file.invoke()를 실행했을 때 얻은 결과`\n",
    "\n",
    "      ```python\n",
    "      content='사과는 일반적으로 **빨간색**입니다.\\n\\n하지만 사과의 품종에 따라 **초록색**, **노란색**, 또는 이 색들이 섞인 **붉은색과 초록색이 섞인 색** 등 다양한 색깔을 띨 수 있습니다.'\n",
    "      ```\n",
    "\n",
    "      * `content` = `invoke 함수`가 **입력한 데이터** (여기서는 `\"fruit\": \"사과\"`)에 대해 **답을 만들어낸 결과** 에 해당\n",
    "      * 사과에 대한 설명\n",
    "        * 사과의 `색깔`에 대해 설명하고 있음 \n",
    "        * **`사과는 일반적으로 빨간색이지만, 품종에 따라 초록색, 노란색, 혹은 빨간색과 초록색이 섞인 색 등이 있다`**\n",
    "\n",
    "    * `b. 추가적인 매개변수 여부`\n",
    "\n",
    "      ```python\n",
    "      additional_kwargs={}\n",
    "      ```\n",
    "      \n",
    "      * `additional_kwargs` = **비어있음** = **추가적인 매개변수(인자들)가 없음**\n",
    "      * 특별히 추가된 옵션 없이 `기본적인 결과만 받았음`\n",
    "\n",
    "    * `c. 응답 데이터 부분`\n",
    "\n",
    "      ```python\n",
    "      response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash-lite', 'safety_ratings': []}\n",
    "      ```\n",
    "      \n",
    "      * `finish_reason: 'STOP'` = **모델이 답을 완료함** = 모델이 더 이상 응답할 필요가 없다고 판단\n",
    "      * `model_name: 'gemini-2.5-flash-lite'` = **사용된 모델 이름**\n",
    "      * `safety_ratings: []` = **비어있음** = 안전성 평가 결과가 없음 = `안전성에 관한 별도의 평가가 없다는 의미`\n",
    "      * `prompt_feedback: {'block_reason': 0, 'safety_ratings': []}` = **프롬프트(질문)에 대한 피드백**\n",
    "        * `block_reason: 0` = **아무 문제 없이 정상적으로 처리되었음**\n",
    "\n",
    "    * `d. 실행된 모델의 고유 ID`\n",
    "\n",
    "      ```python\n",
    "      id='run--5a09635a-b028-4167-abbb-831462ada1f1-0'\n",
    "      ```\n",
    "      \n",
    "      * **모델이 실행된 고유한 ID**\n",
    "      * 여러 번 실행했을 때, 각 실행을 `구별할 수 있도록` 도와줌\n",
    "\n",
    "    * `e. 사용량 메타데이터` \n",
    "\n",
    "      ```python\n",
    "      usage_metadata={'input_tokens': 9, 'output_tokens': 61, 'total_tokens': 70, 'input_token_details': {'cache_read': 0}}\n",
    "      ```\n",
    "      \n",
    "      * `input_tokens: 9` = **입력한 데이터(여기서는 `\"fruit\": \"사과\"`)에 사용된 토큰의 수**\n",
    "      * `output_tokens: 61` = **모델이 생성한 답변에서 사용된 토큰의 수**\n",
    "      * `total_tokens: 70` = **입력과 출력 토큰을 합친 총 토큰 수** = `9+61`\n",
    "      * `input_token_details: {'cache_read': 0}` = **캐시에서 읽어온 데이터가 없음**\n",
    "        * 즉, 이 데이터는 `이전에 저장된 데이터를 사용하지 않고` **`새로 계산한 결과라는 의미`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284f2df0",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929412cb",
   "metadata": {},
   "source": [
    "* **`Q. load 함수가 불안정하다면` 대신 사용할 수 있는 방법은?**\n",
    "\n",
    "  * `langchain` 라이브러이에서 제공하는 다른 방법 사용하기\n",
    "  * `langchain` 라이브러리 최신 버전으로 업데이트하며 사용하기\n",
    "\n",
    "    ```python\n",
    "\n",
    "       # bash\n",
    "       pip install --upgrade langchain\n",
    "    \n",
    "    ```\n",
    "\n",
    "  * 업데이트 후 테스트 후 사용 or **에외 처리** 추가하여 사용하기\n",
    "\n",
    "    ```python\n",
    "\n",
    "        # 예외처리 예시\n",
    "\n",
    "        try:\n",
    "            chain_from_file = load(loaded_chain)\n",
    "            result = chain_from_file.invoke({\"fruit\": \"사과\"})\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"오류 발생:\", e)\n",
    "            # 오류 발생 시 다른 방식으로 처리\n",
    "            result = \"기본 결과\"\n",
    "            \n",
    "        print(result)\n",
    "\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e884ea",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd45cd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.load import load, loads\n",
    "\n",
    "load_chain = load(\n",
    "    loaded_chain, secrets_map={\"GOOGLE_API_KEY\": os.environ[\"GOOGLE_API_KEY\"]}\n",
    ")\n",
    "\n",
    "# 불러온 체인이 정상 동작하는지 확인하기\n",
    "load_chain.invoke({\"fruit\": \"사과\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a24aa1",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 셀 출력 (1.0s)\n",
    "\n",
    "    ```python\n",
    "    AIMessage(content='사과는 일반적으로 **빨간색**입니다.\\n\\n하지만 사과의 품종에 따라 **초록색**, **노란색**, 또는 이 색들이 섞인 **붉은색과 초록색이 섞인 색** 등 다양한 색깔을 띨 수 있습니다.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash-lite', 'safety_ratings': []}, id='run--2b727704-2ef6-4351-bbb1-9ab22e4c3247-0', usage_metadata={'input_tokens': 9, 'output_tokens': 61, 'total_tokens': 70, 'input_token_details': {'cache_read': 0}})\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f182ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# json 파일로드\n",
    "with open(\"fruit_chain.json\", \"r\") as fp:\n",
    "    loaded_from_json_chain = json.load(fp)\n",
    "    loads_chain = load(loaded_from_json_chain)\n",
    "    \n",
    "# 불러온 체인이 정상 동작하는지 확인하기\n",
    "loads_chain.invoke({\"fruit\": \"사과\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f42dd68",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "* 셀 출력 (0.9s)\n",
    "\n",
    "    ```python\n",
    "    AIMessage(content='사과는 일반적으로 **빨간색**입니다.\\n\\n하지만 사과의 품종에 따라 **초록색**, **노란색**, 또는 이 색들이 섞인 **붉은색과 초록색이 섞인 색** 등 다양한 색깔을 띨 수 있습니다.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash-lite', 'safety_ratings': []}, id='run--d27c9e1c-b3f1-4561-b844-9425bcb6824e-0', usage_metadata={'input_tokens': 9, 'output_tokens': 61, 'total_tokens': 70, 'input_token_details': {'cache_read': 0}})\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8c40e8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b977bea",
   "metadata": {},
   "source": [
    "* *next: 토큰 사용량 확인*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e54114",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lc_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
